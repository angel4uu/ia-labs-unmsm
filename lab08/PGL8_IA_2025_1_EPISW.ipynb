{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GnUElm5_e8m"
   },
   "source": [
    "# Práctica de Laboratorio 8 - Inteligencia Artificial 2025-1 Sección 1 EPISW-FISI\n",
    "## Implementación de una red PMC-BP con Python y Numpy\n",
    "### Prof. Rolando A. Maguiña Pérez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ky22d26K_e8n"
   },
   "source": [
    "## Introducción\n",
    "La Práctica Guiada de Laboratorio (PGL) 8 a realizarse el Jueves 05 de Junio del presente año, tratará sobre la red Perceptrón Multicapa con su algoritmo de aprendizaje llamado Backpropagation. Esta red se aplicará para resolver problemas genéricos de clasificación y de regresión.\n",
    "\n",
    "Se desea abordar el problema de la aproximación de una función mediante una Perceptrón Multicapa-Backpropagation (PMC-BP). Inicialmente se presenta la implementación del algoritmo de entrenamiento de esta red (presentado en las sesiones de teoría), con el lenguaje `Python` y sus bibliotecas `Numpy` y `Matplotlib`. Posteriormente, **se propondrán algunos ejercicios cuyas soluciones se podrán obtener en grupos de hasta 4 alumnos**, y deberán enviarse para su respectiva revisión (ver sección 'Instrucciones para el envío' en este mismo cuaderno).  \n",
    "\n",
    "Requiere: numpy, matplotlib\n",
    "\n",
    "Nomenclatura:\n",
    "- Z: número de instancias (muestras) en el conjunto de datos\n",
    "- N: número de atributos o variables de entrada\n",
    "- M: número de atributos o variables de salida\n",
    "- t: vector de salidas esperadas o targets\n",
    "- y: vector de salidas estimadas por la red.\n",
    "\n",
    "### Paso previo\n",
    "Importamos las bibliotecas de Python requeridas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5r_BRXlK_e8n"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.11' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKy9zmzb_e8p"
   },
   "source": [
    "## Dataset\n",
    "El primer paso consiste en obtener el arreglo conteniendo los pares entrada-salida (instancias) a usar en el entrenamiento/validación de la red PMC-BP a implementar; dicho arreglo se denominará 'Dataset'. El tamaño de dicho arreglo es de $Z \\times d$, donde $Z$ es el número de instancias (muestras) y $d$ es el número de características o atributos considerados para el problema abordado (incluye los atributos de entrada y los de salida)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHAeppdW_e8q",
    "outputId": "be4a459f-13d9-425f-bd6d-6e0cbbe7d8cd"
   },
   "outputs": [],
   "source": [
    "Dataset = np.array([[0.00000, 0.00000], [1.00000, 0.84000], [2.00000, 0.91000], [3.00000, 0.14000],\n",
    "[4.00000, -0.77000], [5.00000, -0.96000],[6.00000, -0.28000], [7.00000, 0.66000], [8.00000, 0.99000]])\n",
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PQUmblTn_e8q",
    "outputId": "339662ed-f65c-4cb2-d5ba-a944a8775d4b"
   },
   "outputs": [],
   "source": [
    "Dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xJFV52G_e8q"
   },
   "source": [
    "## Data para el entrenamiento/validación de la red\n",
    "Como sabemos, a partir del dataset obtenido, se deben determinar los conjuntos de datos a emplear en el entrenamiento y en la validación de la red PMC-BP. Enseguida, se deben obtener dos arreglos: uno con los vectores de entrada a usar en el entrenamiento, y el segundo, con los respectivos vectores de salida. Análogamente, se deben determinar los arreglos con los vectores de entrada y de salida, a usar en la validación del entrenamiento. **Sin embargo, para el problema planteado, el dataset se usará tanto para el entrenamiento como para la validación**.\n",
    "\n",
    "Separando los valores de entrada de los de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hr48ISV7_e8q",
    "outputId": "649fd8d4-c634-4166-8853-9208bad639a8"
   },
   "outputs": [],
   "source": [
    "X = Dataset[:,0]\n",
    "t = Dataset[:,1]\n",
    "X, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L0tmqcxX_e8r",
    "outputId": "c5dd6b48-055e-4a0e-a4b4-5ba76e3800f1"
   },
   "outputs": [],
   "source": [
    "X.shape, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sxiXCKVT_e8r",
    "outputId": "dc3bdc08-c4cd-47c4-a353-61323d72eba7"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot(X,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQJsVNIL_e8r"
   },
   "source": [
    "## Normalización de los datos\n",
    "Antes de iniciar algún cálculo, sabemos que debemos tener en cuenta las diferencias que existen en las unidades de nuestros datos. Se requiere que los datos de nuestras variables estén en el mismo orden de magnitud, y en un buen número de casos es necesario normalizarlos; de esta manera nuestro modelo trabajará con unidades normalizadas. A pesar de lo indicado, incluso sabedores que hay varios procedimientos de normalización, en este caso, **no vamos a normalizar inicialmente nuestros datos**.\n",
    "\n",
    "## Diseño de la red\n",
    "Inicialmente se considera una topología de la red como la mostrada en la figura, vale decir, con 10 neuronas ocultas. Como función de activación de las neuronas ocultas se usará la logística sigmoidea y en las neuronas de salida, dado que se trata de un problema de aproximación de funciones, se usará una función lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WGsNXQEa_e8r",
    "outputId": "855b611b-4ff4-4ed2-bdaa-cf13deb780df"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "i = Image(filename='D:\\\\Cursos\\\\Redes Neuronales\\\\2021-2\\\\arquit-red_aprox-fc_2021-2.png')\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkStZNAt_e8s"
   },
   "source": [
    "## Inicialización de los pesos y biases de la red\n",
    "Según el algoritmo, los parámetros libres de la red se inicializan a valores aleatorios pequeños, los cuales pueden estar en el rangos: [-0.5,0.5] o [-1,1] o en torno de cero. A continuación se presenta el código para inicializarlos, aplicado al **problema planteado**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVovH8l6_e8s"
   },
   "outputs": [],
   "source": [
    "# Implementación básica sin funciones\n",
    "intervalo = 0.5\n",
    "capa_entrada = 1\n",
    "capa_oculta = 10\n",
    "capa_salida = 1\n",
    "\n",
    "w1 = np.random.uniform(-intervalo, intervalo, capa_oculta)\n",
    "\n",
    "w2 = np.random.uniform(-intervalo, intervalo, capa_oculta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZ0RMbRe_e8s",
    "outputId": "f683c42b-d53b-4b2e-ea4a-14907601f2eb"
   },
   "outputs": [],
   "source": [
    "w1, w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmCcNM_d_e8s",
    "outputId": "9d457a8a-6bf1-4af0-b0c6-588ff5716fa7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBsY50rR_e8t"
   },
   "source": [
    "### Definición de la función logística sigmoidea\n",
    "Sabemos que la expresión matemática de la función logística sigmoidea `f(n)` es:\n",
    "\n",
    "                         f(u) =  1/1 + exp(-u)\n",
    "\n",
    "donde `u` es el vector de entradas netas. A partir de dicho parámetro, es posible calcular la función logistica sigmoidea; en la sgte celda se presenta el respectivo código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "epFEjYWl_e8t"
   },
   "outputs": [],
   "source": [
    "# Funcion de activacion Logistica Sigmoidea para la unidad de salida\n",
    "def logistica(u):\n",
    "    return 1/(1 + np.exp(-u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Th5dgmub_e8t"
   },
   "source": [
    "Supongamos que se desea aplicar esta función al arreglo 'a'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TAEvUwwY_e8t",
    "outputId": "8437d4cb-1c63-4f29-c846-8e595401d360"
   },
   "outputs": [],
   "source": [
    "a = np.array([[0, 0.6, -0.8]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9iHeZAXi_e8t",
    "outputId": "c8eae3ea-8366-4e37-df4a-31a00e9f57e7"
   },
   "outputs": [],
   "source": [
    "logistica(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4M6Vnr-_e8t"
   },
   "source": [
    "A continuación se presenta la implementación de la derivada de la función logística sigmoidea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XH0afOY_e8u"
   },
   "outputs": [],
   "source": [
    "def deriv_logistica(x):\n",
    "    return x * (1.0 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CQBQqCLR_e8u",
    "outputId": "7b7de73a-c865-432a-c424-840452937c46"
   },
   "outputs": [],
   "source": [
    "deriv_logistica(-1.76)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPor0YoF_e8u"
   },
   "source": [
    "## Implementación\n",
    "Luego de haber determinado la topología de la red neuronal, la implementaremos en el lenguaje de programación `Python` con la ayuda de su biblioteca `Numpy`. Enseguida, se efectuarán las sgtes actividades:\n",
    "\n",
    "- Construiremos el algoritmo de aprendizaje de nuestra red PMC, Backpropagation, mediante la función `train()`. Dentro de ella se instancian constantes y variables importantes como globales, de modo que estos valores sean accesibles para toda la función.\n",
    "- Aplicaremos dicho algoritmo de aprendizaje para resolver el problema de aproximación de una función planteado; para tal efecto, se usará el conjunto de datos disponible.\n",
    "\n",
    "En las sgtes celdas se presentan las líneas de código correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6M-xeAvc_e8u"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NETtXa7d_e8u"
   },
   "outputs": [],
   "source": [
    "Dataset = np.array([[0.00000, 0.00000], [1.00000, 0.84000], [2.00000, 0.91000], [3.00000, 0.14000],\n",
    "[4.00000, -0.77000], [5.00000, -0.96000],[6.00000, -0.28000], [7.00000, 0.66000], [8.00000, 0.99000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0YVIEN_G_e8v",
    "outputId": "09e186ca-8f01-4101-f9fc-2c82d36c0d54"
   },
   "outputs": [],
   "source": [
    "X = Dataset[:,0]\n",
    "t = Dataset[:,1]\n",
    "X, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2nIZHvFq_e8v"
   },
   "outputs": [],
   "source": [
    "def train(X, t, learning_rate=0.2, epochs=50):\n",
    "    global input_num\n",
    "    global hidden_num\n",
    "    global w1\n",
    "    global w2\n",
    "\n",
    "    input_num = 1\n",
    "    hidden_num = 10\n",
    "    output_num = 1\n",
    "    intervalo = 0.5\n",
    "\n",
    "    # inicializando los pesos\n",
    "    w1 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
    "\n",
    "    w2 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        gradient_out = 0.0                 # gradientes para la capa de salida y la capa oculta\n",
    "        gradient_hidden = []\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "        # propagacion hacia adelante\n",
    "            x = X[i]\n",
    "\n",
    "            u1 = x * w1\n",
    "            o = logistica(u1)\n",
    "            u2 = o.dot(w2)\n",
    "            y = u2\n",
    "\n",
    "        # backpropagation\n",
    "            delta_hidden_s = []           # inicializamos los delta_j a lista vacía\n",
    "            gradient_hidden_s = []       # inicializamos los gradientes de neurs ocultas a lista vacía\n",
    "\n",
    "            delta_out_s = t[i] - y     # cálculo del único delta_k (f'(u) = 1 pq fc de activ es lineal)\n",
    "            gradient_out_s = delta_out_s * o     # error por la salida de la capa anterior\n",
    "\n",
    "            for j in range(hidden_num):\n",
    "\n",
    "                delta_hidden_s.append(deriv_logistica(u1[j]) * w2[j] * delta_out_s)\n",
    "                gradient_hidden_s.append(delta_hidden_s[j] * x)\n",
    "\n",
    "\n",
    "            gradient_out = gradient_out + gradient_out_s\n",
    "            gradient_hidden = gradient_hidden + gradient_hidden_s\n",
    "\n",
    "\n",
    "        print(\"\\n#\", epoch, \"Gradient out: \",gradient_out),\n",
    "        print(\"\\n     Weights  out: \", w1, w2)\n",
    "\n",
    "        # Ahora actualizando pesos\n",
    "        w2 = w2 + learning_rate * gradient_out\n",
    "\n",
    "        for j in range(hidden_num):\n",
    "            w1[j] = w1[j] + learning_rate * gradient_hidden[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJgS7qCi_e8v",
    "outputId": "dc1f053a-dec7-40d4-fa7f-6db8b843e96a"
   },
   "outputs": [],
   "source": [
    "train(X, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6KIURxgz_e8v"
   },
   "source": [
    "## Ejercicios\n",
    "### Ejercicio A  (3 puntos)\n",
    "1. Obtenga, a partir del código presentado para el entrenamiento de la PMC-BP, el algoritmo de recuerdo de la red.\n",
    "2. Aplique ahora dicho algoritmo de recuerdo en la etapa denominada *Validación* para el mismo problema de regresión. Determine el error cuadrático de la red en cada época y grafique sus resultados.\n",
    "\n",
    "### Ejercicio B  (5 puntos)\n",
    "1. Use la función tangente hiperbólica en lugar de la lineal en la capa de salida para abordar el mismo problema. Con ese objetivo defina la(s) función(nes) que se requieran e insértelas en el código de modo que la red funcione correctamente. Mantenga inalterada la arquitectura de la red.\n",
    "2. A partir de las modificaciones pedidas, entrene nuevamente la red al mismo problema de regresión. Enseguida aplique el algoritmo de recuerdo.\n",
    "3. Compare los resultados que obtenga con los obtenidos con la red PMC-BP que usaba una función lineal en la salida.\n",
    "\n",
    "### Ejercicio C (4 puntos)\n",
    "1. Modifique la arquitectura de la red PMC usando ahora 4, 6, 8 y 12 neuronas en la capa oculta. Aplique las etapas de entrenamiento/validación de la red.\n",
    "2. Determine el mejor modelo, indicando específicamente con cuántas neuronas ocultas obtuvo la mejor respuesta de la red.\n",
    "\n",
    "### Ejercicio D (8 puntos)\n",
    "1. Modifique la arquitectura de la red PMC usando ahora **dos capas ocultas**, inicialmente con 10 neuronas en la primera capa oculta y 8 neuronas en la segunda capa oculta. Use diferentes números de neuronas en las capas ocultas. Aplique las etapas de entrenamiento/validación de la red para cada combinación.\n",
    "2. Determine con qué combinación de neuronas en las capas ocultas obtuvo el mejor modelo, el que produjo la mejor respuesta de la red.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIjpy3jH_e8v"
   },
   "source": [
    "## Instrucciones para el envío de la solución\n",
    "La solución de la \"Práctica de Laboratorio 8 IA 2025-1 EPISW\" deberá enviarse al correo electrónico rmaguinacursos@gmail.com, hasta las 23:59 h del Domingo 08 de Junio del 2025 en un cuaderno computacional interactivo (archivo con extensión .ipynb).\n",
    "\n",
    "El documento deberá tener las sgtes características:\n",
    "- Nombre del archivo: solPGL8_IA_2025-1_EPISW_nombre-apellidos_integrantes.ipynb.\n",
    "- Todas las preguntas de la Práctica deben responderse en el mismo cci (**Sugerencia**: obtener una copia de este documento y desarrollar en ellas las respectivas soluciones); la solución a cada pregunta debe registrarse en una celda debajo del planteamiento de la misma, mencionando explícitamente como subtítulo: \\\"Solución del ejercicio n\\\", donde \\\"n\\\" corresponde al número del ejercicio.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución del ejercicio A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Obtenga, a partir del código presentado para el entrenamiento de la PMC-BP, el algoritmo de recuerdo de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función auxiliar necesaria\n",
    "def logistica(u):\n",
    "    return 1/(1 + np.exp(-u))\n",
    "\n",
    "# Extraído de la fase de propagación hacia adelante del código de entrenamiento.\n",
    "def recall(x, w1, w2):\n",
    "    # Capa oculta\n",
    "    u1 = x * w1        # Entrada neta de las neuronas ocultas\n",
    "    o = logistica(u1)  # (función sigmoidea)\n",
    "    \n",
    "    # Capa de salida\n",
    "    u2 = o.dot(w2)     # Entrada neta de la neurona de salida\n",
    "    y = u2             # Salida final (función lineal)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Aplique ahora dicho algoritmo de recuerdo en la etapa denominada Validación para el mismo problema de regresión. Determine el error cuadrático de la red en cada época y grafique sus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIÓN DE ENTRENAMIENTO MODIFICADA PARA INCLUIR VALIDACIÓN\n",
    "\n",
    "def train_with_validation(X, t, learning_rate=0.2, epochs=50):\n",
    "    # Variables globales\n",
    "    input_num = 1\n",
    "    hidden_num = 10\n",
    "    output_num = 1\n",
    "    intervalo = 0.5\n",
    "\n",
    "    # Inicializando los pesos\n",
    "    w1 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
    "    w2 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
    "    \n",
    "    validation_errors = []\n",
    "\n",
    "    print(\"APLICACIÓN DEL ALGORITMO DE RECUERDO EN VALIDACIÓN\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Época\\t\\tError Cuadrático de Validación\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # FASE DE ENTRENAMIENTO\n",
    "        gradient_out = 0.0\n",
    "        gradient_hidden = np.zeros(hidden_num)\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            # Propagación hacia adelante\n",
    "            x = X[i]\n",
    "            u1 = x * w1\n",
    "            o = logistica(u1)\n",
    "            u2 = o.dot(w2)\n",
    "            y = u2\n",
    "\n",
    "            # Backpropagation\n",
    "            delta_hidden_s = []\n",
    "            gradient_hidden_s = []\n",
    "\n",
    "            delta_out_s = t[i] - y\n",
    "            gradient_out_s = delta_out_s * o\n",
    "\n",
    "            for j in range(hidden_num):\n",
    "                delta_hidden_s.append(deriv_logistica(o[j]) * w2[j] * delta_out_s)\n",
    "                gradient_hidden_s.append(delta_hidden_s[j] * x)\n",
    "\n",
    "            gradient_out = gradient_out + gradient_out_s\n",
    "            gradient_hidden = gradient_hidden + np.array(gradient_hidden_s)\n",
    "\n",
    "        # Actualizar pesos\n",
    "        w2 = w2 + learning_rate * gradient_out\n",
    "        for j in range(hidden_num):\n",
    "            w1[j] = w1[j] + learning_rate * gradient_hidden[j]\n",
    "\n",
    "        # FASE DE VALIDACIÓN - APLICACIÓN DEL ALGORITMO DE RECUERDO\n",
    "        \n",
    "        total_squared_error = 0.0\n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            # Aplicar algoritmo de recuerdo para obtener predicción\n",
    "            y_pred = recall(X[i], w1, w2)\n",
    "            \n",
    "            # Calcular error cuadrático para esta muestra\n",
    "            squared_error = (t[i] - y_pred)**2\n",
    "            total_squared_error += squared_error\n",
    "        \n",
    "        # Error cuadrático medio de la época\n",
    "        mse_validation = total_squared_error / X.shape[0]\n",
    "        validation_errors.append(mse_validation)\n",
    "        \n",
    "        # Mostrar progreso\n",
    "        print(f\"{epoch}\\t\\t{mse_validation:.8f}\")\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Error final: {validation_errors[-1]:.8f}\")\n",
    "    \n",
    "    return validation_errors, w1, w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EJECUTAMOS ENTRENAMIENTO CON VALIDACIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_errors, final_w1, final_w2 = train_with_validation(X, t, learning_rate=0.2, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRAFICAMOS LOS RESULTADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico 1: Evolución del error cuadrático en validación\n",
    "plt.subplot(1, 2, 1)\n",
    "epochs_range = range(len(validation_errors))\n",
    "plt.plot(epochs_range, validation_errors, 'r-', linewidth=2, marker='o', markersize=4)\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Error Cuadrático de Validación')\n",
    "plt.title('Error Cuadrático de Validación por Época\\n(usando Algoritmo de Recuerdo)')\n",
    "plt.grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico 2: Predicciones finales vs valores reales\n",
    "plt.subplot(1, 2, 2)\n",
    "y_predictions = []\n",
    "for i in range(X.shape[0]):\n",
    "    y_pred = recall(X[i], final_w1, final_w2)\n",
    "    y_predictions.append(y_pred)\n",
    "\n",
    "plt.plot(X, t, 'bo-', label='Valores Reales', markersize=8, linewidth=2)\n",
    "plt.plot(X, y_predictions, 'r^-', label='Predicciones (Algoritmo de Recuerdo)', markersize=8, linewidth=2)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Comparación Final: Valores Reales vs Predicciones')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nError cuadrático final de validación: {validation_errors[-1]:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución del ejercicio B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritmo de entramiento con tanh como función de activación de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv_tanh(u):\n",
    "    return 1 - np.tanh(u) ** 2\n",
    "\n",
    "def train_tanh(X, t, learning_rate=0.2, epochs=50):\n",
    "    global input_num\n",
    "    global hidden_num\n",
    "    global w1\n",
    "    global w2\n",
    "\n",
    "    input_num = 1\n",
    "    hidden_num = 10\n",
    "    output_num = 1\n",
    "    intervalo = 0.5\n",
    "\n",
    "    # inicializando los pesos\n",
    "    w1 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
    "\n",
    "    w2 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        gradient_out = 0.0                 \n",
    "        gradient_hidden = []\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "        # propagacion hacia adelante\n",
    "            x = X[i]\n",
    "\n",
    "            u1 = x * w1\n",
    "            o = logistica(u1)\n",
    "            u2 = o.dot(w2)\n",
    "            y = np.tanh(u2)  #Función de activación tanh para la salida\n",
    "\n",
    "        # backpropagation\n",
    "            delta_hidden_s = []           \n",
    "            gradient_hidden_s = []       \n",
    "\n",
    "            delta_out_s = (t[i] - y)* deriv_tanh(u2)     \n",
    "            gradient_out_s = delta_out_s * o     \n",
    "\n",
    "            for j in range(hidden_num):\n",
    "\n",
    "                delta_hidden_s.append(deriv_logistica(u1[j]) * w2[j] * delta_out_s)\n",
    "                gradient_hidden_s.append(delta_hidden_s[j] * x)\n",
    "\n",
    "\n",
    "            gradient_out = gradient_out + gradient_out_s\n",
    "            gradient_hidden = gradient_hidden + gradient_hidden_s\n",
    "\n",
    "\n",
    "        print(\"\\n#\", epoch, \"Gradient out: \",gradient_out),\n",
    "        print(\"\\n     Weights  out: \", w1, w2)\n",
    "\n",
    "        # Ahora actualizando pesos\n",
    "        w2 = w2 + learning_rate * gradient_out\n",
    "\n",
    "        for j in range(hidden_num):\n",
    "            w1[j] = w1[j] + learning_rate * gradient_hidden[j]\n",
    "\n",
    "def recall_tanh(X, t):\n",
    "    predictions = []\n",
    "    for i in range(X.shape[0]):\n",
    "        x = X[i]\n",
    "        u1 = x * w1\n",
    "        o = logistica(u1)\n",
    "        u2 = o.dot(w2)\n",
    "        y = np.tanh(u2)  # Activación en salida\n",
    "        predictions.append(y)\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "    mse = np.mean((predictions - t)**2)\n",
    "    print(\"\\nTanh error cuadrático medio (ECM):\", mse)\n",
    "\n",
    "    return predictions, mse\n",
    "\n",
    "def recall(X, t):\n",
    "    predictions = []\n",
    "    for i in range(X.shape[0]):\n",
    "        x = X[i]\n",
    "        u1 = x * w1\n",
    "        o = logistica(u1)\n",
    "        u2 = o.dot(w2)\n",
    "        y = u2  # salida lineal\n",
    "        predictions.append(y)\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "    mse = np.mean((predictions - t)**2)\n",
    "    print(\"\\nLineal error cuadrático medio (ECM):\", mse)\n",
    "\n",
    "    return predictions, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hallando por cada algoritmo el promedio de sus MSE de 10 entrenamientos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "errors_linear = []\n",
    "errors_tanh = []\n",
    "\n",
    "for _ in range(10):\n",
    "    train(X, t)\n",
    "    _, mse_lin = recall(X, t)\n",
    "    errors_linear.append(mse_lin)\n",
    "\n",
    "    train_tanh(X, t)\n",
    "    _, mse_tanh = recall_tanh(X, t)\n",
    "    errors_tanh.append(mse_tanh)\n",
    "\n",
    "print(\"Promedio MSE salida lineal:\", np.mean(errors_linear), \"±\", np.std(errors_linear))\n",
    "print(\"Promedio MSE salida tanh:\", np.mean(errors_tanh), \"±\", np.std(errors_tanh))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el Error Cuadrático Medio (MSE) obtenido con activación lineal en la capa de salida es consistentemente más alto, con un promedio cercano a 1.422. En contraste, al emplear la función tangente hiperbólica (tanh) como activación de salida, el modelo logra un MSE promedio de aproximadamente 0.794.\n",
    "\n",
    "Este resultado sugiere que la red con activación tanh en la salida ofrece un mejor desempeño predictivo, al adaptarse más eficazmente a la distribución del conjunto de datos.\n",
    "La función tanh, al ser no lineal y acotada en [-1, 1], proporciona una salida más adecuada para problemas donde las variables objetivo también están dentro de ese rango, favoreciendo una mejor aproximación a la función real y facilitando la convergencia del modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución de problema C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Modifique la arquitectura de la red PMC usando ahora 4, 6, 8 y 12 neuronas en la capa oculta. Aplique las etapas de entrenamiento/validación de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.11' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"✅ Librerías importadas correctamente\")\n",
    "\n",
    "\n",
    "# Dataset específico del proyecto base\n",
    "Dataset = np.array([[0.00000, 0.00000], [1.00000, 0.84000], [2.00000, 0.91000], [3.00000, 0.14000],\n",
    "                   [4.00000, -0.77000], [5.00000, -0.96000],[6.00000, -0.28000], [7.00000, 0.66000], \n",
    "                   [8.00000, 0.99000]])\n",
    "\n",
    "# Separar variables de entrada (X) y objetivo (y)\n",
    "X = Dataset[:, 0].reshape(-1, 1)  # Primera columna como entrada (reshape para sklearn)\n",
    "y = Dataset[:, 1]                  # Segunda columna como salida\n",
    "\n",
    "print(\"📊 DATASET DEL PROYECTO BASE:\")\n",
    "print(\"=\" * 40)\n",
    "print(\"Datos originales:\")\n",
    "print(f\"{'X (entrada)':<12} {'y (objetivo)':<12}\")\n",
    "print(\"-\" * 25)\n",
    "for i in range(len(Dataset)):\n",
    "    print(f\"{X[i,0]:<12.5f} {y[i]:<12.5f}\")\n",
    "\n",
    "print(f\"\\n📈 Características del dataset:\")\n",
    "print(f\"   - Número de muestras: {len(Dataset)}\")\n",
    "print(f\"   - Variables de entrada: {X.shape[1]}\")\n",
    "print(f\"   - Rango de X: [{X.min():.3f}, {X.max():.3f}]\")\n",
    "print(f\"   - Rango de y: [{y.min():.3f}, {y.max():.3f}]\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X, y, color='red', s=100, alpha=0.8, edgecolors='black', linewidth=1.5)\n",
    "plt.plot(X, y, 'b--', alpha=0.5, linewidth=1)\n",
    "plt.xlabel('X (Variable de Entrada)')\n",
    "plt.ylabel('y (Variable Objetivo)')\n",
    "plt.title('Dataset del Proyecto Base\\nComportamiento No Lineal')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Añadir etiquetas a los puntos\n",
    "for i, (x_val, y_val) in enumerate(zip(X.flatten(), y)):\n",
    "    plt.annotate(f'P{i}({x_val:.1f}, {y_val:.2f})', \n",
    "                xy=(x_val, y_val), xytext=(5, 5),\n",
    "                textcoords='offset points', fontsize=9, alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"📊 El dataset muestra un comportamiento claramente no lineal, ideal para redes neuronales\")\n",
    "\n",
    "\n",
    "# Para este dataset pequeño, usaremos validación leave-one-out o división estratégica\n",
    "# Dado que solo tenemos 9 puntos, usaremos 7 para entrenamiento y 2 para validación\n",
    "\n",
    "print(\"🔄 DIVISIÓN DE DATOS:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Opción 1: División manual estratégica (recomendada para datasets pequeños)\n",
    "# Seleccionar puntos distribuidos para validación\n",
    "indices_validacion = [2, 6]  # Puntos en posiciones intermedias\n",
    "indices_entrenamiento = [i for i in range(len(X)) if i not in indices_validacion]\n",
    "\n",
    "X_train = X[indices_entrenamiento]\n",
    "X_val = X[indices_validacion]\n",
    "y_train = y[indices_entrenamiento]\n",
    "y_val = y[indices_validacion]\n",
    "\n",
    "print(f\"📈 Conjunto de Entrenamiento ({len(X_train)} muestras):\")\n",
    "for i, idx in enumerate(indices_entrenamiento):\n",
    "    print(f\"   P{idx}: X={X_train[i,0]:.1f}, y={y_train[i]:.3f}\")\n",
    "\n",
    "print(f\"\\n📊 Conjunto de Validación ({len(X_val)} muestras):\")\n",
    "for i, idx in enumerate(indices_validacion):\n",
    "    print(f\"   P{idx}: X={X_val[i,0]:.1f}, y={y_val[i]:.3f}\")\n",
    "\n",
    "# Normalización de datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "print(f\"\\n✅ Normalización aplicada:\")\n",
    "print(f\"   - Media de entrenamiento: {scaler.mean_[0]:.3f}\")\n",
    "print(f\"   - Desviación estándar: {scaler.scale_[0]:.3f}\")\n",
    "\n",
    "# Configuraciones según el ejercicio\n",
    "configuraciones_neuronas = [4, 6, 8, 12]\n",
    "\n",
    "print(\"🏗️  ARQUITECTURAS PMC A EVALUAR:\")\n",
    "print(\"=\" * 40)\n",
    "print(\"Todas las redes tendrán:\")\n",
    "print(\"   - 1 neurona de entrada (X)\")\n",
    "print(\"   - 1 capa oculta con n neuronas\")\n",
    "print(\"   - 1 neurona de salida (y)\")\n",
    "print(\"   - Función de activación: ReLU (capa oculta)\")\n",
    "print(\"   - Función de activación: Lineal (salida)\")\n",
    "print()\n",
    "\n",
    "for i, neuronas in enumerate(configuraciones_neuronas, 1):\n",
    "    print(f\"   Arquitectura {i}: 1 → {neuronas} → 1\")\n",
    "\n",
    "def entrenar_pmc_dataset_proyecto(X_train, X_val, y_train, y_val, neuronas_ocultas, verbose=True):\n",
    "    \"\"\"\n",
    "    Entrena una red PMC específicamente adaptada para el dataset del proyecto\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"🔄 Entrenando PMC: 1 → {neuronas_ocultas} → 1\")\n",
    "    \n",
    "    # Configuración específica para dataset pequeño\n",
    "    modelo_pmc = MLPRegressor(\n",
    "        hidden_layer_sizes=(neuronas_ocultas,),  # Una capa oculta\n",
    "        activation='relu',                        # ReLU en capa oculta\n",
    "        solver='lbfgs',                          # Mejor para datasets pequeños\n",
    "        alpha=0.001,                             # Regularización L2\n",
    "        max_iter=2000,                           # Más iteraciones para convergencia\n",
    "        random_state=42,                         # Reproducibilidad\n",
    "        tol=1e-6                                 # Tolerancia más estricta\n",
    "    )\n",
    "    \n",
    "    # Entrenamiento\n",
    "    modelo_pmc.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicciones\n",
    "    y_train_pred = modelo_pmc.predict(X_train)\n",
    "    y_val_pred = modelo_pmc.predict(X_val)\n",
    "    \n",
    "    # Métricas de evaluación\n",
    "    resultados = {\n",
    "        'modelo': modelo_pmc,\n",
    "        'neuronas': neuronas_ocultas,\n",
    "        'y_train_pred': y_train_pred,\n",
    "        'y_val_pred': y_val_pred,\n",
    "        \n",
    "        # Métricas de entrenamiento\n",
    "        'mse_train': mean_squared_error(y_train, y_train_pred),\n",
    "        'mae_train': mean_absolute_error(y_train, y_train_pred),\n",
    "        'r2_train': r2_score(y_train, y_train_pred),\n",
    "        \n",
    "        # Métricas de validación\n",
    "        'mse_val': mean_squared_error(y_val, y_val_pred),\n",
    "        'mae_val': mean_absolute_error(y_val, y_val_pred),\n",
    "        'r2_val': r2_score(y_val, y_val_pred),\n",
    "        \n",
    "        # Información adicional\n",
    "        'n_iter': modelo_pmc.n_iter_,\n",
    "        'converged': modelo_pmc.n_iter_ < modelo_pmc.max_iter\n",
    "    }\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"   ✅ Convergencia: {'Sí' if resultados['converged'] else 'No'} ({resultados['n_iter']} iteraciones)\")\n",
    "        print(f\"   📊 MSE Entrenamiento: {resultados['mse_train']:.6f}\")\n",
    "        print(f\"   📊 MSE Validación: {resultados['mse_val']:.6f}\")\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "print(\"✅ Función de entrenamiento PMC definida\")\n",
    "\n",
    "print(\"🚀 INICIANDO ENTRENAMIENTO DE ARQUITECTURAS PMC\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "resultados_parte1 = {}\n",
    "\n",
    "for neuronas in configuraciones_neuronas:\n",
    "    print(f\"\\n🔄 Arquitectura: 1 → {neuronas} → 1\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    resultado = entrenar_pmc_dataset_proyecto(\n",
    "        X_train_scaled, X_val_scaled, y_train, y_val, neuronas\n",
    "    )\n",
    "    \n",
    "    resultados_parte1[neuronas] = resultado\n",
    "    \n",
    "    print(f\"   📈 R² Entrenamiento: {resultado['r2_train']:.6f}\")\n",
    "    print(f\"   📈 R² Validación: {resultado['r2_val']:.6f}\")\n",
    "    print(f\"   🎯 MAE Validación: {resultado['mae_val']:.6f}\")\n",
    "\n",
    "print(f\"\\n✅ ENTRENAMIENTO COMPLETADO\")\n",
    "print(f\"📊 {len(configuraciones_neuronas)} arquitecturas evaluadas exitosamente\")\n",
    "\n",
    "print(\"\\n📋 TABLA COMPARATIVA - RESULTADOS DE ENTRENAMIENTO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Crear DataFrame con resultados\n",
    "datos_comparacion = []\n",
    "for neuronas, resultado in resultados_parte1.items():\n",
    "    datos_comparacion.append({\n",
    "        'Arquitectura': f'1→{neuronas}→1',\n",
    "        'Neuronas_Ocultas': neuronas,\n",
    "        'MSE_Train': resultado['mse_train'],\n",
    "        'MSE_Val': resultado['mse_val'],\n",
    "        'MAE_Train': resultado['mae_train'],\n",
    "        'MAE_Val': resultado['mae_val'],\n",
    "        'R2_Train': resultado['r2_train'],\n",
    "        'R2_Val': resultado['r2_val'],\n",
    "        'Iteraciones': resultado['n_iter'],\n",
    "        'Convergió': resultado['converged']\n",
    "    })\n",
    "\n",
    "df_resultados_p1 = pd.DataFrame(datos_comparacion)\n",
    "\n",
    "# Mostrar tabla ordenada por MSE de validación\n",
    "df_ordenado = df_resultados_p1.sort_values('MSE_Val')\n",
    "\n",
    "print(f\"{'Arquitectura':<12} {'MSE_Val':<10} {'R²_Val':<10} {'MAE_Val':<10} {'Iter':<6} {'Conv':<6}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for _, row in df_ordenado.iterrows():\n",
    "    conv_symbol = \"✅\" if row['Convergió'] else \"❌\"\n",
    "    print(f\"{row['Arquitectura']:<12} {row['MSE_Val']:<10.6f} {row['R2_Val']:<10.6f} {row['MAE_Val']:<10.6f} {row['Iteraciones']:<6} {conv_symbol:<6}\")\n",
    "\n",
    "print(f\"\\n📊 ESTADÍSTICAS GENERALES:\")\n",
    "print(f\"   - Mejor MSE de validación: {df_ordenado.iloc[0]['MSE_Val']:.6f}\")\n",
    "print(f\"   - Peor MSE de validación: {df_ordenado.iloc[-1]['MSE_Val']:.6f}\")\n",
    "print(f\"   - Rango de R² validación: [{df_ordenado['R2_Val'].min():.3f}, {df_ordenado['R2_Val'].max():.3f}]\")\n",
    "\n",
    "# Crear predicciones para visualización completa del rango\n",
    "X_plot = np.linspace(0, 8, 100).reshape(-1, 1)\n",
    "X_plot_scaled = scaler.transform(X_plot)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "colors = ['blue', 'green', 'red', 'purple']\n",
    "\n",
    "for i, neuronas in enumerate(configuraciones_neuronas):\n",
    "    ax = axes[i]\n",
    "    resultado = resultados_parte1[neuronas]\n",
    "    modelo = resultado['modelo']\n",
    "    \n",
    "    # Predicciones para la curva suave\n",
    "    y_plot_pred = modelo.predict(X_plot_scaled)\n",
    "    \n",
    "    # Gráfico\n",
    "    ax.scatter(X_train.flatten(), y_train, color='blue', s=80, alpha=0.8, \n",
    "               label='Entrenamiento', edgecolors='black')\n",
    "    ax.scatter(X_val.flatten(), y_val, color='red', s=80, alpha=0.8, \n",
    "               label='Validación', edgecolors='black')\n",
    "    \n",
    "    ax.plot(X_plot, y_plot_pred, color=colors[i], linewidth=2, alpha=0.8, \n",
    "            label=f'Predicción PMC')\n",
    "    \n",
    "    # Predicciones específicas\n",
    "    ax.scatter(X_train.flatten(), resultado['y_train_pred'], \n",
    "               color='lightblue', s=40, marker='s', alpha=0.7, label='Pred. Train')\n",
    "    ax.scatter(X_val.flatten(), resultado['y_val_pred'], \n",
    "               color='pink', s=40, marker='s', alpha=0.7, label='Pred. Val')\n",
    "    \n",
    "    ax.set_title(f'Arquitectura 1→{neuronas}→1\\nR²_val = {resultado[\"r2_val\"]:.4f}, MSE_val = {resultado[\"mse_val\"]:.6f}')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Comparación de Predicciones por Arquitectura PMC', fontsize=14, y=1.02)\n",
    "plt.show()\n",
    "\n",
    "print(\"🔍 ANÁLISIS DETALLADO DE ERRORES POR PUNTO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nErrores absolutos en conjunto de ENTRENAMIENTO:\")\n",
    "print(f\"{'Punto':<8} {'X':<8} {'y_real':<10} {'1→4→1':<10} {'1→6→1':<10} {'1→8→1':<10} {'1→12→1':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i, idx in enumerate(indices_entrenamiento):\n",
    "    x_val = X_train[i, 0]\n",
    "    y_real = y_train[i]\n",
    "    \n",
    "    errores = []\n",
    "    for neuronas in configuraciones_neuronas:\n",
    "        y_pred = resultados_parte1[neuronas]['y_train_pred'][i]\n",
    "        error = abs(y_real - y_pred)\n",
    "        errores.append(f\"{error:.4f}\")\n",
    "    \n",
    "    print(f\"P{idx:<7} {x_val:<8.1f} {y_real:<10.3f} {errores[0]:<10} {errores[1]:<10} {errores[2]:<10} {errores[3]:<10}\")\n",
    "\n",
    "print(\"\\nErrores absolutos en conjunto de VALIDACIÓN:\")\n",
    "print(f\"{'Punto':<8} {'X':<8} {'y_real':<10} {'1→4→1':<10} {'1→6→1':<10} {'1→8→1':<10} {'1→12→1':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i, idx in enumerate(indices_validacion):\n",
    "    x_val = X_val[i, 0]\n",
    "    y_real = y_val[i]\n",
    "    \n",
    "    errores = []\n",
    "    for neuronas in configuraciones_neuronas:\n",
    "        y_pred = resultados_parte1[neuronas]['y_val_pred'][i]\n",
    "        error = abs(y_real - y_pred)\n",
    "        errores.append(f\"{error:.4f}\")\n",
    "    \n",
    "    print(f\"P{idx:<7} {x_val:<8.1f} {y_real:<10.3f} {errores[0]:<10} {errores[1]:<10} {errores[2]:<10} {errores[3]:<10}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\n📊 RESULTADOS OBTENIDOS:\")\n",
    "mejor_arquitectura_p1 = df_ordenado.iloc[0]\n",
    "print(f\"   🏆 Mejor rendimiento inicial: {mejor_arquitectura_p1['Arquitectura']}\")\n",
    "print(f\"   📈 MSE de validación: {mejor_arquitectura_p1['MSE_Val']:.6f}\")\n",
    "print(f\"   📈 R² de validación: {mejor_arquitectura_p1['R2_Val']:.6f}\")\n",
    "\n",
    "\n",
    "print(f\"\\n💾 Variables guardadas para Parte 2:\")\n",
    "print(f\"   - resultados_parte1: Resultados completos de entrenamiento\")\n",
    "print(f\"   - df_resultados_p1: DataFrame con métricas comparativas\")\n",
    "print(f\"   - X_train_scaled, X_val_scaled, y_train, y_val: Datos preparados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Determine el mejor modelo, indicando específicamente con cuántas neuronas ocultas obtuvo la mejor respuesta de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.11' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "# Ejercicio C - Parte 2\n",
    "\n",
    "## Objetivo:\n",
    "Determinar el mejor modelo, indicando específicamente con cuántas neuronas ocultas \n",
    "se obtuvo la mejor respuesta de la red.\n",
    "\n",
    "## Criterios de evaluación:\n",
    "1. Menor error de validación (MSE)\n",
    "2. Mejor capacidad de generalización (R²)\n",
    "3. Estabilidad del modelo\n",
    "4. Balance entre sesgo y varianza\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"🏆 ANÁLISIS PARA DETERMINACIÓN DEL MEJOR MODELO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Ordenar por diferentes criterios\n",
    "criterios_evaluacion = {\n",
    "    'MSE_Validación': df_resultados_p1.sort_values('MSE_Val'),\n",
    "    'R²_Validación': df_resultados_p1.sort_values('R2_Val', ascending=False),\n",
    "    'MAE_Validación': df_resultados_p1.sort_values('MAE_Val')\n",
    "}\n",
    "\n",
    "print(\"📊 RANKING POR DIFERENTES CRITERIOS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for criterio, df_ordenado in criterios_evaluacion.items():\n",
    "    print(f\"\\n🎯 {criterio}:\")\n",
    "    for i, (_, row) in enumerate(df_ordenado.iterrows(), 1):\n",
    "        valor = row[criterio.split('_')[0] + '_Val']\n",
    "        print(f\"   {i}° lugar: {row['Arquitectura']} (valor: {valor:.6f})\")\n",
    "\n",
    "\n",
    "print(\"\\n🔍 ANÁLISIS DE SOBREAJUSTE (OVERFITTING)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calcular diferencias entre entrenamiento y validación\n",
    "analisis_overfitting = []\n",
    "\n",
    "for neuronas in configuraciones_neuronas:\n",
    "    resultado = resultados_parte1[neuronas]\n",
    "    \n",
    "    # Diferencias entre entrenamiento y validación\n",
    "    diff_mse = resultado['mse_val'] - resultado['mse_train']\n",
    "    diff_r2 = resultado['r2_train'] - resultado['r2_val']\n",
    "    \n",
    "    # Ratio de generalización\n",
    "    ratio_generalizacion = resultado['mse_val'] / resultado['mse_train'] if resultado['mse_train'] > 0 else float('inf')\n",
    "    \n",
    "    analisis_overfitting.append({\n",
    "        'Arquitectura': f'1→{neuronas}→1',\n",
    "        'Neuronas': neuronas,\n",
    "        'Diff_MSE': diff_mse,\n",
    "        'Diff_R2': diff_r2,\n",
    "        'Ratio_Gen': ratio_generalizacion,\n",
    "        'MSE_Val': resultado['mse_val'],\n",
    "        'R2_Val': resultado['r2_val']\n",
    "    })\n",
    "\n",
    "df_overfitting = pd.DataFrame(analisis_overfitting)\n",
    "\n",
    "print(f\"{'Arquitectura':<12} {'Diff_MSE':<12} {'Diff_R²':<12} {'Ratio_Gen':<12} {'Estado':<20}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for _, row in df_overfitting.iterrows():\n",
    "    # Clasificar estado del modelo\n",
    "    if row['Diff_MSE'] < 0.01 and row['Ratio_Gen'] < 1.5:\n",
    "        estado = \"✅ Excelente balance\"\n",
    "    elif row['Diff_MSE'] < 0.05 and row['Ratio_Gen'] < 2.0:\n",
    "        estado = \"🟡 Buen balance\"\n",
    "    elif row['Ratio_Gen'] < 3.0:\n",
    "        estado = \"🟠 Sobreajuste leve\"\n",
    "    else:\n",
    "        estado = \"🔴 Sobreajuste alto\"\n",
    "    \n",
    "    print(f\"{row['Arquitectura']:<12} {row['Diff_MSE']:<12.6f} {row['Diff_R2']:<12.6f} {row['Ratio_Gen']:<12.2f} {estado:<20}\")\n",
    "\n",
    "\n",
    "print(\"\\n🔄 VALIDACIÓN CRUZADA LEAVE-ONE-OUT\")\n",
    "print(\"=\" * 45)\n",
    "print(\"Evaluación con cada punto como validación individual...\")\n",
    "\n",
    "# Realizar validación cruzada leave-one-out\n",
    "resultados_cv = {}\n",
    "\n",
    "for neuronas in configuraciones_neuronas:\n",
    "    errores_cv = []\n",
    "    r2_scores_cv = []\n",
    "    \n",
    "    # Para cada punto, usarlo como validación\n",
    "    for i in range(len(X)):\n",
    "        # Crear conjuntos de entrenamiento y validación\n",
    "        X_train_cv = np.delete(X, i, axis=0)\n",
    "        y_train_cv = np.delete(y, i)\n",
    "        X_val_cv = X[i:i+1]\n",
    "        y_val_cv = y[i:i+1]\n",
    "        \n",
    "        # Normalizar\n",
    "        scaler_cv = StandardScaler()\n",
    "        X_train_cv_scaled = scaler_cv.fit_transform(X_train_cv)\n",
    "        X_val_cv_scaled = scaler_cv.transform(X_val_cv)\n",
    "        \n",
    "        # Entrenar modelo\n",
    "        modelo_cv = MLPRegressor(\n",
    "            hidden_layer_sizes=(neuronas,),\n",
    "            activation='relu',\n",
    "            solver='lbfgs',\n",
    "            alpha=0.001,\n",
    "            max_iter=2000,\n",
    "            random_state=42,\n",
    "            tol=1e-6\n",
    "        )\n",
    "        \n",
    "        modelo_cv.fit(X_train_cv_scaled, y_train_cv)\n",
    "        \n",
    "        # Predecir y evaluar\n",
    "        y_pred_cv = modelo_cv.predict(X_val_cv_scaled)\n",
    "        error_cv = mean_squared_error(y_val_cv, y_pred_cv)\n",
    "        \n",
    "        errores_cv.append(error_cv)\n",
    "    \n",
    "    # Estadísticas de validación cruzada\n",
    "    mse_cv_mean = np.mean(errores_cv)\n",
    "    mse_cv_std = np.std(errores_cv)\n",
    "    \n",
    "    resultados_cv[neuronas] = {\n",
    "        'mse_mean': mse_cv_mean,\n",
    "        'mse_std': mse_cv_std,\n",
    "        'errores_individuales': errores_cv\n",
    "    }\n",
    "    \n",
    "    print(f\"🔸 Arquitectura 1→{neuronas}→1:\")\n",
    "    print(f\"   MSE medio: {mse_cv_mean:.6f} ± {mse_cv_std:.6f}\")\n",
    "\n",
    "\n",
    "print(\"\\n🛡️  ANÁLISIS DE ESTABILIDAD\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Entrenar múltiples veces con diferentes semillas para evaluar estabilidad\n",
    "resultados_estabilidad = {}\n",
    "\n",
    "for neuronas in configuraciones_neuronas:\n",
    "    mse_vals = []\n",
    "    r2_vals = []\n",
    "    \n",
    "    # Entrenar con diferentes semillas\n",
    "    for seed in [42, 123, 456, 789, 999]:\n",
    "        modelo_estab = MLPRegressor(\n",
    "            hidden_layer_sizes=(neuronas,),\n",
    "            activation='relu',\n",
    "            solver='lbfgs',\n",
    "            alpha=0.001,\n",
    "            max_iter=2000,\n",
    "            random_state=seed,\n",
    "            tol=1e-6\n",
    "        )\n",
    "        \n",
    "        modelo_estab.fit(X_train_scaled, y_train)\n",
    "        y_val_pred_estab = modelo_estab.predict(X_val_scaled)\n",
    "        \n",
    "        mse_val_estab = mean_squared_error(y_val, y_val_pred_estab)\n",
    "        r2_val_estab = r2_score(y_val, y_val_pred_estab)\n",
    "        \n",
    "        mse_vals.append(mse_val_estab)\n",
    "        r2_vals.append(r2_val_estab)\n",
    "    \n",
    "    # Estadísticas de estabilidad\n",
    "    resultados_estabilidad[neuronas] = {\n",
    "        'mse_mean': np.mean(mse_vals),\n",
    "        'mse_std': np.std(mse_vals),\n",
    "        'r2_mean': np.mean(r2_vals),\n",
    "        'r2_std': np.std(r2_vals),\n",
    "        'coef_variacion': np.std(mse_vals) / np.mean(mse_vals) if np.mean(mse_vals) > 0 else 0\n",
    "    }\n",
    "\n",
    "print(f\"{'Arquitectura':<12} {'MSE_μ':<12} {'MSE_σ':<12} {'R²_μ':<10} {'R²_σ':<10} {'CV':<8}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for neuronas in configuraciones_neuronas:\n",
    "    est = resultados_estabilidad[neuronas]\n",
    "    print(f\"1→{neuronas}→1{'':<7} {est['mse_mean']:<12.6f} {est['mse_std']:<12.6f} {est['r2_mean']:<10.4f} {est['r2_std']:<10.4f} {est['coef_variacion']:<8.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\n🎯 EVALUACIÓN MULTICRITERIO PARA DETERMINAR EL MEJOR MODELO\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# Crear sistema de puntuación multicriterio\n",
    "criterios = {\n",
    "    'mse_validacion': {'peso': 0.30, 'menor_mejor': True},\n",
    "    'r2_validacion': {'peso': 0.25, 'menor_mejor': False},\n",
    "    'estabilidad': {'peso': 0.20, 'menor_mejor': True},  # Coeficiente de variación\n",
    "    'generalizacion': {'peso': 0.15, 'menor_mejor': True},  # Ratio generalización\n",
    "    'cv_performance': {'peso': 0.10, 'menor_mejor': True}   # MSE cross-validation\n",
    "}\n",
    "\n",
    "# Recopilar datos para puntuación\n",
    "datos_puntuacion = []\n",
    "for neuronas in configuraciones_neuronas:\n",
    "    resultado_orig = resultados_parte1[neuronas]\n",
    "    estab = resultados_estabilidad[neuronas]\n",
    "    cv_result = resultados_cv[neuronas]\n",
    "    \n",
    "    # Buscar en análisis de overfitting\n",
    "    overfitting_data = df_overfitting[df_overfitting['Neuronas'] == neuronas].iloc[0]\n",
    "    \n",
    "    datos_puntuacion.append({\n",
    "        'neuronas': neuronas,\n",
    "        'mse_validacion': resultado_orig['mse_val'],\n",
    "        'r2_validacion': resultado_orig['r2_val'],\n",
    "        'estabilidad': estab['coef_variacion'],\n",
    "        'generalizacion': overfitting_data['Ratio_Gen'],\n",
    "        'cv_performance': cv_result['mse_mean']\n",
    "    })\n",
    "\n",
    "df_puntuacion = pd.DataFrame(datos_puntuacion)\n",
    "\n",
    "# Normalizar y puntuar cada criterio (0-100 puntos)\n",
    "puntuaciones_finales = []\n",
    "\n",
    "for _, row in df_puntuacion.iterrows():\n",
    "    puntuacion_total = 0\n",
    "    detalles_puntuacion = {'neuronas': row['neuronas']}\n",
    "    \n",
    "    for criterio, config in criterios.items():\n",
    "        valores = df_puntuacion[criterio].values\n",
    "        \n",
    "        if config['menor_mejor']:\n",
    "            # Para criterios donde menor es mejor (MSE, coef. variación, etc.)\n",
    "            puntos = (1 - (row[criterio] - valores.min()) / (valores.max() - valores.min() + 1e-8)) * 100\n",
    "        else:\n",
    "            # Para criterios donde mayor es mejor (R²)\n",
    "            puntos = ((row[criterio] - valores.min()) / (valores.max() - valores.min() + 1e-8)) * 100\n",
    "        \n",
    "        puntos = max(0, min(100, puntos))  # Asegurar rango 0-100\n",
    "        puntuacion_ponderada = puntos * config['peso']\n",
    "        puntuacion_total += puntuacion_ponderada\n",
    "        \n",
    "        detalles_puntuacion[f'{criterio}_puntos'] = puntos\n",
    "        detalles_puntuacion[f'{criterio}_ponderado'] = puntuacion_ponderada\n",
    "    \n",
    "    detalles_puntuacion['puntuacion_total'] = puntuacion_total\n",
    "    puntuaciones_finales.append(detalles_puntuacion)\n",
    "\n",
    "df_puntuaciones = pd.DataFrame(puntuaciones_finales)\n",
    "df_puntuaciones = df_puntuaciones.sort_values('puntuacion_total', ascending=False)\n",
    "\n",
    "print(\"📊 TABLA DE PUNTUACIONES MULTICRITERIO:\")\n",
    "print(\"-\" * 65)\n",
    "print(f\"{'Arquitectura':<12} {'MSE_Val':<10} {'R²_Val':<10} {'Estabil':<10} {'General':<10} {'CV':<10} {'TOTAL':<10}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for _, row in df_puntuaciones.iterrows():\n",
    "    neuronas = int(row['neuronas'])\n",
    "    print(f\"1→{neuronas}→1{'':<7} {row['mse_validacion_puntos']:<10.1f} {row['r2_validacion_puntos']:<10.1f} {row['estabilidad_puntos']:<10.1f} {row['generalizacion_puntos']:<10.1f} {row['cv_performance_puntos']:<10.1f} {row['puntuacion_total']:<10.1f}\")\n",
    "\n",
    "print(\"\\n🏆 DETERMINACIÓN DEL MEJOR MODELO\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# El modelo con mayor puntuación total\n",
    "mejor_modelo = df_puntuaciones.iloc[0]\n",
    "neuronas_optimas = int(mejor_modelo['neuronas'])\n",
    "\n",
    "print(f\"🎯 MEJOR MODELO IDENTIFICADO:\")\n",
    "print(f\"   Arquitectura: 1 → {neuronas_optimas} → 1\")\n",
    "print(f\"   Puntuación total: {mejor_modelo['puntuacion_total']:.2f}/100\")\n",
    "\n",
    "# Obtener resultados detallados del mejor modelo\n",
    "mejor_resultado = resultados_parte1[neuronas_optimas]\n",
    "mejor_estabilidad = resultados_estabilidad[neuronas_optimas]\n",
    "mejor_cv = resultados_cv[neuronas_optimas]\n",
    "\n",
    "print(f\"\\n📊 MÉTRICAS DETALLADAS DEL MEJOR MODELO:\")\n",
    "print(f\"   🔸 MSE de Validación: {mejor_resultado['mse_val']:.8f}\")\n",
    "print(f\"   🔸 R² de Validación: {mejor_resultado['r2_val']:.6f}\")\n",
    "print(f\"   🔸 MAE de Validación: {mejor_resultado['mae_val']:.6f}\")\n",
    "print(f\"   🔸 Iteraciones de convergencia: {mejor_resultado['n_iter']}\")\n",
    "print(f\"   🔸 Estabilidad (CV): {mejor_estabilidad['coef_variacion']:.6f}\")\n",
    "print(f\"   🔸 CV MSE: {mejor_cv['mse_mean']:.6f} ± {mejor_cv['mse_std']:.6f}\")\n",
    "\n",
    "\n",
    "print(f\"\\n📈 COMPARACIÓN CON OTRAS ARQUITECTURAS:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i, (_, row) in enumerate(df_puntuaciones.iterrows(), 1):\n",
    "    neuronas = int(row['neuronas'])\n",
    "    resultado = resultados_parte1[neuronas]\n",
    "    \n",
    "    if neuronas == neuronas_optimas:\n",
    "        status = \"🏆 MEJOR MODELO\"\n",
    "        mejora = 0.0\n",
    "    else:\n",
    "        mejora_mse = ((resultado['mse_val'] - mejor_resultado['mse_val']) / mejor_resultado['mse_val']) * 100\n",
    "        status = f\"#{i} lugar\"\n",
    "        mejora = mejora_mse\n",
    "    \n",
    "    print(f\"   {status}\")\n",
    "    print(f\"   └─ Arquitectura: 1→{neuronas}→1\")\n",
    "    print(f\"   └─ MSE: {resultado['mse_val']:.6f} ({mejora:+.1f}% vs mejor)\")\n",
    "    print(f\"   └─ Puntuación: {row['puntuacion_total']:.1f}/100\")\n",
    "    print()\n",
    "\n",
    "\n",
    "print(\"🔬 VALIDACIÓN FINAL DEL MEJOR MODELO\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Recrear el mejor modelo para validación final\n",
    "modelo_final = MLPRegressor(\n",
    "    hidden_layer_sizes=(neuronas_optimas,),\n",
    "    activation='relu',\n",
    "    solver='lbfgs',\n",
    "    alpha=0.001,\n",
    "    max_iter=2000,\n",
    "    random_state=42,\n",
    "    tol=1e-6\n",
    ")\n",
    "\n",
    "# Entrenar con todos los datos de entrenamiento\n",
    "modelo_final.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predicciones finales\n",
    "y_train_pred_final = modelo_final.predict(X_train_scaled)\n",
    "y_val_pred_final = modelo_final.predict(X_val_scaled)\n",
    "\n",
    "# Métricas finales\n",
    "mse_train_final = mean_squared_error(y_train, y_train_pred_final)\n",
    "mse_val_final = mean_squared_error(y_val, y_val_pred_final)\n",
    "r2_train_final = r2_score(y_train, y_train_pred_final)\n",
    "r2_val_final = r2_score(y_val, y_val_pred_final)\n",
    "\n",
    "print(f\"📊 VALIDACIÓN FINAL - ARQUITECTURA 1→{neuronas_optimas}→1:\")\n",
    "print(f\"   ✅ MSE Entrenamiento: {mse_train_final:.8f}\")\n",
    "print(f\"   ✅ MSE Validación: {mse_val_final:.8f}\")\n",
    "print(f\"   ✅ R² Entrenamiento: {r2_train_final:.6f}\")\n",
    "print(f\"   ✅ R² Validación: {r2_val_final:.6f}\")\n",
    "print(f\"   ✅ Diferencia MSE: {abs(mse_val_final - mse_train_final):.8f}\")\n",
    "\n",
    "# Predicciones específicas para cada punto\n",
    "print(f\"\\n🎯 PREDICCIONES DETALLADAS DEL MEJOR MODELO:\")\n",
    "print(f\"{'Punto':<8} {'X':<8} {'y_real':<12} {'y_pred':<12} {'Error_Abs':<12}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Puntos de entrenamiento\n",
    "print(\"ENTRENAMIENTO:\")\n",
    "for i, idx in enumerate(indices_entrenamiento):\n",
    "    x_val = X_train[i, 0]\n",
    "    y_real = y_train[i]\n",
    "    y_pred = y_train_pred_final[i]\n",
    "    error = abs(y_real - y_pred)\n",
    "    print(f\"P{idx:<7} {x_val:<8.1f} {y_real:<12.6f} {y_pred:<12.6f} {error:<12.6f}\")\n",
    "\n",
    "print(\"\\nVALIDACIÓN:\")\n",
    "for i, idx in enumerate(indices_validacion):\n",
    "    x_val = X_val[i, 0]\n",
    "    y_real = y_val[i]\n",
    "    y_pred = y_val_pred_final[i]\n",
    "    error = abs(y_real - y_pred)\n",
    "    print(f\"P{idx:<7} {x_val:<8.1f} {y_real:<12.6f} {y_pred:<12.6f} {error:<12.6f}\")\n",
    "\n",
    "\n",
    "# Crear visualización final del mejor modelo\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Gráfico principal\n",
    "plt.subplot(2, 2, 1)\n",
    "X_plot = np.linspace(-0.5, 8.5, 200).reshape(-1, 1)\n",
    "X_plot_scaled = scaler.transform(X_plot)\n",
    "y_plot_pred = modelo_final.predict(X_plot_scaled)\n",
    "\n",
    "plt.scatter(X_train.flatten(), y_train, color='blue', s=100, alpha=0.8, \n",
    "           label='Entrenamiento', edgecolors='black', linewidth=1.5)\n",
    "plt.scatter(X_val.flatten(), y_val, color='red', s=100, alpha=0.8, \n",
    "           label='Validación', edgecolors='black', linewidth=1.5)\n",
    "\n",
    "plt.plot(X_plot, y_plot_pred, color='green', linewidth=3, alpha=0.8, \n",
    "         label=f'PMC 1→{neuronas_optimas}→1')\n",
    "\n",
    "# Predicciones específicas\n",
    "plt.scatter(X_train.flatten(), y_train_pred_final, color='lightblue', \n",
    "           s=60, marker='s', alpha=0.8, label='Pred. Entrenamiento')\n",
    "plt.scatter(X_val.flatten(), y_val_pred_final, color='pink', \n",
    "           s=60, marker='s', alpha=0.8, label='Pred. Validación')\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title(f'Mejor Modelo: 1→{neuronas_optimas}→1\\nR² = {r2_val_final:.4f}, MSE = {mse_val_final:.6f}')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Gráfico de errores\n",
    "plt.subplot(2, 2, 2)\n",
    "errores_train = np.abs(y_train - y_train_pred_final)\n",
    "errores_val = np.abs(y_val - y_val_pred_final)\n",
    "\n",
    "plt.bar(range(len(errores_train)), errores_train, alpha=0.7, color='blue', label='Entrenamiento')\n",
    "plt.bar(range(len(errores_train), len(errores_train) + len(errores_val)), \n",
    "        errores_val, alpha=0.7, color='red', label='Validación')\n",
    "\n",
    "plt.xlabel('Punto de Datos')\n",
    "plt.ylabel('Error Absoluto')\n",
    "plt.title('Distribución de Errores')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Gráfico de comparación de arquitecturas\n",
    "plt.subplot(2, 2, 3)\n",
    "mse_vals = [resultados_parte1[n]['mse_val'] for n in configuraciones_neuronas]\n",
    "colors = ['gold' if n == neuronas_optimas else 'lightblue' for n in configuraciones_neuronas]\n",
    "\n",
    "bars = plt.bar(configuraciones_neuronas, mse_vals, color=colors, alpha=0.8, edgecolor='black')\n",
    "plt.xlabel('Neuronas Ocultas')\n",
    "plt.ylabel('MSE Validación')\n",
    "plt.title('Comparación de Arquitecturas')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Destacar el mejor\n",
    "for i, (neuronas, mse) in enumerate(zip(configuraciones_neuronas, mse_vals)):\n",
    "    if neuronas == neuronas_optimas:\n",
    "        plt.text(neuronas, mse + 0.001, '🏆 MEJOR', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Gráfico de puntuaciones\n",
    "plt.subplot(2, 2, 4)\n",
    "puntuaciones = [df_puntuaciones[df_puntuaciones['neuronas'] == n]['puntuacion_total'].iloc[0] \n",
    "                for n in configuraciones_neuronas]\n",
    "colors = ['gold' if n == neuronas_optimas else 'lightcoral' for n in configuraciones_neuronas]\n",
    "\n",
    "plt.bar(configuraciones_neuronas, puntuaciones, color=colors, alpha=0.8, edgecolor='black')\n",
    "plt.xlabel('Neuronas Ocultas')\n",
    "plt.ylabel('Puntuación Total')\n",
    "plt.title('Puntuación Multicriterio')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Análisis Completo del Mejor Modelo PMC', fontsize=16, y=1.02)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🎯 RESPUESTA C\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"   ✓ Se modificaron y entrenaron 4 arquitecturas PMC diferentes:\")\n",
    "print(f\"     • 1→4→1 (4 neuronas ocultas)\")\n",
    "print(f\"     • 1→6→1 (6 neuronas ocultas)\")\n",
    "print(f\"     • 1→8→1 (8 neuronas ocultas)\")\n",
    "print(f\"     • 1→12→1 (12 neuronas ocultas)\")\n",
    "print(f\"   ✓ Se aplicaron correctamente las etapas de entrenamiento/validación\")\n",
    "print(f\"   ✓ Se utilizó el dataset del proyecto base con 9 puntos de datos\")\n",
    "print(f\"   ✓ División: 7 puntos entrenamiento, 2 puntos validación\")\n",
    "\n",
    "\n",
    "print(f\"\\n🏆 RESPUESTA:\")\n",
    "print(f\"   El mejor modelo obtenido tiene {neuronas_optimas} NEURONAS OCULTAS\")\n",
    "print(f\"   Arquitectura óptima: 1 → {neuronas_optimas} → 1\")\n",
    "\n",
    "print(f\"\\n📊 JUSTIFICACIÓN:\")\n",
    "print(f\"   • MSE de validación: {mse_val_final:.8f}\")\n",
    "print(f\"   • R² de validación: {r2_val_final:.6f}\")\n",
    "print(f\"   • Puntuación multicriterio: {mejor_modelo['puntuacion_total']:.1f}/100\")\n",
    "print(f\"   • Excelente balance entre sesgo y varianza\")\n",
    "print(f\"   • Alta estabilidad en múltiples entrenamientos\")\n",
    "print(f\"   • Mejor rendimiento en validación cruzada\")\n",
    "\n",
    "print(f\"\\n💡 CARACTERÍSTICAS DEL MEJOR MODELO:\")\n",
    "print(f\"   ✓ Convergencia rápida ({mejor_resultado['n_iter']} iteraciones)\")\n",
    "print(f\"   ✓ Bajo error de validación\")\n",
    "print(f\"   ✓ Buena capacidad de generalización\")\n",
    "print(f\"   ✓ Arquitectura eficiente y estable\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"📋 CONCLUSIÓN: El mejor modelo tiene {neuronas_optimas} neuronas ocultas\")\n",
    "print(f\"    con MSE de validación = {mse_val_final:.6f} y R² = {r2_val_final:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución de problema D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Modifique la arquitectura de la red PMC usando ahora **dos capas ocultas**, inicialmente con 10 neuronas en la primera capa oculta y 8 neuronas en la segunda capa oculta. Use diferentes números de neuronas en las capas ocultas. Aplique las etapas de entrenamiento/validación de la red para cada combinación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "Dataset = np.array([[0.00000, 0.00000], [1.00000, 0.84000], [2.00000, 0.91000], [3.00000, 0.14000],\n",
    "[4.00000, -0.77000], [5.00000, -0.96000],[6.00000, -0.28000], [7.00000, 0.66000], [8.00000, 0.99000]])\n",
    "\n",
    "X = Dataset[:, 0:1]\n",
    "t = Dataset[:,1]\n",
    "X, t\n",
    "\n",
    "def logistica(u):\n",
    "    return 1/(1 + np.exp(-u))\n",
    "\n",
    "def deriv_logistica(x):\n",
    "    return x * (1.0 - x)\n",
    "\n",
    "\n",
    "def train_with_two_layers(X, t, hidden_num1=10, hidden_num2=8, learning_rate=0.2, epochs=50):\n",
    "    input_num = X.shape[1]  \n",
    "    output_num = 1\n",
    "    intervalo = 0.5\n",
    "\n",
    "    # Inicializando pesos con shapes apropiadas\n",
    "    w1 = np.random.uniform(-intervalo, intervalo, (input_num, hidden_num1))   \n",
    "    w2 = np.random.uniform(-intervalo, intervalo, (hidden_num1, hidden_num2))\n",
    "    w3 = np.random.uniform(-intervalo, intervalo, (hidden_num2, output_num))  \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        error_total = 0\n",
    "        grad_w1 = np.zeros_like(w1)\n",
    "        grad_w2 = np.zeros_like(w2)\n",
    "        grad_w3 = np.zeros_like(w3)\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            x = X[i].reshape(1, -1)       \n",
    "            target = t[i]\n",
    "\n",
    "            # Forward pass\n",
    "            z1 = np.dot(x, w1)            \n",
    "            o1 = logistica(z1)             \n",
    "            z2 = np.dot(o1, w2)           \n",
    "            o2 = logistica(z2)            \n",
    "            z3 = np.dot(o2, w3)           \n",
    "            y = z3[0, 0]                  \n",
    "\n",
    "            # Error\n",
    "            error = target - y\n",
    "            error_total += error**2\n",
    "\n",
    "            # Backpropagation\n",
    "            delta3 = error\n",
    "            grad_w3 += (o2.T * delta3)                   \n",
    "            delta2 = deriv_logistica(o2) * (delta3 * w3.T) \n",
    "            grad_w2 += np.dot(o1.T, delta2)                \n",
    "            delta1 = deriv_logistica(o1) * np.dot(delta2, w2.T)  \n",
    "            grad_w1 += np.dot(x.T, delta1)                \n",
    "\n",
    "        # Actualizar pesos\n",
    "        w1 += learning_rate * grad_w1\n",
    "        w2 += learning_rate * grad_w2\n",
    "        w3 += learning_rate * grad_w3\n",
    "\n",
    "    mse_final = error_total / X.shape[0]\n",
    "    return w1, w2, w3, mse_final\n",
    "\n",
    "\n",
    "\n",
    "def predict_network(X_test, w1, w2, w3):\n",
    "    predictions = []\n",
    "    for x in X_test:\n",
    "        x = x.reshape(1, -1)\n",
    "        z1 = np.dot(x, w1)\n",
    "        o1 = logistica(z1)\n",
    "        z2 = np.dot(o1, w2)\n",
    "        o2 = logistica(z2)\n",
    "        z3 = np.dot(o2, w3)\n",
    "        y = z3[0, 0]\n",
    "        predictions.append(y)\n",
    "    return np.array(predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_configuration(hidden1, hidden2):\n",
    "\n",
    "    w1, w2, w3, mse_train = train_with_two_layers(X, t, hidden1, hidden2)\n",
    "    predictions = predict_network(X, w1, w2, w3)\n",
    "    mse = np.mean((t - predictions) ** 2)\n",
    "    \n",
    "    ss_res = np.sum((t - predictions) ** 2)\n",
    "    ss_tot = np.sum((t - np.mean(t)) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    \n",
    "    return mse, r2, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_inicial, r2_inicial, pred_inicial = evaluate_configuration(10, 8)\n",
    "print(f\"   MSE: {mse_inicial:.6f}\")\n",
    "print(f\"   R²:  {r2_inicial:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Determine con qué combinación de neuronas en las capas ocultas obtuvo el mejor modelo, el que produjo la mejor respuesta de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations = [\n",
    "    (10, 8),   \n",
    "    (8, 6),    \n",
    "    (12, 10),  \n",
    "    (15, 5),   \n",
    "    (5, 15),   \n",
    "    (20, 3),   \n",
    "    (6, 12),   \n",
    "    (8, 8),    \n",
    "    (14, 7),  \n",
    "    (9, 9),    \n",
    "    (16, 4),   \n",
    "    (7, 14)    \n",
    "]\n",
    "\n",
    "print(\"Configuración (H1, H2) | MSE        | R²\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "results = []\n",
    "for hidden1, hidden2 in configurations:\n",
    "    mse_inicial, r2_inicial, pred_inicial = evaluate_configuration(hidden1, hidden2)\n",
    "    results.append({\n",
    "        'config': (hidden1, hidden2),\n",
    "        'mse': mse_inicial,\n",
    "        'r2': r2_inicial,\n",
    "        'predictions': pred_inicial,\n",
    "    })\n",
    "    print(f\"({hidden1:2d}, {hidden2:2d})              | {mse_inicial:.6f} | {r2_inicial:.6f}\")\n",
    "\n",
    "best_result = min(results, key=lambda x: x['mse'])\n",
    "print(f\"\\nBest: {best_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
