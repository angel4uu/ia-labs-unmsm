{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GnUElm5_e8m"
   },
   "source": [
    "# Práctica de Laboratorio 8 - Inteligencia Artificial 2025-1 Sección 1 EPISW-FISI\n",
    "## Implementación de una red PMC-BP con Python y Numpy\n",
    "### Prof. Rolando A. Maguiña Pérez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ky22d26K_e8n"
   },
   "source": [
    "## Introducción\n",
    "La Práctica Guiada de Laboratorio (PGL) 8 a realizarse el Jueves 05 de Junio del presente año, tratará sobre la red Perceptrón Multicapa con su algoritmo de aprendizaje llamado Backpropagation. Esta red se aplicará para resolver problemas genéricos de clasificación y de regresión.\n",
    "\n",
    "Se desea abordar el problema de la aproximación de una función mediante una Perceptrón Multicapa-Backpropagation (PMC-BP). Inicialmente se presenta la implementación del algoritmo de entrenamiento de esta red (presentado en las sesiones de teoría), con el lenguaje `Python` y sus bibliotecas `Numpy` y `Matplotlib`. Posteriormente, **se propondrán algunos ejercicios cuyas soluciones se podrán obtener en grupos de hasta 4 alumnos**, y deberán enviarse para su respectiva revisión (ver sección 'Instrucciones para el envío' en este mismo cuaderno).  \n",
    "\n",
    "Requiere: numpy, matplotlib\n",
    "\n",
    "Nomenclatura:\n",
    "- Z: número de instancias (muestras) en el conjunto de datos\n",
    "- N: número de atributos o variables de entrada\n",
    "- M: número de atributos o variables de salida\n",
    "- t: vector de salidas esperadas o targets\n",
    "- y: vector de salidas estimadas por la red.\n",
    "\n",
    "### Paso previo\n",
    "Importamos las bibliotecas de Python requeridas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5r_BRXlK_e8n"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.11' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKy9zmzb_e8p"
   },
   "source": [
    "## Dataset\n",
    "El primer paso consiste en obtener el arreglo conteniendo los pares entrada-salida (instancias) a usar en el entrenamiento/validación de la red PMC-BP a implementar; dicho arreglo se denominará 'Dataset'. El tamaño de dicho arreglo es de $Z \\times d$, donde $Z$ es el número de instancias (muestras) y $d$ es el número de características o atributos considerados para el problema abordado (incluye los atributos de entrada y los de salida)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHAeppdW_e8q",
    "outputId": "be4a459f-13d9-425f-bd6d-6e0cbbe7d8cd"
   },
   "outputs": [],
   "source": [
    "Dataset = np.array([[0.00000, 0.00000], [1.00000, 0.84000], [2.00000, 0.91000], [3.00000, 0.14000],\n",
    "[4.00000, -0.77000], [5.00000, -0.96000],[6.00000, -0.28000], [7.00000, 0.66000], [8.00000, 0.99000]])\n",
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PQUmblTn_e8q",
    "outputId": "339662ed-f65c-4cb2-d5ba-a944a8775d4b"
   },
   "outputs": [],
   "source": [
    "Dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xJFV52G_e8q"
   },
   "source": [
    "## Data para el entrenamiento/validación de la red\n",
    "Como sabemos, a partir del dataset obtenido, se deben determinar los conjuntos de datos a emplear en el entrenamiento y en la validación de la red PMC-BP. Enseguida, se deben obtener dos arreglos: uno con los vectores de entrada a usar en el entrenamiento, y el segundo, con los respectivos vectores de salida. Análogamente, se deben determinar los arreglos con los vectores de entrada y de salida, a usar en la validación del entrenamiento. **Sin embargo, para el problema planteado, el dataset se usará tanto para el entrenamiento como para la validación**.\n",
    "\n",
    "Separando los valores de entrada de los de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hr48ISV7_e8q",
    "outputId": "649fd8d4-c634-4166-8853-9208bad639a8"
   },
   "outputs": [],
   "source": [
    "X = Dataset[:,0]\n",
    "t = Dataset[:,1]\n",
    "X, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L0tmqcxX_e8r",
    "outputId": "c5dd6b48-055e-4a0e-a4b4-5ba76e3800f1"
   },
   "outputs": [],
   "source": [
    "X.shape, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sxiXCKVT_e8r",
    "outputId": "dc3bdc08-c4cd-47c4-a353-61323d72eba7"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot(X,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQJsVNIL_e8r"
   },
   "source": [
    "## Normalización de los datos\n",
    "Antes de iniciar algún cálculo, sabemos que debemos tener en cuenta las diferencias que existen en las unidades de nuestros datos. Se requiere que los datos de nuestras variables estén en el mismo orden de magnitud, y en un buen número de casos es necesario normalizarlos; de esta manera nuestro modelo trabajará con unidades normalizadas. A pesar de lo indicado, incluso sabedores que hay varios procedimientos de normalización, en este caso, **no vamos a normalizar inicialmente nuestros datos**.\n",
    "\n",
    "## Diseño de la red\n",
    "Inicialmente se considera una topología de la red como la mostrada en la figura, vale decir, con 10 neuronas ocultas. Como función de activación de las neuronas ocultas se usará la logística sigmoidea y en las neuronas de salida, dado que se trata de un problema de aproximación de funciones, se usará una función lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WGsNXQEa_e8r",
    "outputId": "855b611b-4ff4-4ed2-bdaa-cf13deb780df"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "i = Image(filename='D:\\\\Cursos\\\\Redes Neuronales\\\\2021-2\\\\arquit-red_aprox-fc_2021-2.png')\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkStZNAt_e8s"
   },
   "source": [
    "## Inicialización de los pesos y biases de la red\n",
    "Según el algoritmo, los parámetros libres de la red se inicializan a valores aleatorios pequeños, los cuales pueden estar en el rangos: [-0.5,0.5] o [-1,1] o en torno de cero. A continuación se presenta el código para inicializarlos, aplicado al **problema planteado**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVovH8l6_e8s"
   },
   "outputs": [],
   "source": [
    "# Implementación básica sin funciones\n",
    "intervalo = 0.5\n",
    "capa_entrada = 1\n",
    "capa_oculta = 10\n",
    "capa_salida = 1\n",
    "\n",
    "w1 = np.random.uniform(-intervalo, intervalo, capa_oculta)\n",
    "\n",
    "w2 = np.random.uniform(-intervalo, intervalo, capa_oculta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZ0RMbRe_e8s",
    "outputId": "f683c42b-d53b-4b2e-ea4a-14907601f2eb"
   },
   "outputs": [],
   "source": [
    "w1, w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmCcNM_d_e8s",
    "outputId": "9d457a8a-6bf1-4af0-b0c6-588ff5716fa7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBsY50rR_e8t"
   },
   "source": [
    "### Definición de la función logística sigmoidea\n",
    "Sabemos que la expresión matemática de la función logística sigmoidea `f(n)` es:\n",
    "\n",
    "                         f(u) =  1/1 + exp(-u)\n",
    "\n",
    "donde `u` es el vector de entradas netas. A partir de dicho parámetro, es posible calcular la función logistica sigmoidea; en la sgte celda se presenta el respectivo código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "epFEjYWl_e8t"
   },
   "outputs": [],
   "source": [
    "# Funcion de activacion Logistica Sigmoidea para la unidad de salida\n",
    "def logistica(u):\n",
    "    return 1/(1 + np.exp(-u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Th5dgmub_e8t"
   },
   "source": [
    "Supongamos que se desea aplicar esta función al arreglo 'a'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TAEvUwwY_e8t",
    "outputId": "8437d4cb-1c63-4f29-c846-8e595401d360"
   },
   "outputs": [],
   "source": [
    "a = np.array([[0, 0.6, -0.8]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9iHeZAXi_e8t",
    "outputId": "c8eae3ea-8366-4e37-df4a-31a00e9f57e7"
   },
   "outputs": [],
   "source": [
    "logistica(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4M6Vnr-_e8t"
   },
   "source": [
    "A continuación se presenta la implementación de la derivada de la función logística sigmoidea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XH0afOY_e8u"
   },
   "outputs": [],
   "source": [
    "def deriv_logistica(x):\n",
    "    return x * (1.0 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CQBQqCLR_e8u",
    "outputId": "7b7de73a-c865-432a-c424-840452937c46"
   },
   "outputs": [],
   "source": [
    "deriv_logistica(-1.76)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPor0YoF_e8u"
   },
   "source": [
    "## Implementación\n",
    "Luego de haber determinado la topología de la red neuronal, la implementaremos en el lenguaje de programación `Python` con la ayuda de su biblioteca `Numpy`. Enseguida, se efectuarán las sgtes actividades:\n",
    "\n",
    "- Construiremos el algoritmo de aprendizaje de nuestra red PMC, Backpropagation, mediante la función `train()`. Dentro de ella se instancian constantes y variables importantes como globales, de modo que estos valores sean accesibles para toda la función.\n",
    "- Aplicaremos dicho algoritmo de aprendizaje para resolver el problema de aproximación de una función planteado; para tal efecto, se usará el conjunto de datos disponible.\n",
    "\n",
    "En las sgtes celdas se presentan las líneas de código correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6M-xeAvc_e8u"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NETtXa7d_e8u"
   },
   "outputs": [],
   "source": [
    "Dataset = np.array([[0.00000, 0.00000], [1.00000, 0.84000], [2.00000, 0.91000], [3.00000, 0.14000],\n",
    "[4.00000, -0.77000], [5.00000, -0.96000],[6.00000, -0.28000], [7.00000, 0.66000], [8.00000, 0.99000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0YVIEN_G_e8v",
    "outputId": "09e186ca-8f01-4101-f9fc-2c82d36c0d54"
   },
   "outputs": [],
   "source": [
    "X = Dataset[:,0]\n",
    "t = Dataset[:,1]\n",
    "X, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2nIZHvFq_e8v"
   },
   "outputs": [],
   "source": [
    "def train(X, t, learning_rate=0.2, epochs=50):\n",
    "    global input_num\n",
    "    global hidden_num\n",
    "    global w1\n",
    "    global w2\n",
    "\n",
    "    input_num = 1\n",
    "    hidden_num = 10\n",
    "    output_num = 1\n",
    "    intervalo = 0.5\n",
    "\n",
    "    # inicializando los pesos\n",
    "    w1 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
    "\n",
    "    w2 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        gradient_out = 0.0                 # gradientes para la capa de salida y la capa oculta\n",
    "        gradient_hidden = []\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "        # propagacion hacia adelante\n",
    "            x = X[i]\n",
    "\n",
    "            u1 = x * w1\n",
    "            o = logistica(u1)\n",
    "            u2 = o.dot(w2)\n",
    "            y = u2\n",
    "\n",
    "        # backpropagation\n",
    "            delta_hidden_s = []           # inicializamos los delta_j a lista vacía\n",
    "            gradient_hidden_s = []       # inicializamos los gradientes de neurs ocultas a lista vacía\n",
    "\n",
    "            delta_out_s = t[i] - y     # cálculo del único delta_k (f'(u) = 1 pq fc de activ es lineal)\n",
    "            gradient_out_s = delta_out_s * o     # error por la salida de la capa anterior\n",
    "\n",
    "            for j in range(hidden_num):\n",
    "\n",
    "                delta_hidden_s.append(deriv_logistica(u1[j]) * w2[j] * delta_out_s)\n",
    "                gradient_hidden_s.append(delta_hidden_s[j] * x)\n",
    "\n",
    "\n",
    "            gradient_out = gradient_out + gradient_out_s\n",
    "            gradient_hidden = gradient_hidden + gradient_hidden_s\n",
    "\n",
    "\n",
    "        print(\"\\n#\", epoch, \"Gradient out: \",gradient_out),\n",
    "        print(\"\\n     Weights  out: \", w1, w2)\n",
    "\n",
    "        # Ahora actualizando pesos\n",
    "        w2 = w2 + learning_rate * gradient_out\n",
    "\n",
    "        for j in range(hidden_num):\n",
    "            w1[j] = w1[j] + learning_rate * gradient_hidden[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJgS7qCi_e8v",
    "outputId": "dc1f053a-dec7-40d4-fa7f-6db8b843e96a"
   },
   "outputs": [],
   "source": [
    "train(X, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6KIURxgz_e8v"
   },
   "source": [
    "## Ejercicios\n",
    "### Ejercicio A  (3 puntos)\n",
    "1. Obtenga, a partir del código presentado para el entrenamiento de la PMC-BP, el algoritmo de recuerdo de la red.\n",
    "2. Aplique ahora dicho algoritmo de recuerdo en la etapa denominada *Validación* para el mismo problema de regresión. Determine el error cuadrático de la red en cada época y grafique sus resultados.\n",
    "\n",
    "### Ejercicio B  (5 puntos)\n",
    "1. Use la función tangente hiperbólica en lugar de la lineal en la capa de salida para abordar el mismo problema. Con ese objetivo defina la(s) función(nes) que se requieran e insértelas en el código de modo que la red funcione correctamente. Mantenga inalterada la arquitectura de la red.\n",
    "2. A partir de las modificaciones pedidas, entrene nuevamente la red al mismo problema de regresión. Enseguida aplique el algoritmo de recuerdo.\n",
    "3. Compare los resultados que obtenga con los obtenidos con la red PMC-BP que usaba una función lineal en la salida.\n",
    "\n",
    "### Ejercicio C (4 puntos)\n",
    "1. Modifique la arquitectura de la red PMC usando ahora 4, 6, 8 y 12 neuronas en la capa oculta. Aplique las etapas de entrenamiento/validación de la red.\n",
    "2. Determine el mejor modelo, indicando específicamente con cuántas neuronas ocultas obtuvo la mejor respuesta de la red.\n",
    "\n",
    "### Ejercicio D (8 puntos)\n",
    "1. Modifique la arquitectura de la red PMC usando ahora **dos capas ocultas**, inicialmente con 10 neuronas en la primera capa oculta y 8 neuronas en la segunda capa oculta. Use diferentes números de neuronas en las capas ocultas. Aplique las etapas de entrenamiento/validación de la red para cada combinación.\n",
    "2. Determine con qué combinación de neuronas en las capas ocultas obtuvo el mejor modelo, el que produjo la mejor respuesta de la red.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIjpy3jH_e8v"
   },
   "source": [
    "## Instrucciones para el envío de la solución\n",
    "La solución de la \"Práctica de Laboratorio 8 IA 2025-1 EPISW\" deberá enviarse al correo electrónico rmaguinacursos@gmail.com, hasta las 23:59 h del Domingo 08 de Junio del 2025 en un cuaderno computacional interactivo (archivo con extensión .ipynb).\n",
    "\n",
    "El documento deberá tener las sgtes características:\n",
    "- Nombre del archivo: solPGL8_IA_2025-1_EPISW_nombre-apellidos_integrantes.ipynb.\n",
    "- Todas las preguntas de la Práctica deben responderse en el mismo cci (**Sugerencia**: obtener una copia de este documento y desarrollar en ellas las respectivas soluciones); la solución a cada pregunta debe registrarse en una celda debajo del planteamiento de la misma, mencionando explícitamente como subtítulo: \\\"Solución del ejercicio n\\\", donde \\\"n\\\" corresponde al número del ejercicio.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución del ejercicio A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Obtenga, a partir del código presentado para el entrenamiento de la PMC-BP, el algoritmo de recuerdo de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función auxiliar necesaria\n",
    "def logistica(u):\n",
    "    return 1/(1 + np.exp(-u))\n",
    "\n",
    "# Extraído de la fase de propagación hacia adelante del código de entrenamiento.\n",
    "def recall(x, w1, w2):\n",
    "    # Capa oculta\n",
    "    u1 = x * w1        # Entrada neta de las neuronas ocultas\n",
    "    o = logistica(u1)  # (función sigmoidea)\n",
    "    \n",
    "    # Capa de salida\n",
    "    u2 = o.dot(w2)     # Entrada neta de la neurona de salida\n",
    "    y = u2             # Salida final (función lineal)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Aplique ahora dicho algoritmo de recuerdo en la etapa denominada Validación para el mismo problema de regresión. Determine el error cuadrático de la red en cada época y grafique sus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIÓN DE ENTRENAMIENTO MODIFICADA PARA INCLUIR VALIDACIÓN\n",
    "\n",
    "def train_with_validation(X, t, learning_rate=0.2, epochs=50):\n",
    "    # Variables globales\n",
    "    input_num = 1\n",
    "    hidden_num = 10\n",
    "    output_num = 1\n",
    "    intervalo = 0.5\n",
    "\n",
    "    # Inicializando los pesos\n",
    "    w1 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
    "    w2 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
    "    \n",
    "    validation_errors = []\n",
    "\n",
    "    print(\"APLICACIÓN DEL ALGORITMO DE RECUERDO EN VALIDACIÓN\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Época\\t\\tError Cuadrático de Validación\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # FASE DE ENTRENAMIENTO\n",
    "        gradient_out = 0.0\n",
    "        gradient_hidden = np.zeros(hidden_num)\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            # Propagación hacia adelante\n",
    "            x = X[i]\n",
    "            u1 = x * w1\n",
    "            o = logistica(u1)\n",
    "            u2 = o.dot(w2)\n",
    "            y = u2\n",
    "\n",
    "            # Backpropagation\n",
    "            delta_hidden_s = []\n",
    "            gradient_hidden_s = []\n",
    "\n",
    "            delta_out_s = t[i] - y\n",
    "            gradient_out_s = delta_out_s * o\n",
    "\n",
    "            for j in range(hidden_num):\n",
    "                delta_hidden_s.append(deriv_logistica(o[j]) * w2[j] * delta_out_s)\n",
    "                gradient_hidden_s.append(delta_hidden_s[j] * x)\n",
    "\n",
    "            gradient_out = gradient_out + gradient_out_s\n",
    "            gradient_hidden = gradient_hidden + np.array(gradient_hidden_s)\n",
    "\n",
    "        # Actualizar pesos\n",
    "        w2 = w2 + learning_rate * gradient_out\n",
    "        for j in range(hidden_num):\n",
    "            w1[j] = w1[j] + learning_rate * gradient_hidden[j]\n",
    "\n",
    "        # FASE DE VALIDACIÓN - APLICACIÓN DEL ALGORITMO DE RECUERDO\n",
    "        \n",
    "        total_squared_error = 0.0\n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            # Aplicar algoritmo de recuerdo para obtener predicción\n",
    "            y_pred = recall(X[i], w1, w2)\n",
    "            \n",
    "            # Calcular error cuadrático para esta muestra\n",
    "            squared_error = (t[i] - y_pred)**2\n",
    "            total_squared_error += squared_error\n",
    "        \n",
    "        # Error cuadrático medio de la época\n",
    "        mse_validation = total_squared_error / X.shape[0]\n",
    "        validation_errors.append(mse_validation)\n",
    "        \n",
    "        # Mostrar progreso\n",
    "        print(f\"{epoch}\\t\\t{mse_validation:.8f}\")\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Error final: {validation_errors[-1]:.8f}\")\n",
    "    \n",
    "    return validation_errors, w1, w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EJECUTAMOS ENTRENAMIENTO CON VALIDACIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_errors, final_w1, final_w2 = train_with_validation(X, t, learning_rate=0.2, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRAFICAMOS LOS RESULTADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico 1: Evolución del error cuadrático en validación\n",
    "plt.subplot(1, 2, 1)\n",
    "epochs_range = range(len(validation_errors))\n",
    "plt.plot(epochs_range, validation_errors, 'r-', linewidth=2, marker='o', markersize=4)\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Error Cuadrático de Validación')\n",
    "plt.title('Error Cuadrático de Validación por Época\\n(usando Algoritmo de Recuerdo)')\n",
    "plt.grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico 2: Predicciones finales vs valores reales\n",
    "plt.subplot(1, 2, 2)\n",
    "y_predictions = []\n",
    "for i in range(X.shape[0]):\n",
    "    y_pred = recall(X[i], final_w1, final_w2)\n",
    "    y_predictions.append(y_pred)\n",
    "\n",
    "plt.plot(X, t, 'bo-', label='Valores Reales', markersize=8, linewidth=2)\n",
    "plt.plot(X, y_predictions, 'r^-', label='Predicciones (Algoritmo de Recuerdo)', markersize=8, linewidth=2)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Comparación Final: Valores Reales vs Predicciones')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nError cuadrático final de validación: {validation_errors[-1]:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución del ejercicio B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritmo de entramiento con tanh como función de activación de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv_tanh(u):\n",
    "    return 1 - np.tanh(u) ** 2\n",
    "\n",
    "def train_tanh(X, t, learning_rate=0.2, epochs=50):\n",
    "    global input_num\n",
    "    global hidden_num\n",
    "    global w1\n",
    "    global w2\n",
    "\n",
    "    input_num = 1\n",
    "    hidden_num = 10\n",
    "    output_num = 1\n",
    "    intervalo = 0.5\n",
    "\n",
    "    # inicializando los pesos\n",
    "    w1 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
    "\n",
    "    w2 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        gradient_out = 0.0                 \n",
    "        gradient_hidden = []\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "        # propagacion hacia adelante\n",
    "            x = X[i]\n",
    "\n",
    "            u1 = x * w1\n",
    "            o = logistica(u1)\n",
    "            u2 = o.dot(w2)\n",
    "            y = np.tanh(u2)  #Función de activación tanh para la salida\n",
    "\n",
    "        # backpropagation\n",
    "            delta_hidden_s = []           \n",
    "            gradient_hidden_s = []       \n",
    "\n",
    "            delta_out_s = (t[i] - y)* deriv_tanh(u2)     \n",
    "            gradient_out_s = delta_out_s * o     \n",
    "\n",
    "            for j in range(hidden_num):\n",
    "\n",
    "                delta_hidden_s.append(deriv_logistica(u1[j]) * w2[j] * delta_out_s)\n",
    "                gradient_hidden_s.append(delta_hidden_s[j] * x)\n",
    "\n",
    "\n",
    "            gradient_out = gradient_out + gradient_out_s\n",
    "            gradient_hidden = gradient_hidden + gradient_hidden_s\n",
    "\n",
    "\n",
    "        print(\"\\n#\", epoch, \"Gradient out: \",gradient_out),\n",
    "        print(\"\\n     Weights  out: \", w1, w2)\n",
    "\n",
    "        # Ahora actualizando pesos\n",
    "        w2 = w2 + learning_rate * gradient_out\n",
    "\n",
    "        for j in range(hidden_num):\n",
    "            w1[j] = w1[j] + learning_rate * gradient_hidden[j]\n",
    "\n",
    "def recall_tanh(X, t):\n",
    "    predictions = []\n",
    "    for i in range(X.shape[0]):\n",
    "        x = X[i]\n",
    "        u1 = x * w1\n",
    "        o = logistica(u1)\n",
    "        u2 = o.dot(w2)\n",
    "        y = np.tanh(u2)  # Activación en salida\n",
    "        predictions.append(y)\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "    mse = np.mean((predictions - t)**2)\n",
    "    print(\"\\nTanh error cuadrático medio (ECM):\", mse)\n",
    "\n",
    "    return predictions, mse\n",
    "\n",
    "def recall(X, t):\n",
    "    predictions = []\n",
    "    for i in range(X.shape[0]):\n",
    "        x = X[i]\n",
    "        u1 = x * w1\n",
    "        o = logistica(u1)\n",
    "        u2 = o.dot(w2)\n",
    "        y = u2  # salida lineal\n",
    "        predictions.append(y)\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "    mse = np.mean((predictions - t)**2)\n",
    "    print(\"\\nLineal error cuadrático medio (ECM):\", mse)\n",
    "\n",
    "    return predictions, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hallando por cada algoritmo el promedio de sus MSE de 10 entrenamientos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "errors_linear = []\n",
    "errors_tanh = []\n",
    "\n",
    "for _ in range(10):\n",
    "    train(X, t)\n",
    "    _, mse_lin = recall(X, t)\n",
    "    errors_linear.append(mse_lin)\n",
    "\n",
    "    train_tanh(X, t)\n",
    "    _, mse_tanh = recall_tanh(X, t)\n",
    "    errors_tanh.append(mse_tanh)\n",
    "\n",
    "print(\"Promedio MSE salida lineal:\", np.mean(errors_linear), \"±\", np.std(errors_linear))\n",
    "print(\"Promedio MSE salida tanh:\", np.mean(errors_tanh), \"±\", np.std(errors_tanh))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el Error Cuadrático Medio (MSE) obtenido con activación lineal en la capa de salida es consistentemente más alto, con un promedio cercano a 1.422. En contraste, al emplear la función tangente hiperbólica (tanh) como activación de salida, el modelo logra un MSE promedio de aproximadamente 0.794.\n",
    "\n",
    "Este resultado sugiere que la red con activación tanh en la salida ofrece un mejor desempeño predictivo, al adaptarse más eficazmente a la distribución del conjunto de datos.\n",
    "La función tanh, al ser no lineal y acotada en [-1, 1], proporciona una salida más adecuada para problemas donde las variables objetivo también están dentro de ese rango, favoreciendo una mejor aproximación a la función real y facilitando la convergencia del modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución de problema C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Modifique la arquitectura de la red PMC usando ahora 4, 6, 8 y 12 neuronas en la capa oculta. Aplique las etapas de entrenamiento/validación de la red.\n",
    "2. Determine el mejor modelo, indicando específicamente con cuántas neuronas ocultas obtuvo la mejor respuesta de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.11' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar dataset\n",
    "from sklearn.datasets import load_wine\n",
    "data = load_wine()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Preprocesamiento\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# neuronas ocultas\n",
    "hidden_neurons = [4, 6, 8, 12]\n",
    "results = []\n",
    "\n",
    "print(\"Resultados de entrenamiento y validación:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for neurons in hidden_neurons:\n",
    "    # Crear modelo PMC\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=(neurons,),\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        max_iter=1000,\n",
    "        random_state=42,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1\n",
    "    )\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    mlp.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predicciones\n",
    "    y_train_pred = mlp.predict(X_train_scaled)\n",
    "    y_val_pred = mlp.predict(X_val_scaled)\n",
    "    y_test_pred = mlp.predict(X_test_scaled)\n",
    "    \n",
    "    # Calcular accuracy\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    val_acc = accuracy_score(y_val, y_val_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Guardar resultados\n",
    "    results.append({\n",
    "        'neuronas': neurons,\n",
    "        'train_accuracy': train_acc,\n",
    "        'val_accuracy': val_acc,\n",
    "        'test_accuracy': test_acc,\n",
    "        'loss_curve': mlp.loss_curve_\n",
    "    })\n",
    "    \n",
    "    print(f\"Neuronas: {neurons}\")\n",
    "    print(f\"  Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"  Val Accuracy: {val_acc:.4f}\")\n",
    "    print(f\"  Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"  Iteraciones: {mlp.n_iter_}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# Determinar mejor modelo\n",
    "best_model = max(results, key=lambda x: x['val_accuracy'])\n",
    "print(f\"\\nMejor modelo:\")\n",
    "print(f\"Neuronas ocultas: {best_model['neuronas']}\")\n",
    "print(f\"Accuracy de validación: {best_model['val_accuracy']:.4f}\")\n",
    "print(f\"Accuracy de prueba: {best_model['test_accuracy']:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Accuracy por número de neuronas\n",
    "plt.subplot(2, 2, 1)\n",
    "neurons_list = [r['neuronas'] for r in results]\n",
    "train_accs = [r['train_accuracy'] for r in results]\n",
    "val_accs = [r['val_accuracy'] for r in results]\n",
    "test_accs = [r['test_accuracy'] for r in results]\n",
    "\n",
    "plt.plot(neurons_list, train_accs, 'bo-', label='Train')\n",
    "plt.plot(neurons_list, val_accs, 'ro-', label='Validación')\n",
    "plt.plot(neurons_list, test_accs, 'go-', label='Test')\n",
    "plt.xlabel('Número de Neuronas Ocultas')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Número de Neuronas')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Comparación directa de accuracies\n",
    "plt.subplot(2, 2, 2)\n",
    "x = np.arange(len(neurons_list))\n",
    "width = 0.25\n",
    "\n",
    "plt.bar(x - width, train_accs, width, label='Train', alpha=0.8)\n",
    "plt.bar(x, val_accs, width, label='Validación', alpha=0.8)\n",
    "plt.bar(x + width, test_accs, width, label='Test', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Configuración')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparación de Accuracies por Configuración')\n",
    "plt.xticks(x, [f'{n} neuronas' for n in neurons_list])\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "print(\"\\nTabla Resumen:\")\n",
    "print(\"=\" * 60)\n",
    "df_results = pd.DataFrame(results)[['neuronas', 'train_accuracy', 'val_accuracy', 'test_accuracy']]\n",
    "print(df_results.round(4))\n",
    "\n",
    "print(f\"\\nConclusión:\")\n",
    "print(f\"La mejor configuración es con {best_model['neuronas']} neuronas ocultas\")\n",
    "print(f\"obteniendo un accuracy de validación de {best_model['val_accuracy']:.4f}\")\n",
    "print(f\"y un accuracy de prueba de {best_model['test_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución de problema D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Modifique la arquitectura de la red PMC usando ahora **dos capas ocultas**, inicialmente con 10 neuronas en la primera capa oculta y 8 neuronas en la segunda capa oculta. Use diferentes números de neuronas en las capas ocultas. Aplique las etapas de entrenamiento/validación de la red para cada combinación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "Dataset = np.array([[0.00000, 0.00000], [1.00000, 0.84000], [2.00000, 0.91000], [3.00000, 0.14000],\n",
    "[4.00000, -0.77000], [5.00000, -0.96000],[6.00000, -0.28000], [7.00000, 0.66000], [8.00000, 0.99000]])\n",
    "\n",
    "X = Dataset[:, 0:1]\n",
    "t = Dataset[:,1]\n",
    "X, t\n",
    "\n",
    "def logistica(u):\n",
    "    return 1/(1 + np.exp(-u))\n",
    "\n",
    "def deriv_logistica(x):\n",
    "    return x * (1.0 - x)\n",
    "\n",
    "\n",
    "def train_with_two_layers(X, t, hidden_num1=10, hidden_num2=8, learning_rate=0.2, epochs=50):\n",
    "    input_num = X.shape[1]  \n",
    "    output_num = 1\n",
    "    intervalo = 0.5\n",
    "\n",
    "    # Inicializando pesos con shapes apropiadas\n",
    "    w1 = np.random.uniform(-intervalo, intervalo, (input_num, hidden_num1))   \n",
    "    w2 = np.random.uniform(-intervalo, intervalo, (hidden_num1, hidden_num2))\n",
    "    w3 = np.random.uniform(-intervalo, intervalo, (hidden_num2, output_num))  \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        error_total = 0\n",
    "        grad_w1 = np.zeros_like(w1)\n",
    "        grad_w2 = np.zeros_like(w2)\n",
    "        grad_w3 = np.zeros_like(w3)\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            x = X[i].reshape(1, -1)       \n",
    "            target = t[i]\n",
    "\n",
    "            # Forward pass\n",
    "            z1 = np.dot(x, w1)            \n",
    "            o1 = logistica(z1)             \n",
    "            z2 = np.dot(o1, w2)           \n",
    "            o2 = logistica(z2)            \n",
    "            z3 = np.dot(o2, w3)           \n",
    "            y = z3[0, 0]                  \n",
    "\n",
    "            # Error\n",
    "            error = target - y\n",
    "            error_total += error**2\n",
    "\n",
    "            # Backpropagation\n",
    "            delta3 = error\n",
    "            grad_w3 += (o2.T * delta3)                   \n",
    "            delta2 = deriv_logistica(o2) * (delta3 * w3.T) \n",
    "            grad_w2 += np.dot(o1.T, delta2)                \n",
    "            delta1 = deriv_logistica(o1) * np.dot(delta2, w2.T)  \n",
    "            grad_w1 += np.dot(x.T, delta1)                \n",
    "\n",
    "        # Actualizar pesos\n",
    "        w1 += learning_rate * grad_w1\n",
    "        w2 += learning_rate * grad_w2\n",
    "        w3 += learning_rate * grad_w3\n",
    "\n",
    "    mse_final = error_total / X.shape[0]\n",
    "    return w1, w2, w3, mse_final\n",
    "\n",
    "\n",
    "\n",
    "def predict_network(X_test, w1, w2, w3):\n",
    "    predictions = []\n",
    "    for x in X_test:\n",
    "        x = x.reshape(1, -1)\n",
    "        z1 = np.dot(x, w1)\n",
    "        o1 = logistica(z1)\n",
    "        z2 = np.dot(o1, w2)\n",
    "        o2 = logistica(z2)\n",
    "        z3 = np.dot(o2, w3)\n",
    "        y = z3[0, 0]\n",
    "        predictions.append(y)\n",
    "    return np.array(predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_configuration(hidden1, hidden2):\n",
    "\n",
    "    w1, w2, w3, mse_train = train_with_two_layers(X, t, hidden1, hidden2)\n",
    "    predictions = predict_network(X, w1, w2, w3)\n",
    "    mse = np.mean((t - predictions) ** 2)\n",
    "    \n",
    "    ss_res = np.sum((t - predictions) ** 2)\n",
    "    ss_tot = np.sum((t - np.mean(t)) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    \n",
    "    return mse, r2, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_inicial, r2_inicial, pred_inicial = evaluate_configuration(10, 8)\n",
    "print(f\"   MSE: {mse_inicial:.6f}\")\n",
    "print(f\"   R²:  {r2_inicial:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Determine con qué combinación de neuronas en las capas ocultas obtuvo el mejor modelo, el que produjo la mejor respuesta de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations = [\n",
    "    (10, 8),   \n",
    "    (8, 6),    \n",
    "    (12, 10),  \n",
    "    (15, 5),   \n",
    "    (5, 15),   \n",
    "    (20, 3),   \n",
    "    (6, 12),   \n",
    "    (8, 8),    \n",
    "    (14, 7),  \n",
    "    (9, 9),    \n",
    "    (16, 4),   \n",
    "    (7, 14)    \n",
    "]\n",
    "\n",
    "print(\"Configuración (H1, H2) | MSE        | R²\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "results = []\n",
    "for hidden1, hidden2 in configurations:\n",
    "    mse_inicial, r2_inicial, pred_inicial = evaluate_configuration(hidden1, hidden2)\n",
    "    results.append({\n",
    "        'config': (hidden1, hidden2),\n",
    "        'mse': mse_inicial,\n",
    "        'r2': r2_inicial,\n",
    "        'predictions': pred_inicial,\n",
    "    })\n",
    "    print(f\"({hidden1:2d}, {hidden2:2d})              | {mse_inicial:.6f} | {r2_inicial:.6f}\")\n",
    "\n",
    "best_result = min(results, key=lambda x: x['mse'])\n",
    "print(f\"\\nBest: {best_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
