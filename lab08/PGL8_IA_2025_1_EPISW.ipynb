{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GnUElm5_e8m"
   },
   "source": [
    "# Práctica de Laboratorio 8 - Inteligencia Artificial 2025-1 Sección 1 EPISW-FISI\n",
    "## Implementación de una red PMC-BP con Python y Numpy\n",
    "### Prof. Rolando A. Maguiña Pérez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ky22d26K_e8n"
   },
   "source": [
    "## Introducción\n",
    "La Práctica Guiada de Laboratorio (PGL) 8 a realizarse el Jueves 05 de Junio del presente año, tratará sobre la red Perceptrón Multicapa con su algoritmo de aprendizaje llamado Backpropagation. Esta red se aplicará para resolver problemas genéricos de clasificación y de regresión.\n",
    "\n",
    "Se desea abordar el problema de la aproximación de una función mediante una Perceptrón Multicapa-Backpropagation (PMC-BP). Inicialmente se presenta la implementación del algoritmo de entrenamiento de esta red (presentado en las sesiones de teoría), con el lenguaje `Python` y sus bibliotecas `Numpy` y `Matplotlib`. Posteriormente, **se propondrán algunos ejercicios cuyas soluciones se podrán obtener en grupos de hasta 4 alumnos**, y deberán enviarse para su respectiva revisión (ver sección 'Instrucciones para el envío' en este mismo cuaderno).  \n",
    "\n",
    "Requiere: numpy, matplotlib\n",
    "\n",
    "Nomenclatura:\n",
    "- Z: número de instancias (muestras) en el conjunto de datos\n",
    "- N: número de atributos o variables de entrada\n",
    "- M: número de atributos o variables de salida\n",
    "- t: vector de salidas esperadas o targets\n",
    "- y: vector de salidas estimadas por la red.\n",
    "\n",
    "### Paso previo\n",
    "Importamos las bibliotecas de Python requeridas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "5r_BRXlK_e8n"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKy9zmzb_e8p"
   },
   "source": [
    "## Dataset\n",
    "El primer paso consiste en obtener el arreglo conteniendo los pares entrada-salida (instancias) a usar en el entrenamiento/validación de la red PMC-BP a implementar; dicho arreglo se denominará 'Dataset'. El tamaño de dicho arreglo es de $Z \\times d$, donde $Z$ es el número de instancias (muestras) y $d$ es el número de características o atributos considerados para el problema abordado (incluye los atributos de entrada y los de salida)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "lHAeppdW_e8q",
    "outputId": "be4a459f-13d9-425f-bd6d-6e0cbbe7d8cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.  ],\n",
       "       [ 1.  ,  0.84],\n",
       "       [ 2.  ,  0.91],\n",
       "       [ 3.  ,  0.14],\n",
       "       [ 4.  , -0.77],\n",
       "       [ 5.  , -0.96],\n",
       "       [ 6.  , -0.28],\n",
       "       [ 7.  ,  0.66],\n",
       "       [ 8.  ,  0.99]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset = np.array([[0.00000, 0.00000], [1.00000, 0.84000], [2.00000, 0.91000], [3.00000, 0.14000],\n",
    "[4.00000, -0.77000], [5.00000, -0.96000],[6.00000, -0.28000], [7.00000, 0.66000], [8.00000, 0.99000]])\n",
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "PQUmblTn_e8q",
    "outputId": "339662ed-f65c-4cb2-d5ba-a944a8775d4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xJFV52G_e8q"
   },
   "source": [
    "## Data para el entrenamiento/validación de la red\n",
    "Como sabemos, a partir del dataset obtenido, se deben determinar los conjuntos de datos a emplear en el entrenamiento y en la validación de la red PMC-BP. Enseguida, se deben obtener dos arreglos: uno con los vectores de entrada a usar en el entrenamiento, y el segundo, con los respectivos vectores de salida. Análogamente, se deben determinar los arreglos con los vectores de entrada y de salida, a usar en la validación del entrenamiento. **Sin embargo, para el problema planteado, el dataset se usará tanto para el entrenamiento como para la validación**.\n",
    "\n",
    "Separando los valores de entrada de los de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Hr48ISV7_e8q",
    "outputId": "649fd8d4-c634-4166-8853-9208bad639a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2., 3., 4., 5., 6., 7., 8.]),\n",
       " array([ 0.  ,  0.84,  0.91,  0.14, -0.77, -0.96, -0.28,  0.66,  0.99]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Dataset[:,0]\n",
    "t = Dataset[:,1]\n",
    "X, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "L0tmqcxX_e8r",
    "outputId": "c5dd6b48-055e-4a0e-a4b4-5ba76e3800f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9,), (9,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "sxiXCKVT_e8r",
    "outputId": "dc3bdc08-c4cd-47c4-a353-61323d72eba7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2630852d5b0>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot(X,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQJsVNIL_e8r"
   },
   "source": [
    "## Normalización de los datos\n",
    "Antes de iniciar algún cálculo, sabemos que debemos tener en cuenta las diferencias que existen en las unidades de nuestros datos. Se requiere que los datos de nuestras variables estén en el mismo orden de magnitud, y en un buen número de casos es necesario normalizarlos; de esta manera nuestro modelo trabajará con unidades normalizadas. A pesar de lo indicado, incluso sabedores que hay varios procedimientos de normalización, en este caso, **no vamos a normalizar inicialmente nuestros datos**.\n",
    "\n",
    "## Diseño de la red\n",
    "Inicialmente se considera una topología de la red como la mostrada en la figura, vale decir, con 10 neuronas ocultas. Como función de activación de las neuronas ocultas se usará la logística sigmoidea y en las neuronas de salida, dado que se trata de un problema de aproximación de funciones, se usará una función lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "WGsNXQEa_e8r",
    "outputId": "855b611b-4ff4-4ed2-bdaa-cf13deb780df"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\Cursos\\\\Redes Neuronales\\\\2021-2\\\\arquit-red_aprox-fc_2021-2.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m----> 2\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mCursos\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mRedes Neuronales\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m2021-2\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43marquit-red_aprox-fc_2021-2.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m i\n",
      "File \u001b[1;32m~\\.conda\\envs\\unmsm\\lib\\site-packages\\IPython\\core\\display.py:970\u001b[0m, in \u001b[0;36mImage.__init__\u001b[1;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata, alt)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munconfined \u001b[38;5;241m=\u001b[39m unconfined\n\u001b[0;32m    969\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malt \u001b[38;5;241m=\u001b[39m alt\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m, {}):\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\.conda\\envs\\unmsm\\lib\\site-packages\\IPython\\core\\display.py:327\u001b[0m, in \u001b[0;36mDisplayObject.__init__\u001b[1;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 327\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data()\n",
      "File \u001b[1;32m~\\.conda\\envs\\unmsm\\lib\\site-packages\\IPython\\core\\display.py:1005\u001b[0m, in \u001b[0;36mImage.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed:\n\u001b[1;32m-> 1005\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1006\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretina:\n\u001b[0;32m   1007\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retina_shape()\n",
      "File \u001b[1;32m~\\.conda\\envs\\unmsm\\lib\\site-packages\\IPython\\core\\display.py:353\u001b[0m, in \u001b[0;36mDisplayObject.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_flags \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 353\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_flags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    354\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;66;03m# Deferred import\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\Cursos\\\\Redes Neuronales\\\\2021-2\\\\arquit-red_aprox-fc_2021-2.png'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "i = Image(filename='D:\\\\Cursos\\\\Redes Neuronales\\\\2021-2\\\\arquit-red_aprox-fc_2021-2.png')\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkStZNAt_e8s"
   },
   "source": [
    "## Inicialización de los pesos y biases de la red\n",
    "Según el algoritmo, los parámetros libres de la red se inicializan a valores aleatorios pequeños, los cuales pueden estar en el rangos: [-0.5,0.5] o [-1,1] o en torno de cero. A continuación se presenta el código para inicializarlos, aplicado al **problema planteado**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "lVovH8l6_e8s"
   },
   "outputs": [],
   "source": [
    "# Implementación básica sin funciones\n",
    "intervalo = 0.5\n",
    "capa_entrada = 1\n",
    "capa_oculta = 10\n",
    "capa_salida = 1\n",
    "\n",
    "w1 = np.random.uniform(-intervalo, intervalo, capa_oculta)\n",
    "\n",
    "w2 = np.random.uniform(-intervalo, intervalo, capa_oculta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "CZ0RMbRe_e8s",
    "outputId": "f683c42b-d53b-4b2e-ea4a-14907601f2eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.48543661,  0.32035173,  0.19209055,  0.17775835, -0.38123247,\n",
       "         0.10300245, -0.28683227, -0.35867768, -0.40888733,  0.1403196 ]),\n",
       " array([-0.43644151, -0.48153812,  0.20395238,  0.04731693, -0.36902877,\n",
       "         0.07051824,  0.08115365,  0.16113583,  0.28553806, -0.34650052]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1, w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmCcNM_d_e8s",
    "outputId": "9d457a8a-6bf1-4af0-b0c6-588ff5716fa7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBsY50rR_e8t"
   },
   "source": [
    "### Definición de la función logística sigmoidea\n",
    "Sabemos que la expresión matemática de la función logística sigmoidea `f(n)` es:\n",
    "\n",
    "                         f(u) =  1/1 + exp(-u)\n",
    "\n",
    "donde `u` es el vector de entradas netas. A partir de dicho parámetro, es posible calcular la función logistica sigmoidea; en la sgte celda se presenta el respectivo código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "epFEjYWl_e8t"
   },
   "outputs": [],
   "source": [
    "# Funcion de activacion Logistica Sigmoidea para la unidad de salida\n",
    "def logistica(u):\n",
    "    return 1/(1 + np.exp(-u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Th5dgmub_e8t"
   },
   "source": [
    "Supongamos que se desea aplicar esta función al arreglo 'a'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "TAEvUwwY_e8t",
    "outputId": "8437d4cb-1c63-4f29-c846-8e595401d360"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0.6, -0.8]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[0, 0.6, -0.8]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "9iHeZAXi_e8t",
    "outputId": "c8eae3ea-8366-4e37-df4a-31a00e9f57e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.64565631, 0.31002552]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistica(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4M6Vnr-_e8t"
   },
   "source": [
    "A continuación se presenta la implementación de la derivada de la función logística sigmoidea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "3XH0afOY_e8u"
   },
   "outputs": [],
   "source": [
    "def deriv_logistica(x):\n",
    "    return x * (1.0 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "CQBQqCLR_e8u",
    "outputId": "7b7de73a-c865-432a-c424-840452937c46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.8576"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deriv_logistica(-1.76)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPor0YoF_e8u"
   },
   "source": [
    "## Implementación\n",
    "Luego de haber determinado la topología de la red neuronal, la implementaremos en el lenguaje de programación `Python` con la ayuda de su biblioteca `Numpy`. Enseguida, se efectuarán las sgtes actividades:\n",
    "\n",
    "- Construiremos el algoritmo de aprendizaje de nuestra red PMC, Backpropagation, mediante la función `train()`. Dentro de ella se instancian constantes y variables importantes como globales, de modo que estos valores sean accesibles para toda la función.\n",
    "- Aplicaremos dicho algoritmo de aprendizaje para resolver el problema de aproximación de una función planteado; para tal efecto, se usará el conjunto de datos disponible.\n",
    "\n",
    "En las sgtes celdas se presentan las líneas de código correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "6M-xeAvc_e8u"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "NETtXa7d_e8u"
   },
   "outputs": [],
   "source": [
    "Dataset = np.array([[0.00000, 0.00000], [1.00000, 0.84000], [2.00000, 0.91000], [3.00000, 0.14000],\n",
    "[4.00000, -0.77000], [5.00000, -0.96000],[6.00000, -0.28000], [7.00000, 0.66000], [8.00000, 0.99000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "0YVIEN_G_e8v",
    "outputId": "09e186ca-8f01-4101-f9fc-2c82d36c0d54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2., 3., 4., 5., 6., 7., 8.]),\n",
       " array([ 0.  ,  0.84,  0.91,  0.14, -0.77, -0.96, -0.28,  0.66,  0.99]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Dataset[:,0]\n",
    "t = Dataset[:,1]\n",
    "X, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "2nIZHvFq_e8v"
   },
   "outputs": [],
   "source": [
    "def train(X, t, learning_rate=0.2, epochs=50):\n",
    "    global input_num\n",
    "    global hidden_num\n",
    "    global w1\n",
    "    global w2\n",
    "\n",
    "    input_num = 1\n",
    "    hidden_num = 10\n",
    "    output_num = 1\n",
    "    intervalo = 0.5\n",
    "\n",
    "    # inicializando los pesos\n",
    "    w1 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
    "\n",
    "    w2 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        gradient_out = 0.0                 # gradientes para la capa de salida y la capa oculta\n",
    "        gradient_hidden = []\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "        # propagacion hacia adelante\n",
    "            x = X[i]\n",
    "\n",
    "            u1 = x * w1\n",
    "            o = logistica(u1)\n",
    "            u2 = o.dot(w2)\n",
    "            y = u2\n",
    "\n",
    "        # backpropagation\n",
    "            delta_hidden_s = []           # inicializamos los delta_j a lista vacía\n",
    "            gradient_hidden_s = []       # inicializamos los gradientes de neurs ocultas a lista vacía\n",
    "\n",
    "            delta_out_s = t[i] - y     # cálculo del único delta_k (f'(u) = 1 pq fc de activ es lineal)\n",
    "            gradient_out_s = delta_out_s * o     # error por la salida de la capa anterior\n",
    "\n",
    "            for j in range(hidden_num):\n",
    "\n",
    "                delta_hidden_s.append(deriv_logistica(u1[j]) * w2[j] * delta_out_s)\n",
    "                gradient_hidden_s.append(delta_hidden_s[j] * x)\n",
    "\n",
    "\n",
    "            gradient_out = gradient_out + gradient_out_s\n",
    "            gradient_hidden = gradient_hidden + gradient_hidden_s\n",
    "\n",
    "\n",
    "        print(\"\\n#\", epoch, \"Gradient out: \",gradient_out),\n",
    "        print(\"\\n     Weights  out: \", w1, w2)\n",
    "\n",
    "        # Ahora actualizando pesos\n",
    "        w2 = w2 + learning_rate * gradient_out\n",
    "\n",
    "        for j in range(hidden_num):\n",
    "            w1[j] = w1[j] + learning_rate * gradient_hidden[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "oJgS7qCi_e8v",
    "outputId": "dc1f053a-dec7-40d4-fa7f-6db8b843e96a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 0 Gradient out:  [4.67754966 2.41192841 1.41897651 1.05888044 4.37839218 2.22988246\n",
      " 4.71423501 4.73714912 4.04253004 3.68432291]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [ 0.05247443  0.26493141 -0.04954986 -0.1587592   0.16138252  0.4393208\n",
      " -0.20448302 -0.48738186 -0.04361713 -0.48445625]\n",
      "\n",
      "# 1 Gradient out:  [-27.38960038 -13.95147333  -7.9024863   -5.35567761 -25.30282729\n",
      " -12.9201749  -27.65293504 -27.81733918 -23.14870183 -21.02112634]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [0.98798436 0.74731709 0.23424544 0.05301689 1.03706095 0.88529729\n",
      " 0.73836398 0.46004796 0.76488888 0.25240833]\n",
      "\n",
      "# 2 Gradient out:  [158.66520367  80.93325168  46.10010886  31.77704272 146.90412491\n",
      "  74.9197651  160.14286966 161.06541795 134.60355818 122.29926109]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [-4.48993572 -2.04297758 -1.34625182 -1.01811863 -4.02350451 -1.69873769\n",
      " -4.79222302 -5.10341988 -3.86485149 -3.95181693]\n",
      "\n",
      "# 3 Gradient out:  [-920.68527508 -469.56337609 -267.24938335 -183.70950991 -852.11542831\n",
      " -434.71234752 -929.30734002 -934.69035596 -780.5671193  -709.15617011]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [27.24310501 14.14367276  7.87376995  5.33728991 25.35732048 13.28521533\n",
      " 27.23635091 27.10966372 23.05586015 20.50803528]\n",
      "\n",
      "# 4 Gradient out:  [5341.018526   2724.02880098 1550.54935444 1066.34777326 4943.55614532\n",
      " 2521.80662216 5390.98889491 5422.18685913 4528.66134745 4114.40344901]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [-156.89395     -79.76900246  -45.57610672  -31.40461207 -145.06576519\n",
      "  -73.65725417 -158.62511709 -159.82840748 -133.05756371 -121.32319874]\n",
      "\n",
      "# 5 Gradient out:  [-30985.29649617 -15803.13865213  -8995.17726284  -6185.71649998\n",
      " -28679.14724867 -14630.01967878 -31275.24093982 -31456.26181654\n",
      " -26272.02138172 -23868.75110896]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [911.3097552  465.03675774 264.53376417 181.86494258 843.64546388\n",
      " 430.70407026 919.57266189 924.60896435 772.67470578 701.55749106]\n",
      "\n",
      "# 6 Gradient out:  [179756.33716268  91679.40060457  52184.22608948  35885.9994668\n",
      " 166377.88907727  84873.68323521 181438.3573985  182488.49220217\n",
      " 152413.48425357 138471.28579929]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [-5285.74954404 -2695.59097269 -1534.5016884  -1055.27835742\n",
      " -4892.18398586 -2495.2998655  -5335.47552608 -5366.64339896\n",
      " -4481.72957056 -4072.19273073]\n",
      "\n",
      "# 7 Gradient out:  [-1042829.37225988  -531864.31406206  -302738.85936713  -208186.73018667\n",
      "  -965216.00371044  -492382.02115168 -1052587.40663044 -1058679.63517022\n",
      "  -884203.45285015  -803319.89056514]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [30665.5178885  15640.28914823  8902.3435295   6121.92153594\n",
      " 28383.3938296  14479.43678154 30952.19595362 31131.05504147\n",
      " 26000.96728015 23622.06442913]\n",
      "\n",
      "# 8 Gradient out:  [6049816.74220338 3085530.23669877 1756293.7237314  1207764.27443674\n",
      " 5599554.84430839 2856479.63612936 6106426.45485175 6141769.56728529\n",
      " 5129572.94648459 4660339.19441674]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [-177900.35656348  -90732.57366419  -51645.42834393  -35515.42450139\n",
      " -164659.80691249  -83996.96744879 -179565.28537247 -180604.87199257\n",
      " -150839.72328988 -137041.9136839 ]\n",
      "\n",
      "# 9 Gradient out:  [-35097097.09633251 -17900237.21919253 -10188872.44866962\n",
      "  -7006661.37313726 -32484970.46632103 -16571434.84868057\n",
      " -35425509.83129562 -35630547.5833075  -29758441.39718221\n",
      " -27036252.74463513]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [1032062.9918772   526373.47367557  299613.31640235  206037.43038596\n",
      "  955251.16194919  487298.95977708 1041720.00559788 1047749.04146449\n",
      "  875074.86600704  795025.92519945]\n",
      "\n",
      "# 10 Gradient out:  [2.03610501e+08 1.03845519e+08 5.91092027e+07 4.06480868e+07\n",
      " 1.88456644e+08 9.61366730e+07 2.05515738e+08 2.06705233e+08\n",
      " 1.72639098e+08 1.56846732e+08]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [-5987356.4273893  -3053673.97016294 -1738161.17333157 -1195294.84424149\n",
      " -5541742.93131502 -2826988.00995904 -6043381.96066124 -6078360.47519701\n",
      " -5076613.41342941 -4612224.62372758]\n",
      "\n",
      "# 11 Gradient out:  [-1.18121553e+09 -6.02444075e+08 -3.42913101e+08 -2.35813728e+08\n",
      " -1.09330272e+09 -5.57722371e+08 -1.19226847e+09 -1.19916915e+09\n",
      " -1.00153962e+09 -9.09922596e+08]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [34734743.78928935 17715429.84681996 10083679.36095923  6934322.51032701\n",
      " 32149585.82424773 16400346.5959427  35059765.60999396 35262686.19175737\n",
      " 29451206.15928418 26757121.78779003]\n",
      "\n",
      "# 12 Gradient out:  [6.85264327e+09 3.49498820e+09 1.98935850e+09 1.36803768e+09\n",
      " 6.34263039e+09 3.23554199e+09 6.91676525e+09 6.95679849e+09\n",
      " 5.81028064e+09 5.27877834e+09]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [-2.01508362e+08 -1.02773385e+08 -5.84989407e+07 -4.02284231e+07\n",
      " -1.86510958e+08 -9.51441275e+07 -2.03393929e+08 -2.04571144e+08\n",
      " -1.70856718e+08 -1.55227398e+08]\n",
      "\n",
      "# 13 Gradient out:  [-3.97545737e+10 -2.02756455e+10 -1.15409625e+10 -7.93646373e+09\n",
      " -3.67958110e+10 -1.87705076e+10 -4.01265676e+10 -4.03588144e+10\n",
      " -3.37074645e+10 -3.06240343e+10]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [1.16902029e+09 5.96224254e+08 3.39372758e+08 2.33379113e+08\n",
      " 1.08201512e+09 5.51964271e+08 1.17995912e+09 1.18678855e+09\n",
      " 9.91199410e+08 9.00528271e+08]\n",
      "\n",
      "# 14 Gradient out:  [2.30630147e+11 1.17626091e+11 6.69531485e+10 4.60421941e+10\n",
      " 2.13465333e+11 1.08894261e+11 2.32788214e+11 2.34135559e+11\n",
      " 1.95548758e+11 1.77660704e+11]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [-6.78189444e+09 -3.45890484e+09 -1.96881974e+09 -1.35391363e+09\n",
      " -6.27714709e+09 -3.20213724e+09 -6.84535440e+09 -6.88497433e+09\n",
      " -5.75029348e+09 -5.22427858e+09]\n",
      "\n",
      "# 15 Gradient out:  [-1.33796592e+12 -6.82389980e+11 -3.88418566e+11 -2.67106827e+11\n",
      " -1.23838685e+12 -6.31733588e+11 -1.35048562e+12 -1.35830204e+12\n",
      " -1.13444655e+12 -1.03067171e+12]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [3.93441350e+10 2.00663134e+10 1.14218100e+10 7.85452520e+09\n",
      " 3.64159196e+10 1.85767150e+10 3.97122884e+10 3.99421374e+10\n",
      " 3.33594580e+10 3.03078621e+10]\n",
      "\n",
      "# 16 Gradient out:  [7.76200696e+12 3.95878227e+12 2.25335157e+12 1.54957986e+12\n",
      " 7.18431403e+12 3.66490688e+12 7.83463809e+12 7.87998385e+12\n",
      " 6.58132008e+12 5.97928603e+12]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [-2.28249049e+11 -1.16411683e+11 -6.62619032e+10 -4.55668401e+10\n",
      " -2.11261450e+11 -1.07770003e+11 -2.30384835e+11 -2.31718270e+11\n",
      " -1.93529851e+11 -1.75826479e+11]\n",
      "\n",
      "# 17 Gradient out:  [-4.50301096e+13 -2.29662767e+13 -1.30724784e+13 -8.98965323e+12\n",
      " -4.16787114e+13 -2.12614030e+13 -4.54514681e+13 -4.57145346e+13\n",
      " -3.81805332e+13 -3.46879237e+13]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [1.32415234e+12 6.75344772e+11 3.84408411e+11 2.64349132e+11\n",
      " 1.22560136e+12 6.25211373e+11 1.33654278e+12 1.34427850e+12\n",
      " 1.12273416e+12 1.02003073e+12]\n",
      "\n",
      "# 18 Gradient out:  [2.61235371e+14 1.33235381e+14 7.58380064e+13 5.21521137e+13\n",
      " 2.41792741e+14 1.23344814e+14 2.63679819e+14 2.65205960e+14\n",
      " 2.21498589e+14 2.01236744e+14]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [-7.68186957e+12 -3.91791056e+12 -2.23008726e+12 -1.53358151e+12\n",
      " -7.11014093e+12 -3.62706923e+12 -7.75375084e+12 -7.79862843e+12\n",
      " -6.51337247e+12 -5.91755401e+12]\n",
      "\n",
      "# 19 Gradient out:  [-1.51551750e+15 -7.72944915e+14 -4.39962726e+14 -3.02552601e+14\n",
      " -1.40272402e+15 -7.15566287e+14 -1.52969859e+15 -1.53855227e+15\n",
      " -1.28499057e+15 -1.16744454e+15]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [4.45652046e+13 2.27291657e+13 1.29375140e+13 8.89684123e+12\n",
      " 4.12484074e+13 2.10418936e+13 4.49822129e+13 4.52425635e+13\n",
      " 3.77863454e+13 3.43297947e+13]\n",
      "\n",
      "# 20 Gradient out:  [8.79204559e+15 4.48412303e+15 2.55237722e+15 1.75521316e+15\n",
      " 8.13769130e+15 4.15124960e+15 8.87431506e+15 8.92567832e+15\n",
      " 7.45467847e+15 6.77275293e+15]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [-2.58538295e+14 -1.31859817e+14 -7.50550311e+13 -5.16136790e+13\n",
      " -2.39296397e+14 -1.22071364e+14 -2.60957506e+14 -2.62467890e+14\n",
      " -2.19211769e+14 -1.99159113e+14]\n",
      "\n",
      "# 21 Gradient out:  [-5.10057229e+16 -2.60139617e+16 -1.48072305e+16 -1.01826037e+16\n",
      " -4.72095854e+16 -2.40828468e+16 -5.14829968e+16 -5.17809730e+16\n",
      " -4.32471898e+16 -3.92911019e+16]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [1.49987082e+15 7.64964790e+14 4.35420413e+14 2.99428953e+14\n",
      " 1.38824186e+15 7.08178557e+14 1.51390551e+15 1.52266777e+15\n",
      " 1.27172392e+15 1.15539147e+15]\n",
      "\n",
      "# 22 Gradient out:  [2.95901988e+17 1.50916065e+17 8.59019082e+16 5.90728356e+16\n",
      " 2.73879271e+17 1.39712994e+17 2.98670820e+17 3.00399484e+17\n",
      " 2.50892031e+17 2.27941386e+17]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [-8.70127376e+15 -4.43782754e+15 -2.52602568e+15 -1.73709179e+15\n",
      " -8.05367523e+15 -4.10839080e+15 -8.78269385e+15 -8.83352682e+15\n",
      " -7.37771403e+15 -6.70282891e+15]\n",
      "\n",
      "# 23 Gradient out:  [-1.71663064e+18 -8.75516727e+17 -4.98346930e+17 -3.42702123e+17\n",
      " -1.58886917e+18 -8.10523805e+17 -1.73269360e+18 -1.74272218e+18\n",
      " -1.45551218e+18 -1.32236748e+18]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [5.04791238e+16 2.57453854e+16 1.46543560e+16 1.00774753e+16\n",
      " 4.67221789e+16 2.38342080e+16 5.09514702e+16 5.12463700e+16\n",
      " 4.28006923e+16 3.88854483e+16]\n",
      "\n",
      "# 24 Gradient out:  [9.95877303e+18 5.07917789e+18 2.89108435e+18 1.98813454e+18\n",
      " 9.21758422e+18 4.70213128e+18 1.00519599e+19 1.01101392e+19\n",
      " 8.44393380e+18 7.67151496e+18]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [-2.92847003e+17 -1.49357960e+17 -8.50150300e+16 -5.84629492e+16\n",
      " -2.71051655e+17 -1.38270553e+17 -2.95587249e+17 -2.97298066e+17\n",
      " -2.48301744e+17 -2.25588048e+17]\n",
      "\n",
      "# 25 Gradient out:  [-5.77743157e+19 -2.94660824e+19 -1.67721887e+19 -1.15338619e+19\n",
      " -5.34744209e+19 -2.72787036e+19 -5.83149251e+19 -5.86524435e+19\n",
      " -4.89862050e+19 -4.45051339e+19]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [1.69890760e+18 8.66477618e+17 4.93201840e+17 3.39163959e+17\n",
      " 1.57246519e+18 8.02155704e+17 1.71480473e+18 1.72472977e+18\n",
      " 1.44048502e+18 1.30871494e+18]\n",
      "\n",
      "# 26 Gradient out:  [3.35168956e+20 1.70943021e+20 9.73013161e+19 6.69119554e+19\n",
      " 3.10223766e+20 1.58253274e+20 3.38305219e+20 3.40263281e+20\n",
      " 2.84186060e+20 2.58189804e+20]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [-9.85595554e+18 -5.02673887e+18 -2.86123589e+18 -1.96760842e+18\n",
      " -9.12241899e+18 -4.65358501e+18 -9.94818030e+18 -1.00057589e+19\n",
      " -8.35675598e+18 -7.59231184e+18]\n",
      "\n",
      "# 27 Gradient out:  [-1.94443201e+21 -9.91700086e+20 -5.64478871e+20 -3.88179591e+20\n",
      " -1.79971627e+21 -9.18082434e+20 -1.96262657e+21 -1.97398597e+21\n",
      " -1.64866245e+21 -1.49784910e+21]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [5.71778356e+19 2.91618654e+19 1.65990273e+19 1.14147827e+19\n",
      " 5.29223343e+19 2.69970697e+19 5.77128636e+19 5.80468973e+19\n",
      " 4.84804561e+19 4.40456490e+19]\n",
      "\n",
      "# 28 Gradient out:  [1.12803283e+22 5.75319808e+21 3.27473881e+21 2.25196519e+21\n",
      " 1.04407818e+22 5.32611641e+21 1.13858812e+22 1.14517811e+22\n",
      " 9.56446590e+21 8.68954506e+21]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [-3.31708567e+20 -1.69178152e+20 -9.62967469e+19 -6.62211355e+19\n",
      " -3.07020919e+20 -1.56619417e+20 -3.34812450e+20 -3.36750297e+20\n",
      " -2.81252034e+20 -2.55524172e+20]\n",
      "\n",
      "# 29 Gradient out:  [-6.54411185e+22 -3.33763086e+22 -1.89979020e+22 -1.30644355e+22\n",
      " -6.05706164e+22 -3.08986589e+22 -6.60534682e+22 -6.64357762e+22\n",
      " -5.54868025e+22 -5.04110816e+22]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [1.92435709e+21 9.81461464e+20 5.58651015e+20 3.84171903e+20\n",
      " 1.78113543e+21 9.08603864e+20 1.94236380e+21 1.95360592e+21\n",
      " 1.63164115e+21 1.48238484e+21]\n",
      "\n",
      "# 30 Gradient out:  [3.79646753e+23 1.93627607e+23 1.10213455e+23 7.57913470e+22\n",
      " 3.51391271e+23 1.79253897e+23 3.83199207e+23 3.85417109e+23\n",
      " 3.21898294e+23 2.92452266e+23]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [-1.11638666e+22 -5.69380026e+21 -3.24092938e+21 -2.22871520e+21\n",
      " -1.03329879e+22 -5.27112791e+21 -1.12683298e+22 -1.13335493e+22\n",
      " -9.46571936e+21 -8.59983148e+21]\n",
      "\n",
      "# 31 Gradient out:  [-2.20246322e+24 -1.12330128e+24 -6.39386694e+23 -4.39692038e+23\n",
      " -2.03854332e+24 -1.03991437e+24 -2.22307225e+24 -2.23593907e+24\n",
      " -1.86744427e+24 -1.69661760e+24]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [6.47654840e+22 3.30317212e+22 1.88017617e+22 1.29295542e+22\n",
      " 5.99452664e+22 3.05796515e+22 6.53715115e+22 6.57498724e+22\n",
      " 5.49139394e+22 4.98906218e+22]\n",
      "\n",
      "# 32 Gradient out:  [1.27772573e+25 6.51666251e+24 3.70930521e+24 2.55080686e+24\n",
      " 1.18263008e+25 6.03290598e+24 1.28968175e+25 1.29714624e+25\n",
      " 1.08336955e+25 9.84267042e+24]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [-3.75727161e+23 -1.91628535e+23 -1.09075577e+23 -7.50088534e+22\n",
      " -3.47763398e+23 -1.77403224e+23 -3.79242938e+23 -3.81437942e+23\n",
      " -3.18574915e+23 -2.89432898e+23]\n",
      "\n",
      "# 33 Gradient out:  [-7.41253262e+25 -3.78054321e+25 -2.15189733e+25 -1.47981203e+25\n",
      " -6.86084957e+25 -3.49989917e+25 -7.48189362e+25 -7.52519775e+25\n",
      " -6.28500464e+25 -5.71007640e+25]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [2.17972430e+24 1.11170397e+24 6.32785465e+23 4.35152520e+23\n",
      " 2.01749676e+24 1.02917797e+24 2.20012056e+24 2.21285454e+24\n",
      " 1.84816419e+24 1.67910119e+24]\n",
      "\n",
      "# 34 Gradient out:  [4.30026870e+26 2.19322497e+26 1.24839069e+26 8.58490569e+25\n",
      " 3.98021812e+26 2.03041358e+26 4.34050744e+26 4.36562967e+26\n",
      " 3.64615039e+26 3.31261447e+26]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [-1.26453409e+25 -6.44938245e+24 -3.67100918e+24 -2.52447154e+24\n",
      " -1.17042024e+25 -5.97062037e+24 -1.27636667e+25 -1.28375410e+25\n",
      " -1.07218451e+25 -9.74105161e+24]\n",
      "\n",
      "# 35 Gradient out:  [-2.49473586e+27 -1.27236630e+27 -7.24234981e+26 -4.98040321e+26\n",
      " -2.30906335e+27 -1.17791373e+27 -2.51807975e+27 -2.53265404e+27\n",
      " -2.11525901e+27 -1.92176319e+27]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [7.33600331e+25 3.74151170e+25 2.12968046e+25 1.46453399e+25\n",
      " 6.79001601e+25 3.46376512e+25 7.40464821e+25 7.44750525e+25\n",
      " 6.22011628e+25 5.65112378e+25]\n",
      "\n",
      "# 36 Gradient out:  [1.44728328e+28 7.38144068e+27 4.20153972e+27 2.88930561e+27\n",
      " 1.33956819e+28 6.83348839e+27 1.46082589e+28 1.46928094e+28\n",
      " 1.22713553e+28 1.11488185e+28]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [-4.25587138e+26 -2.17058143e+26 -1.23550191e+26 -8.49627244e+25\n",
      " -3.93912510e+26 -2.00945095e+26 -4.29569468e+26 -4.32055755e+26\n",
      " -3.60850640e+26 -3.27841400e+26]\n",
      "\n",
      "# 37 Gradient out:  [-8.39619508e+28 -4.28223118e+28 -2.43745973e+28 -1.67618695e+28\n",
      " -7.77130225e+28 -3.96434495e+28 -8.47476048e+28 -8.52381117e+28\n",
      " -7.11904119e+28 -6.46781847e+28]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [2.46897942e+27 1.25922999e+27 7.16757752e+26 4.92898397e+26\n",
      " 2.28522386e+27 1.16575258e+27 2.49208231e+27 2.50650612e+27\n",
      " 2.09342042e+27 1.90192231e+27]\n",
      "\n",
      "# 38 Gradient out:  [4.87092560e+29 2.48427166e+29 1.41405540e+29 9.72414513e+28\n",
      " 4.50840348e+29 2.29985477e+29 4.91650413e+29 4.94496015e+29\n",
      " 4.13000409e+29 3.75220708e+29]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [-1.43234107e+28 -7.30523237e+27 -4.15816171e+27 -2.85947551e+27\n",
      " -1.32573806e+28 -6.76293731e+27 -1.44574386e+28 -1.45411162e+28\n",
      " -1.21446620e+28 -1.10337146e+28]\n",
      "\n",
      "# 39 Gradient out:  [-2.82579383e+30 -1.44121264e+30 -8.20342857e+29 -5.64131575e+29\n",
      " -2.61548210e+30 -1.33422597e+30 -2.85223552e+30 -2.86874385e+30\n",
      " -2.39595942e+30 -2.17678619e+30]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [8.30951014e+28 4.23802009e+28 2.41229463e+28 1.65888148e+28\n",
      " 7.69106889e+28 3.92341581e+28 8.38726440e+28 8.43580868e+28\n",
      " 7.04554198e+28 6.40104269e+28]\n",
      "\n",
      "# 40 Gradient out:  [1.63934156e+31 8.36097716e+30 4.75909503e+30 3.27272402e+30\n",
      " 1.51733239e+31 7.74031017e+30 1.65468130e+31 1.66425836e+31\n",
      " 1.38997962e+31 1.26282959e+31]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [-4.82063664e+29 -2.45862326e+29 -1.39945625e+29 -9.62375002e+28\n",
      " -4.46185731e+29 -2.27611035e+29 -4.86574460e+29 -4.89390683e+29\n",
      " -4.08736463e+29 -3.71346812e+29]\n",
      "\n",
      "# 41 Gradient out:  [-9.51039213e+31 -4.85049446e+31 -2.76091701e+31 -1.89862135e+31\n",
      " -8.80257439e+31 -4.49042389e+31 -9.59938336e+31 -9.65494321e+31\n",
      " -8.06375658e+31 -7.32611490e+31]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [2.79661945e+30 1.42633311e+30 8.11873380e+29 5.58307304e+29\n",
      " 2.58847904e+30 1.32045100e+30 2.82278815e+30 2.83912604e+30\n",
      " 2.37122278e+30 2.15431237e+30]\n",
      "\n",
      "# 42 Gradient out:  [5.51731017e+32 2.81394101e+32 1.60170425e+32 1.10145646e+32\n",
      " 5.10668041e+32 2.60505151e+32 5.56893709e+32 5.60116930e+32\n",
      " 4.67806643e+32 4.25013477e+32]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [-1.62241648e+31 -8.27465582e+30 -4.70996064e+30 -3.23893539e+30\n",
      " -1.50166697e+31 -7.66039679e+30 -1.63759786e+31 -1.64707604e+31\n",
      " -1.37562904e+31 -1.24979174e+31]\n",
      "\n",
      "# 43 Gradient out:  [-3.20078406e+33 -1.63246532e+33 -9.29204500e+32 -6.38993310e+32\n",
      " -2.96256342e+33 -1.51128124e+33 -3.23073464e+33 -3.24943366e+33\n",
      " -2.71390950e+33 -2.46565141e+33]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [9.41220387e+31 4.80041644e+31 2.73241244e+31 1.87901939e+31\n",
      " 8.71169385e+31 4.44406335e+31 9.50027632e+31 9.55526255e+31\n",
      " 7.98050383e+31 7.25047780e+31]\n",
      "\n",
      "# 44 Gradient out:  [1.85688647e+34 9.47050070e+33 5.39063939e+33 3.70702306e+33\n",
      " 1.71868636e+34 8.76746958e+33 1.87426184e+34 1.88510980e+34\n",
      " 1.57443355e+34 1.43041038e+34]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [-5.46034774e+32 -2.78488900e+32 -1.58516776e+32 -1.09008468e+32\n",
      " -5.05395745e+32 -2.57815615e+32 -5.51144164e+32 -5.54334107e+32\n",
      " -4.62976861e+32 -4.20625505e+32]\n",
      "\n",
      "# 45 Gradient out:  [-1.07724460e+35 -5.49416776e+34 -3.12729792e+34 -2.15057337e+34\n",
      " -9.97069903e+34 -5.08631489e+34 -1.08732466e+35 -1.09361794e+35\n",
      " -9.13383817e+34 -8.29830951e+34]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [3.16773816e+33 1.61561124e+33 9.19611102e+32 6.32396143e+32\n",
      " 2.93197698e+33 1.49567830e+33 3.19737952e+33 3.21588549e+33\n",
      " 2.68589025e+33 2.44019526e+33]\n",
      "\n",
      "# 46 Gradient out:  [6.24947166e+35 3.18735834e+35 1.81425460e+35 1.24762262e+35\n",
      " 5.78435026e+35 2.95074866e+35 6.30794961e+35 6.34445911e+35\n",
      " 5.29885809e+35 4.81413877e+35]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [-1.83771539e+34 -9.37272429e+33 -5.33498474e+33 -3.66875059e+33\n",
      " -1.70094211e+34 -8.67695148e+33 -1.85491138e+34 -1.86564734e+34\n",
      " -1.55817861e+34 -1.41564238e+34]\n",
      "\n",
      "# 47 Gradient out:  [-3.62553648e+36 -1.84909774e+36 -1.05251237e+36 -7.23789394e+35\n",
      " -3.35570333e+36 -1.71183221e+36 -3.65946157e+36 -3.68064201e+36\n",
      " -3.07405239e+36 -2.79284981e+36]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [1.06612279e+35 5.43744426e+34 3.09501072e+34 2.12837017e+34\n",
      " 9.86775841e+34 5.03380218e+34 1.07609878e+35 1.08232709e+35\n",
      " 9.03953756e+34 8.21263516e+34]\n",
      "\n",
      "# 48 Gradient out:  [2.10330016e+37 1.07272609e+37 6.10599133e+36 4.19895471e+36\n",
      " 1.94676054e+37 9.93093572e+36 2.12298129e+37 2.13526880e+37\n",
      " 1.78336500e+37 1.62022958e+37]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [-6.18495016e+35 -3.15445106e+35 -1.79552366e+35 -1.23474177e+35\n",
      " -5.72463082e+35 -2.92028421e+35 -6.24282436e+35 -6.27895693e+35\n",
      " -5.24415102e+35 -4.76443609e+35]\n",
      "\n",
      "# 49 Gradient out:  [-1.22019778e+38 -6.22325820e+37 -3.54229853e+37 -2.43596008e+37\n",
      " -1.12938369e+38 -5.76128218e+37 -1.23161549e+38 -1.23874390e+38\n",
      " -1.03459224e+38 -9.39951689e+37]\n",
      "\n",
      "     Weights  out:  [ 0.41151227 -0.08081722 -0.30672053 -0.48899476  0.28489919 -0.11173181\n",
      "  0.43237358  0.44622384  0.19346445  0.12130329] [3.58810530e+36 1.83000708e+36 1.04164590e+36 7.16316766e+35\n",
      " 3.32105800e+36 1.69415872e+36 3.62168015e+36 3.64264191e+36\n",
      " 3.04231491e+36 2.76401555e+36]\n"
     ]
    }
   ],
   "source": [
    "train(X, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6KIURxgz_e8v"
   },
   "source": [
    "## Ejercicios\n",
    "### Ejercicio A  (3 puntos)\n",
    "1. Obtenga, a partir del código presentado para el entrenamiento de la PMC-BP, el algoritmo de recuerdo de la red.\n",
    "2. Aplique ahora dicho algoritmo de recuerdo en la etapa denominada *Validación* para el mismo problema de regresión. Determine el error cuadrático de la red en cada época y grafique sus resultados.\n",
    "\n",
    "### Ejercicio B  (5 puntos)\n",
    "1. Use la función tangente hiperbólica en lugar de la lineal en la capa de salida para abordar el mismo problema. Con ese objetivo defina la(s) función(nes) que se requieran e insértelas en el código de modo que la red funcione correctamente. Mantenga inalterada la arquitectura de la red.\n",
    "2. A partir de las modificaciones pedidas, entrene nuevamente la red al mismo problema de regresión. Enseguida aplique el algoritmo de recuerdo.\n",
    "3. Compare los resultados que obtenga con los obtenidos con la red PMC-BP que usaba una función lineal en la salida.\n",
    "\n",
    "### Ejercicio C (4 puntos)\n",
    "1. Modifique la arquitectura de la red PMC usando ahora 4, 6, 8 y 12 neuronas en la capa oculta. Aplique las etapas de entrenamiento/validación de la red.\n",
    "2. Determine el mejor modelo, indicando específicamente con cuántas neuronas ocultas obtuvo la mejor respuesta de la red.\n",
    "\n",
    "### Ejercicio D (8 puntos)\n",
    "1. Modifique la arquitectura de la red PMC usando ahora **dos capas ocultas**, inicialmente con 10 neuronas en la primera capa oculta y 8 neuronas en la segunda capa oculta. Use diferentes números de neuronas en las capas ocultas. Aplique las etapas de entrenamiento/validación de la red para cada combinación.\n",
    "2. Determine con qué combinación de neuronas en las capas ocultas obtuvo el mejor modelo, el que produjo la mejor respuesta de la red.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIjpy3jH_e8v"
   },
   "source": [
    "## Instrucciones para el envío de la solución\n",
    "La solución de la \"Práctica de Laboratorio 8 IA 2025-1 EPISW\" deberá enviarse al correo electrónico rmaguinacursos@gmail.com, hasta las 23:59 h del Domingo 08 de Junio del 2025 en un cuaderno computacional interactivo (archivo con extensión .ipynb).\n",
    "\n",
    "El documento deberá tener las sgtes características:\n",
    "- Nombre del archivo: solPGL8_IA_2025-1_EPISW_nombre-apellidos_integrantes.ipynb.\n",
    "- Todas las preguntas de la Práctica deben responderse en el mismo cci (**Sugerencia**: obtener una copia de este documento y desarrollar en ellas las respectivas soluciones); la solución a cada pregunta debe registrarse en una celda debajo del planteamiento de la misma, mencionando explícitamente como subtítulo: \\\"Solución del ejercicio n\\\", donde \\\"n\\\" corresponde al número del ejercicio.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución del ejercicio A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Obtenga, a partir del código presentado para el entrenamiento de la PMC-BP, el algoritmo de recuerdo de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función auxiliar necesaria\n",
    "def logistica(u):\n",
    "    return 1/(1 + np.exp(-u))\n",
    "\n",
    "# Extraído de la fase de propagación hacia adelante del código de entrenamiento.\n",
    "def recall(x, w1, w2):\n",
    "    # Capa oculta\n",
    "    u1 = x * w1        # Entrada neta de las neuronas ocultas\n",
    "    o = logistica(u1)  # (función sigmoidea)\n",
    "    \n",
    "    # Capa de salida\n",
    "    u2 = o.dot(w2)     # Entrada neta de la neurona de salida\n",
    "    y = u2             # Salida final (función lineal)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Aplique ahora dicho algoritmo de recuerdo en la etapa denominada Validación para el mismo problema de regresión. Determine el error cuadrático de la red en cada época y grafique sus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIÓN DE ENTRENAMIENTO MODIFICADA PARA INCLUIR VALIDACIÓN\n",
    "\n",
    "def train_with_validation(X, t, learning_rate=0.2, epochs=50):\n",
    "    # Variables globales\n",
    "    input_num = 1\n",
    "    hidden_num = 10\n",
    "    output_num = 1\n",
    "    intervalo = 0.5\n",
    "\n",
    "    # Inicializando los pesos\n",
    "    w1 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
    "    w2 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
    "    \n",
    "    validation_errors = []\n",
    "\n",
    "    print(\"APLICACIÓN DEL ALGORITMO DE RECUERDO EN VALIDACIÓN\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Época\\t\\tError Cuadrático de Validación\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # FASE DE ENTRENAMIENTO\n",
    "        gradient_out = 0.0\n",
    "        gradient_hidden = np.zeros(hidden_num)\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            # Propagación hacia adelante\n",
    "            x = X[i]\n",
    "            u1 = x * w1\n",
    "            o = logistica(u1)\n",
    "            u2 = o.dot(w2)\n",
    "            y = u2\n",
    "\n",
    "            # Backpropagation\n",
    "            delta_hidden_s = []\n",
    "            gradient_hidden_s = []\n",
    "\n",
    "            delta_out_s = t[i] - y\n",
    "            gradient_out_s = delta_out_s * o\n",
    "\n",
    "            for j in range(hidden_num):\n",
    "                delta_hidden_s.append(deriv_logistica(o[j]) * w2[j] * delta_out_s)\n",
    "                gradient_hidden_s.append(delta_hidden_s[j] * x)\n",
    "\n",
    "            gradient_out = gradient_out + gradient_out_s\n",
    "            gradient_hidden = gradient_hidden + np.array(gradient_hidden_s)\n",
    "\n",
    "        # Actualizar pesos\n",
    "        w2 = w2 + learning_rate * gradient_out\n",
    "        for j in range(hidden_num):\n",
    "            w1[j] = w1[j] + learning_rate * gradient_hidden[j]\n",
    "\n",
    "        # FASE DE VALIDACIÓN - APLICACIÓN DEL ALGORITMO DE RECUERDO\n",
    "        \n",
    "        total_squared_error = 0.0\n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            # Aplicar algoritmo de recuerdo para obtener predicción\n",
    "            y_pred = recall(X[i], w1, w2)\n",
    "            \n",
    "            # Calcular error cuadrático para esta muestra\n",
    "            squared_error = (t[i] - y_pred)**2\n",
    "            total_squared_error += squared_error\n",
    "        \n",
    "        # Error cuadrático medio de la época\n",
    "        mse_validation = total_squared_error / X.shape[0]\n",
    "        validation_errors.append(mse_validation)\n",
    "        \n",
    "        # Mostrar progreso\n",
    "        print(f\"{epoch}\\t\\t{mse_validation:.8f}\")\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Error final: {validation_errors[-1]:.8f}\")\n",
    "    \n",
    "    return validation_errors, w1, w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EJECUTAMOS ENTRENAMIENTO CON VALIDACIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APLICACIÓN DEL ALGORITMO DE RECUERDO EN VALIDACIÓN\n",
      "============================================================\n",
      "Época\t\tError Cuadrático de Validación\n",
      "----------------------------------------\n",
      "0\t\t0.55389724\n",
      "1\t\t2.30458748\n",
      "2\t\t16.39099252\n",
      "3\t\t7.90580149\n",
      "4\t\t2.40446508\n",
      "5\t\t1.11930457\n",
      "6\t\t0.80154472\n",
      "7\t\t0.70591921\n",
      "8\t\t0.66431444\n",
      "9\t\t0.63823634\n",
      "10\t\t0.61815906\n",
      "11\t\t0.60127798\n",
      "12\t\t0.58649736\n",
      "13\t\t0.57323918\n",
      "14\t\t0.56113013\n",
      "15\t\t0.54990387\n",
      "16\t\t0.53936241\n",
      "17\t\t0.52935733\n",
      "18\t\t0.51977936\n",
      "19\t\t0.51055262\n",
      "20\t\t0.50163140\n",
      "21\t\t0.49299854\n",
      "22\t\t0.48466392\n",
      "23\t\t0.47666194\n",
      "24\t\t0.46904656\n",
      "25\t\t0.46188294\n",
      "26\t\t0.45523586\n",
      "27\t\t0.44915651\n",
      "28\t\t0.44367115\n",
      "29\t\t0.43877525\n",
      "30\t\t0.43443496\n",
      "31\t\t0.43059516\n",
      "32\t\t0.42719026\n",
      "33\t\t0.42415425\n",
      "34\t\t0.42142725\n",
      "35\t\t0.41895854\n",
      "36\t\t0.41670682\n",
      "37\t\t0.41463919\n",
      "38\t\t0.41272958\n",
      "39\t\t0.41095725\n",
      "40\t\t0.40930560\n",
      "41\t\t0.40776114\n",
      "42\t\t0.40631281\n",
      "43\t\t0.40495138\n",
      "44\t\t0.40366907\n",
      "45\t\t0.40245920\n",
      "46\t\t0.40131600\n",
      "47\t\t0.40023441\n",
      "48\t\t0.39920992\n",
      "49\t\t0.39823854\n",
      "----------------------------------------\n",
      "Error final: 0.39823854\n"
     ]
    }
   ],
   "source": [
    "validation_errors, final_w1, final_w2 = train_with_validation(X, t, learning_rate=0.2, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRAFICAMOS LOS RESULTADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x500 with 0 Axes>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gráfico 1: Evolución del error cuadrático en validación\n",
    "plt.subplot(1, 2, 1)\n",
    "epochs_range = range(len(validation_errors))\n",
    "plt.plot(epochs_range, validation_errors, 'r-', linewidth=2, marker='o', markersize=4)\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Error Cuadrático de Validación')\n",
    "plt.title('Error Cuadrático de Validación por Época\\n(usando Algoritmo de Recuerdo)')\n",
    "plt.grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error cuadrático final de validación: 0.39823854\n"
     ]
    }
   ],
   "source": [
    "# Gráfico 2: Predicciones finales vs valores reales\n",
    "plt.subplot(1, 2, 2)\n",
    "y_predictions = []\n",
    "for i in range(X.shape[0]):\n",
    "    y_pred = recall(X[i], final_w1, final_w2)\n",
    "    y_predictions.append(y_pred)\n",
    "\n",
    "plt.plot(X, t, 'bo-', label='Valores Reales', markersize=8, linewidth=2)\n",
    "plt.plot(X, y_predictions, 'r^-', label='Predicciones (Algoritmo de Recuerdo)', markersize=8, linewidth=2)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Comparación Final: Valores Reales vs Predicciones')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nError cuadrático final de validación: {validation_errors[-1]:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución del ejercicio B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritmo de entramiento con tanh como función de activación de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv_tanh(u):\n",
    "    return 1 - np.tanh(u) ** 2\n",
    "\n",
    "def train_tanh(X, t, learning_rate=0.2, epochs=50):\n",
    "    global input_num\n",
    "    global hidden_num\n",
    "    global w1\n",
    "    global w2\n",
    "\n",
    "    input_num = 1\n",
    "    hidden_num = 10\n",
    "    output_num = 1\n",
    "    intervalo = 0.5\n",
    "\n",
    "    # inicializando los pesos\n",
    "    w1 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
    "\n",
    "    w2 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        gradient_out = 0.0                 \n",
    "        gradient_hidden = []\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "        # propagacion hacia adelante\n",
    "            x = X[i]\n",
    "\n",
    "            u1 = x * w1\n",
    "            o = logistica(u1)\n",
    "            u2 = o.dot(w2)\n",
    "            y = np.tanh(u2)  #Función de activación tanh para la salida\n",
    "\n",
    "        # backpropagation\n",
    "            delta_hidden_s = []           \n",
    "            gradient_hidden_s = []       \n",
    "\n",
    "            delta_out_s = (t[i] - y)* deriv_tanh(u2)     \n",
    "            gradient_out_s = delta_out_s * o     \n",
    "\n",
    "            for j in range(hidden_num):\n",
    "\n",
    "                delta_hidden_s.append(deriv_logistica(u1[j]) * w2[j] * delta_out_s)\n",
    "                gradient_hidden_s.append(delta_hidden_s[j] * x)\n",
    "\n",
    "\n",
    "            gradient_out = gradient_out + gradient_out_s\n",
    "            gradient_hidden = gradient_hidden + gradient_hidden_s\n",
    "\n",
    "\n",
    "        print(\"\\n#\", epoch, \"Gradient out: \",gradient_out),\n",
    "        print(\"\\n     Weights  out: \", w1, w2)\n",
    "\n",
    "        # Ahora actualizando pesos\n",
    "        w2 = w2 + learning_rate * gradient_out\n",
    "\n",
    "        for j in range(hidden_num):\n",
    "            w1[j] = w1[j] + learning_rate * gradient_hidden[j]\n",
    "\n",
    "def recall_tanh(X, t):\n",
    "    predictions = []\n",
    "    for i in range(X.shape[0]):\n",
    "        x = X[i]\n",
    "        u1 = x * w1\n",
    "        o = logistica(u1)\n",
    "        u2 = o.dot(w2)\n",
    "        y = np.tanh(u2)  # Activación en salida\n",
    "        predictions.append(y)\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "    mse = np.mean((predictions - t)**2)\n",
    "    print(\"\\nTanh error cuadrático medio (ECM):\", mse)\n",
    "\n",
    "    return predictions, mse\n",
    "\n",
    "def recall(X, t):\n",
    "    predictions = []\n",
    "    for i in range(X.shape[0]):\n",
    "        x = X[i]\n",
    "        u1 = x * w1\n",
    "        o = logistica(u1)\n",
    "        u2 = o.dot(w2)\n",
    "        y = u2  # salida lineal\n",
    "        predictions.append(y)\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "    mse = np.mean((predictions - t)**2)\n",
    "    print(\"\\nLineal error cuadrático medio (ECM):\", mse)\n",
    "\n",
    "    return predictions, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hallando por cada algoritmo el promedio de sus MSE de 10 entrenamientos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 0 Gradient out:  [-1.46095541 -2.07669021 -1.59263821 -2.45169014 -0.02387927 -2.61335293\n",
      " -0.01568067 -1.8691403  -0.57611545 -0.01487795]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [-0.17074516  0.43013317  0.48061367  0.34437716 -0.22851983 -0.29882195\n",
      " -0.43481713  0.36781667 -0.46296285 -0.01055918]\n",
      "\n",
      "# 1 Gradient out:  [ 7.07361362  8.92035009  7.48659612  9.9443951   2.81125972 10.41497114\n",
      "  2.78775641  8.32456468  4.3351748   2.78544682]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [-0.46293624  0.01479513  0.16208603 -0.14596087 -0.23329569 -0.82149253\n",
      " -0.43795327 -0.00601139 -0.57818594 -0.01353477]\n",
      "\n",
      "# 2 Gradient out:  [-31.6260847  -40.68450495 -33.62143653 -45.89748088 -10.60488189\n",
      " -48.26921495 -10.48594051 -37.71661049 -18.33619449 -10.47426284]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [0.95178648 1.79886515 1.65940525 1.84291815 0.32895626 1.26150169\n",
      " 0.11959801 1.65890155 0.28884902 0.5435546 ]\n",
      "\n",
      "# 3 Gradient out:  [143.37500283 183.83241728 152.31786454 206.90650813  49.62832354\n",
      " 217.40694646  49.10210665 170.62391247  83.87298701  49.0504357 ]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [-5.37343046 -6.33803584 -5.06488205 -7.33657802 -1.79202012 -8.3923413\n",
      " -1.97759009 -5.88442055 -3.37838988 -1.55129797]\n",
      "\n",
      "# 4 Gradient out:  [-648.35841857 -831.76119528 -688.86474406 -936.59761828 -223.21508093\n",
      " -984.31795528 -220.82329559 -771.83278917 -378.78021689 -220.58844378]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [23.30157011 30.42844761 25.39869086 34.0447236   8.13364459 35.08904799\n",
      "  7.84283124 28.24036194 13.39620753  8.25878917]\n",
      "\n",
      "# 5 Gradient out:  [2933.28147717 3762.69886488 3116.50196736 4236.5539281  1010.80918935\n",
      " 4452.22425922  999.99990325 3491.73370105 1713.97984311  998.93852452]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [-106.3701136  -135.92379144 -112.37425795 -153.27480005  -36.5093716\n",
      " -161.77454306  -36.32182788 -126.12619589  -62.35983585  -35.85889959]\n",
      "\n",
      "# 6 Gradient out:  [-13269.55065932 -17021.89313722 -14098.41623269 -19165.91707218\n",
      "  -4571.94699264 -20141.77956767  -4523.03699236 -15795.97152633\n",
      "  -7753.51694863  -4518.23445486]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [480.28618183 616.61598153 510.92613552 694.03598557 165.65246627\n",
      " 728.67030878 163.67815277 572.22054432 280.43613277 163.92880532]\n",
      "\n",
      "# 7 Gradient out:  [60029.59303846 77004.50811816 63779.26800143 86703.40064475\n",
      " 20683.43180839 91117.85843413 20462.18046792 71458.71953989\n",
      " 35075.88219044 20440.45550451]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [-2173.62395004 -2787.76264591 -2308.75711102 -3139.14742887\n",
      "  -748.73693226 -3299.68560475  -740.9292457  -2586.97376095\n",
      " -1270.26725696  -739.71808566]\n",
      "\n",
      "# 8 Gradient out:  [-271564.70156666 -348356.72265917 -288527.64140923 -392233.37780348\n",
      "  -93568.22507935 -412203.91192737  -92567.30748118 -323268.33099813\n",
      " -158677.96207287  -92469.02605249]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [ 9832.29465766 12613.13897772 10447.09648926 14201.53270008\n",
      "  3387.94942942 14923.88608207  3351.50684788 11704.77014703\n",
      "  5744.90918113  3348.37301525]\n",
      "\n",
      "# 9 Gradient out:  [1228517.87543238 1575913.37619042 1305255.6915353  1774404.43714305\n",
      "  423288.94241038 1864747.93326733  418760.95181564 1462417.34312896\n",
      "  717835.13837754  418316.34240255]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [-44480.64565568 -57058.20555411 -47258.43179258 -64245.14286061\n",
      " -15325.69558645 -67516.8963034  -15161.95464835 -52948.89605259\n",
      " -25990.68323344 -15145.43219525]\n",
      "\n",
      "# 10 Gradient out:  [-5557629.54049149 -7129194.40049078 -5904779.80920235 -8027138.33144477\n",
      " -1914895.0336471  -8435838.87277623 -1894411.07734779 -6615755.4006317\n",
      " -3247378.03235793 -1892399.7304613 ]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [201222.9294308  258124.46968397 213792.70651448 290635.744568\n",
      "  69332.09289563 305432.69035006  68590.23571477 239534.5725732\n",
      " 117576.34444207  68517.83628526]\n",
      "\n",
      "# 11 Gradient out:  [25141878.17944702 32251400.68490873 26712333.70049155 36313563.3525907\n",
      "  8662696.67299318 38162462.79572586  8570030.35259336 29928680.11446907\n",
      " 14690648.45088887  8560931.32346517]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [ -910302.9786675  -1167714.41041418  -967163.25532599 -1314791.92172096\n",
      "  -313646.91383379 -1381735.08420518  -310291.97975478 -1083616.50755314\n",
      "  -531899.26202952  -309962.109807  ]\n",
      "\n",
      "# 12 Gradient out:  [-1.13738066e+08 -1.45900474e+08 -1.20842570e+08 -1.64277086e+08\n",
      " -3.91887334e+07 -1.72641228e+08 -3.87695250e+07 -1.35392836e+08\n",
      " -6.64582788e+07 -3.87283623e+07]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [4118072.65722191 5282565.72656756 4375303.48477232 5947920.74879718\n",
      " 1418892.42076484 6250757.47493999 1403714.09076389 4902119.51534067\n",
      " 2406230.42814825 1402224.15488603]\n",
      "\n",
      "# 13 Gradient out:  [5.14533862e+08 6.60031746e+08 5.46673567e+08 7.43164766e+08\n",
      " 1.77283921e+08 7.81002886e+08 1.75387486e+08 6.12496777e+08\n",
      " 3.00647233e+08 1.75201272e+08]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [-18629540.55084351 -23897529.04703233 -19793210.51143946\n",
      " -26907496.36829591  -6418854.26352922 -28277488.1412487\n",
      "  -6350190.89931528 -22176447.71857883 -10885425.33044728\n",
      "  -6343448.3078356 ]\n",
      "\n",
      "# 14 Gradient out:  [-2.32767361e+09 -2.98588410e+09 -2.47306879e+09 -3.36196535e+09\n",
      " -8.02005731e+08 -3.53313930e+09 -7.93426541e+08 -2.77084307e+09\n",
      " -1.36008275e+09 -7.92584139e+08]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [8.42772319e+07 1.08108820e+08 8.95415028e+07 1.21725457e+08\n",
      " 2.90379300e+07 1.27923089e+08 2.87273062e+07 1.00322908e+08\n",
      " 4.92440212e+07 2.86968061e+07]\n",
      "\n",
      "# 15 Gradient out:  [1.05300445e+10 1.35076895e+10 1.11877903e+10 1.52090244e+10\n",
      " 3.62815300e+09 1.59833895e+10 3.58934204e+09 1.25348763e+10\n",
      " 6.15280930e+09 3.58553114e+09]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [-3.81257491e+08 -4.89068000e+08 -4.05072255e+08 -5.50667614e+08\n",
      " -1.31363216e+08 -5.78704771e+08 -1.29958002e+08 -4.53845706e+08\n",
      " -2.22772529e+08 -1.29820022e+08]\n",
      "\n",
      "# 16 Gradient out:  [-4.76363335e+10 -6.11067506e+10 -5.06118766e+10 -6.88033330e+10\n",
      " -1.64132172e+10 -7.23064441e+10 -1.62376422e+10 -5.67058903e+10\n",
      " -2.78343816e+10 -1.62204023e+10]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [1.72475140e+09 2.21246990e+09 1.83248581e+09 2.49113726e+09\n",
      " 5.94267385e+08 2.61797313e+09 5.87910406e+08 2.05312955e+09\n",
      " 1.00778933e+09 5.87286207e+08]\n",
      "\n",
      "# 17 Gradient out:  [2.15499590e+11 2.76437726e+11 2.28960499e+11 3.11255905e+11\n",
      " 7.42509197e+10 3.27103451e+11 7.34566451e+10 2.56528898e+11\n",
      " 1.25918546e+11 7.33786543e+10]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [-7.80251530e+09 -1.00088802e+10 -8.28988952e+09 -1.12695293e+10\n",
      " -2.68837605e+09 -1.18433157e+10 -2.65961804e+09 -9.28804852e+09\n",
      " -4.55908699e+09 -2.65679425e+09]\n",
      "\n",
      "# 18 Gradient out:  [-9.74887655e+11 -1.25056259e+12 -1.03578278e+12 -1.40807478e+12\n",
      " -3.35899966e+11 -1.47976669e+12 -3.32306787e+11 -1.16049806e+12\n",
      " -5.69636515e+11 -3.31953968e+11]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [3.52974028e+10 4.52786650e+10 3.75022103e+10 5.09816516e+10\n",
      " 1.21618079e+10 5.35773745e+10 1.20317110e+10 4.20177311e+10\n",
      " 2.06246221e+10 1.20189366e+10]\n",
      "\n",
      "# 19 Gradient out:  [4.41024476e+12 5.65735662e+12 4.68572511e+12 6.36991802e+12\n",
      " 1.51956080e+12 6.69424141e+12 1.50330580e+12 5.24991824e+12\n",
      " 2.57694971e+12 1.50170970e+12]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [-1.59680128e+11 -2.04833854e+11 -1.69654345e+11 -2.30633305e+11\n",
      " -5.50181852e+10 -2.42375964e+11 -5.44296464e+10 -1.90081880e+11\n",
      " -9.33026808e+10 -5.43718570e+10]\n",
      "\n",
      "# 20 Gradient out:  [-1.99512824e+13 -2.55930284e+13 -2.11975139e+13 -2.88165487e+13\n",
      " -6.87426394e+12 -3.02837388e+13 -6.80072879e+12 -2.37498385e+13\n",
      " -1.16577319e+13 -6.79350827e+12]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [7.22368825e+11 9.26637471e+11 7.67490676e+11 1.04335030e+12\n",
      " 2.48893975e+11 1.09647232e+12 2.46231514e+11 8.59901767e+11\n",
      " 4.22087260e+11 2.45970083e+11]\n",
      "\n",
      "# 21 Gradient out:  [9.02565932e+13 1.15779002e+14 9.58943568e+13 1.30361722e+14\n",
      " 3.10981336e+13 1.36999068e+14 3.07654717e+13 1.07440689e+14\n",
      " 5.27378216e+13 3.07328071e+13]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [-3.26788765e+12 -4.19196820e+12 -3.47201210e+12 -4.71995944e+12\n",
      " -1.12595881e+12 -4.96027545e+12 -1.11391424e+12 -3.89006594e+12\n",
      " -1.90945913e+12 -1.11273157e+12]\n",
      "\n",
      "# 22 Gradient out:  [-4.08307219e+14 -5.23766746e+14 -4.33811612e+14 -5.89736773e+14\n",
      " -1.40683268e+14 -6.19763130e+14 -1.39178355e+14 -4.86045476e+14\n",
      " -2.38577953e+14 -1.39030586e+14]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [1.47834310e+13 1.89638321e+13 1.57068593e+13 2.13523849e+13\n",
      " 5.09366791e+12 2.24395382e+13 5.03918009e+12 1.75980718e+13\n",
      " 8.63810519e+12 5.03382986e+12]\n",
      "\n",
      "# 23 Gradient out:  [1.84712030e+15 2.36944179e+15 1.96249832e+15 2.66788024e+15\n",
      " 6.36429891e+14 2.80371495e+15 6.29621894e+14 2.19879645e+15\n",
      " 1.07929069e+15 6.28953408e+14]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [-6.68780129e+13 -8.57895172e+13 -7.10554631e+13 -9.65949697e+13\n",
      " -2.30429856e+13 -1.01513088e+14 -2.27964909e+13 -7.96110235e+13\n",
      " -3.90774855e+13 -2.27722873e+13]\n",
      "\n",
      "# 24 Gradient out:  [-8.35609373e+15 -1.07189974e+16 -8.87804652e+15 -1.20690880e+16\n",
      " -2.87911287e+15 -1.26835837e+16 -2.84831452e+15 -9.94702362e+15\n",
      " -4.88254835e+15 -2.84529039e+15]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [3.02546047e+14 3.88098841e+14 3.21444202e+14 4.36981079e+14\n",
      " 1.04242993e+14 4.59229903e+14 1.03127888e+14 3.60148267e+14\n",
      " 1.76780652e+14 1.03018394e+14]\n",
      "\n",
      "# 25 Gradient out:  [3.78017081e+16 4.84911281e+16 4.01629439e+16 5.45987343e+16\n",
      " 1.30246725e+16 5.73786204e+16 1.28853454e+16 4.49988351e+16\n",
      " 2.20879126e+16 1.28716647e+16]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [-1.36867270e+15 -1.75570064e+15 -1.45416510e+15 -1.97683652e+15\n",
      " -4.71579582e+14 -2.07748684e+15 -4.66535016e+14 -1.62925646e+15\n",
      " -7.99729017e+14 -4.66039683e+14]\n",
      "\n",
      "# 26 Gradient out:  [-1.71009228e+17 -2.19366552e+17 -1.81691103e+17 -2.46996442e+17\n",
      " -5.89216547e+16 -2.59572227e+17 -5.82913599e+16 -2.03567945e+17\n",
      " -9.99223861e+16 -5.82294704e+16]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [6.19166893e+15 7.94252498e+15 6.57842367e+15 8.94291034e+15\n",
      " 2.13335492e+15 9.39823724e+15 2.11053407e+15 7.37051056e+15\n",
      " 3.61785349e+15 2.10829326e+15]\n",
      "\n",
      "# 27 Gradient out:  [7.73619964e+17 9.92381208e+17 8.21943153e+17 1.11737466e+18\n",
      " 2.66552682e+17 1.17426562e+18 2.63701323e+17 9.20910692e+17\n",
      " 4.52033809e+17 2.63421345e+17]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [-2.80101767e+16 -3.59307855e+16 -2.97597968e+16 -4.04563780e+16\n",
      " -9.65097602e+15 -4.25162082e+16 -9.54773791e+15 -3.33430785e+16\n",
      " -1.63666237e+16 -9.53760082e+15]\n",
      "\n",
      "# 28 Gradient out:  [-3.49974008e+18 -4.48938296e+18 -3.71834690e+18 -5.05483450e+18\n",
      " -1.20584414e+18 -5.31220061e+18 -1.19294503e+18 -4.16606112e+18\n",
      " -2.04493280e+18 -1.19167845e+18]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [1.26713816e+17 1.62545456e+17 1.34628834e+17 1.83018554e+17\n",
      " 4.36595604e+16 1.92336916e+17 4.31925267e+16 1.50839060e+17\n",
      " 7.40401381e+16 4.31466681e+16]\n",
      "\n",
      "# 29 Gradient out:  [1.58322964e+19 2.03092916e+19 1.68212407e+19 2.28673091e+19\n",
      " 5.45505710e+18 2.40315946e+19 5.39670344e+18 1.88466324e+19\n",
      " 9.25096765e+18 5.39097361e+18]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [-5.73234199e+17 -7.35331136e+17 -6.09040546e+17 -8.27948345e+17\n",
      " -1.97509269e+17 -8.70103207e+17 -1.95396479e+17 -6.82373164e+17\n",
      " -3.34946421e+17 -1.95189021e+17]\n",
      "\n",
      "# 30 Gradient out:  [-7.16229219e+19 -9.18761731e+19 -7.60967568e+19 -1.03448259e+20\n",
      " -2.46778558e+19 -1.08715311e+20 -2.44138727e+19 -8.52593232e+19\n",
      " -4.18499828e+19 -2.43879518e+19]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [2.59322509e+18 3.32652719e+18 2.75520760e+18 3.74551348e+18\n",
      " 8.93502151e+17 3.93621572e+18 8.83944209e+17 3.08695331e+18\n",
      " 1.51524711e+18 8.83005701e+17]\n",
      "\n",
      "# 31 Gradient out:  [3.24011300e+20 4.15633955e+20 3.44250254e+20 4.67984325e+20\n",
      " 1.11638899e+20 4.91811674e+20 1.10444679e+20 3.85700323e+20\n",
      " 1.89323012e+20 1.10327417e+20]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [-1.17313593e+19 -1.50487074e+19 -1.24641438e+19 -1.69441382e+19\n",
      " -4.04206901e+18 -1.78068464e+19 -3.99883032e+18 -1.39649113e+19\n",
      " -6.85474946e+18 -3.99458466e+18]\n",
      "\n",
      "# 32 Gradient out:  [-1.46577827e+21 -1.88026534e+21 -1.55733625e+21 -2.11709052e+21\n",
      " -5.05037547e+20 -2.22488186e+21 -4.99635075e+20 -1.74485011e+21\n",
      " -8.56468763e+20 -4.99104599e+20]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [5.30709007e+19 6.80780835e+19 5.63859071e+19 7.66527267e+19\n",
      " 1.82857108e+19 8.05554884e+19 1.80901055e+19 6.31751533e+19\n",
      " 3.10098530e+19 1.80708987e+19]\n",
      "\n",
      "# 33 Gradient out:  [6.63095988e+21 8.50603692e+21 7.04515437e+21 9.57739833e+21\n",
      " 2.28471371e+21 1.00650301e+22 2.26027375e+21 7.89343881e+21\n",
      " 3.87453555e+21 2.25787395e+21]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [-2.40084753e+20 -3.07974985e+20 -2.55081342e+20 -3.46765378e+20\n",
      " -8.27217985e+19 -3.64420884e+20 -8.18369096e+19 -2.85794868e+20\n",
      " -1.40283900e+20 -8.17500211e+19]\n",
      "\n",
      "# 34 Gradient out:  [-2.99974627e+22 -3.84800285e+22 -3.18712162e+22 -4.33267060e+22\n",
      " -1.03357004e+22 -4.55326786e+22 -1.02251376e+22 -3.57087271e+22\n",
      " -1.75278146e+22 -1.02142813e+22]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [1.08610722e+21 1.39323240e+21 1.15394953e+21 1.56871429e+21\n",
      " 3.74220944e+20 1.64858513e+21 3.70217840e+20 1.29289289e+21\n",
      " 6.34623210e+20 3.69824770e+20]\n",
      "\n",
      "# 35 Gradient out:  [1.35703998e+23 1.74077847e+23 1.44180577e+23 1.96003485e+23\n",
      " 4.67571501e+22 2.05982973e+23 4.62569810e+22 1.61540897e+23\n",
      " 7.92931907e+22 4.62078687e+22]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [-4.91338532e+21 -6.30277331e+21 -5.22029370e+21 -7.09662691e+21\n",
      " -1.69291913e+21 -7.45795058e+21 -1.67480969e+21 -5.84885252e+21\n",
      " -2.87093972e+21 -1.67303150e+21]\n",
      "\n",
      "# 36 Gradient out:  [-6.13904428e+23 -7.87501934e+23 -6.52251189e+23 -8.86690216e+23\n",
      " -2.11522297e+23 -9.31835911e+23 -2.09259608e+23 -7.30786663e+23\n",
      " -3.58710439e+23 -2.09037431e+23]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [2.22274144e+22 2.85127961e+22 2.36158216e+22 3.21040702e+22\n",
      " 7.65851089e+21 3.37386439e+22 7.57658651e+21 2.64593269e+22\n",
      " 1.29876984e+22 7.56854225e+21]\n",
      "\n",
      "# 37 Gradient out:  [2.77721107e+24 3.56254002e+24 2.95068604e+24 4.01125284e+24\n",
      " 9.56894980e+23 4.21548516e+24 9.46658914e+23 3.30596868e+24\n",
      " 1.62275194e+24 9.45653821e+23]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [-1.00553471e+23 -1.28987591e+23 -1.06834416e+23 -1.45233973e+23\n",
      " -3.46459486e+22 -1.52628538e+23 -3.42753350e+22 -1.19698006e+23\n",
      " -5.87543894e+22 -3.42389440e+22]\n",
      "\n",
      "# 38 Gradient out:  [-1.25636842e+25 -1.61163939e+25 -1.33484587e+25 -1.81463031e+25\n",
      " -4.32884862e+24 -1.90702193e+25 -4.28254219e+24 -1.49557038e+25\n",
      " -7.34108512e+24 -4.27799530e+24]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [4.54888743e+23 5.83520412e+23 4.83302791e+23 6.57016596e+23\n",
      " 1.56733048e+23 6.90468495e+23 1.55056448e+23 5.41495730e+23\n",
      " 2.65795999e+23 1.54891820e+23]\n",
      "\n",
      "# 39 Gradient out:  [5.68362129e+25 7.29081360e+25 6.03864148e+25 8.20911391e+25\n",
      " 1.95830585e+25 8.62707968e+25 1.93735752e+25 6.76573492e+25\n",
      " 3.32099622e+25 1.93530057e+25]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [-2.05784809e+24 -2.63975837e+24 -2.18638896e+24 -2.97224402e+24\n",
      " -7.09036676e+23 -3.12357536e+24 -7.01451991e+23 -2.44964504e+24\n",
      " -1.20242102e+24 -7.00707241e+23]\n",
      "\n",
      "# 40 Gradient out:  [-2.57118457e+26 -3.29825415e+26 -2.73179036e+26 -3.71367936e+26\n",
      " -8.85908038e+25 -3.90276077e+26 -8.76431331e+25 -3.06071647e+26\n",
      " -1.50236862e+26 -8.75500800e+25]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [9.30939448e+24 1.19418688e+25 9.89089399e+24 1.34459838e+25\n",
      " 3.20757502e+24 1.41305840e+25 3.17326305e+24 1.10818248e+25\n",
      " 5.43957142e+24 3.16989391e+24]\n",
      "\n",
      "# 41 Gradient out:  [1.16316513e+27 1.49208045e+27 1.23582077e+27 1.68001255e+27\n",
      " 4.00771439e+26 1.76555013e+27 3.96484320e+26 1.38462198e+27\n",
      " 6.79648911e+26 3.96063362e+26]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [-4.21142970e+25 -5.40232141e+25 -4.47449131e+25 -6.08276034e+25\n",
      " -1.45105857e+25 -6.39246314e+25 -1.43553636e+25 -5.01325046e+25\n",
      " -2.46078010e+25 -1.43401221e+25]\n",
      "\n",
      "# 42 Gradient out:  [-5.26198369e+27 -6.74994697e+27 -5.59066683e+27 -7.60012347e+27\n",
      " -1.81302956e+27 -7.98708258e+27 -1.79363528e+27 -6.26382108e+27\n",
      " -3.07462920e+27 -1.79173093e+27]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [1.90518730e+26 2.44392875e+26 2.02419241e+26 2.75174907e+26\n",
      " 6.56437021e+25 2.89185394e+26 6.49415004e+25 2.26791892e+26\n",
      " 1.11321981e+26 6.48725503e+25]\n",
      "\n",
      "# 43 Gradient out:  [2.38044209e+28 3.05357424e+28 2.52913338e+28 3.43818127e+28\n",
      " 8.20187239e+27 3.61323574e+28 8.11413558e+27 2.83365822e+28\n",
      " 1.39091589e+28 8.10552059e+27]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [-8.61878009e+26 -1.10559652e+27 -9.15714125e+26 -1.24484979e+27\n",
      " -2.96962211e+26 -1.30823112e+27 -2.93785556e+26 -1.02597232e+27\n",
      " -5.03603859e+26 -2.93473636e+26]\n",
      "\n",
      "# 44 Gradient out:  [-1.07687611e+29 -1.38139094e+29 -1.14414181e+29 -1.55538137e+29\n",
      " -3.71040341e+28 -1.63457337e+29 -3.67071260e+28 -1.28190425e+29\n",
      " -6.29229378e+28 -3.66681530e+28]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [3.89900616e+27 5.00155196e+27 4.14255263e+27 5.63151275e+27\n",
      " 1.34341227e+27 5.91824035e+27 1.32904156e+27 4.64134411e+27\n",
      " 2.27822793e+27 1.32763048e+27]\n",
      "\n",
      "# 45 Gradient out:  [4.87162515e+29 6.24920436e+29 5.17592503e+29 7.03631079e+29\n",
      " 1.67853056e+29 7.39456347e+29 1.66057503e+29 5.79914156e+29\n",
      " 2.84653884e+29 1.65881196e+29]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [-1.76385160e+28 -2.26262669e+28 -1.87402835e+28 -2.54761146e+28\n",
      " -6.07739454e+27 -2.67732270e+28 -6.01238363e+27 -2.09967409e+28\n",
      " -1.03063596e+28 -6.00600013e+27]\n",
      "\n",
      "# 46 Gradient out:  [-2.20384977e+30 -2.82704583e+30 -2.34151044e+30 -3.18312091e+30\n",
      " -7.59341916e+29 -3.34518902e+30 -7.51219108e+29 -2.62344420e+30\n",
      " -1.28773125e+30 -7.50421519e+29]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [7.97939870e+28 1.02357820e+29 8.47782171e+28 1.15250101e+29\n",
      " 2.74932166e+28 1.21118042e+29 2.71991170e+28 9.49860902e+28\n",
      " 4.66244171e+28 2.71702390e+28]\n",
      "\n",
      "# 47 Gradient out:  [9.96988405e+30 1.27891291e+31 1.05926402e+31 1.43999591e+31\n",
      " 3.43514834e+30 1.51331308e+31 3.39840198e+30 1.18680660e+31\n",
      " 5.82550202e+30 3.39479381e+30]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [-3.60975966e+29 -4.63051345e+29 -3.83523872e+29 -5.21374081e+29\n",
      " -1.24375167e+29 -5.47919762e+29 -1.23044705e+29 -4.29702751e+29\n",
      " -2.10921833e+29 -1.22914065e+29]\n",
      "\n",
      "# 48 Gradient out:  [-4.51022522e+31 -5.78560917e+31 -4.79195072e+31 -6.51432437e+31\n",
      " -1.55400932e+31 -6.84600019e+31 -1.53738582e+31 -5.36893413e+31\n",
      " -2.63536928e+31 -1.53575353e+31]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [1.63300084e+30 2.09477447e+30 1.73500417e+30 2.35861773e+30\n",
      " 5.62654501e+29 2.47870639e+30 5.56635691e+29 1.94391046e+30\n",
      " 9.54178571e+29 5.56044696e+29]\n",
      "\n",
      "# 49 Gradient out:  [2.04035789e+32 2.61732235e+32 2.16780625e+32 2.94698212e+32\n",
      " 7.03010384e+31 3.09702726e+32 6.95490163e+31 2.42882485e+32\n",
      " 1.19220133e+32 6.94751743e+31]\n",
      "\n",
      "     Weights  out:  [ 0.04669171  0.21867134  0.08014333  0.37570345 -0.41927831  0.49132634\n",
      " -0.42488763  0.15491346 -0.18486636 -0.42544442] [-7.38744960e+30 -9.47644386e+30 -7.84889727e+30 -1.06700310e+31\n",
      " -2.54536413e+30 -1.12132940e+31 -2.51813594e+30 -8.79395781e+30\n",
      " -4.31655999e+30 -2.51546237e+30]\n",
      "\n",
      "Lineal error cuadrático medio (ECM): 3.5213051881139695e+64\n",
      "\n",
      "# 0 Gradient out:  [-1.85018081 -1.32329801 -1.81645605 -1.40520876 -0.36107077 -0.32987029\n",
      " -1.0942939  -1.13127312 -0.39638482 -1.83459013]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [ 0.25885035 -0.14899477  0.46221854  0.20149478 -0.10016722 -0.00100892\n",
      " -0.01788377 -0.10165198  0.41823394  0.38634049]\n",
      "\n",
      "# 1 Gradient out:  [3.55946    2.71852827 3.5092784  2.86924765 1.00381821 0.95741476\n",
      " 2.26740556 2.34186647 1.05476205 3.53598722]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [-0.11118582 -0.41365437  0.09892733 -0.07954697 -0.17238138 -0.06698298\n",
      " -0.23674255 -0.3279066   0.33895698  0.01942246]\n",
      "\n",
      "# 2 Gradient out:  [-0.17320061 -0.1335154  -0.17052459 -0.1395956  -0.0616238  -0.05914854\n",
      " -0.1164879  -0.11923959 -0.06437624 -0.17195647]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [0.60070618 0.13005128 0.80078301 0.49430256 0.02838227 0.12449998\n",
      " 0.21673856 0.14046669 0.54990939 0.7266199 ]\n",
      "\n",
      "# 3 Gradient out:  [-0.22895481 -0.17540481 -0.2253589  -0.18362647 -0.07826396 -0.07493778\n",
      " -0.1523708  -0.15609361 -0.08196656 -0.22728354]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [0.56606606 0.1033482  0.76667809 0.46638344 0.01605751 0.11267027\n",
      " 0.19344098 0.11661878 0.53703414 0.69222861]\n",
      "\n",
      "# 4 Gradient out:  [-0.32893102 -0.24988357 -0.32365401 -0.26205453 -0.10622461 -0.10134337\n",
      " -0.21576725 -0.22128205 -0.11166663 -0.32647958]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [5.20275100e-01 6.82672370e-02 7.21606315e-01 4.29658148e-01\n",
      " 4.04715457e-04 9.76827113e-02 1.62966822e-01 8.54000532e-02\n",
      " 5.20640829e-01 6.46771901e-01]\n",
      "\n",
      "# 5 Gradient out:  [-0.54340021 -0.40762512 -0.53441952 -0.42861766 -0.16021212 -0.15190477\n",
      " -0.34874327 -0.35826307 -0.16949736 -0.53923149]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [ 0.4544889   0.01829052  0.65687551  0.37724724 -0.02084021  0.07741404\n",
      "  0.11981337  0.04114364  0.4983075   0.58147599]\n",
      "\n",
      "# 6 Gradient out:  [-1.14418228 -0.83905394 -1.12433935 -0.88650772 -0.28108331 -0.26272712\n",
      " -0.70593233 -0.72745458 -0.30170973 -1.13498697]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [ 0.34580885 -0.0632345   0.54999161  0.29152371 -0.05288263  0.04703308\n",
      "  0.05006472 -0.03050897  0.46440803  0.47362969]\n",
      "\n",
      "# 7 Gradient out:  [-1.52652877 -1.01362397 -1.49275466 -1.08743018 -0.13041158 -0.09915841\n",
      " -0.81635512 -0.84771587 -0.16630995 -1.51100451]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [ 0.1169724  -0.23104529  0.32512374  0.11422217 -0.10909929 -0.00551234\n",
      " -0.09112175 -0.17599989  0.40406609  0.24663229]\n",
      "\n",
      "# 8 Gradient out:  [3.34743791 2.55487558 3.29783225 2.69215121 0.97912626 0.93325606\n",
      " 2.14829906 2.21519483 1.02924546 3.32421077]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [-0.18833336 -0.43377008  0.02657281 -0.10326387 -0.13518161 -0.02534402\n",
      " -0.25439277 -0.34554306  0.3708041  -0.05556861]\n",
      "\n",
      "# 9 Gradient out:  [-0.35185772 -0.26395962 -0.34602904 -0.27754225 -0.10383541 -0.09844379\n",
      " -0.22585621 -0.23201698 -0.10985598 -0.34915129]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [0.48115423 0.07720503 0.68613926 0.43516637 0.06064364 0.16130719\n",
      " 0.17526704 0.09749591 0.57665319 0.60927355]\n",
      "\n",
      "# 10 Gradient out:  [-0.60136326 -0.4458881  -0.59114227 -0.47000209 -0.16199598 -0.15254118\n",
      " -0.3782087  -0.38915287 -0.17257948 -0.59662094]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [0.41078268 0.02441311 0.61693345 0.37965792 0.03987656 0.14161843\n",
      " 0.1300958  0.05109251 0.55468199 0.53944329]\n",
      "\n",
      "# 11 Gradient out:  [-1.34117909 -0.97390049 -1.31737053 -1.03104131 -0.30224546 -0.28022049\n",
      " -0.81368306 -0.83958123 -0.32702429 -1.33015033]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [ 0.29051003 -0.06476451  0.498705    0.2856575   0.00747736  0.1111102\n",
      "  0.05445406 -0.02673807  0.5201661   0.4201191 ]\n",
      "\n",
      "# 12 Gradient out:  [-0.09658417  0.03454868 -0.08375043  0.02988002  0.13582966  0.14771242\n",
      "  0.02618286  0.02869033  0.12189959 -0.09075408]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [ 0.02227421 -0.25954461  0.23523089  0.07944924 -0.05297173  0.0550661\n",
      " -0.10828255 -0.19465431  0.45476124  0.15408903]\n",
      "\n",
      "# 13 Gradient out:  [0.03048398 0.11976944 0.04139885 0.1230888  0.1321983  0.14230511\n",
      " 0.08750681 0.09395588 0.12039402 0.03544101]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [ 0.00295738 -0.25263487  0.2184808   0.08542525 -0.0258058   0.08460858\n",
      " -0.10304598 -0.18891625  0.47914116  0.13593822]\n",
      "\n",
      "# 14 Gradient out:  [-0.5153016  -0.28790367 -0.49578427 -0.30785031 -0.00703662  0.01102633\n",
      " -0.25233856 -0.25699347 -0.02766081 -0.50633662]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [ 0.00905417 -0.22868098  0.22676057  0.11004301  0.00063387  0.1130696\n",
      " -0.08554462 -0.17012507  0.50321996  0.14302642]\n",
      "\n",
      "# 15 Gradient out:  [2.15336986 1.66373505 2.12891478 1.7639973  0.5575733  0.53496337\n",
      " 1.35071126 1.40302295 0.58244405 2.1419085 ]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [-0.09400615 -0.28626172  0.12760372  0.04847295 -0.00077346  0.11527487\n",
      " -0.13601233 -0.22152376  0.4976878   0.0417591 ]\n",
      "\n",
      "# 16 Gradient out:  [-0.72321443 -0.52892008 -0.71053513 -0.55915949 -0.17335545 -0.16162641\n",
      " -0.4440008  -0.45773494 -0.18650965 -0.71733492]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [0.33666782 0.04648529 0.55338668 0.40127241 0.1107412  0.22226754\n",
      " 0.13412992 0.05908083 0.61417661 0.4701408 ]\n",
      "\n",
      "# 17 Gradient out:  [-1.74269212 -1.24976029 -1.71070774 -1.32607397 -0.35181445 -0.32222561\n",
      " -1.03642077 -1.07087089 -0.38514685 -1.72788315]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [ 0.19202494 -0.05929872  0.41127965  0.28944051  0.07607011  0.18994226\n",
      "  0.04532976 -0.03246616  0.57687468  0.32667381]\n",
      "\n",
      "# 18 Gradient out:  [3.11835921 2.37011391 3.0757485  2.50917328 0.80202868 0.76262705\n",
      " 1.94899434 2.01874631 0.84537063 3.09842838]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [-0.15651349 -0.30925078  0.0691381   0.02422571  0.00570722  0.12549714\n",
      " -0.16195439 -0.24664034  0.49984531 -0.01890282]\n",
      "\n",
      "# 19 Gradient out:  [-0.23979757 -0.17833538 -0.23573473 -0.18785304 -0.06620835 -0.06245015\n",
      " -0.15161917 -0.15593962 -0.07040736 -0.23791138]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [0.46715835 0.164772   0.6842878  0.52606037 0.16611296 0.27802255\n",
      " 0.22784447 0.15710892 0.66891943 0.60078286]\n",
      "\n",
      "# 20 Gradient out:  [-0.35123897 -0.25953832 -0.34520638 -0.27377029 -0.09200554 -0.08642521\n",
      " -0.2195742  -0.22603773 -0.09824837 -0.34843941]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [0.41919884 0.12910492 0.63714086 0.48848976 0.15287129 0.26553252\n",
      " 0.19752064 0.125921   0.65483796 0.55320058]\n",
      "\n",
      "# 21 Gradient out:  [-0.60208807 -0.44083355 -0.59155175 -0.46592772 -0.1457372  -0.1359906\n",
      " -0.37035079 -0.38175082 -0.15666251 -0.59720146]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [0.34895105 0.07719726 0.56809958 0.4337357  0.13447018 0.24824748\n",
      " 0.1536058  0.08071345 0.63518829 0.4835127 ]\n",
      "\n",
      "# 22 Gradient out:  [-1.35610642 -0.97791609 -1.33158251 -1.03674135 -0.28644957 -0.26376289\n",
      " -0.81300462 -0.83965984 -0.31196896 -1.34474562]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [ 0.22853343 -0.01096945  0.44978923  0.34055016  0.10532274  0.22104936\n",
      "  0.07953564  0.00436329  0.60385579  0.36407241]\n",
      "\n",
      "# 23 Gradient out:  [-0.08619373  0.01361171 -0.0731799   0.01715032  0.03051453  0.04256003\n",
      " -0.02060157 -0.01376957  0.01688719 -0.08021536]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [-0.04268785 -0.20655267  0.18347273  0.13320189  0.04803283  0.16829678\n",
      " -0.08306528 -0.16356868  0.54146199  0.09512329]\n",
      "\n",
      "# 24 Gradient out:  [0.17405884 0.20170626 0.18291567 0.21779937 0.07524841 0.0834485\n",
      " 0.13069512 0.14356036 0.06597092 0.17811229]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [-0.0599266  -0.20383033  0.16883675  0.13663195  0.05413573  0.17680878\n",
      " -0.08718559 -0.1663226   0.54483943  0.07908021]\n",
      "\n",
      "# 25 Gradient out:  [-0.98305274 -0.64673157 -0.95599217 -0.68408997 -0.1615447  -0.13650684\n",
      " -0.56092158 -0.57377766 -0.18971107 -0.97054748]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [-0.02511483 -0.16348907  0.20541988  0.18019183  0.06918541  0.19349848\n",
      " -0.06104657 -0.13761053  0.55803362  0.11470267]\n",
      "\n",
      "# 26 Gradient out:  [3.36640259 2.54830445 3.31755178 2.69520791 0.87759743 0.83242533\n",
      " 2.10816836 2.18083794 0.92712591 3.3435422 ]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [-0.22172537 -0.29283539  0.01422145  0.04337383  0.03687647  0.16619712\n",
      " -0.17323089 -0.25236606  0.5200914  -0.07940682]\n",
      "\n",
      "# 27 Gradient out:  [-0.20273198 -0.15009994 -0.19925951 -0.15825954 -0.05400809 -0.05079597\n",
      " -0.12718906 -0.13089446 -0.05759843 -0.20112006]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [0.45155514 0.2168255  0.67773181 0.58241541 0.21239596 0.33268218\n",
      " 0.24840279 0.18380153 0.70551658 0.58930162]\n",
      "\n",
      "# 28 Gradient out:  [-0.2809924  -0.20700204 -0.27612945 -0.21849386 -0.07175534 -0.06725696\n",
      " -0.17472433 -0.17994513 -0.0767884  -0.27873571]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [0.41100875 0.18680552 0.6378799  0.55076351 0.20159434 0.32252299\n",
      " 0.22296497 0.15762264 0.6939969  0.5490776 ]\n",
      "\n",
      "# 29 Gradient out:  [-0.43736063 -0.32004013 -0.42968934 -0.33830231 -0.10528802 -0.09819175\n",
      " -0.26873094 -0.27703067 -0.11323903 -0.43380227]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [0.35481027 0.14540511 0.58265401 0.50706473 0.18724328 0.3090716\n",
      " 0.18802011 0.12163361 0.67863922 0.49333046]\n",
      "\n",
      "# 30 Gradient out:  [-0.83711817 -0.60653151 -0.82214027 -0.64248872 -0.18404463 -0.17018911\n",
      " -0.5055358  -0.52187074 -0.19960366 -0.83017551]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [0.26733814 0.08139708 0.49671614 0.43940427 0.16618567 0.28943325\n",
      " 0.13427392 0.06622748 0.65599141 0.40657001]\n",
      "\n",
      "# 31 Gradient out:  [-2.04279843 -1.45304348 -2.00407552 -1.54311774 -0.38938646 -0.3535636\n",
      " -1.20279011 -1.24311744 -0.4297267  -2.0248696 ]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [ 0.09991451 -0.03990922  0.33228809  0.31090653  0.12937674  0.25539543\n",
      "  0.03316676 -0.03814667  0.61607068  0.24053491]\n",
      "\n",
      "# 32 Gradient out:  [3.26881498 2.49097174 3.21796514 2.62242106 0.97118648 0.92416877\n",
      " 2.10395898 2.16752423 1.02214706 3.24495226]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [-0.30864518 -0.33051792 -0.06852701  0.00228298  0.05149945  0.18468271\n",
      " -0.20739126 -0.28677016  0.53012534 -0.16443901]\n",
      "\n",
      "# 33 Gradient out:  [-0.39309186 -0.28617441 -0.38612303 -0.30284872 -0.09021555 -0.08376904\n",
      " -0.23930369 -0.24688659 -0.09744338 -0.38985997]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [0.34511782 0.16767643 0.57506602 0.52676719 0.24573675 0.36951646\n",
      " 0.21340054 0.14673469 0.73455475 0.48455144]\n",
      "\n",
      "# 34 Gradient out:  [-0.71314883 -0.51513863 -0.70031013 -0.54606439 -0.15193629 -0.14005966\n",
      " -0.42822547 -0.4422853  -0.16527552 -0.70719798]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [0.26649944 0.11044155 0.49784141 0.46619745 0.22769364 0.35276265\n",
      " 0.1655398  0.09735737 0.71506608 0.40657944]\n",
      "\n",
      "# 35 Gradient out:  [-1.72183815 -1.22796201 -1.68965995 -1.30424832 -0.32972487 -0.29995708\n",
      " -1.0148487  -1.04925436 -0.36322206 -1.70693419]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [0.12386968 0.00741382 0.35777938 0.35698457 0.19730638 0.32475072\n",
      " 0.07989471 0.00890031 0.68201097 0.26513985]\n",
      "\n",
      "# 36 Gradient out:  [2.80129646 2.1020539  2.76304547 2.23474948 0.61395867 0.57858706\n",
      " 1.69817017 1.76516472 0.65311272 2.78343364]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [-0.22049795 -0.23817858  0.01984739  0.09613491  0.13136141  0.26475931\n",
      " -0.12307503 -0.20095056  0.60936656 -0.07624699]\n",
      "\n",
      "# 37 Gradient out:  [-0.38060485 -0.27690538 -0.37384767 -0.29308094 -0.0868192  -0.08056847\n",
      " -0.23143393 -0.2387906  -0.09382787 -0.37747116]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [0.33976134 0.1822322  0.57245649 0.5430848  0.25415314 0.38047672\n",
      " 0.216559   0.15208238 0.73998911 0.48043974]\n",
      "\n",
      "# 38 Gradient out:  [-0.67959353 -0.49077103 -0.66735205 -0.52026833 -0.14436374 -0.13303958\n",
      " -0.40786325 -0.42127563 -0.15708208 -0.67391943]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [0.26364037 0.12685112 0.49768696 0.48446861 0.2367893  0.36436302\n",
      " 0.17027221 0.10432426 0.72122353 0.40494551]\n",
      "\n",
      "# 39 Gradient out:  [-1.6164314  -1.15352185 -1.58633048 -1.22520505 -0.31003532 -0.28218927\n",
      " -0.95303287 -0.98541308 -0.34136837 -1.60248897]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [0.12772166 0.02869692 0.36421655 0.38041495 0.20791655 0.33775511\n",
      " 0.08869956 0.02006913 0.68980712 0.27016162]\n",
      "\n",
      "# 40 Gradient out:  [2.11914905 1.59488971 2.09418496 1.70274347 0.4080109  0.3849263\n",
      " 1.25908605 1.31515478 0.4338627  2.10751324]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [-0.19556462 -0.20200745  0.04695045  0.13537394  0.14590949  0.28131725\n",
      " -0.10190701 -0.17701348  0.62153344 -0.05033617]\n",
      "\n",
      "# 41 Gradient out:  [-0.83705001 -0.60291439 -0.82188687 -0.63948218 -0.17348586 -0.15945889\n",
      " -0.50017116 -0.51679028 -0.18924827 -0.83002293]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [0.22826519 0.11697049 0.46578744 0.47592263 0.22751167 0.35830251\n",
      " 0.1499102  0.08601747 0.70830598 0.37116647]\n",
      "\n",
      "# 42 Gradient out:  [-2.04534299 -1.45184731 -2.00615086 -1.54215391 -0.38422964 -0.34797313\n",
      " -1.20126111 -1.24162557 -0.42500731 -2.02718997]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [ 0.06085519 -0.00361239  0.30141007  0.34802619  0.1928145   0.32641074\n",
      "  0.04987597 -0.01734058  0.67045633  0.20516189]\n",
      "\n",
      "# 43 Gradient out:  [3.21772251 2.44505551 3.16664664 2.57478251 0.94227836 0.8950524\n",
      " 2.06371775 2.12632156 0.99336103 3.1937404 ]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [-0.34821341 -0.29398185 -0.09982011  0.03959541  0.11596857  0.25681611\n",
      " -0.19037625 -0.2656657   0.58545486 -0.20027611]\n",
      "\n",
      "# 44 Gradient out:  [-0.42686492 -0.30827144 -0.41917767 -0.32681915 -0.0905074  -0.08339624\n",
      " -0.25610435 -0.26454558 -0.09849112 -0.42330129]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [0.29533109 0.19502925 0.53350922 0.55455191 0.30442424 0.43582659\n",
      " 0.2223673  0.15959862 0.78412707 0.43847197]\n",
      "\n",
      "# 45 Gradient out:  [-0.8080944  -0.57949905 -0.79333149 -0.61525869 -0.15978454 -0.14612774\n",
      " -0.47898807 -0.49524801 -0.17514022 -0.80125401]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [0.20995811 0.13337497 0.44967369 0.48918808 0.28632276 0.41914734\n",
      " 0.17114643 0.1066895  0.76442885 0.35381171]\n",
      "\n",
      "# 46 Gradient out:  [-1.97944465 -1.40316121 -1.94138364 -1.4909754  -0.36534332 -0.33013351\n",
      " -1.15927228 -1.19856991 -0.40491893 -1.96181154]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [0.04833923 0.01747516 0.29100739 0.36613635 0.25436585 0.38992179\n",
      " 0.07534881 0.0076399  0.7294008  0.19356091]\n",
      "\n",
      "# 47 Gradient out:  [3.23278686 2.43477106 3.18130676 2.57097268 0.86430847 0.81670769\n",
      " 2.03254809 2.09867225 0.915976   3.20863643]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [-0.3475497  -0.26315709 -0.09726934  0.06794127  0.18129719  0.32389509\n",
      " -0.15650564 -0.23207409  0.64841702 -0.1988014 ]\n",
      "\n",
      "# 48 Gradient out:  [-0.35578841 -0.25630093 -0.34935249 -0.27188133 -0.07345108 -0.06749745\n",
      " -0.21246193 -0.21955649 -0.08013766 -0.35280518]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [0.29900767 0.22379713 0.53899202 0.5821358  0.35415888 0.48723663\n",
      " 0.25000397 0.18766036 0.83161222 0.44292589]\n",
      "\n",
      "# 49 Gradient out:  [-0.61522931 -0.44078053 -0.60398353 -0.46812175 -0.12003833 -0.10963515\n",
      " -0.36387008 -0.37631536 -0.13173647 -0.61001859]\n",
      "\n",
      "     Weights  out:  [ 0.49145695  0.10853994  0.44759827  0.14940338 -0.44884513 -0.48936123\n",
      "  0.00227328  0.0190594  -0.40928675  0.47027718] [0.22784999 0.17253694 0.46912152 0.52775954 0.33946866 0.47373714\n",
      " 0.20751159 0.14374907 0.81558468 0.37236485]\n",
      "\n",
      "Tanh error cuadrático medio (ECM): 0.9520101179034258\n",
      "\n",
      "# 0 Gradient out:  [0.84673138 0.79334885 0.55193642 1.17229574 0.47061461 1.09700699\n",
      " 1.22328235 1.26185539 0.64081047 1.30421892]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [ 0.36011612  0.136795   -0.17949595 -0.41961334 -0.01427817  0.45691228\n",
      " -0.43555818 -0.29495627  0.02563554  0.38784742]\n",
      "\n",
      "# 1 Gradient out:  [-4.00055338 -3.75567673 -2.40119422 -5.63976439 -1.52616966 -5.19189718\n",
      " -6.02001447 -6.39944053 -2.98590751 -6.97498474]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [ 0.52946239  0.29546477 -0.06910867 -0.18515419  0.07984475  0.67631367\n",
      " -0.19090171 -0.04258519  0.15379764  0.6486912 ]\n",
      "\n",
      "# 2 Gradient out:  [19.76618711 18.5397911  12.02520642 27.81709368  8.19196144 25.68563299\n",
      " 29.5619836  31.24115681 14.76079918 33.70489558]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [-0.27064828 -0.45567057 -0.54934751 -1.31310706 -0.22538918 -0.36206576\n",
      " -1.39490461 -1.3224733  -0.44338387 -0.74630575]\n",
      "\n",
      "# 3 Gradient out:  [ -96.92819494  -90.93813041  -58.85296861 -136.40796675  -39.58496863\n",
      " -125.88696584 -145.08841326 -153.50922101  -72.4051537  -165.96010959]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [3.68258914 3.25228765 1.85569377 4.25031167 1.41300311 4.77506084\n",
      " 4.51749211 4.92575806 2.50877597 5.99467337]\n",
      "\n",
      "# 4 Gradient out:  [475.9017897  446.46138278 289.03655183 669.78092693 194.89121593\n",
      " 618.18335362 712.28408079 753.44864303 355.45043409 814.21777158]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [-15.70304985 -14.93533844  -9.91489995 -23.03128168  -6.50399062\n",
      " -20.40233233 -24.50019054 -25.77608614 -11.97225477 -27.19734855]\n",
      "\n",
      "# 5 Gradient out:  [-2336.125058   -2191.6422721  -1418.78746288 -3287.77294108\n",
      "  -956.1975989  -3034.43845929 -3496.52401632 -3698.76888411\n",
      " -1744.91705638 -3997.43137602]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [ 79.47730809  74.35693812  47.89241042 110.92490371  32.47425257\n",
      " 103.23433839 117.95662562 124.91364247  59.11783205 135.64620577]\n",
      "\n",
      "# 6 Gradient out:  [11468.03888695 10758.73299084  6964.84793891 16139.78054222\n",
      "  4694.42972657 14896.20462695 17164.43515914 18157.08531654\n",
      "  8565.71259153 19622.86812086]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [-387.74770351 -363.9715163  -235.86508216 -546.62968451 -158.76526721\n",
      " -503.65335347 -581.34817765 -614.84013435 -289.86557923 -663.84006943]\n",
      "\n",
      "# 7 Gradient out:  [-56296.31182229 -52814.39072738 -34190.26444646 -79229.64747328\n",
      " -23044.41196984 -73124.92773824 -84259.75086592 -89132.81128314\n",
      " -42048.96653671 -96328.64890428]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [1905.86007388 1787.77508187 1157.10450563 2681.32642394  780.1206781\n",
      " 2475.58757192 2851.53885418 3016.57692895 1423.27693908 3260.73355474]\n",
      "\n",
      "# 8 Gradient out:  [276357.39249897 259264.66955049 167839.25651418 388936.79296005\n",
      " 113124.92454909 358968.8862035  413629.36710963 437550.95404052\n",
      " 206417.36544504 472874.82406651]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [ -9353.40229058  -8775.10306361  -5680.94838367 -13164.60307072\n",
      "  -3828.76171587 -12149.39797573 -14000.411319   -14809.98532767\n",
      "  -6986.51636827 -16004.99622612]\n",
      "\n",
      "# 9 Gradient out:  [-1356632.36965613 -1272724.6173912   -823919.26098896 -1909282.01150869\n",
      "  -555327.39357758 -1762170.18769913 -2030497.40832604 -2147928.11283025\n",
      " -1013298.43682693 -2321332.55474599]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [45918.07620921 43077.83084649 27886.90291917 64622.75552129\n",
      " 18796.22319395 59644.37926497 68725.46210292 72700.20548043\n",
      " 34296.95672074 78569.96858718]\n",
      "\n",
      "# 10 Gradient out:  [ 6659678.623879    6247777.25221711  4044601.57690285  9372623.80178664\n",
      "  2726090.38393508  8650455.10122177  9967667.44307178 10544132.04526056\n",
      "  4974259.72614231 11395370.32017504]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [-225408.39772201 -211467.09263175 -136896.94927862 -317233.64678045\n",
      "  -92269.25552157 -292789.65827485 -337374.01956228 -356885.41708562\n",
      " -168362.73064464 -385696.54236201]\n",
      "\n",
      "# 11 Gradient out:  [-32692216.59415842 -30670201.8298199  -19854860.67242585\n",
      " -46010004.90217416 -13382317.68278321 -42464894.53714685\n",
      " -48931061.20013901 -51760913.4694244  -24418532.25633612\n",
      " -55939623.86299455]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [1106527.32705379 1038088.35781167  672023.36610195 1557291.11357688\n",
      "  452948.82126545 1437301.3619695  1656159.46905207 1751940.99196649\n",
      "  826489.21458382 1893377.521673  ]\n",
      "\n",
      "# 12 Gradient out:  [1.60485376e+08 1.50559349e+08 9.74670764e+07 2.25862107e+08\n",
      " 6.56935049e+07 2.08459238e+08 2.40201509e+08 2.54093191e+08\n",
      " 1.19870040e+08 2.74606389e+08]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [-5431915.9917779  -5095952.00815231 -3298948.76838322 -7644709.86685795\n",
      " -2223514.71529119 -7055677.54545987 -8130052.77097573 -8600241.70191839\n",
      " -4057217.23668341 -9294547.25092592]\n",
      "\n",
      "# 13 Gradient out:  [-7.87819197e+08 -7.39092551e+08 -4.78463745e+08 -1.10875214e+09\n",
      " -3.22487978e+08 -1.02332184e+09 -1.17914395e+09 -1.24733791e+09\n",
      " -5.88439404e+08 -1.34803675e+09]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [26665159.15223359 25015917.88052388 16194466.51217937 37527711.57974193\n",
      " 10915186.27111744 34636170.0669761  39910248.94512394 42218396.55401015\n",
      " 19916790.81279378 45626730.51094726]\n",
      "\n",
      "# 14 Gradient out:  [3.86738719e+09 3.62818916e+09 2.34876805e+09 5.44283999e+09\n",
      " 1.58308642e+09 5.02346450e+09 5.78839183e+09 6.12315452e+09\n",
      " 2.88863616e+09 6.61748291e+09]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [-1.30898680e+08 -1.22802592e+08 -7.94982825e+07 -1.84222717e+08\n",
      " -5.35824092e+07 -1.70028197e+08 -1.95918541e+08 -2.07249186e+08\n",
      " -9.77710900e+07 -2.23980620e+08]\n",
      "\n",
      "# 15 Gradient out:  [-1.89849191e+10 -1.78107012e+10 -1.15300510e+10 -2.67187824e+10\n",
      " -7.77133660e+09 -2.46600773e+10 -2.84150888e+10 -3.00584315e+10\n",
      " -1.41802517e+10 -3.24850788e+10]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [6.42578759e+08 6.02835239e+08 3.90255328e+08 9.04345282e+08\n",
      " 2.63034875e+08 8.34664703e+08 9.61759826e+08 1.01738172e+09\n",
      " 4.79956141e+08 1.09951596e+09]\n",
      "\n",
      "# 16 Gradient out:  [9.31965523e+10 8.74323422e+10 5.66007678e+10 1.31161918e+11\n",
      " 3.81493213e+10 1.21055780e+11 1.39489049e+11 1.47556182e+11\n",
      " 6.96105450e+10 1.59468541e+11]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [-3.15440506e+09 -2.95930499e+09 -1.91575486e+09 -4.43941120e+09\n",
      " -1.29123245e+09 -4.09735075e+09 -4.72125794e+09 -4.99430459e+09\n",
      " -2.35609419e+09 -5.39749979e+09]\n",
      "\n",
      "# 17 Gradient out:  [-4.57499835e+11 -4.29203454e+11 -2.77851930e+11 -6.43870984e+11\n",
      " -1.87274183e+11 -5.94260173e+11 -6.84748689e+11 -7.24350070e+11\n",
      " -3.41716642e+11 -7.82827576e+11]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [1.54849054e+10 1.45271634e+10 9.40439869e+09 2.17929724e+10\n",
      " 6.33863181e+09 2.01138052e+10 2.31765519e+10 2.45169319e+10\n",
      " 1.15660148e+10 2.64962084e+10]\n",
      "\n",
      "# 18 Gradient out:  [2.24585668e+12 2.10695036e+12 1.36396904e+12 3.16074857e+12\n",
      " 9.19324867e+11 2.91721018e+12 3.36141633e+12 3.55581864e+12\n",
      " 1.67747952e+12 3.84288344e+12]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [-7.60150617e+10 -7.13135274e+10 -4.61659873e+10 -1.06981224e+11\n",
      " -3.11162048e+10 -9.87382293e+10 -1.13773186e+11 -1.20353082e+11\n",
      " -5.67773136e+10 -1.30069307e+11]\n",
      "\n",
      "# 19 Gradient out:  [-1.10248613e+13 -1.03429732e+13 -6.69569418e+12 -1.55160455e+13\n",
      " -4.51294565e+12 -1.43205209e+13 -1.65011192e+13 -1.74554359e+13\n",
      " -8.23471023e+12 -1.88646307e+13]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [3.73156274e+11 3.50076545e+11 2.26627821e+11 5.25168489e+11\n",
      " 1.52748769e+11 4.84703807e+11 5.58510079e+11 5.90810646e+11\n",
      " 2.78718590e+11 6.38507381e+11]\n",
      "\n",
      "# 20 Gradient out:  [5.41208027e+13 5.07734291e+13 3.28690162e+13 7.61679280e+13\n",
      " 2.21539514e+13 7.02991238e+13 8.10036329e+13 8.56883527e+13\n",
      " 4.04240123e+13 9.26060591e+13]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [-1.83181598e+12 -1.71851810e+12 -1.11251102e+12 -2.57804062e+12\n",
      " -7.49840361e+11 -2.37940038e+12 -2.74171376e+12 -2.90027653e+12\n",
      " -1.36822346e+12 -3.13441876e+12]\n",
      "\n",
      "# 21 Gradient out:  [-2.65677836e+14 -2.49245652e+14 -1.61353281e+14 -3.73906691e+14\n",
      " -1.08753263e+14 -3.45096860e+14 -3.97645061e+14 -4.20642248e+14\n",
      " -1.98440592e+14 -4.54601117e+14]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [8.99234456e+12 8.43616772e+12 5.46129222e+12 1.26555450e+13\n",
      " 3.68094992e+12 1.16804244e+13 1.34590128e+13 1.42373940e+13\n",
      " 6.71657900e+12 1.53867931e+13]\n",
      "\n",
      "# 22 Gradient out:  [1.30420668e+15 1.22354145e+15 7.92079725e+14 1.83549976e+15\n",
      " 5.33867386e+14 1.69407293e+15 1.95203090e+15 2.06492359e+15\n",
      " 9.74140521e+14 2.23162694e+15]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [-4.41432226e+13 -4.14129627e+13 -2.68093640e+13 -6.21257933e+13\n",
      " -1.80697026e+13 -5.73389476e+13 -6.60699993e+13 -6.98910556e+13\n",
      " -3.29715393e+13 -7.55334304e+13]\n",
      "\n",
      "# 23 Gradient out:  [-6.40232205e+15 -6.00633820e+15 -3.88830203e+15 -9.01042817e+15\n",
      " -2.62074331e+15 -8.31616695e+15 -9.58247696e+15 -1.01366647e+16\n",
      " -4.78203449e+15 -1.09550078e+16]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [2.16698114e+14 2.03295328e+14 1.31606581e+14 3.04974160e+14\n",
      " 8.87037746e+13 2.81475639e+14 3.24336181e+14 3.43093662e+14\n",
      " 1.61856565e+14 3.70791957e+14]\n",
      "\n",
      "# 24 Gradient out:  [3.14288588e+16 2.94849828e+16 1.90875896e+16 4.42319947e+16\n",
      " 1.28651716e+16 4.08238815e+16 4.70401697e+16 4.97606651e+16\n",
      " 2.34749027e+16 5.37778934e+16]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [-1.06376630e+15 -9.97972313e+14 -6.46053826e+14 -1.49711147e+15\n",
      " -4.35444888e+14 -1.38175775e+15 -1.59215921e+15 -1.68423928e+15\n",
      " -7.94550334e+14 -1.82020960e+15]\n",
      "\n",
      "# 25 Gradient out:  [-1.54283580e+17 -1.44741135e+17 -9.37005595e+16 -2.17133894e+17\n",
      " -6.31548456e+16 -2.00403541e+17 -2.30919163e+17 -2.44274016e+17\n",
      " -1.15237783e+17 -2.63994502e+17]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [5.22200547e+15 4.89902424e+15 3.17146409e+15 7.34928746e+15\n",
      " 2.13758942e+15 6.78301855e+15 7.81587472e+15 8.26789375e+15\n",
      " 3.90043020e+15 8.93536908e+15]\n",
      "\n",
      "# 26 Gradient out:  [7.57374718e+17 7.10531064e+17 4.59973996e+17 1.06590553e+18\n",
      " 3.10025755e+17 9.83776596e+17 1.13357712e+18 1.19913580e+18\n",
      " 5.65699756e+17 1.29594323e+18]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [-2.56347106e+16 -2.40492028e+16 -1.55686478e+16 -3.60774913e+16\n",
      " -1.04933797e+16 -3.32976896e+16 -3.83679579e+16 -4.05869095e+16\n",
      " -1.91471265e+16 -4.38635313e+16]\n",
      "\n",
      "# 27 Gradient out:  [-3.71793591e+18 -3.48798144e+18 -2.25800228e+18 -5.23250693e+18\n",
      " -1.52190964e+18 -4.82933778e+18 -5.56470527e+18 -5.88653139e+18\n",
      " -2.77700772e+18 -6.36175696e+18]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [1.25840233e+17 1.18057010e+17 7.64261513e+16 1.77103615e+17\n",
      " 5.15117713e+16 1.63457630e+17 1.88347466e+17 1.99240250e+17\n",
      " 9.39928248e+16 2.15325115e+17]\n",
      "\n",
      "# 28 Gradient out:  [1.82512660e+19 1.71224246e+19 1.10844838e+19 2.56862620e+19\n",
      " 7.47102113e+18 2.37071134e+19 2.73170163e+19 2.88968537e+19\n",
      " 1.36322701e+19 3.12297257e+19]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [-6.17746950e+17 -5.79539279e+17 -3.75174304e+17 -8.69397770e+17\n",
      " -2.52870158e+17 -8.02409926e+17 -9.24593587e+17 -9.78066027e+17\n",
      " -4.61408720e+17 -1.05702628e+18]\n",
      "\n",
      "# 29 Gradient out:  [-8.95950654e+19 -8.40536074e+19 -5.44134882e+19 -1.26093298e+20\n",
      " -3.66750792e+19 -1.16377701e+20 -1.34098635e+20 -1.41854023e+20\n",
      " -6.69205157e+19 -1.53306040e+20]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [3.03250626e+18 2.84494563e+18 1.84172245e+18 4.26785462e+18\n",
      " 1.24133407e+18 3.93901276e+18 4.53880968e+18 4.80130472e+18\n",
      " 2.26504531e+18 5.18891885e+18]\n",
      "\n",
      "# 30 Gradient out:  [4.39820215e+20 4.12617319e+20 2.67114622e+20 6.18989239e+20\n",
      " 1.80037161e+20 5.71295587e+20 6.58287266e+20 6.96358292e+20\n",
      " 3.28511347e+20 7.52575994e+20]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [-1.48865068e+19 -1.39657759e+19 -9.04097518e+18 -2.09508049e+19\n",
      " -6.09368178e+18 -1.93365274e+19 -2.22809174e+19 -2.35694998e+19\n",
      " -1.11190578e+19 -2.54722891e+19]\n",
      "\n",
      "# 31 Gradient out:  [-2.15906781e+21 -2.02552939e+21 -1.31125983e+21 -3.03860463e+21\n",
      " -8.83798484e+20 -2.80447753e+21 -3.23151778e+21 -3.41840761e+21\n",
      " -1.61265501e+21 -3.69437908e+21]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [7.30775362e+19 6.85576880e+19 4.43819493e+19 1.02847043e+20\n",
      " 2.99137505e+19 9.49225900e+19 1.09376536e+20 1.15702159e+20\n",
      " 5.45832115e+19 1.25042910e+20]\n",
      "\n",
      "# 32 Gradient out:  [1.05988166e+22 9.94327944e+21 6.43694583e+21 1.49164436e+22\n",
      " 4.33854741e+21 1.37671188e+22 1.58634501e+22 1.67808882e+22\n",
      " 7.91648815e+21 1.81356260e+22]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [-3.58736026e+20 -3.36548190e+20 -2.17870018e+20 -5.04873883e+20\n",
      " -1.46845946e+20 -4.65972917e+20 -5.36927020e+20 -5.67979364e+20\n",
      " -2.67947791e+20 -6.13832906e+20]\n",
      "\n",
      "# 33 Gradient out:  [-5.20293588e+22 -4.88113411e+22 -3.15988262e+22 -7.32244952e+22\n",
      " -2.12978343e+22 -6.75824850e+22 -7.78733291e+22 -8.23770127e+22\n",
      " -3.88618671e+22 -8.90273913e+22]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [1.76102730e+21 1.65210770e+21 1.06951915e+21 2.47841484e+21\n",
      " 7.20863536e+20 2.28745085e+21 2.63576299e+21 2.78819827e+21\n",
      " 1.31534984e+21 3.01329230e+21]\n",
      "\n",
      "# 34 Gradient out:  [2.55410984e+23 2.39613805e+23 1.55117946e+23 3.59457444e+23\n",
      " 1.04550602e+23 3.31760940e+23 3.82278468e+23 4.04386952e+23\n",
      " 1.90772055e+23 4.37033515e+23]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [-8.64484447e+21 -8.11016053e+21 -5.25024609e+21 -1.21664842e+22\n",
      " -3.53870332e+21 -1.12290462e+22 -1.29389028e+22 -1.36872043e+22\n",
      " -6.45702358e+21 -1.47921860e+22]\n",
      "\n",
      "# 35 Gradient out:  [-1.25380693e+24 -1.17625893e+24 -7.61470603e+23 -1.76456873e+24\n",
      " -5.13236619e+23 -1.62860719e+24 -1.87659663e+24 -1.98512670e+24\n",
      " -9.36495842e+23 -2.14538796e+24]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [4.24373523e+22 3.98126005e+22 2.57733431e+22 5.97250046e+22\n",
      " 1.73714172e+22 5.51231418e+22 6.35167908e+22 6.71901862e+22\n",
      " 3.16973874e+22 7.26145171e+22]\n",
      "\n",
      "# 36 Gradient out:  [6.15491077e+24 5.77422932e+24 3.73804252e+24 8.66222925e+24\n",
      " 2.51946733e+24 7.99479706e+24 9.21217180e+24 9.74494351e+24\n",
      " 4.59723759e+24 1.05316625e+25]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [-2.08324034e+23 -1.95439185e+23 -1.26520777e+23 -2.93188741e+23\n",
      " -8.52759066e+22 -2.70598297e+23 -3.11802536e+23 -3.29835153e+23\n",
      " -1.55601781e+23 -3.56463075e+23]\n",
      "\n",
      "# 37 Gradient out:  [-3.02143223e+25 -2.83455653e+25 -1.83499689e+25 -4.25226938e+25\n",
      " -1.23680100e+25 -3.92462838e+25 -4.52223497e+25 -4.78377144e+25\n",
      " -2.25677387e+25 -5.16997009e+25]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [1.02265812e+24 9.59406679e+23 6.21087727e+23 1.43925711e+24\n",
      " 4.18617559e+23 1.32836111e+24 1.53063182e+24 1.61915355e+24\n",
      " 7.63845737e+23 1.74986943e+24]\n",
      "\n",
      "# 38 Gradient out:  [1.48321447e+26 1.39147760e+26 9.00795958e+25 2.08742973e+26\n",
      " 6.07142902e+25 1.92659148e+26 2.21995525e+26 2.34834293e+26\n",
      " 1.10784535e+26 2.53792700e+26]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [-5.02020633e+24 -4.70970639e+24 -3.04890606e+24 -7.06528165e+24\n",
      " -2.05498444e+24 -6.52089564e+24 -7.51383812e+24 -7.94838933e+24\n",
      " -3.74970201e+24 -8.59007075e+24]\n",
      "\n",
      "# 39 Gradient out:  [-7.28106735e+26 -6.83073308e+26 -4.42198764e+26 -1.02471469e+27\n",
      " -2.98045122e+26 -9.45759541e+26 -1.08977117e+27 -1.15279640e+27\n",
      " -5.43838859e+26 -1.24586281e+27]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [2.46440830e+25 2.31198456e+25 1.49670131e+25 3.46833130e+25\n",
      " 1.00878736e+25 3.20109340e+25 3.68852669e+25 3.90184692e+25\n",
      " 1.84072051e+25 4.21684693e+25]\n",
      "\n",
      "# 40 Gradient out:  [3.57426003e+27 3.35319192e+27 2.17074406e+27 5.03030197e+27\n",
      " 1.46309698e+27 4.64271289e+27 5.34966284e+27 5.65905231e+27\n",
      " 2.66969306e+27 6.11591327e+27]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [-1.20977264e+26 -1.13494816e+26 -7.34727397e+25 -1.70259624e+26\n",
      " -4.95211508e+25 -1.57140974e+26 -1.81068968e+26 -1.91540812e+26\n",
      " -9.03605668e+25 -2.07004093e+26]\n",
      "\n",
      "# 41 Gradient out:  [-1.75459642e+28 -1.64607457e+28 -1.06561351e+28 -2.46936423e+28\n",
      " -7.18231105e+27 -2.27909759e+28 -2.62613778e+28 -2.77801640e+28\n",
      " -1.31054648e+28 -3.00228844e+28]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [5.93874741e+26 5.57143567e+26 3.60676071e+26 8.35800770e+26\n",
      " 2.43098245e+26 7.71401603e+26 8.88863600e+26 9.40269651e+26\n",
      " 4.43578045e+26 1.01617856e+27]\n",
      "\n",
      "# 42 Gradient out:  [8.61327544e+28 8.08054405e+28 5.23107337e+28 1.21220549e+29\n",
      " 3.52578078e+28 1.11880402e+29 1.28916529e+29 1.36372217e+29\n",
      " 6.43344398e+28 1.47381682e+29]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [-2.91531811e+27 -2.73500558e+27 -1.77055094e+27 -4.10292768e+27\n",
      " -1.19336397e+27 -3.78679359e+27 -4.36341196e+27 -4.61576314e+27\n",
      " -2.17751491e+27 -4.98839832e+27]\n",
      "\n",
      "# 43 Gradient out:  [-4.22823806e+29 -3.96672139e+29 -2.56792247e+29 -5.95069024e+29\n",
      " -1.73079807e+29 -5.49218445e+29 -6.32848418e+29 -6.69448227e+29\n",
      " -3.15816357e+29 -7.23493453e+29]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [1.43112328e+28 1.34260825e+28 8.69159581e+27 2.01411822e+28\n",
      " 5.85819759e+27 1.85892868e+28 2.14198938e+28 2.26586802e+28\n",
      " 1.06893730e+28 2.44879381e+28]\n",
      "\n",
      "# 44 Gradient out:  [2.07563281e+30 1.94725485e+30 1.26058752e+30 2.92118081e+30\n",
      " 8.49644982e+29 2.69610133e+30 3.10663903e+30 3.28630670e+30\n",
      " 1.55033558e+30 3.55161352e+30]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [-7.02535285e+28 -6.59083452e+28 -4.26668536e+28 -9.88726226e+28\n",
      " -2.87577637e+28 -9.12544022e+28 -1.05149790e+29 -1.11230965e+29\n",
      " -5.24738983e+28 -1.20210752e+29]\n",
      "\n",
      "# 45 Gradient out:  [-1.01892360e+31 -9.55903142e+30 -6.18819655e+30 -1.43400127e+31\n",
      " -4.17088862e+30 -1.32351024e+31 -1.52504230e+31 -1.61324076e+31\n",
      " -7.61056345e+30 -1.74347931e+31]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [3.44873034e+29 3.23542624e+29 2.09450650e+29 4.85363540e+29\n",
      " 1.41171233e+29 4.47965863e+29 5.16178017e+29 5.46030374e+29\n",
      " 2.57593218e+29 5.90111952e+29]\n",
      "\n",
      "# 46 Gradient out:  [5.00187367e+31 4.69250760e+31 3.03777214e+31 7.03948084e+31\n",
      " 2.04748010e+31 6.49708280e+31 7.48639928e+31 7.91936360e+31\n",
      " 3.73600894e+31 8.55870175e+31]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [-1.69297417e+30 -1.58826366e+30 -1.02818866e+30 -2.38263900e+30\n",
      " -6.93006492e+29 -2.19905462e+30 -2.53390659e+30 -2.68045115e+30\n",
      " -1.26451947e+30 -2.89684666e+30]\n",
      "\n",
      "# 47 Gradient out:  [-2.45540884e+32 -2.30354171e+32 -1.49123569e+32 -3.45566574e+32\n",
      " -1.00510350e+32 -3.18940373e+32 -3.67505702e+32 -3.88759826e+32\n",
      " -1.83399861e+32 -4.20144796e+32]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [8.31077317e+30 7.79675155e+30 5.04735562e+30 1.16963227e+31\n",
      " 3.40195370e+30 1.07951110e+31 1.24388920e+31 1.31582761e+31\n",
      " 6.20749841e+30 1.42205568e+31]\n",
      "\n",
      "# 48 Gradient out:  [1.20535482e+33 1.13080358e+33 7.32044339e+32 1.69637875e+33\n",
      " 4.93403107e+32 1.56567131e+33 1.80407745e+33 1.90841348e+33\n",
      " 9.00305904e+32 2.06248161e+33]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [-4.07974036e+31 -3.82740827e+31 -2.47773583e+31 -5.74169920e+31\n",
      " -1.67001162e+31 -5.29929635e+31 -6.10622484e+31 -6.45936891e+31\n",
      " -3.04724738e+31 -6.98084023e+31]\n",
      "\n",
      "# 49 Gradient out:  [-5.91706045e+33 -5.55109005e+33 -3.59358964e+33 -8.32748614e+33\n",
      " -2.42210505e+33 -7.68584618e+33 -8.85617671e+33 -9.36835999e+33\n",
      " -4.41958198e+33 -1.01246771e+34]\n",
      "\n",
      "     Weights  out:  [-0.01771573 -0.04599661 -0.22340592  0.18310977 -0.40028752  0.12299662\n",
      "  0.24134095  0.31046772 -0.14003667  0.45792555] [2.00273561e+32 1.87886634e+32 1.21631509e+32 2.81858757e+32\n",
      " 8.19805051e+31 2.60141298e+32 2.99753241e+32 3.17089006e+32\n",
      " 1.49588707e+32 3.42687919e+32]\n",
      "\n",
      "Lineal error cuadrático medio (ECM): 4.5428180451234147e+67\n",
      "\n",
      "# 0 Gradient out:  [2.78967969 2.63913405 1.70265809 2.37326153 0.87493509 0.86242687\n",
      " 2.06588841 2.28548377 0.95786363 1.61493277]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.33441516 -0.26449828 -0.42691856  0.3877364  -0.08136894 -0.20894849\n",
      "  0.23783901  0.12648324  0.14215064 -0.08884159]\n",
      "\n",
      "# 1 Gradient out:  [-0.52877521 -0.4889354  -0.3141545  -0.42882472 -0.14684636 -0.14349829\n",
      " -0.37328667 -0.4119311  -0.16892017 -0.29983153]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [ 0.22352078  0.26332853 -0.08638694  0.86238871  0.09361808 -0.03646312\n",
      "  0.6510167   0.58357999  0.33372336  0.23414496]\n",
      "\n",
      "# 2 Gradient out:  [-1.01967218 -0.94071362 -0.59067565 -0.82056051 -0.25610791 -0.24948519\n",
      " -0.70924442 -0.78671271 -0.29993535 -0.56195607]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [ 0.11776573  0.16554145 -0.14921784  0.77662377  0.0642488  -0.06516277\n",
      "  0.57635936  0.50119377  0.29993933  0.17417866]\n",
      "\n",
      "# 3 Gradient out:  [-2.12991547 -1.94979683 -1.15257229 -1.67257525 -0.38765448 -0.37261735\n",
      " -1.41935812 -1.59514401 -0.48819274 -1.08792929]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.0861687  -0.02260127 -0.26735297  0.61251167  0.01302722 -0.11505981\n",
      "  0.43451048  0.34385123  0.23995226  0.06178744]\n",
      "\n",
      "# 4 Gradient out:  [3.40682655 3.19362493 2.04685173 2.84314532 1.00243862 0.98461175\n",
      " 2.47114548 2.73447367 1.120027   1.94428067]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.5121518  -0.41256064 -0.49786743  0.27799662 -0.06450367 -0.18958328\n",
      "  0.15063885  0.02482243  0.14231371 -0.15579841]\n",
      "\n",
      "# 5 Gradient out:  [-0.60487252 -0.5584724  -0.35379618 -0.48818842 -0.15805496 -0.15415868\n",
      " -0.42312008 -0.46840416 -0.18378105 -0.33700483]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [ 0.16921352  0.22616435 -0.08849708  0.84662568  0.13598405  0.00733907\n",
      "  0.64486795  0.57171716  0.36631911  0.23305772]\n",
      "\n",
      "# 6 Gradient out:  [-1.24435998 -1.14620084 -0.70932278 -0.99630366 -0.29195466 -0.28372841\n",
      " -0.85733148 -0.95404649 -0.346483   -0.67347201]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [ 0.04823901  0.11446987 -0.15925631  0.748988    0.10437306 -0.02349267\n",
      "  0.56024393  0.47803633  0.3295629   0.16565676]\n",
      "\n",
      "# 7 Gradient out:  [-1.69464485 -1.53383969 -0.88258512 -1.29458732 -0.24234101 -0.22888967\n",
      " -1.0898976  -1.23067545 -0.33223617 -0.83229215]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.20063298 -0.1147703  -0.30112087  0.54972726  0.04598213 -0.08023835\n",
      "  0.38877764  0.28722703  0.2602663   0.03096235]\n",
      "\n",
      "# 8 Gradient out:  [3.48665796 3.26791215 2.09773042 2.90997444 1.03129842 1.01298818\n",
      " 2.53049996 2.79910533 1.15182356 1.99311036]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.53956195 -0.42153824 -0.47763789  0.2908098  -0.00248608 -0.12601629\n",
      "  0.17079812  0.04109194  0.19381907 -0.13549608]\n",
      "\n",
      "# 9 Gradient out:  [-0.49481061 -0.45650539 -0.28717337 -0.39841199 -0.12530787 -0.12209192\n",
      " -0.34456807 -0.38204548 -0.14654809 -0.27327166]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [ 0.15776964  0.23204419 -0.05809181  0.87280469  0.20377361  0.07658135\n",
      "  0.67689811  0.600913    0.42418378  0.263126  ]\n",
      "\n",
      "# 10 Gradient out:  [-0.92739391 -0.85429383 -0.52914672 -0.74283421 -0.21858303 -0.21245366\n",
      " -0.63939831 -0.71139573 -0.25916609 -0.5024422 ]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [ 0.05880752  0.14074311 -0.11552648  0.79312229  0.17871203  0.05216297\n",
      "  0.6079845   0.52450391  0.39487416  0.20847166]\n",
      "\n",
      "# 11 Gradient out:  [-2.09500731 -1.92095944 -1.15629509 -1.6555224  -0.42248871 -0.4079197\n",
      " -1.41270638 -1.58135175 -0.51936121 -1.09417075]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.12667127 -0.03011565 -0.22135583  0.64455545  0.13499543  0.00967223\n",
      "  0.48010484  0.38222476  0.34304094  0.10798322]\n",
      "\n",
      "# 12 Gradient out:  [3.5623973  3.33961912 2.13149445 2.97245606 1.03354677 1.01491463\n",
      " 2.58023007 2.85809083 1.1563216  2.02302397]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.54567273 -0.41430754 -0.45261484  0.31345097  0.05049769 -0.0719117\n",
      "  0.19756356  0.06595442  0.2391687  -0.11085093]\n",
      "\n",
      "# 13 Gradient out:  [-0.37607917 -0.34685399 -0.21756595 -0.30251977 -0.09400382 -0.0915502\n",
      " -0.26140526 -0.29002468 -0.11020852 -0.20694762]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [ 0.16680673  0.25361628 -0.02631595  0.90794218  0.25720704  0.13107122\n",
      "  0.71360957  0.63757258  0.47043302  0.29375387]\n",
      "\n",
      "# 14 Gradient out:  [-0.62126006 -0.57241151 -0.35529804 -0.49802946 -0.14794301 -0.14384535\n",
      " -0.42896056 -0.47704264 -0.17504938 -0.33745626]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [ 0.0915909   0.18424548 -0.06982914  0.84743823  0.23840628  0.11276118\n",
      "  0.66132852  0.57956765  0.44839132  0.25236434]\n",
      "\n",
      "# 15 Gradient out:  [-1.29765022 -1.19338325 -0.72851529 -1.0339235  -0.28451106 -0.27577584\n",
      " -0.88602463 -0.98895272 -0.34244785 -0.69036313]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.03266111  0.06976318 -0.14088875  0.74783233  0.20881768  0.08399211\n",
      "  0.57553641  0.48415912  0.41338144  0.18487309]\n",
      "\n",
      "# 16 Gradient out:  [-1.49981685 -1.35043555 -0.80992026 -1.14046476 -0.26338874 -0.25078913\n",
      " -0.97281198 -1.08699667 -0.34644635 -0.77035289]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.29219116 -0.16891347 -0.28659181  0.54104763  0.15191546  0.02883694\n",
      "  0.39833148  0.28636857  0.34489187  0.04680047]\n",
      "\n",
      "# 17 Gradient out:  [3.51890313 3.29619782 2.10825721 2.93296777 1.02550512 1.00684623\n",
      " 2.54777021 2.8204556  1.14809342 2.00200867]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.59215453 -0.43900058 -0.44857586  0.31295468  0.09923771 -0.02132088\n",
      "  0.20376909  0.06896924  0.2756026  -0.10727011]\n",
      "\n",
      "# 18 Gradient out:  [-0.41982018 -0.38674112 -0.23963311 -0.33637414 -0.09916932 -0.09639421\n",
      " -0.28957132 -0.32215644 -0.11752233 -0.22753775]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [ 0.1116261   0.22023899 -0.02692442  0.89954824  0.30433874  0.18004836\n",
      "  0.71332313  0.63306036  0.50522128  0.29313162]\n",
      "\n",
      "# 19 Gradient out:  [-0.72810282 -0.67006872 -0.41098274 -0.581404   -0.16371837 -0.15885364\n",
      " -0.49895206 -0.55635743 -0.19594168 -0.38967588]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [ 0.02766206  0.14289076 -0.07485104  0.83227341  0.28450487  0.16076952\n",
      "  0.65540887  0.56862907  0.48171682  0.24762407]\n",
      "\n",
      "# 20 Gradient out:  [-1.62073835 -1.4882195  -0.89955535 -1.28568607 -0.33664387 -0.32554417\n",
      " -1.09848655 -1.2286988  -0.4103081  -0.85136672]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.1179585   0.00887702 -0.15704759  0.71599261  0.2517612   0.1289988\n",
      "  0.55561845  0.45735759  0.44252848  0.1696889 ]\n",
      "\n",
      "# 21 Gradient out:  [1.01711025 0.98951191 0.57182066 0.90104234 0.24170527 0.23965327\n",
      " 0.75823679 0.8631114  0.25738499 0.52690957]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.44210617 -0.28876688 -0.33695866  0.45885539  0.18443243  0.06388996\n",
      "  0.33592114  0.21161782  0.36046686 -0.00058445]\n",
      "\n",
      "# 22 Gradient out:  [-2.1920545  -2.00525687 -1.20730283 -1.72452668 -0.43660193 -0.42093271\n",
      " -1.47186133 -1.64698311 -0.54043735 -1.14318867]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.23868412 -0.0908645  -0.22259453  0.63906386  0.23277348  0.11182062\n",
      "  0.4875685   0.3842401   0.41194386  0.10479746]\n",
      "\n",
      "# 23 Gradient out:  [3.32098968 3.10664408 2.01860532 2.76769512 1.01795554 0.99990567\n",
      " 2.41624747 2.66448187 1.13553778 1.92245766]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.67709502 -0.49191587 -0.4640551   0.29415852  0.1454531   0.02763407\n",
      "  0.19319623  0.05484348  0.30385639 -0.12384027]\n",
      "\n",
      "# 24 Gradient out:  [-0.68877126 -0.63336618 -0.38512988 -0.54851551 -0.1483771  -0.14373485\n",
      " -0.46949063 -0.52451842 -0.17915151 -0.36469734]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.01289709  0.12941294 -0.06033403  0.84769755  0.34904421  0.22761521\n",
      "  0.67644573  0.58773986  0.53096394  0.26065126]\n",
      "\n",
      "# 25 Gradient out:  [-1.5019033  -1.37854166 -0.8295075  -1.18986502 -0.30475932 -0.2944269\n",
      " -1.01522815 -1.13672448 -0.37332808 -0.78451994]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.15065134  0.00273971 -0.13736001  0.73799445  0.31936879  0.19886824\n",
      "  0.5825476   0.48283617  0.49513364  0.18771179]\n",
      "\n",
      "# 26 Gradient out:  [-8.50685230e-02 -3.26783251e-02 -7.45969678e-02  1.92908066e-03\n",
      " -5.20653945e-02 -4.73839716e-02 -2.04836324e-02 -2.82619036e-05\n",
      " -8.04610471e-02 -8.74914446e-02]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.451032   -0.27296862 -0.30326151  0.50002144  0.25841692  0.13998286\n",
      "  0.37950197  0.25549128  0.42046803  0.03080781]\n",
      "\n",
      "# 27 Gradient out:  [0.21326906 0.24387118 0.09533133 0.24406381 0.01855438 0.0214102\n",
      " 0.18737519 0.23190931 0.00220709 0.07325953]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.46804571 -0.27950429 -0.3181809   0.50040726  0.24800384  0.13050606\n",
      "  0.37540525  0.25548562  0.40437582  0.01330952]\n",
      "\n",
      "# 28 Gradient out:  [-0.94822197 -0.83497355 -0.53922289 -0.69601016 -0.2089893  -0.19928647\n",
      " -0.60882717 -0.66577194 -0.27142323 -0.52219934]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.42539189 -0.23073005 -0.29911464  0.54922002  0.25171472  0.1347881\n",
      "  0.41288029  0.30186749  0.40481724  0.02796142]\n",
      "\n",
      "# 29 Gradient out:  [3.10869752 2.91916757 1.78849823 2.58867497 0.77864113 0.7629232\n",
      " 2.21896622 2.48209874 0.88355124 1.68449147]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.61503629 -0.39772476 -0.40695921  0.41001799  0.20991686  0.09493081\n",
      "  0.29111485  0.1687131   0.35053259 -0.07647844]\n",
      "\n",
      "# 30 Gradient out:  [-0.47265073 -0.43489731 -0.26621632 -0.37722022 -0.10528248 -0.10211739\n",
      " -0.32353238 -0.36091684 -0.12624104 -0.25233418]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [ 0.00670322  0.18610875 -0.04925957  0.92775298  0.36564509  0.24751545\n",
      "  0.7349081   0.66513285  0.52724284  0.26041985]\n",
      "\n",
      "# 31 Gradient out:  [-0.86618531 -0.79620222 -0.48278643 -0.68900362 -0.18380354 -0.17794066\n",
      " -0.58923702 -0.65870006 -0.22268227 -0.45700324]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.08782693  0.09912929 -0.10250283  0.85230894  0.34458859  0.22709197\n",
      "  0.67020162  0.59294948  0.50199463  0.20995301]\n",
      "\n",
      "# 32 Gradient out:  [-1.98870177 -1.82227784 -1.09498453 -1.5697965  -0.39668939 -0.38273929\n",
      " -1.33891235 -1.49928368 -0.48918401 -1.03588586]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.26106399 -0.06011115 -0.19906012  0.71450821  0.30782788  0.19150384\n",
      "  0.55235422  0.46120946  0.45745817  0.11855237]\n",
      "\n",
      "# 33 Gradient out:  [3.28132155 3.0756657  1.89959872 2.72596165 0.84121154 0.82409122\n",
      " 2.34259061 2.61489553 0.95482745 1.79254467]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.65880434 -0.42456672 -0.41805702  0.40054891  0.22849     0.11495598\n",
      "  0.28457175  0.16135273  0.35962137 -0.08862481]\n",
      "\n",
      "# 34 Gradient out:  [-0.42733253 -0.39309668 -0.23992191 -0.34074887 -0.09382187 -0.09095211\n",
      " -0.29199006 -0.32594471 -0.11282974 -0.22731093]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.00254004  0.19056642 -0.03813728  0.94574124  0.39673231  0.27977423\n",
      "  0.75308987  0.68433183  0.55058686  0.26988413]\n",
      "\n",
      "# 35 Gradient out:  [-0.74652275 -0.68614395 -0.41535646 -0.59359737 -0.15712868 -0.15207072\n",
      " -0.50738709 -0.56741863 -0.19067195 -0.39306621]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.08800654  0.11194708 -0.08612166  0.87759147  0.37796794  0.2615838\n",
      "  0.69469186  0.61914289  0.52802091  0.22442194]\n",
      "\n",
      "# 36 Gradient out:  [-1.67370513 -1.53508725 -0.92101597 -1.32350575 -0.33342129 -0.32180892\n",
      " -1.12827866 -1.26404342 -0.41046894 -0.87080769]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.23731109 -0.02528171 -0.16919295  0.758872    0.3465422   0.23116966\n",
      "  0.59321444  0.50565917  0.48988652  0.1458087 ]\n",
      "\n",
      "# 37 Gradient out:  [1.36397757 1.30849229 0.72701505 1.16947544 0.24833522 0.24401843\n",
      " 0.97337103 1.11586308 0.27984573 0.66760683]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.57205212 -0.33229916 -0.35339615  0.49417085  0.27985794  0.16680788\n",
      "  0.36755871  0.25285048  0.40779274 -0.02835284]\n",
      "\n",
      "# 38 Gradient out:  [-2.01887878 -1.84922839 -1.11026453 -1.59228891 -0.40022845 -0.38600452\n",
      " -1.35777769 -1.52062858 -0.49450309 -1.05029546]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.2992566  -0.0706007  -0.20799314  0.72806594  0.32952498  0.21561156\n",
      "  0.56223291  0.4760231   0.46376188  0.10516853]\n",
      "\n",
      "# 39 Gradient out:  [3.32876482 3.11734554 1.93162515 2.76202173 0.86080449 0.84317251\n",
      " 2.37606167 2.64995231 0.97748727 1.82421221]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.70303236 -0.44044638 -0.43004604  0.40960815  0.2494793   0.13841066\n",
      "  0.29067737  0.17189738  0.36486126 -0.10489056]\n",
      "\n",
      "# 40 Gradient out:  [-0.42971343 -0.3951544  -0.24030863 -0.34225873 -0.09265261 -0.08975635\n",
      " -0.29296175 -0.32729302 -0.11184311 -0.22755603]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.03727939  0.18302273 -0.04372102  0.9620125   0.42164019  0.30704516\n",
      "  0.76588971  0.70188784  0.56035872  0.25995188]\n",
      "\n",
      "# 41 Gradient out:  [-0.75239449 -0.69133194 -0.4171801  -0.59766433 -0.15579255 -0.15067813\n",
      " -0.51037473 -0.57116004 -0.18972015 -0.39460799]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.12322208  0.10399185 -0.09178274  0.89356075  0.40310967  0.28909389\n",
      "  0.70729736  0.63642924  0.53799009  0.21444067]\n",
      "\n",
      "# 42 Gradient out:  [-1.68999013 -1.54956007 -0.92802453 -1.3353058  -0.33315884 -0.32139402\n",
      " -1.13772338 -1.2751159  -0.41121145 -0.87722563]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.27370098 -0.03427454 -0.17521876  0.77402789  0.37195116  0.25895826\n",
      "  0.60522241  0.52219723  0.50004606  0.13551907]\n",
      "\n",
      "# 43 Gradient out:  [1.4689362  1.40489598 0.77716164 1.25121014 0.25595072 0.25093107\n",
      " 1.04014045 1.19316007 0.29227677 0.7137317 ]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.61169901 -0.34418655 -0.36082367  0.50696673  0.30531939  0.19467946\n",
      "  0.37767774  0.26717405  0.41780378 -0.03992605]\n",
      "\n",
      "# 44 Gradient out:  [-1.93375173 -1.77167668 -1.06210301 -1.52565302 -0.38117699 -0.36759118\n",
      " -1.30034353 -1.45687468 -0.47124446 -1.00438371]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.31791177 -0.06320736 -0.20539134  0.75720875  0.35650954  0.24486568\n",
      "  0.58570583  0.50580606  0.47625913  0.10282029]\n",
      "\n",
      "# 45 Gradient out:  [3.0345981  2.84704396 1.72240944 2.51862691 0.71856074 0.70302179\n",
      " 2.15078641 2.41260748 0.82246336 1.61890818]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.70466211 -0.41754269 -0.41781194  0.45207815  0.28027414  0.17134744\n",
      "  0.32563712  0.21443113  0.38201024 -0.09805646]\n",
      "\n",
      "# 46 Gradient out:  [-0.53607628 -0.49277225 -0.29851399 -0.42642118 -0.11330167 -0.10967345\n",
      " -0.36457157 -0.40764465 -0.13735407 -0.28251478]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.09774249  0.1518661  -0.07333005  0.95580353  0.42398629  0.3119518\n",
      "  0.7557944   0.69695263  0.54650291  0.22572518]\n",
      "\n",
      "# 47 Gradient out:  [-1.04335076 -0.95804002 -0.5754925  -0.82716404 -0.21057881 -0.20343484\n",
      " -0.70538307 -0.79016733 -0.25799242 -0.54403153]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.20495775  0.05331165 -0.13303285  0.8705193   0.40132595  0.29001711\n",
      "  0.68288009  0.6154237   0.5190321   0.16922222]\n",
      "\n",
      "# 48 Gradient out:  [-2.20603909 -2.01385649 -1.21575361 -1.72954724 -0.44005804 -0.42389672\n",
      " -1.47755535 -1.65187465 -0.54669646 -1.15229316]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.4136279  -0.13829636 -0.24813135  0.70508649  0.35921019  0.24933014\n",
      "  0.54180348  0.45739023  0.46743361  0.06041592]\n",
      "\n",
      "# 49 Gradient out:  [3.17416571 2.9643544  1.93896561 2.64064974 0.98954382 0.97180063\n",
      " 2.31042221 2.54330013 1.10427218 1.84913607]\n",
      "\n",
      "     Weights  out:  [ 0.48318358  0.32976323 -0.02884177  0.18067726 -0.41998156 -0.43387501\n",
      "  0.07438135  0.14647643 -0.3413225  -0.05390035] [-0.85483572 -0.54106765 -0.49128207  0.35917704  0.27119858  0.16455079\n",
      "  0.24629241  0.1270153   0.35809432 -0.17004271]\n",
      "\n",
      "Tanh error cuadrático medio (ECM): 1.037423402982589\n",
      "\n",
      "# 0 Gradient out:  [-0.07244306 -0.14828033 -0.40231883 -0.90665187 -1.09870103 -0.08729025\n",
      " -0.89440603 -0.0892823  -0.06223618 -0.72140189]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [ 0.0294115   0.18854681  0.15610023 -0.15800273 -0.11973059 -0.09395893\n",
      "  0.38201103  0.20454116 -0.17760273  0.2469363 ]\n",
      "\n",
      "# 1 Gradient out:  [0.78191452 0.88225572 1.33267688 2.84586293 3.1218461  0.80205019\n",
      " 2.82424354 0.80471064 0.76763675 2.41361515]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [ 0.01492289  0.15889074  0.07563646 -0.33933311 -0.33947079 -0.11141698\n",
      "  0.20312983  0.1866847  -0.19004997  0.10265592]\n",
      "\n",
      "# 2 Gradient out:  [ -2.15125767  -2.61885186  -4.41580274  -9.30102345 -10.52549421\n",
      "  -2.2442194   -9.21467072  -2.25658662  -2.08626464  -7.77082997]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [ 0.17130579  0.33534189  0.34217184  0.22983948  0.28489843  0.04899306\n",
      "  0.76797853  0.34762683 -0.03652262  0.58537895]\n",
      "\n",
      "# 3 Gradient out:  [ 7.29008126  8.67439804 14.2214468  30.2706211  33.94438873  7.56568549\n",
      " 30.00409646  7.60230013  7.09682015 25.38284514]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [-0.25894574 -0.18842849 -0.54098871 -1.63036521 -1.82020041 -0.39985082\n",
      " -1.07495561 -0.10369049 -0.45377555 -0.96878704]\n",
      "\n",
      "# 4 Gradient out:  [ -23.50398064  -28.14344916  -46.47411648  -98.4727869  -110.72802919\n",
      "  -24.42737112  -97.59202241  -24.55009499  -22.85705548  -82.49697647]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [1.19907051 1.54645112 2.30330065 4.42375901 4.96867733 1.11328628\n",
      " 4.92586368 1.41676953 0.96558848 4.10778199]\n",
      "\n",
      "# 5 Gradient out:  [ 76.65743934  91.62229849 151.00809945 320.500162   360.08807204\n",
      "  79.63606542 317.64674535  80.03189787  74.57009003 268.56767566]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [ -3.50172562  -4.08223871  -6.99152264 -15.27079837 -17.1769285\n",
      "  -3.77218795 -14.5925408   -3.49324946  -3.60582262 -12.39161331]\n",
      "\n",
      "# 6 Gradient out:  [ -249.31731643  -298.14689295  -491.65393041 -1042.89593918\n",
      " -1172.00927711  -259.03630268 -1033.59817698  -260.32790976\n",
      "  -242.50699925  -873.85313794]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [11.82976225 14.24222099 23.21009725 48.82923403 54.8406859  12.15502514\n",
      " 48.93680827 12.51313011 11.30819539 41.32192182]\n",
      "\n",
      "# 7 Gradient out:  [ 811.43820713  970.20767001 1599.66390351 3393.83684955 3813.70990894\n",
      "  843.03959038 3363.59226677  847.239224    789.29389233 2843.78161486]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [ -38.03370104  -45.3871576   -75.12068884 -159.74995381 -179.56116952\n",
      "  -39.6522354  -157.78282713  -39.55245184  -37.19320446 -133.44870576]\n",
      "\n",
      "# 8 Gradient out:  [ -2640.45638657  -3157.24883428  -5205.85090425 -11044.04330227\n",
      " -12410.66302677  -2743.31840282 -10945.6105731   -2756.98818473\n",
      "  -2568.37747338  -9254.0352651 ]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [124.25394039 148.6543764  244.81209187 519.0174161  583.18081227\n",
      " 128.95568268 514.93562623 129.89539296 120.66557401 435.30761721]\n",
      "\n",
      "# 9 Gradient out:  [ 8592.58794916 10274.18999142 16940.45033578 35939.28847063\n",
      " 40386.22338579  8927.29291738 35618.98308844  8971.77328169\n",
      "  8358.04830854 30114.32790386]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [ -403.83733693  -482.79539046  -796.35808898 -1689.79124435\n",
      " -1898.95179308  -419.70799789 -1674.18648839  -421.50224399\n",
      "  -393.00992067 -1415.49943581]\n",
      "\n",
      "# 10 Gradient out:  [ -27961.66367378  -33434.01219497  -55127.40009757 -116952.49433254\n",
      " -131423.85750843  -29050.87629702 -115910.15450336  -29195.62642535\n",
      "  -27198.41424637  -97997.04864961]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [1314.68025291 1572.04260783 2591.73197817 5498.06644977 6178.29288407\n",
      " 1365.75058559 5449.6101293  1372.85241235 1278.59974104 4607.36614496]\n",
      "\n",
      "# 11 Gradient out:  [ 90992.10912923 108799.93798274 179393.69052361 380583.47973607\n",
      " 427675.49068036  94536.56762199 377191.53924896  95007.60584642\n",
      "  88508.38245969 318899.25003901]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [ -4277.65248185  -5114.75983117  -8433.74804134 -17892.43241673\n",
      " -20106.47861761  -4444.42467382 -17732.42077138  -4466.27287272\n",
      "  -4161.08310824 -14992.04358496]\n",
      "\n",
      "# 12 Gradient out:  [ -296103.78595523  -354053.62967292  -583777.99175911 -1238483.54869902\n",
      " -1391729.27000417  -307638.08453114 -1227445.58380636  -309170.92676024\n",
      "  -288021.29794412 -1037752.5038986 ]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [13920.769344   16645.22776538 27444.99006338 58224.26353048\n",
      " 65428.61951846 14462.88885058 57705.88707841 14535.24829656\n",
      " 13540.5933837  48787.80642284]\n",
      "\n",
      "# 13 Gradient out:  [ 963572.36318406 1152150.92441583 1899712.99711372 4030237.06918125\n",
      " 4528924.54346581 1001106.91536548 3994317.65755977 1006095.04236878\n",
      "  937270.58405079 3377023.99445534]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [ -45299.98784705  -54165.4981692   -89310.60828844 -189472.44620932\n",
      " -212917.23448237  -47064.72805565 -187783.22968286  -47298.93705548\n",
      "  -44063.66620512 -158762.69435688]\n",
      "\n",
      "# 14 Gradient out:  [ -3135628.95706568  -3749295.92765322  -6181990.81535121\n",
      " -13115079.62090616 -14737894.10241047  -3257772.82521926\n",
      " -12998191.70993819  -3274005.04574852  -3050038.45877322\n",
      " -10989412.69328538]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [147414.48478976 176264.68671396 290631.9911343  616574.96762693\n",
      " 692867.67421079 153156.65501745 611080.3018291  153920.07141827\n",
      " 143390.45060504 516642.10453419]\n",
      "\n",
      "# 15 Gradient out:  [10203872.20556523 12200849.20455334 20117253.59565407 42678708.99140625\n",
      " 47959624.18799148 10601349.18737688 42298335.77797626 10654171.60177105\n",
      "  9925346.1239287  35761425.80986031]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [ -479711.30662337  -573594.49881668  -945766.17193594 -2006440.95655431\n",
      " -2254711.14627131  -498397.9100264  -1988558.04015854  -500880.93773143\n",
      "  -466617.24114961 -1681240.43412289]\n",
      "\n",
      "# 16 Gradient out:  [-3.32051427e+07 -3.97036470e+07 -6.54649791e+07 -1.38883808e+08\n",
      " -1.56068808e+08 -3.44986007e+07 -1.37646008e+08 -3.46704939e+07\n",
      " -3.22987713e+07 -1.16373787e+08]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [1561063.13448967 1866575.34209399 3077684.54719487 6529300.84172694\n",
      " 7337213.69132699 1621871.92744898 6471109.11543671 1629953.38262278\n",
      " 1518451.98363613 5471044.72784918]\n",
      "\n",
      "# 17 Gradient out:  [1.08055205e+08 1.29202448e+08 2.13034222e+08 4.51951629e+08\n",
      " 5.07874554e+08 1.12264339e+08 4.47923618e+08 1.12823708e+08\n",
      " 1.05105718e+08 3.78700177e+08]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [ -5079965.40915158  -6074154.0670087  -10015311.2811111\n",
      " -21247460.69803075 -23876547.88931654  -5277848.21729557\n",
      " -21058092.54265593  -5304145.39429967  -4941302.26925216\n",
      " -17803712.6435299 ]\n",
      "\n",
      "# 18 Gradient out:  [-3.51630092e+08 -4.20446831e+08 -6.93249741e+08 -1.47072779e+09\n",
      " -1.65271054e+09 -3.65327330e+08 -1.45761995e+09 -3.67147615e+08\n",
      " -3.42031956e+08 -1.23235505e+09]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [16531075.65064103 19766335.54871809 32591533.12807035 69142865.12725595\n",
      " 77698362.99064769 17175019.487238   68526631.15126969 17260596.24990428\n",
      " 16079841.29353214 57936322.76394778]\n",
      "\n",
      "# 19 Gradient out:  [1.14426437e+09 1.36820579e+09 2.25595305e+09 4.78599939e+09\n",
      " 5.37820234e+09 1.18883752e+09 4.74334426e+09 1.19476104e+09\n",
      " 1.11303040e+09 4.01029380e+09]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [-5.37949427e+07 -6.43230307e+07 -1.06058415e+08 -2.25002692e+08\n",
      " -2.52843744e+08 -5.58904465e+07 -2.22997359e+08 -5.61689267e+07\n",
      " -5.23265499e+07 -1.88534687e+08]\n",
      "\n",
      "# 20 Gradient out:  [-3.72363168e+09 -4.45237532e+09 -7.34125651e+09 -1.55744594e+10\n",
      " -1.75015889e+10 -3.86868033e+09 -1.54356523e+10 -3.88795647e+09\n",
      " -3.62199100e+09 -1.30501809e+10]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [1.75057931e+08 2.09318128e+08 3.45132195e+08 7.32197186e+08\n",
      " 8.22796723e+08 1.81877058e+08 7.25671492e+08 1.82783281e+08\n",
      " 1.70279530e+08 6.13524072e+08]\n",
      "\n",
      "# 21 Gradient out:  [1.21173334e+10 1.44887897e+10 2.38897024e+10 5.06819506e+10\n",
      " 5.69531592e+10 1.25893465e+10 5.02302487e+10 1.26520743e+10\n",
      " 1.17865773e+10 4.24675174e+10]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [-5.69668405e+08 -6.81156936e+08 -1.12311911e+09 -2.38269469e+09\n",
      " -2.67752106e+09 -5.91859008e+08 -2.36145897e+09 -5.94808012e+08\n",
      " -5.54118670e+08 -1.99651211e+09]\n",
      "\n",
      "# 22 Gradient out:  [-3.94318724e+10 -4.71489960e+10 -7.77411716e+10 -1.64927723e+11\n",
      " -1.85335307e+11 -4.09678835e+10 -1.63457808e+11 -4.11720106e+10\n",
      " -3.83555354e+10 -1.38196554e+11]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [1.85379828e+09 2.21660100e+09 3.65482138e+09 7.75369544e+09\n",
      " 8.71311079e+09 1.92601029e+09 7.68459077e+09 1.93560686e+09\n",
      " 1.80319678e+09 6.49699137e+09]\n",
      "\n",
      "# 23 Gradient out:  [1.28318047e+11 1.53430885e+11 2.52983049e+11 5.36702977e+11\n",
      " 6.03112740e+11 1.33316490e+11 5.31919621e+11 1.33980754e+11\n",
      " 1.24815463e+11 4.49715189e+11]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [-6.03257619e+09 -7.21319820e+09 -1.18934129e+10 -2.52318491e+10\n",
      " -2.83539505e+10 -6.26756642e+09 -2.50069707e+10 -6.29879527e+09\n",
      " -5.86791029e+09 -2.11423195e+10]\n",
      "\n",
      "# 24 Gradient out:  [-4.17568839e+11 -4.99290303e+11 -8.23250047e+11 -1.74652315e+12\n",
      " -1.96263186e+12 -4.33834625e+11 -1.73095729e+12 -4.35996255e+11\n",
      " -4.06170831e+11 -1.46345003e+12]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [1.96310332e+10 2.34729788e+10 3.87031969e+10 8.21087462e+10\n",
      " 9.22685974e+10 2.03957315e+10 8.13769535e+10 2.04973555e+10\n",
      " 1.90951822e+10 6.88007183e+10]\n",
      "\n",
      "# 25 Gradient out:  [1.35884031e+12 1.62477592e+12 2.67899625e+12 5.68348459e+12\n",
      " 6.38673924e+12 1.41177196e+12 5.63283064e+12 1.41880627e+12\n",
      " 1.32174925e+12 4.76231632e+12]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [-6.38827346e+10 -7.63850819e+10 -1.25946812e+11 -2.67195883e+11\n",
      " -3.00257774e+11 -6.63711935e+10 -2.64814504e+11 -6.67018955e+10\n",
      " -6.21389840e+10 -2.23889287e+11]\n",
      "\n",
      "# 26 Gradient out:  [-4.42189845e+12 -5.28729832e+12 -8.71791131e+12 -1.84950295e+13\n",
      " -2.07835402e+13 -4.59414707e+12 -1.83301929e+13 -4.61703792e+12\n",
      " -4.30119779e+12 -1.54973906e+13]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [2.07885328e+11 2.48570102e+11 4.09852437e+11 8.69501035e+11\n",
      " 9.77090074e+11 2.15983199e+11 8.61751623e+11 2.17059359e+11\n",
      " 2.02210866e+11 7.28573977e+11]\n",
      "\n",
      "# 27 Gradient out:  [1.43896127e+13 1.72057717e+13 2.83695723e+13 6.01859846e+13\n",
      " 6.76331893e+13 1.49501392e+13 5.96495781e+13 1.50246299e+13\n",
      " 1.39968322e+13 5.04311558e+13]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [-6.76494362e+11 -8.08889562e+11 -1.33372983e+12 -2.82950486e+12\n",
      " -3.17961797e+12 -7.02846215e+11 -2.80428695e+12 -7.06348225e+11\n",
      " -6.58028693e+11 -2.37090415e+12]\n",
      "\n",
      "# 28 Gradient out:  [-4.68262573e+13 -5.59905195e+13 -9.23194332e+13 -1.95855472e+14\n",
      " -2.20089949e+14 -4.86503060e+13 -1.94109914e+14 -4.88927116e+13\n",
      " -4.55480823e+13 -1.64111594e+14]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [2.20142819e+12 2.63226478e+12 4.34018463e+12 9.20769205e+12\n",
      " 1.03470199e+13 2.28718162e+12 9.12562866e+12 2.29857776e+12\n",
      " 2.14133774e+12 7.71532701e+12]\n",
      "\n",
      "# 29 Gradient out:  [1.52380638e+14 1.82202713e+14 3.00423202e+14 6.37347156e+14\n",
      " 7.16210280e+14 1.58316404e+14 6.31666811e+14 1.59105234e+14\n",
      " 1.48221239e+14 5.34047153e+14]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [-7.16382328e+12 -8.56583913e+12 -1.41237020e+13 -2.99634024e+13\n",
      " -3.36709698e+13 -7.44287959e+12 -2.96963542e+13 -7.47996457e+12\n",
      " -6.96827872e+12 -2.51069917e+13]\n",
      "\n",
      "# 30 Gradient out:  [-4.95872621e+14 -5.92918744e+14 -9.77628406e+14 -2.07403649e+15\n",
      " -2.33067057e+15 -5.15188617e+14 -2.05555168e+15 -5.17755602e+14\n",
      " -4.82337224e+14 -1.73788064e+15]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [2.33123044e+13 2.78747034e+13 4.59609384e+13 9.75060287e+13\n",
      " 1.09571086e+14 2.42204013e+13 9.66370080e+13 2.43410822e+13\n",
      " 2.26759690e+13 8.17024388e+13]\n",
      "\n",
      "# 31 Gradient out:  [1.61365419e+15 1.92945885e+15 3.18136979e+15 6.74926895e+15\n",
      " 7.58440006e+15 1.67651174e+15 6.68911621e+15 1.68486515e+15\n",
      " 1.56960770e+15 5.65536040e+15]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [-7.58622198e+13 -9.07090454e+13 -1.49564743e+14 -3.17301270e+14\n",
      " -3.56563027e+14 -7.88173221e+13 -3.14473328e+14 -7.92100383e+13\n",
      " -7.37914758e+13 -2.65873689e+14]\n",
      "\n",
      "# 32 Gradient out:  [-5.25110633e+15 -6.27878862e+15 -1.03527206e+16 -2.19632738e+16\n",
      " -2.46809331e+16 -5.45565553e+15 -2.17675265e+16 -5.48283895e+15\n",
      " -5.10777152e+15 -1.84035086e+16]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [2.46868619e+14 2.95182725e+14 4.86709216e+14 1.03255252e+15\n",
      " 1.16031698e+15 2.56485027e+14 1.02334992e+15 2.57762992e+14\n",
      " 2.40130064e+14 8.65198391e+14]\n",
      "\n",
      "# 33 Gradient out:  [1.70879968e+16 2.04322505e+16 3.36895210e+16 7.14722439e+16\n",
      " 8.03159712e+16 1.77536348e+16 7.08352489e+16 1.78420943e+16\n",
      " 1.66215608e+16 5.98881599e+16]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [-8.03352647e+14 -9.60574999e+14 -1.58383491e+15 -3.36010224e+15\n",
      " -3.77586963e+15 -8.34646080e+14 -3.33015539e+15 -8.38804798e+14\n",
      " -7.81424240e+14 -2.81550332e+15]\n",
      "\n",
      "# 34 Gradient out:  [-5.56072599e+16 -6.64900325e+16 -1.09631455e+17 -2.32582888e+17\n",
      " -2.61361887e+17 -5.77733597e+16 -2.30509997e+17 -5.80612220e+16\n",
      " -5.40893976e+16 -1.94886300e+17]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [2.61424671e+15 3.12587509e+15 5.15406928e+15 1.09343465e+16\n",
      " 1.22873246e+16 2.71608089e+15 1.08368944e+16 2.72961407e+15\n",
      " 2.54288793e+15 9.16212865e+15]\n",
      "\n",
      "# 35 Gradient out:  [1.80955520e+17 2.16369921e+17 3.56759477e+17 7.56864438e+17\n",
      " 8.50516216e+17 1.88004379e+17 7.50118897e+17 1.88941132e+17\n",
      " 1.76016137e+17 6.34193303e+17]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [-8.50720526e+15 -1.01721314e+16 -1.67722217e+16 -3.55822310e+16\n",
      " -3.99850528e+16 -8.83859106e+15 -3.52651050e+16 -8.88263034e+15\n",
      " -8.27499160e+15 -2.98151314e+16]\n",
      "\n",
      "# 36 Gradient out:  [-5.88860167e+17 -7.04104675e+17 -1.16095627e+18 -2.46296614e+18\n",
      " -2.76772502e+18 -6.11798358e+17 -2.44101500e+18 -6.14846712e+17\n",
      " -5.72786571e+17 -2.06377332e+18]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [2.76838988e+16 3.31018528e+16 5.45796737e+16 1.15790657e+17\n",
      " 1.30118190e+17 2.87622848e+16 1.14758674e+17 2.89055961e+16\n",
      " 2.69282359e+16 9.70235293e+16]\n",
      "\n",
      "# 37 Gradient out:  [1.91625155e+18 2.29127686e+18 3.77794996e+18 8.01491245e+18\n",
      " 9.00664988e+18 1.99089634e+18 7.94347969e+18 2.00081620e+18\n",
      " 1.86394532e+18 6.71587083e+18]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [-9.00881346e+16 -1.07719082e+17 -1.77611579e+17 -3.76802571e+17\n",
      " -4.23426813e+17 -9.35973868e+16 -3.73444325e+17 -9.40637463e+16\n",
      " -8.76290784e+16 -3.15731134e+17]\n",
      "\n",
      "# 38 Gradient out:  [-6.23580980e+18 -7.45620621e+18 -1.22940944e+19 -2.60818939e+19\n",
      " -2.93091769e+19 -6.47871670e+18 -2.58494395e+19 -6.51099763e+18\n",
      " -6.06559641e+18 -2.18545906e+19]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [2.93162175e+17 3.50536290e+17 5.77978412e+17 1.22617992e+18\n",
      " 1.37790316e+18 3.04581881e+17 1.21525161e+18 3.06099495e+17\n",
      " 2.85159986e+17 1.02744303e+18]\n",
      "\n",
      "# 39 Gradient out:  [2.02923901e+19 2.42637684e+19 4.00070827e+19 8.48749371e+19\n",
      " 9.53770671e+19 2.10828506e+19 8.41184907e+19 2.11878983e+19\n",
      " 1.97384866e+19 7.11185703e+19]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [-9.53999785e+17 -1.14070495e+18 -1.88084046e+18 -3.99019886e+18\n",
      " -4.48393221e+18 -9.91161458e+17 -3.95463629e+18 -9.96100032e+17\n",
      " -9.27959296e+17 -3.34347509e+18]\n",
      "\n",
      "# 40 Gradient out:  [-6.60349028e+19 -7.89584461e+19 -1.30189880e+20 -2.76197540e+20\n",
      " -3.10373265e+20 -6.86071963e+19 -2.73735935e+20 -6.89490394e+19\n",
      " -6.42324064e+19 -2.31431973e+20]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [3.10447823e+18 3.71204872e+18 6.12057607e+18 1.29847885e+19\n",
      " 1.45914812e+19 3.22540866e+18 1.28690619e+19 3.24147962e+18\n",
      " 3.01973803e+18 1.08802390e+19]\n",
      "\n",
      "# 41 Gradient out:  [2.14888851e+20 2.56944268e+20 4.23660102e+20 8.98793965e+20\n",
      " 1.01000761e+21 2.23259534e+20 8.90783481e+20 2.24371949e+20\n",
      " 2.09023220e+20 7.53119166e+20]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [-1.01025023e+19 -1.20796405e+19 -1.99173998e+19 -4.22547195e+19\n",
      " -4.74831718e+19 -1.04960306e+19 -4.18781251e+19 -1.05483283e+19\n",
      " -9.82674326e+18 -3.54061557e+19]\n",
      "\n",
      "# 42 Gradient out:  [-6.99285021e+20 -8.36140530e+20 -1.37866233e+21 -2.92482906e+21\n",
      " -3.28673725e+21 -7.26524651e+20 -2.89876158e+21 -7.30144642e+20\n",
      " -6.80197256e+20 -2.45077838e+21]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [3.28752679e+19 3.93092132e+19 6.48146206e+19 1.37504074e+20\n",
      " 1.54518350e+20 3.41558761e+19 1.36278571e+20 3.43260616e+19\n",
      " 3.19779008e+19 1.15217677e+20]\n",
      "\n",
      "# 43 Gradient out:  [2.27559288e+21 2.72094408e+21 4.48640266e+21 9.51789327e+21\n",
      " 1.06956043e+22 2.36423529e+21 9.43306522e+21 2.37601536e+21\n",
      " 2.21347804e+21 7.97525141e+21]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [-1.06981736e+20 -1.27918893e+20 -2.10917844e+20 -4.47461739e+20\n",
      " -5.02829100e+20 -1.11149054e+20 -4.43473744e+20 -1.11702867e+20\n",
      " -1.04061550e+20 -3.74937999e+20]\n",
      "\n",
      "# 44 Gradient out:  [-7.40516787e+21 -8.85441673e+21 -1.45995204e+22 -3.09728502e+22\n",
      " -3.48053231e+22 -7.69362541e+21 -3.06968052e+22 -7.73195976e+21\n",
      " -7.20303555e+21 -2.59528301e+22]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [3.48136841e+20 4.16269924e+20 6.86362687e+20 1.45611692e+21\n",
      " 1.63629177e+21 3.61698004e+20 1.44313930e+21 3.63500205e+20\n",
      " 3.38634057e+20 1.22011228e+21]\n",
      "\n",
      "# 45 Gradient out:  [2.40976809e+22 2.88137842e+22 4.75093328e+22 1.00790944e+23\n",
      " 1.13262466e+23 2.50363710e+22 9.98926466e+22 2.51611175e+22\n",
      " 2.34399078e+22 8.44549414e+22]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [-1.13289673e+21 -1.35461342e+21 -2.23354140e+21 -4.73845312e+21\n",
      " -5.32477286e+21 -1.17702708e+21 -4.69622174e+21 -1.18289175e+21\n",
      " -1.10197305e+21 -3.97045374e+21]\n",
      "\n",
      "# 46 Gradient out:  [-7.84179692e+22 -9.37649747e+22 -1.54603483e+23 -3.27990945e+23\n",
      " -3.68575406e+23 -8.14726270e+22 -3.25067732e+23 -8.18785736e+22\n",
      " -7.62774631e+22 -2.74830803e+23]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [3.68663945e+21 4.40814342e+21 7.26832516e+21 1.54197357e+22\n",
      " 1.73277203e+22 3.83024712e+21 1.52823076e+22 3.84933176e+21\n",
      " 3.58600851e+21 1.29205345e+22]\n",
      "\n",
      "# 47 Gradient out:  [2.55185464e+23 3.05127241e+23 5.03106136e+23 1.06733855e+24\n",
      " 1.19940732e+24 2.65125842e+23 1.05782592e+24 2.66446862e+23\n",
      " 2.48219892e+23 8.94346368e+23]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [-1.19969544e+22 -1.43448515e+22 -2.36523714e+22 -5.01784534e+22\n",
      " -5.63873610e+22 -1.24642783e+22 -4.97312388e+22 -1.25263829e+22\n",
      " -1.16694841e+22 -4.20456260e+22]\n",
      "\n",
      "# 48 Gradient out:  [-8.30417081e+23 -9.92936153e+23 -1.63719329e+24 -3.47330193e+24\n",
      " -3.90307625e+24 -8.62764770e+23 -3.44234619e+24 -8.67063592e+23\n",
      " -8.07749919e+23 -2.91035582e+24]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [3.90401384e+22 4.66805967e+22 7.69688559e+22 1.63289257e+23\n",
      " 1.83494102e+23 4.05608902e+22 1.61833944e+23 4.07629894e+22\n",
      " 3.79744943e+22 1.36823648e+23]\n",
      "\n",
      "# 49 Gradient out:  [2.70231900e+24 3.23118382e+24 5.32770656e+24 1.13027176e+25\n",
      " 1.27012767e+25 2.80758390e+24 1.12019824e+25 2.82157301e+24\n",
      " 2.62855619e+24 9.47079487e+24]\n",
      "\n",
      "     Weights  out:  [-0.47961746 -0.3820712  -0.16124188  0.257667    0.45328799 -0.45740666\n",
      "  0.24756884 -0.45457782 -0.49624119  0.10857378] [-1.27043278e+23 -1.51906634e+23 -2.50469802e+23 -5.31371128e+23\n",
      " -5.97121147e+23 -1.31992064e+23 -5.26635293e+23 -1.32649729e+23\n",
      " -1.23575490e+23 -4.45247516e+23]\n",
      "\n",
      "Lineal error cuadrático medio (ECM): 3.170370917431998e+49\n",
      "\n",
      "# 0 Gradient out:  [2.84368777 2.769078   2.07262976 2.48862297 2.80413283 1.14955942\n",
      " 2.69146978 0.92025285 2.31473857 0.9105836 ]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [-0.25317674 -0.1161333  -0.26868833 -0.1971307  -0.18947416  0.38016169\n",
      " -0.41691222 -0.17958105  0.02511784  0.25923526]\n",
      "\n",
      "# 1 Gradient out:  [-0.58491624 -0.56625358 -0.40235071 -0.49665097 -0.57507165 -0.19168334\n",
      " -0.54665228 -0.13516463 -0.45607373 -0.1329614 ]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [0.31556081 0.43768229 0.14583762 0.30059389 0.3713524  0.61007358\n",
      " 0.12138174 0.00446952 0.48806555 0.44135198]\n",
      "\n",
      "# 2 Gradient out:  [-1.39036159 -1.3441451  -0.93745929 -1.17121297 -1.36600189 -0.41525691\n",
      " -1.29548134 -0.27548674 -1.070501   -0.2700869 ]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [ 0.19857756  0.32443158  0.06536748  0.2012637   0.25633807  0.57173691\n",
      "  0.01205128 -0.02256341  0.39685081  0.4147597 ]\n",
      "\n",
      "# 3 Gradient out:  [1.32682396 1.30619899 0.91558236 1.18715963 1.31636917 0.33288233\n",
      " 1.28010723 0.26982327 1.08327498 0.26763712]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [-0.07949476  0.05560256 -0.12212438 -0.0329789  -0.0168623   0.48868553\n",
      " -0.24704498 -0.07766075  0.18275061  0.36074232]\n",
      "\n",
      "# 4 Gradient out:  [-1.44414771 -1.39604075 -0.97297683 -1.21606824 -1.41879189 -0.42988051\n",
      " -1.34538704 -0.28440301 -1.11130916 -0.27878456]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [ 0.18587004  0.31684236  0.06099209  0.20445303  0.24641153  0.55526199\n",
      "  0.00897646 -0.0236961   0.3994056   0.41426975]\n",
      "\n",
      "# 5 Gradient out:  [1.82070362 1.78470398 1.25637136 1.60820243 1.80212436 0.49480581\n",
      " 1.74252043 0.38494621 1.47012518 0.38088322]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [-0.1029595   0.03763421 -0.13360328 -0.03876062 -0.03734685  0.46928589\n",
      " -0.26010095 -0.0805767   0.17714377  0.35851284]\n",
      "\n",
      "# 6 Gradient out:  [-0.81330188 -0.78700859 -0.55553957 -0.68875681 -0.79943678 -0.25797721\n",
      " -0.75936038 -0.17838693 -0.63143316 -0.1752945 ]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [ 0.26118122  0.394575    0.117671    0.28287987  0.32307802  0.56824705\n",
      "  0.08840314 -0.00358746  0.4711688   0.43468948]\n",
      "\n",
      "# 7 Gradient out:  [-2.0274976  -1.95690928 -1.35173546 -1.69571437 -1.99027173 -0.58140767\n",
      " -1.88284894 -0.36810452 -1.54639176 -0.35987436]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [ 0.09852084  0.23717328  0.00656308  0.14512851  0.16319067  0.51665161\n",
      " -0.06346894 -0.03926485  0.34488217  0.39963058]\n",
      "\n",
      "# 8 Gradient out:  [2.61652384 2.54747381 1.92543371 2.29339514 2.5798269  1.10685739\n",
      " 2.47637828 0.89419981 2.13880554 0.88508303]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [-0.30697868 -0.15420857 -0.26378401 -0.19401437 -0.23486368  0.40037008\n",
      " -0.44003872 -0.11288575  0.03560382  0.32765571]\n",
      "\n",
      "# 9 Gradient out:  [-0.97654448 -0.94429599 -0.65958546 -0.82352092 -0.95954527 -0.29348216\n",
      " -0.91034124 -0.19591108 -0.75298273 -0.19213281]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [0.21632609 0.35528619 0.12130273 0.26466466 0.2811017  0.62174155\n",
      " 0.05523693 0.06595421 0.46336493 0.50467232]\n",
      "\n",
      "# 10 Gradient out:  [-1.93514472 -1.86237515 -1.28897578 -1.60389229 -1.89663611 -0.57790501\n",
      " -1.78726516 -0.3578016  -1.46417172 -0.34915817]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [ 0.02101719  0.16642699 -0.01061436  0.09996048  0.08919265  0.56304512\n",
      " -0.12683132  0.026772    0.31276838  0.46624575]\n",
      "\n",
      "# 11 Gradient out:  [2.22209022 2.16359898 1.66522852 1.95539969 2.19088754 1.0169569\n",
      " 2.10432157 0.83621888 1.83248627 0.82827094]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [-0.36601175 -0.20604804 -0.26840952 -0.22081798 -0.29013457  0.44746412\n",
      " -0.48428435 -0.04478832  0.01993404  0.39641412]\n",
      "\n",
      "# 12 Gradient out:  [-1.90440026 -1.83793761 -1.26716294 -1.59209475 -1.86933862 -0.53968725\n",
      " -1.76826187 -0.33868804 -1.45122049 -0.33089515]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [ 0.07840629  0.22667176  0.06463619  0.17026195  0.14804293  0.6508555\n",
      " -0.06342003  0.12245545  0.38643129  0.56206831]\n",
      "\n",
      "# 13 Gradient out:  [2.93489985 2.85451202 2.10633254 2.55311815 2.89226148 1.11479241\n",
      " 2.77103055 0.86755398 2.36638495 0.85708285]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [-0.30247376 -0.14091577 -0.1887964  -0.148157   -0.22582479  0.54291805\n",
      " -0.41707241  0.05471784  0.09618719  0.49588928]\n",
      "\n",
      "# 14 Gradient out:  [-0.40382071 -0.39052169 -0.27282908 -0.34069192 -0.39680944 -0.12131619\n",
      " -0.37652185 -0.08106118 -0.31152353 -0.07949868]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [0.28450621 0.42998664 0.23247011 0.36246663 0.3526275  0.76587653\n",
      " 0.1371337  0.22822864 0.56946418 0.66730585]\n",
      "\n",
      "# 15 Gradient out:  [-0.79134859 -0.76483115 -0.52958804 -0.66524619 -0.7773746  -0.22675572\n",
      " -0.73687518 -0.14654027 -0.60692414 -0.1434402 ]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [0.20374207 0.3518823  0.17790429 0.29432825 0.27326562 0.7416133\n",
      " 0.06182933 0.21201641 0.50715948 0.65140611]\n",
      "\n",
      "# 16 Gradient out:  [-1.97892492 -1.90861263 -1.31436328 -1.65065261 -1.94180364 -0.5603811\n",
      " -1.83515705 -0.34765528 -1.50431643 -0.33936834]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [ 0.04547235  0.19891607  0.07198668  0.16127901  0.1177907   0.69626215\n",
      " -0.08554571  0.18270835  0.38577465  0.62271807]\n",
      "\n",
      "# 17 Gradient out:  [2.69059026 2.61594406 1.95699401 2.34472759 2.65085779 1.09316402\n",
      " 2.53956899 0.86292192 2.18140935 0.85294114]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [-0.35031263 -0.18280645 -0.19088597 -0.16885151 -0.27057003  0.58418593\n",
      " -0.45257711  0.1131773   0.08491136  0.5548444 ]\n",
      "\n",
      "# 18 Gradient out:  [-0.76726169 -0.74132039 -0.5105454  -0.64372464 -0.75359454 -0.21331145\n",
      " -0.71394669 -0.13485711 -0.58648786 -0.13183086]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [0.18780542 0.34038236 0.20051283 0.30009401 0.25960153 0.80281874\n",
      " 0.05533668 0.28576168 0.52119324 0.72543263]\n",
      "\n",
      "# 19 Gradient out:  [-1.92060086 -1.85209422 -1.27210163 -1.60059421 -1.88443291 -0.53573693\n",
      " -1.78051463 -0.32844483 -1.45773097 -0.32036458]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [ 0.03435308  0.19211828  0.09840375  0.17134908  0.10888262  0.76015645\n",
      " -0.08745266  0.25879026  0.40389566  0.69906646]\n",
      "\n",
      "# 20 Gradient out:  [2.73495655 2.65714273 1.95508489 2.37077217 2.69359642 1.03049424\n",
      " 2.57704661 0.79075697 2.1962591  0.78046023]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [-0.34976709 -0.17830056 -0.15601658 -0.14876976 -0.26800396  0.65300906\n",
      " -0.44355558  0.19310129  0.11234947  0.63499354]\n",
      "\n",
      "# 21 Gradient out:  [-0.61913953 -0.59815596 -0.4109234  -0.51908302 -0.6080862  -0.1695893\n",
      " -0.57599771 -0.10613459 -0.47262648 -0.10368949]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [0.19722422 0.35312798 0.2350004  0.32538467 0.27071532 0.85910791\n",
      " 0.07185374 0.35125269 0.55160129 0.79108559]\n",
      "\n",
      "# 22 Gradient out:  [-1.50326438 -1.4507718  -0.99168987 -1.25483951 -1.47559336 -0.4035013\n",
      " -1.39554161 -0.24476762 -1.14123978 -0.23863406]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [ 0.07339631  0.23349679  0.15281572  0.22156807  0.14909808  0.82519005\n",
      " -0.0433458   0.33002577  0.45707599  0.77034769]\n",
      "\n",
      "# 23 Gradient out:  [1.82140681 1.77977285 1.17293784 1.57375455 1.8000352  0.30464469\n",
      " 1.73035402 0.17900024 1.41525307 0.17469003]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [-0.22725656 -0.05665757 -0.04552225 -0.02939983 -0.14602059  0.74448979\n",
      " -0.32245413  0.28107224  0.22882804  0.72262088]\n",
      "\n",
      "# 24 Gradient out:  [-0.98362328 -0.95000968 -0.65138333 -0.82358001 -0.96591525 -0.26701564\n",
      " -0.91453592 -0.16538014 -0.74952725 -0.16146436]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [0.1370248  0.299297   0.18906532 0.28535108 0.21398645 0.80541873\n",
      " 0.02361668 0.31687229 0.51187865 0.75755888]\n",
      "\n",
      "# 25 Gradient out:  [-1.83094778 -1.75873961 -1.22861747 -1.51172245 -1.79258045 -0.58464364\n",
      " -1.6854744  -0.3654626  -1.38401463 -0.35659062]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [-0.05969986  0.10929506  0.05878865  0.12063507  0.0208034   0.7520156\n",
      " -0.1592905   0.28379627  0.3619732   0.72526601]\n",
      "\n",
      "# 26 Gradient out:  [2.3561295  2.28999326 1.7432524  2.058824   2.32077452 1.03652608\n",
      " 2.22355426 0.83175771 1.92456559 0.82262307]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [-0.42588941 -0.24245286 -0.18693485 -0.18170942 -0.33771269  0.63508687\n",
      " -0.49638538  0.21070375  0.08517028  0.65394789]\n",
      "\n",
      "# 27 Gradient out:  [-1.55163332 -1.49706355 -1.0214872  -1.2937288  -1.52286307 -0.41279071\n",
      " -1.43968773 -0.24776823 -1.17610366 -0.24138657]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [ 0.04533649  0.21554579  0.16171564  0.23005538  0.12644221  0.84239209\n",
      " -0.05167453  0.37705529  0.47008339  0.8184725 ]\n",
      "\n",
      "# 28 Gradient out:  [2.03059966 1.98045253 1.31685306 1.74707521 2.00466507 0.38100257\n",
      " 1.92267922 0.22921744 1.57513023 0.22376553]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [-0.26499018 -0.08386692 -0.0425818  -0.02869038 -0.1781304   0.75983394\n",
      " -0.33961208  0.32750164  0.23486266  0.77019519]\n",
      "\n",
      "# 29 Gradient out:  [-0.80386877 -0.77640368 -0.53148005 -0.67289788 -0.78940249 -0.21591544\n",
      " -0.7473947  -0.1328768  -0.61213103 -0.1296808 ]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [0.14112976 0.31222359 0.22078881 0.32072466 0.22280261 0.83603446\n",
      " 0.04492377 0.37334513 0.54988871 0.81494829]\n",
      "\n",
      "# 30 Gradient out:  [-1.95996781 -1.8885708  -1.29624146 -1.62919614 -1.92223524 -0.5484931\n",
      " -1.81430798 -0.33232506 -1.48372062 -0.32384329]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [-0.019644    0.15694285  0.1144928   0.18614509  0.06492212  0.79285137\n",
      " -0.10455517  0.34676977  0.4274625   0.78901213]\n",
      "\n",
      "# 31 Gradient out:  [2.54581606 2.47180425 1.83184971 2.20618941 2.50636652 0.99653366\n",
      " 2.39652153 0.76797522 2.04803122 0.75797582]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [-0.41163756 -0.22077131 -0.14475549 -0.13969414 -0.31952493  0.68315275\n",
      " -0.46741677  0.28030476  0.13071838  0.72424348]\n",
      "\n",
      "# 32 Gradient out:  [-0.97987577 -0.94601188 -0.64433222 -0.81839516 -0.96204088 -0.25587937\n",
      " -0.91023646 -0.15351869 -0.74355567 -0.14958439]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [0.09752565 0.27358954 0.22161445 0.30154374 0.18174837 0.88245948\n",
      " 0.01188754 0.4338998  0.54032462 0.87583864]\n",
      "\n",
      "# 33 Gradient out:  [-1.77891325 -1.70713052 -1.19387525 -1.46492358 -1.74071665 -0.57548045\n",
      " -1.63474579 -0.35731399 -1.34183597 -0.34838917]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [-0.0984495   0.08438717  0.092748    0.13786471 -0.0106598   0.83128361\n",
      " -0.17015975  0.40319606  0.39161349  0.84592176]\n",
      "\n",
      "# 34 Gradient out:  [2.35733977 2.28823536 1.71730541 2.04677755 2.32039686 0.97940827\n",
      " 2.21882556 0.76544961 1.9065929  0.75590422]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [-0.45423215 -0.25703894 -0.14602705 -0.15512    -0.35880313  0.71618752\n",
      " -0.49710891  0.33173326  0.12324629  0.77624393]\n",
      "\n",
      "# 35 Gradient out:  [-1.46723009 -1.41530285 -0.96141883 -1.22147345 -1.43985871 -0.38011506\n",
      " -1.36065909 -0.22310949 -1.10916555 -0.21704687]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [ 0.0172358   0.20060814  0.19743403  0.25423551  0.10527624  0.91206918\n",
      " -0.0533438   0.48482319  0.50456487  0.92742477]\n",
      "\n",
      "# 36 Gradient out:  [1.46041123 1.43080688 0.90601831 1.26292173 1.44552401 0.13805122\n",
      " 1.39299673 0.04980246 1.12393386 0.04723085]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [-0.27621021 -0.08245243  0.00515027  0.00994082 -0.1826955   0.83604617\n",
      " -0.32547562  0.44020129  0.28273176  0.8840154 ]\n",
      "\n",
      "# 37 Gradient out:  [-1.48687071 -1.43440472 -0.97590855 -1.23860677 -1.45921427 -0.3886867\n",
      " -1.37920165 -0.23004432 -1.12516192 -0.22391633]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [ 0.01587203  0.20370894  0.18635393  0.26252516  0.1064093   0.86365641\n",
      " -0.04687627  0.45016178  0.50751853  0.89346157]\n",
      "\n",
      "# 38 Gradient out:  [1.61159434 1.5765843  1.01392406 1.39119536 1.59380288 0.19953134\n",
      " 1.53349235 0.09456146 1.24315671 0.09123402]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [-0.28150211 -0.083172   -0.00882778  0.01480381 -0.18543355  0.78591907\n",
      " -0.3227166   0.40415292  0.28248615  0.8486783 ]\n",
      "\n",
      "# 39 Gradient out:  [-1.28489689 -1.24010034 -0.84466263 -1.07207056 -1.26129411 -0.33676661\n",
      " -1.19286721 -0.20133828 -0.97409366 -0.1961206 ]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [ 0.04081676  0.23214486  0.19395703  0.29304288  0.13332702  0.82582534\n",
      " -0.01601813  0.42306521  0.53111749  0.8669251 ]\n",
      "\n",
      "# 40 Gradient out:  [ 0.15492467  0.17037649  0.04063369  0.16939611  0.16385445 -0.21788955\n",
      "  0.17960044 -0.16911111  0.12821049 -0.1662008 ]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [-0.21616262 -0.01587521  0.02502451  0.07862877 -0.1189318   0.75847201\n",
      " -0.25459157  0.38279755  0.33629876  0.82770098]\n",
      "\n",
      "# 41 Gradient out:  [-0.58903423 -0.55071825 -0.4391214  -0.45733388 -0.56816753 -0.3737466\n",
      " -0.51637754 -0.25606749 -0.43737775 -0.2506353 ]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [-0.18517768  0.01820009  0.03315125  0.11250799 -0.08616091  0.7148941\n",
      " -0.21867149  0.34897533  0.36194086  0.79446082]\n",
      "\n",
      "# 42 Gradient out:  [2.18026947 2.12549573 1.4295892  1.87727286 2.15184387 0.45395171\n",
      " 2.063234   0.28779828 1.6976118  0.28168315]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [-0.30298453 -0.09194356 -0.05467303  0.02104121 -0.19979442  0.64014478\n",
      " -0.32194699  0.29776183  0.27446531  0.74433376]\n",
      "\n",
      "# 43 Gradient out:  [-0.64885511 -0.62688848 -0.43122957 -0.54420101 -0.63728236 -0.17912376\n",
      " -0.60370467 -0.1126881  -0.49566568 -0.11012545]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [0.13306936 0.33315558 0.23124481 0.39649579 0.23057436 0.73093512\n",
      " 0.09069981 0.35532149 0.61398767 0.8006704 ]\n",
      "\n",
      "# 44 Gradient out:  [-1.60522515 -1.54908256 -1.05995687 -1.33995027 -1.57562427 -0.43391088\n",
      " -1.49006357 -0.26412429 -1.21898148 -0.25755608]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [ 0.00329834  0.20777789  0.14499889  0.28765559  0.10311788  0.69511037\n",
      " -0.03004113  0.33278387  0.51485453  0.77864531]\n",
      "\n",
      "# 45 Gradient out:  [2.37674404 2.31493682 1.57649834 2.04542705 2.34451977 0.55146026\n",
      " 2.24598099 0.36349697 1.85588861 0.35636995]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [-0.31774669 -0.10203862 -0.06699248  0.01966553 -0.21200697  0.6083282\n",
      " -0.32805384  0.27995901  0.27105824  0.72713409]\n",
      "\n",
      "# 46 Gradient out:  [-0.51044496 -0.49327142 -0.34045313 -0.4286839  -0.50139587 -0.1435468\n",
      " -0.47515656 -0.09159512 -0.39078102 -0.08958789]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [0.15760212 0.36094874 0.24830719 0.42875094 0.25689698 0.71862025\n",
      " 0.12114236 0.3526584  0.64223596 0.79840808]\n",
      "\n",
      "# 47 Gradient out:  [-1.13747728 -1.09843899 -0.75269493 -0.95183254 -1.11690879 -0.30807207\n",
      " -1.05726591 -0.1900317  -0.866132   -0.18548112]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [0.05551313 0.26229446 0.18021656 0.34301416 0.15661781 0.68991089\n",
      " 0.02611104 0.33433938 0.56407976 0.7804905 ]\n",
      "\n",
      "# 48 Gradient out:  [-1.05479785 -1.00342188 -0.7345051  -0.85149012 -1.02718592 -0.45306042\n",
      " -0.95412809 -0.29635303 -0.7911282  -0.28961123]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [-0.17198233  0.04260666  0.02967757  0.15264765 -0.06676395  0.62829647\n",
      " -0.18534214  0.29633304  0.39085336  0.74339428]\n",
      "\n",
      "# 49 Gradient out:  [2.84643493 2.76636324 1.9744915  2.4551109  2.80413554 0.91227524\n",
      " 2.68178041 0.6667541  2.25597911 0.65662657]\n",
      "\n",
      "     Weights  out:  [ 0.40138425  0.34636935  0.04559063  0.19547397  0.3711583  -0.3054256\n",
      "  0.29720639 -0.4814608   0.12700953 -0.49096749] [-0.3829419  -0.15807772 -0.11722345 -0.01765037 -0.27220113  0.53768439\n",
      " -0.37616776  0.23706243  0.23262772  0.68547203]\n",
      "\n",
      "Tanh error cuadrático medio (ECM): 1.1159164417124894\n",
      "\n",
      "# 0 Gradient out:  [-0.80894694 -1.00639182 -3.05450415 -4.48548723 -4.12026763 -1.41442421\n",
      " -3.96609094 -4.0636664  -3.25722825 -1.60733208]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [ 0.34279457 -0.36718661 -0.09471679  0.40680389  0.06793252 -0.21661825\n",
      "  0.40403324 -0.19848206  0.46143841  0.1441748 ]\n",
      "\n",
      "# 1 Gradient out:  [ 5.82417103  6.65014508 16.3777293  22.7185919  21.18495749  8.42232093\n",
      " 20.53512499 20.94762729 17.35012581  9.3007489 ]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [ 0.18100518 -0.56846498 -0.70561762 -0.49029355 -0.75612101 -0.4995031\n",
      " -0.38918495 -1.01121534 -0.19000724 -0.17729162]\n",
      "\n",
      "# 2 Gradient out:  [ -29.29252505  -33.83126813  -85.7123711  -120.07680894 -111.64828912\n",
      "  -43.47673878 -108.08492696 -110.34508551  -90.88712633  -48.20524001]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [1.34583938 0.76156404 2.56992824 4.05342483 3.48087049 1.18496109\n",
      " 3.71784005 3.17831011 3.28001792 1.68285816]\n",
      "\n",
      "# 3 Gradient out:  [154.94107642 178.59000121 450.51259563 630.05222227 586.14366243\n",
      " 228.94464067 567.56865691 579.35229318 477.64683983 253.68362053]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [ -4.51266562  -6.00468959 -14.57254598 -19.96193696 -18.84878734\n",
      "  -7.51038667 -17.89914534 -18.89070699 -14.89740734  -7.95818984]\n",
      "\n",
      "# 4 Gradient out:  [ -812.94662113  -937.34980247 -2366.08891094 -3310.03107321\n",
      " -3079.04045048 -1202.13109165 -2981.33740591 -3043.31626937\n",
      " -2508.64541469 -1332.16056889]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [ 26.47554966  29.71331065  75.52997315 106.04850749  98.37994515\n",
      "  38.27854147  95.61458604  96.97975165  80.63196062  42.77853427]\n",
      "\n",
      "# 5 Gradient out:  [ 4270.86154594  4924.12631542 12428.45157693 17385.79897417\n",
      " 16172.84088382  6314.65365863 15659.77371133 15985.24504632\n",
      " 13177.22998663  6997.57539794]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [-136.11377457 -157.75664984 -397.68780904 -555.95770715 -517.42814495\n",
      " -202.14767686 -500.65289514 -511.68350223 -421.09712232 -223.65357951]\n",
      "\n",
      "# 6 Gradient out:  [-22432.59006455 -25864.11856865 -65281.72731623 -91321.59048584\n",
      " -84950.03305223 -33168.29203664 -82254.95767757 -83964.61406621\n",
      " -69214.78629442 -36755.48952451]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [ 718.05853462  827.06861324 2088.00250635 2921.20208768 2717.14003182\n",
      " 1060.78305486 2631.30184713 2685.36550704 2214.34887501 1175.86150008]\n",
      "\n",
      "# 7 Gradient out:  [117830.53020711 135854.89202155 342900.67944205 479677.57339473\n",
      " 446210.5120179  174220.73135319 432054.41480918 441034.52306355\n",
      " 363559.56409726 193062.87489352]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [ -3768.45947829  -4345.75510048 -10968.3429569  -15343.11600949\n",
      " -14272.86657863  -5572.87535246 -13819.68968839 -14107.5573062\n",
      " -11628.60838388  -6175.23640483]\n",
      "\n",
      "# 8 Gradient out:  [ -618919.08931576  -713594.46618118 -1801128.36285518 -2519566.77461669\n",
      " -2343776.52210295  -915116.05977395 -2269419.73492706 -2316588.94780429\n",
      " -1909641.72470771 -1014086.82389314]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [19797.64656313 22825.22330383 57611.79293151 80592.39866946\n",
      " 74969.23582495 29271.27091817 72591.19327345 74099.34730651\n",
      " 61083.30443558 32437.33857388]\n",
      "\n",
      "# 9 Gradient out:  [ 3250950.18133686  3748244.25049349  9460651.77329584 13234338.52020619\n",
      " 12310978.61104894  4806761.34624793 11920410.42342485 12168172.52928436\n",
      " 10030631.76360461  5326617.58824683]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [-103986.17130002 -119893.66993241 -302613.87963953 -423320.95625388\n",
      " -393786.06859564 -153751.94103662 -381292.75371196 -389218.44225435\n",
      " -320845.04050596 -170380.02620475]\n",
      "\n",
      "# 10 Gradient out:  [-17076021.20862536 -19688120.5362353  -49693253.97721598\n",
      " -69515015.26677778 -64664951.76954083 -25248113.91543083\n",
      " -62613443.50165918 -63914844.95658566 -52687144.9974933\n",
      " -27978723.75524776]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [ 546203.86496735  629755.18016629 1589516.47501964 2223546.74778736\n",
      " 2068409.65361415  807600.32821297 2002789.33097301 2044416.06360252\n",
      " 1685281.31221496  894943.49144462]\n",
      "\n",
      "# 11 Gradient out:  [8.96939330e+07 1.03414311e+08 2.61020019e+08 3.65136293e+08\n",
      " 3.39660730e+08 1.32618870e+08 3.28884927e+08 3.35720700e+08\n",
      " 2.76745805e+08 1.46961738e+08]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [ -2869000.37675772  -3307868.92708077  -8349134.32042356\n",
      " -11679456.3055682  -10864580.70029402  -4242022.45487319\n",
      " -10519899.36935883 -10738552.92771461  -8852147.6872837\n",
      "  -4700801.25960494]\n",
      "\n",
      "# 12 Gradient out:  [-4.71128577e+08 -5.43196573e+08 -1.37104023e+09 -1.91792395e+09\n",
      " -1.78411038e+09 -6.96597164e+08 -1.72750913e+09 -1.76341488e+09\n",
      " -1.45364188e+09 -7.71934874e+08]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [15069786.22042352 17374993.18484659 43854869.4730336  61347802.3848241\n",
      " 57067565.28460531 22281751.44727365 55257085.99323747 56405587.13489284\n",
      " 46497013.36070766 24691546.43216721]\n",
      "\n",
      "# 13 Gradient out:  [2.47466165e+09 2.85320780e+09 7.20155991e+09 1.00741349e+10\n",
      " 9.37126243e+09 3.65896355e+09 9.07395730e+09 9.26255675e+09\n",
      " 7.63543542e+09 4.05468427e+09]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [-7.91559293e+07 -9.12643215e+07 -2.30353176e+08 -3.22236988e+08\n",
      " -2.99754510e+08 -1.17037681e+08 -2.90244739e+08 -2.96277389e+08\n",
      " -2.44231363e+08 -1.29695428e+08]\n",
      "\n",
      "# 14 Gradient out:  [-1.29984692e+10 -1.49868301e+10 -3.78270923e+10 -5.29156512e+10\n",
      " -4.92237255e+10 -1.92191627e+10 -4.76620932e+10 -4.86527354e+10\n",
      " -4.01060775e+10 -2.12977352e+10]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [4.15776402e+08 4.79377238e+08 1.20995881e+09 1.69259000e+09\n",
      " 1.57449798e+09 6.14755028e+08 1.52454672e+09 1.55623396e+09\n",
      " 1.28285572e+09 6.81241425e+08]\n",
      "\n",
      "# 15 Gradient out:  [6.82760818e+10 7.87201954e+10 1.98691523e+11 2.77946062e+11\n",
      " 2.58553762e+11 1.00951051e+11 2.50351093e+11 2.55554565e+11\n",
      " 2.10662178e+11 1.11869012e+11]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [-2.18391744e+09 -2.51798877e+09 -6.35545965e+09 -8.89054023e+09\n",
      " -8.27024713e+09 -3.22907751e+09 -8.00787192e+09 -8.17431311e+09\n",
      " -6.73835978e+09 -3.57830561e+09]\n",
      "\n",
      "# 16 Gradient out:  [-3.58628641e+11 -4.13487651e+11 -1.04365203e+12 -1.45994638e+12\n",
      " -1.35808590e+12 -5.30257994e+11 -1.31500036e+12 -1.34233225e+12\n",
      " -1.10652938e+12 -5.87605949e+11]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [1.14712989e+10 1.32260503e+10 3.33828450e+10 4.66986722e+10\n",
      " 4.34405053e+10 1.69611327e+10 4.20623467e+10 4.29365999e+10\n",
      " 3.53940758e+10 1.87954968e+10]\n",
      "\n",
      "# 17 Gradient out:  [1.88374170e+12 2.17189550e+12 5.48191252e+12 7.66855058e+12\n",
      " 7.13351572e+12 2.78524630e+12 6.90720354e+12 7.05076767e+12\n",
      " 5.81218368e+12 3.08647359e+12]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [-6.02544293e+10 -6.94714800e+10 -1.75347560e+11 -2.45290604e+11\n",
      " -2.28176676e+11 -8.90904662e+10 -2.20937726e+11 -2.25529850e+11\n",
      " -1.85911800e+11 -9.87256930e+10]\n",
      "\n",
      "# 18 Gradient out:  [-9.89458838e+12 -1.14081522e+13 -2.87944297e+13 -4.02800191e+13\n",
      " -3.74696816e+13 -1.46298538e+13 -3.62809487e+13 -3.70350372e+13\n",
      " -3.05292202e+13 -1.62120877e+13]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [3.16493910e+11 3.64907619e+11 9.21034944e+11 1.28841951e+12\n",
      " 1.19852647e+12 4.67958793e+11 1.16050298e+12 1.18462368e+12\n",
      " 9.76524936e+11 5.18569024e+11]\n",
      "\n",
      "# 19 Gradient out:  [5.19725604e+13 5.99227431e+13 1.51246336e+14 2.11575827e+14\n",
      " 1.96814179e+14 7.68451330e+13 1.90570211e+14 1.94531155e+14\n",
      " 1.60358539e+14 8.51560143e+13]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [-1.66242377e+12 -1.91672281e+12 -4.83785100e+12 -6.76758430e+12\n",
      " -6.29540986e+12 -2.45801197e+12 -6.09568675e+12 -6.22238375e+12\n",
      " -5.12931910e+12 -2.72384852e+12]\n",
      "\n",
      "# 20 Gradient out:  [-2.72992360e+14 -3.14751687e+14 -7.94440256e+14 -1.11132844e+15\n",
      " -1.03379104e+15 -4.03638652e+14 -1.00099382e+15 -1.02179917e+15\n",
      " -8.42303243e+14 -4.47292593e+14]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [8.73208832e+12 1.00678258e+13 2.54114162e+13 3.55475812e+13\n",
      " 3.30674260e+13 1.29110146e+13 3.20183555e+13 3.26838473e+13\n",
      " 2.69423888e+13 1.43073543e+13]\n",
      "\n",
      "# 21 Gradient out:  [1.43392644e+15 1.65327252e+15 4.17289660e+15 5.83739134e+15\n",
      " 5.43011647e+15 2.12016240e+15 5.25784497e+15 5.36712768e+15\n",
      " 4.42430291e+15 2.34946017e+15]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [-4.58663837e+13 -5.28825116e+13 -1.33476635e+14 -1.86718107e+14\n",
      " -1.73690782e+14 -6.78167158e+13 -1.68180408e+14 -1.71675987e+14\n",
      " -1.41518260e+14 -7.51511643e+13]\n",
      "\n",
      "# 22 Gradient out:  [-7.53187762e+15 -8.68402026e+15 -2.19186602e+16 -3.06616266e+16\n",
      " -2.85223645e+16 -1.11364176e+16 -2.76174869e+16 -2.81915080e+16\n",
      " -2.32392032e+16 -1.23408328e+16]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [2.40918905e+14 2.77771993e+14 7.01102685e+14 9.80760161e+14\n",
      " 9.12332513e+14 3.56215764e+14 8.83388585e+14 9.01749549e+14\n",
      " 7.43342322e+14 3.94740870e+14]\n",
      "\n",
      "# 23 Gradient out:  [3.95621272e+16 4.56139003e+16 1.15130498e+17 1.61054020e+17\n",
      " 1.49817279e+17 5.84954235e+16 1.45064297e+17 1.48079414e+17\n",
      " 1.22066815e+17 6.48217645e+16]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [-1.26545662e+15 -1.45903206e+15 -3.68262936e+15 -5.15156515e+15\n",
      " -4.79214039e+15 -1.87106776e+15 -4.64010880e+15 -4.73655205e+15\n",
      " -3.90449832e+15 -2.07342569e+15]\n",
      "\n",
      "# 24 Gradient out:  [-2.07805011e+17 -2.39592704e+17 -6.04737312e+17 -8.45956343e+17\n",
      " -7.86933959e+17 -3.07254513e+17 -7.61968325e+17 -7.77805606e+17\n",
      " -6.41171183e+17 -3.40484408e+17]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [6.64696883e+15 7.66374800e+15 1.93434703e+16 2.70592389e+16\n",
      " 2.51713155e+16 9.82801694e+15 2.43727506e+16 2.48793308e+16\n",
      " 2.05088648e+16 1.08909272e+16]\n",
      "\n",
      "# 25 Gradient out:  [1.09152176e+18 1.25849058e+18 3.17645821e+18 4.44349128e+18\n",
      " 4.13346884e+18 1.61389268e+18 4.00233373e+18 4.08552102e+18\n",
      " 3.36783167e+18 1.78843685e+18]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [-3.49140334e+16 -4.02547929e+16 -1.01603992e+17 -1.42132030e+17\n",
      " -1.32215476e+17 -5.16228856e+16 -1.28020914e+17 -1.30681790e+17\n",
      " -1.07725372e+17 -5.72059545e+16]\n",
      "\n",
      "# 26 Gradient out:  [-5.73335426e+18 -6.61037886e+18 -1.66847432e+19 -2.33399925e+19\n",
      " -2.17115610e+19 -8.47717271e+18 -2.10227574e+19 -2.14597091e+19\n",
      " -1.76899562e+19 -9.39398778e+18]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [1.83390318e+17 2.11443324e+17 5.33687650e+17 7.46566226e+17\n",
      " 6.94478291e+17 2.71155650e+17 6.72445832e+17 6.86422414e+17\n",
      " 5.65840961e+17 3.00481416e+17]\n",
      "\n",
      "# 27 Gradient out:  [3.01151588e+19 3.47218400e+19 8.76386961e+19 1.22596224e+20\n",
      " 1.14042684e+20 4.45274077e+19 1.10424657e+20 1.12719800e+20\n",
      " 9.29187026e+19 4.93430933e+19]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [-9.63280534e+17 -1.11063245e+18 -2.80326099e+18 -3.92143228e+18\n",
      " -3.64783390e+18 -1.42427889e+18 -3.53210566e+18 -3.60551940e+18\n",
      " -2.97215027e+18 -1.57831614e+18]\n",
      "\n",
      "# 28 Gradient out:  [-1.58183630e+20 -1.82380798e+20 -4.60333189e+20 -6.43951967e+20\n",
      " -5.99023430e+20 -2.33885766e+20 -5.80019295e+20 -5.92074820e+20\n",
      " -4.88067083e+20 -2.59180756e+20]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [5.05975123e+18 5.83373555e+18 1.47244782e+19 2.05978125e+19\n",
      " 1.91607029e+19 7.48120265e+18 1.85528258e+19 1.89384407e+19\n",
      " 1.56115903e+19 8.29030251e+18]\n",
      "\n",
      "# 29 Gradient out:  [8.30879262e+20 9.57977905e+20 2.41795753e+21 3.38243808e+21\n",
      " 3.14644533e+21 1.22851418e+21 3.04662374e+21 3.10994689e+21\n",
      " 2.56363327e+21 1.36137927e+21]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [-2.65769749e+19 -3.06424241e+19 -7.73421597e+19 -1.08192581e+20\n",
      " -1.00643983e+20 -3.92959506e+19 -9.74510331e+19 -9.94765233e+19\n",
      " -8.20018263e+19 -4.35458487e+19]\n",
      "\n",
      "# 30 Gradient out:  [-4.36429703e+21 -5.03189851e+21 -1.27006237e+22 -1.77666782e+22\n",
      " -1.65270968e+22 -6.45292406e+21 -1.60027714e+22 -1.63353842e+22\n",
      " -1.34658037e+22 -7.15081452e+21]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [1.39598878e+20 1.60953157e+20 4.06249347e+20 5.68295035e+20\n",
      " 5.28645083e+20 2.06406885e+20 5.11873714e+20 5.22512854e+20\n",
      " 4.30724827e+20 2.28730005e+20]\n",
      "\n",
      "# 31 Gradient out:  [2.29240148e+22 2.64306750e+22 6.67116112e+22 9.33216945e+22\n",
      " 8.68106388e+22 3.38947890e+22 8.40565543e+22 8.58036443e+22\n",
      " 7.07308146e+22 3.75605458e+22]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [-7.33260527e+20 -8.45426546e+20 -2.13387540e+21 -2.98504060e+21\n",
      " -2.77677428e+21 -1.08417793e+21 -2.68868057e+21 -2.74456398e+21\n",
      " -2.26243591e+21 -1.20143290e+21]\n",
      "\n",
      "# 32 Gradient out:  [-1.20411249e+23 -1.38830419e+23 -3.50411064e+23 -4.90183848e+23\n",
      " -4.55983715e+23 -1.78036610e+23 -4.41517542e+23 -4.50694351e+23\n",
      " -3.71522432e+23 -1.97291455e+23]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [3.85154244e+21 4.44070845e+21 1.12084469e+22 1.56792983e+22\n",
      " 1.45853535e+22 5.69477987e+21 1.41226303e+22 1.44161649e+22\n",
      " 1.18837270e+22 6.31067625e+21]\n",
      "\n",
      "# 33 Gradient out:  [6.32475114e+23 7.29224104e+23 1.84057785e+24 2.57475184e+24\n",
      " 2.39511137e+24 9.35159513e+23 2.31912600e+24 2.36732833e+24\n",
      " 1.95146794e+24 1.03629799e+24]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [-2.02307074e+22 -2.33253754e+22 -5.88737660e+22 -8.23574713e+22\n",
      " -7.66113895e+22 -2.99125421e+22 -7.41808782e+22 -7.57227052e+22\n",
      " -6.24207593e+22 -3.31476147e+22]\n",
      "\n",
      "# 34 Gradient out:  [-3.32215448e+24 -3.83034062e+24 -9.66786488e+24 -1.35242054e+25\n",
      " -1.25806214e+25 -4.91204206e+24 -1.21814987e+25 -1.24346875e+25\n",
      " -1.02503289e+25 -5.44328453e+24]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [1.06264315e+23 1.22519445e+23 3.09241804e+23 4.32592897e+23\n",
      " 4.02410885e+23 1.57119361e+23 3.89644321e+23 3.97742960e+23\n",
      " 3.27872829e+23 1.74111983e+23]\n",
      "\n",
      "# 35 Gradient out:  [1.74500310e+25 2.01193422e+25 5.07816669e+25 7.10375768e+25\n",
      " 6.60812842e+25 2.58011140e+25 6.39848425e+25 6.53147481e+25\n",
      " 5.38411320e+25 2.85915314e+25]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [-5.58166580e+23 -6.43548679e+23 -1.62433117e+24 -2.27224818e+24\n",
      " -2.11371340e+24 -8.25289051e+23 -2.04665543e+24 -2.08919454e+24\n",
      " -1.72219296e+24 -9.14544922e+23]\n",
      "\n",
      "# 36 Gradient out:  [-9.16584659e+25 -1.05679356e+26 -2.66737044e+26 -3.73133738e+26\n",
      " -3.47100193e+26 -1.35523571e+26 -3.36088371e+26 -3.43073866e+26\n",
      " -2.82807266e+26 -1.50180587e+26]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [2.93183962e+24 3.38031976e+24 8.53200221e+24 1.19352672e+25\n",
      " 1.11025434e+25 4.33493375e+24 1.07503131e+25 1.09737551e+25\n",
      " 9.04603345e+24 4.80376135e+24]\n",
      "\n",
      "# 37 Gradient out:  [4.81447532e+26 5.55094006e+26 1.40106961e+27 1.95993153e+27\n",
      " 1.82318708e+27 7.11854474e+26 1.76534612e+27 1.80203830e+27\n",
      " 1.48548046e+27 7.88842277e+26]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [-1.53998536e+25 -1.77555514e+25 -4.48154065e+25 -6.26914805e+25\n",
      " -5.83174951e+25 -2.27697805e+25 -5.64673612e+25 -5.76410182e+25\n",
      " -4.75154197e+25 -2.52323560e+25]\n",
      "\n",
      "# 38 Gradient out:  [-2.52886325e+27 -2.91570055e+27 -7.35929301e+27 -1.02947850e+28\n",
      " -9.57651772e+27 -3.73910447e+27 -9.27270082e+27 -9.46543109e+27\n",
      " -7.80267153e+27 -4.14349251e+27]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [8.08896528e+25 9.32632499e+25 2.35398516e+26 3.29294826e+26\n",
      " 3.06319922e+26 1.19601114e+26 2.96601862e+26 3.02766642e+26\n",
      " 2.49580673e+26 1.32536099e+26]\n",
      "\n",
      "# 39 Gradient out:  [1.32831699e+28 1.53150810e+28 3.86556050e+28 5.40746430e+28\n",
      " 5.03018545e+28 1.96401129e+28 4.87060184e+28 4.97183582e+28\n",
      " 4.09845060e+28 2.17642116e+28]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [-4.24882997e+26 -4.89876860e+26 -1.23646009e+27 -1.72966217e+27\n",
      " -1.60898362e+27 -6.28219780e+26 -1.55793830e+27 -1.59031958e+27\n",
      " -1.31095363e+27 -6.96162404e+26]\n",
      "\n",
      "# 40 Gradient out:  [-6.97715075e+28 -8.04443747e+28 -2.03043390e+29 -2.84033812e+29\n",
      " -2.64216769e+29 -1.03162144e+29 -2.55834440e+29 -2.61151882e+29\n",
      " -2.15276233e+29 -1.14319238e+29]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [2.23175097e+27 2.57313935e+27 6.49466092e+27 9.08526644e+27\n",
      " 8.45138729e+27 3.29980280e+27 8.18326537e+27 8.35335206e+27\n",
      " 6.88594758e+27 3.65667991e+27]\n",
      "\n",
      "# 41 Gradient out:  [3.66483551e+29 4.22544118e+29 1.06651075e+30 1.49192305e+30\n",
      " 1.38783156e+30 5.41872039e+29 1.34380233e+30 1.37173285e+30\n",
      " 1.13076528e+30 6.00476064e+29]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [-1.17225505e+28 -1.35157356e+28 -3.41140171e+28 -4.77214959e+28\n",
      " -4.43919665e+28 -1.73326261e+28 -4.29836227e+28 -4.38770243e+28\n",
      " -3.61692991e+28 -1.92071676e+28]\n",
      "\n",
      "# 42 Gradient out:  [-1.92500059e+30 -2.21946572e+30 -5.60198082e+30 -7.83651200e+30\n",
      " -7.28975847e+30 -2.84625051e+30 -7.05848945e+30 -7.20519802e+30\n",
      " -5.93948578e+30 -3.15407547e+30]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [6.15741598e+28 7.09930880e+28 1.79188133e+29 2.50663113e+29\n",
      " 2.33174345e+29 9.10417817e+28 2.25776843e+29 2.30469546e+29\n",
      " 1.89983758e+29 1.00888045e+29]\n",
      "\n",
      "# 43 Gradient out:  [1.01113059e+31 1.16580207e+31 2.94251034e+31 4.11622574e+31\n",
      " 3.82903662e+31 1.49502861e+31 3.70755968e+31 3.78462019e+31\n",
      " 3.11978904e+31 1.65671751e+31]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [-3.23425959e+29 -3.72900056e+29 -9.41208031e+29 -1.31663929e+30\n",
      " -1.22477735e+30 -4.78208321e+29 -1.18592105e+30 -1.21057006e+30\n",
      " -9.97913399e+29 -5.29927049e+29]\n",
      "\n",
      "# 44 Gradient out:  [-5.31108961e+31 -6.12352087e+31 -1.54559028e+32 -2.16209894e+32\n",
      " -2.01124927e+32 -7.85282435e+31 -1.94744200e+32 -1.98791899e+32\n",
      " -1.63870813e+32 -8.70211549e+31]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [1.69883522e+30 1.95870408e+30 4.94381265e+30 6.91581219e+30\n",
      " 6.43329589e+30 2.51184889e+30 6.22919832e+30 6.35867032e+30\n",
      " 5.24166468e+30 2.78350797e+30]\n",
      "\n",
      "# 45 Gradient out:  [2.78971611e+32 3.21645577e+32 8.11840586e+32 1.13566946e+33\n",
      " 1.05643378e+33 4.12479400e+32 1.02291822e+33 1.04417926e+33\n",
      " 8.60751898e+32 4.57089477e+32]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [-8.92334401e+30 -1.02883377e+31 -2.59679930e+31 -3.63261667e+31\n",
      " -3.37916896e+31 -1.31937998e+31 -3.27196416e+31 -3.33997095e+31\n",
      " -2.75324979e+31 -1.46207230e+31]\n",
      "\n",
      "# 46 Gradient out:  [-1.46533320e+33 -1.68948354e+33 -4.26429401e+33 -5.96524556e+33\n",
      " -5.54905030e+33 -2.16659953e+33 -5.37300560e+33 -5.48468189e+33\n",
      " -4.52120678e+33 -2.40091953e+33]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [4.68709781e+31 5.40407777e+31 1.36400124e+32 1.90807724e+32\n",
      " 1.77495067e+32 6.93020802e+31 1.71864001e+32 1.75436143e+32\n",
      " 1.44617882e+32 7.67971724e+31]\n",
      "\n",
      "# 47 Gradient out:  [7.69684554e+33 8.87422314e+33 2.23987365e+34 3.13331968e+34\n",
      " 2.91470793e+34 1.13803344e+34 2.82223825e+34 2.88089762e+34\n",
      " 2.37482029e+34 1.26111295e+34]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [-2.46195663e+32 -2.83855930e+32 -7.16458677e+32 -1.00224139e+33\n",
      " -9.32314993e+32 -3.64017826e+32 -9.02737118e+32 -9.21500235e+32\n",
      " -7.59623474e+32 -4.03386733e+32]\n",
      "\n",
      "# 48 Gradient out:  [-4.04286418e+34 -4.66129646e+34 -1.17652159e+35 -1.64581527e+35\n",
      " -1.53098672e+35 -5.97766271e+34 -1.48241586e+35 -1.51322743e+35\n",
      " -1.24740400e+35 -6.62415316e+34]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [1.29317345e+33 1.49098870e+33 3.76328862e+33 5.26439797e+33\n",
      " 4.89710086e+33 1.91204906e+33 4.74173938e+33 4.84029500e+33\n",
      " 3.99001710e+33 2.11883916e+33]\n",
      "\n",
      "# 49 Gradient out:  [2.12356487e+35 2.44840414e+35 6.17982649e+35 8.64485011e+35\n",
      " 8.04169882e+35 3.13984194e+35 7.78657435e+35 7.94841594e+35\n",
      " 6.55214518e+35 3.47941912e+35]\n",
      "\n",
      "     Weights  out:  [-0.37315975 -0.30839787  0.09310761  0.48914821  0.33574652 -0.20526701\n",
      "  0.28962261  0.31800728  0.13060189 -0.16456551] [-6.79255492e+33 -7.83160423e+33 -1.97671432e+34 -2.76519074e+34\n",
      " -2.57226335e+34 -1.00432763e+34 -2.49065779e+34 -2.54242536e+34\n",
      " -2.09580628e+34 -1.11294672e+34]\n",
      "\n",
      "Lineal error cuadrático medio (ECM): 3.694785981319781e+71\n",
      "\n",
      "# 0 Gradient out:  [-1.88808778 -1.97447511 -1.8983853  -1.39691905 -0.47584134 -0.9446061\n",
      " -0.91298346 -0.46831112 -0.69760185 -1.80708091]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.36142389 -0.0624619   0.45955662  0.12405992  0.47948655 -0.28670511\n",
      " -0.02512432  0.49959443 -0.48337255  0.37376201]\n",
      "\n",
      "# 1 Gradient out:  [3.41434955 3.5331325  3.42823078 2.67103463 1.1310552  1.85373749\n",
      " 1.79856134 1.12089696 1.44689226 3.30492145]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [-0.01619367 -0.45735693  0.07987956 -0.15532389  0.38431828 -0.47562633\n",
      " -0.20772101  0.40593221 -0.62289292  0.01234582]\n",
      "\n",
      "# 2 Gradient out:  [-0.23387481 -0.24321697 -0.23497316 -0.18268328 -0.08674546 -0.13551952\n",
      " -0.13222866 -0.08595101 -0.10986605 -0.22532153]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.66667624  0.24926958  0.76552571  0.37888304  0.61052932 -0.10487883\n",
      "  0.15199126  0.6301116  -0.33351447  0.67333011]\n",
      "\n",
      "# 3 Gradient out:  [-0.34354661 -0.35754353 -0.34519444 -0.26644751 -0.12177501 -0.19526316\n",
      " -0.19029739 -0.12058164 -0.15657221 -0.33069935]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.61990128  0.20062618  0.71853108  0.34234638  0.59318023 -0.13198273\n",
      "  0.12554553  0.6129214  -0.35548768  0.62826581]\n",
      "\n",
      "# 4 Gradient out:  [-0.59091489 -0.61567517 -0.59383652 -0.45338998 -0.1948832  -0.32604707\n",
      " -0.31716595 -0.19276296 -0.25689187 -0.56809263]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.55119196  0.12911748  0.64949219  0.28905688  0.56882523 -0.17103536\n",
      "  0.08748605  0.58880507 -0.38680212  0.56212594]\n",
      "\n",
      "# 5 Gradient out:  [-1.32846235 -1.38687983 -1.33539043 -0.99912616 -0.37931601 -0.69367606\n",
      " -0.67236553 -0.3742673  -0.52770901 -1.27413401]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.43300898  0.00598244  0.53072489  0.19837888  0.52984859 -0.23624478\n",
      "  0.02405286  0.55025248 -0.4381805   0.44850741]\n",
      "\n",
      "# 6 Gradient out:  [0.28253264 0.26692688 0.28053541 0.30816893 0.24117642 0.2275292\n",
      " 0.22340632 0.24258685 0.21405553 0.29762373]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.16731651 -0.27139352  0.2636468  -0.00144635  0.45398538 -0.37497999\n",
      " -0.11042025  0.47539902 -0.5437223   0.19368061]\n",
      "\n",
      "# 7 Gradient out:  [-1.39782082 -1.47656557 -1.40727036 -0.98107208 -0.25553043 -0.64800272\n",
      " -0.62397938 -0.24864602 -0.45124572 -1.32379962]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.22382304 -0.21800815  0.31975389  0.06018744  0.50222067 -0.32947415\n",
      " -0.06573898  0.52391639 -0.50091119  0.25320536]\n",
      "\n",
      "# 8 Gradient out:  [3.2790727  3.39553655 3.29261957 2.57083181 1.11812397 1.80491013\n",
      " 1.7530799  1.10826623 1.42101814 3.17285471]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [-0.05574113 -0.51332126  0.03829981 -0.13602698  0.45111458 -0.45907469\n",
      " -0.19053486  0.47418719 -0.59116034 -0.01155457]\n",
      "\n",
      "# 9 Gradient out:  [-0.32232636 -0.33577768 -0.32391212 -0.24775752 -0.10755228 -0.17866923\n",
      " -0.17385193 -0.10640224 -0.1411691  -0.30994662]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.60007341  0.16578605  0.69682373  0.37813938  0.67473938 -0.09809267\n",
      "  0.16008112  0.69584043 -0.30695671  0.62301637]\n",
      "\n",
      "# 10 Gradient out:  [-0.54014652 -0.56317609 -0.54286627 -0.41166686 -0.16979684 -0.29238468\n",
      " -0.28406882 -0.16782127 -0.2276767  -0.51888245]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.53560814  0.09863051  0.6320413   0.32858788  0.65322892 -0.13382651\n",
      "  0.12531074  0.67455998 -0.33519053  0.56102705]\n",
      "\n",
      "# 11 Gradient out:  [-1.17289475 -1.22470687 -1.17903436 -0.88118706 -0.33194229 -0.61039004\n",
      " -0.5915019  -0.32747053 -0.46334338 -1.12477263]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.42757884 -0.01400471  0.52346805  0.24625451  0.61926955 -0.19230345\n",
      "  0.06849697  0.64099573 -0.38072587  0.45725056]\n",
      "\n",
      "# 12 Gradient out:  [-1.15190261 -1.22246719 -1.16032204 -0.80360928 -0.22846943 -0.5531443\n",
      " -0.53464273 -0.22239342 -0.39624432 -1.08655661]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.19299989 -0.25894608  0.28766118  0.0700171   0.5528811  -0.31438146\n",
      " -0.04980341  0.57550163 -0.47339455  0.23229603]\n",
      "\n",
      "# 13 Gradient out:  [3.42986874 3.5507413  3.44395334 2.68050611 1.12972888 1.85791589\n",
      " 1.80238214 1.11944779 1.44835958 3.31909847]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [-0.03738064 -0.50343952  0.05559677 -0.09070476  0.50718721 -0.42501032\n",
      " -0.15673195  0.53102294 -0.55264341  0.01498471]\n",
      "\n",
      "# 14 Gradient out:  [-0.1938904  -0.20191191 -0.19483535 -0.14952863 -0.06614854 -0.10845025\n",
      " -0.10558596 -0.06546367 -0.08615146 -0.18651771]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.64859311  0.20670874  0.74438744  0.44539646  0.73313299 -0.05342714\n",
      "  0.20374448  0.7549125  -0.26297149  0.67880441]\n",
      "\n",
      "# 15 Gradient out:  [-0.26819607 -0.27943284 -0.26952099 -0.20583228 -0.08851619 -0.14800043\n",
      " -0.14396859 -0.08755512 -0.11662268 -0.25785065]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.60981503  0.16632636  0.70542036  0.41549074  0.71990328 -0.07511719\n",
      "  0.18262728  0.74181976 -0.28020178  0.64150086]\n",
      "\n",
      "# 16 Gradient out:  [-0.41588251 -0.43359931 -0.41797424 -0.31707252 -0.13100243 -0.2252841\n",
      " -0.21888589 -0.1294833  -0.17550851 -0.39953107]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.55617582  0.11043979  0.65151617  0.37432428  0.70220004 -0.10471727\n",
      "  0.15383357  0.72430874 -0.30352632  0.58993073]\n",
      "\n",
      "# 17 Gradient out:  [-0.78997008 -0.82446384 -0.79405158 -0.59625471 -0.23117302 -0.41608776\n",
      " -0.4035281  -0.22820326 -0.31838624 -0.75800864]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.47299932  0.02371993  0.56792132  0.31090978  0.67599955 -0.14977409\n",
      "  0.11005639  0.69841208 -0.33862802  0.51002452]\n",
      "\n",
      "# 18 Gradient out:  [-1.92436957 -2.01360423 -1.93497024 -1.42462464 -0.4923756  -0.96867623\n",
      " -0.93675131 -0.48464864 -0.71865812 -1.84123093]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.3150053  -0.14117284  0.409111    0.19165883  0.62976495 -0.23299165\n",
      "  0.02935077  0.65277143 -0.40230527  0.35842279]\n",
      "\n",
      "# 19 Gradient out:  [3.31641171 3.43556746 3.33024143 2.59807257 1.12735894 1.82351075\n",
      " 1.77108107 1.11731649 1.43493075 3.20818967]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [-0.06986861 -0.54389369  0.02211695 -0.09326609  0.53128983 -0.42672689\n",
      " -0.1579995   0.5558417  -0.54603689 -0.00982339]\n",
      "\n",
      "# 20 Gradient out:  [-0.2754414  -0.28712553 -0.27682028 -0.210339   -0.08772829 -0.1498458\n",
      " -0.14562952 -0.0867272  -0.11704952 -0.26466567]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.59341373  0.14321981  0.68816524  0.42634842  0.75676162 -0.06202474\n",
      "  0.19621672  0.779305   -0.25905074  0.63181454]\n",
      "\n",
      "# 21 Gradient out:  [-0.43201852 -0.4506298  -0.43421768 -0.32784238 -0.13146343 -0.23089597\n",
      " -0.22413973 -0.12986497 -0.17835862 -0.41481404]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.53832545  0.0857947   0.63280118  0.38428062  0.73921596 -0.0919939\n",
      "  0.16709081  0.76195956 -0.28246065  0.57888141]\n",
      "\n",
      "# 22 Gradient out:  [-0.83799766 -0.8749514  -0.84237311 -0.62994046 -0.23761819 -0.436261\n",
      " -0.42276031 -0.23443258 -0.33125876 -0.80371448]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.45192175 -0.00433126  0.54595765  0.31871214  0.71292327 -0.1381731\n",
      "  0.12226287  0.73598656 -0.31813237  0.4959186 ]\n",
      "\n",
      "# 23 Gradient out:  [-2.01420643 -2.1092225  -2.02548486 -1.48726731 -0.51033381 -1.01191\n",
      " -0.97855255 -0.50212424 -0.74974131 -1.92587213]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.28432221 -0.17932154  0.37748303  0.19272405  0.66539963 -0.2254253\n",
      "  0.03771081  0.68910005 -0.38438412  0.3351757 ]\n",
      "\n",
      "# 24 Gradient out:  [3.01507456 3.12577538 3.02783385 2.37622467 1.08891178 1.70546874\n",
      " 1.65989144 1.07972512 1.36522301 2.91603619]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [-0.11851907 -0.60116604 -0.02761394 -0.10472941  0.56333287 -0.4278073\n",
      " -0.1579997   0.5886752  -0.53433238 -0.04999872]\n",
      "\n",
      "# 25 Gradient out:  [-0.57327354 -0.59849007 -0.57625834 -0.43117527 -0.16290146 -0.2985989\n",
      " -0.28936184 -0.16072845 -0.22681118 -0.54988746]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.48449584  0.02398904  0.57795283  0.37051553  0.78111523 -0.08671355\n",
      "  0.17397858  0.80462022 -0.26128778  0.53320852]\n",
      "\n",
      "# 26 Gradient out:  [-1.28767028 -1.34602637 -1.29459051 -0.95854528 -0.33913076 -0.65330393\n",
      " -0.63200566 -0.33408728 -0.48741892 -1.23339819]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.36984113 -0.09570897  0.46270116  0.28428047  0.74853494 -0.14643333\n",
      "  0.11610622  0.77247453 -0.30665002  0.42323102]\n",
      "\n",
      "# 27 Gradient out:  [-0.24733142 -0.28543105 -0.25171822 -0.14894797 -0.10794343 -0.18676989\n",
      " -0.18767219 -0.10498051 -0.1717133  -0.21541179]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.11230707 -0.36491425  0.20378305  0.09257142  0.68070878 -0.27709412\n",
      " -0.01029491  0.70565708 -0.4041338   0.17655139]\n",
      "\n",
      "# 28 Gradient out:  [1.3085826  1.3342573  1.31171971 1.02581188 0.31204278 0.60062609\n",
      " 0.57317825 0.30950211 0.41493912 1.28125507]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.06284079 -0.42200046  0.15343941  0.06278182  0.6591201  -0.31444809\n",
      " -0.04782935  0.68466098 -0.43847646  0.13346903]\n",
      "\n",
      "# 29 Gradient out:  [-1.69616529 -1.77424813 -1.70542867 -1.25822002 -0.43819086 -0.8558411\n",
      " -0.82771097 -0.43144212 -0.63607319 -1.62354566]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.32455731 -0.155149    0.41578335  0.2679442   0.72152865 -0.19432288\n",
      "  0.0668063   0.7465614  -0.35548864  0.38972004]\n",
      "\n",
      "# 30 Gradient out:  [3.05126215 3.15444309 3.06338015 2.36222864 0.8914666  1.5660727\n",
      " 1.51274049 0.88250729 1.17840246 2.95476985]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [-0.01467575 -0.50999862  0.07469762  0.01630019  0.63389048 -0.3654911\n",
      " -0.0987359   0.66027298 -0.48270328  0.06501091]\n",
      "\n",
      "# 31 Gradient out:  [-0.23985686 -0.25010008 -0.24106616 -0.18267039 -0.07489464 -0.12946921\n",
      " -0.12576182 -0.07401629 -0.10064059 -0.23040263]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.59557668  0.12088999  0.68737365  0.48874592  0.8121838  -0.05227656\n",
      "  0.2038122   0.83677443 -0.24702279  0.65596488]\n",
      "\n",
      "# 32 Gradient out:  [-0.35670184 -0.37212522 -0.35852457 -0.2702687  -0.10724398 -0.18975242\n",
      " -0.18414217 -0.10591886 -0.14613942 -0.34243947]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.54760531  0.07086998  0.63916042  0.45221184  0.79720487 -0.0781704\n",
      "  0.17865984  0.82197117 -0.2671509   0.60988435]\n",
      "\n",
      "# 33 Gradient out:  [-0.62853633 -0.65619529 -0.63181002 -0.4727917  -0.1788756  -0.32759096\n",
      " -0.31747299 -0.17649255 -0.24893951 -0.6028897 ]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.47626494 -0.00355507  0.5674555   0.3981581   0.77575608 -0.11612088\n",
      "  0.1418314   0.8007874  -0.29637879  0.54139646]\n",
      "\n",
      "# 34 Gradient out:  [-1.47054363 -1.53755068 -1.4784913  -1.09331967 -0.38463817 -0.7446065\n",
      " -0.72025869 -0.37884643 -0.55476739 -1.40822065]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.35055768 -0.13479412  0.4410935   0.30359976  0.73998096 -0.18163907\n",
      "  0.07833681  0.76548889 -0.34616669  0.42081852]\n",
      "\n",
      "# 35 Gradient out:  [1.49553092 1.52920801 1.49960144 1.16828301 0.36903009 0.70017231\n",
      " 0.66975856 0.36581593 0.49172374 1.46094871]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.05644895 -0.44230426  0.14539524  0.08493583  0.66305333 -0.33056037\n",
      " -0.06571493  0.68971961 -0.45712017  0.13917439]\n",
      "\n",
      "# 36 Gradient out:  [-1.44972901 -1.5156427  -1.45754685 -1.07852888 -0.38093068 -0.73517225\n",
      " -0.71120161 -0.37523342 -0.54831224 -1.38842261]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.35555513 -0.13646266  0.44531553  0.31859243  0.73685934 -0.19052591\n",
      "  0.06823678  0.76288279 -0.35877542  0.43136413]\n",
      "\n",
      "# 37 Gradient out:  [1.30828448 1.33407259 1.31141726 1.02901919 0.32465537 0.60952246\n",
      " 0.58244492 0.32213106 0.42635014 1.28112543]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.06560933 -0.4395912   0.15380616  0.10288665  0.66067321 -0.33756036\n",
      " -0.07400354  0.68783611 -0.46843787  0.15367961]\n",
      "\n",
      "# 38 Gradient out:  [-1.69040158 -1.76806926 -1.69961665 -1.25441551 -0.43765605 -0.85348068\n",
      " -0.82545636 -0.43094162 -0.63460039 -1.61815154]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.32726623 -0.17277668  0.41608961  0.30869049  0.72560428 -0.21565587\n",
      "  0.04248544  0.75226232 -0.38316784  0.4099047 ]\n",
      "\n",
      "# 39 Gradient out:  [3.0432225  3.1455796  3.05524663 2.35735429 0.89106678 1.56281697\n",
      " 1.5096147  0.88217214 1.17637789 2.94742763]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [-0.01081409 -0.52639053  0.07616628  0.05780739  0.63807307 -0.38635201\n",
      " -0.12260583  0.666074   -0.51008792  0.08627439]\n",
      "\n",
      "# 40 Gradient out:  [-0.23932734 -0.24952608 -0.24053102 -0.18247209 -0.07536907 -0.12962058\n",
      " -0.12593716 -0.0744951  -0.10097255 -0.22991996]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.59783041  0.10272539  0.68721561  0.52927824  0.81628643 -0.07378861\n",
      "  0.17931711  0.84250842 -0.27481234  0.67575991]\n",
      "\n",
      "# 41 Gradient out:  [-0.35559861 -0.37094499 -0.35741171 -0.2697131  -0.1077883  -0.18976426\n",
      " -0.18419302 -0.10647058 -0.14644651 -0.34141558]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.54996494  0.05282017  0.6391094   0.49278383  0.80121261 -0.09971273\n",
      "  0.15412968  0.8276094  -0.29500685  0.62977592]\n",
      "\n",
      "# 42 Gradient out:  [-0.62560087 -0.65308531 -0.62885313 -0.47100477 -0.17934543 -0.32695062\n",
      " -0.3169119  -0.17697855 -0.248905   -0.60012796]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.47884522 -0.02136883  0.56762706  0.43884121  0.77965495 -0.13766558\n",
      "  0.11729107  0.80631529 -0.32429615  0.56149281]\n",
      "\n",
      "# 43 Gradient out:  [-1.46142746 -1.52789444 -1.46931104 -1.08713337 -0.38376602 -0.74095584\n",
      " -0.7167877  -0.37802086 -0.55254909 -1.39960561]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.35372505 -0.15198589  0.44185644  0.34464025  0.74378587 -0.2030557\n",
      "  0.05390869  0.77091958 -0.37407715  0.44146721]\n",
      "\n",
      "# 44 Gradient out:  [1.41507213 1.44544428 1.41873968 1.11030955 0.356926   0.66619245\n",
      " 0.63741391 0.35401579 0.46996802 1.38375611]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.06143955 -0.45756478  0.14799423  0.12721358  0.66703267 -0.35124687\n",
      " -0.08944885  0.69531541 -0.48458697  0.16154609]\n",
      "\n",
      "# 45 Gradient out:  [-1.55075677 -1.62149558 -1.55914834 -1.15273424 -0.40547489 -0.78524517\n",
      " -0.75957989 -0.39935957 -0.58505246 -1.48495251]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.34445398 -0.16847592  0.43174216  0.34927549  0.73841787 -0.21800838\n",
      "  0.03803393  0.76611856 -0.39059336  0.43829731]\n",
      "\n",
      "# 46 Gradient out:  [2.19395929 2.25768339 2.20152307 1.70365007 0.59448137 1.08123978\n",
      " 1.04012928 0.5887573  0.79022458 2.13233578]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.03430262 -0.49277504  0.1199125   0.11872864  0.65732289 -0.37505741\n",
      " -0.11388204  0.68624665 -0.50760386  0.14130681]\n",
      "\n",
      "# 47 Gradient out:  [-0.66657672 -0.69587092 -0.67004304 -0.50187372 -0.19123102 -0.34847684\n",
      " -0.33778612 -0.18870851 -0.2653497  -0.63942873]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.47309448 -0.04123836  0.56021711  0.45945866  0.77621916 -0.15880946\n",
      "  0.09414381  0.80399811 -0.34955894  0.56777397]\n",
      "\n",
      "# 48 Gradient out:  [-1.5940748  -1.66689859 -1.60271445 -1.18448387 -0.4158678  -0.80664318\n",
      " -0.78025009 -0.40957169 -0.60071384 -1.52632543]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.33977914 -0.18041254  0.4262085   0.35908391  0.73797296 -0.22850483\n",
      "  0.02658659  0.76625641 -0.40262888  0.43988822]\n",
      "\n",
      "# 49 Gradient out:  [2.51584275 2.59372196 2.52504912 1.9505851  0.70107978 1.25913431\n",
      " 1.21321388 0.69417965 0.93068337 2.44154761]\n",
      "\n",
      "     Weights  out:  [ 0.39220184  0.48459091  0.4017322   0.10224055 -0.35290107 -0.09168155\n",
      " -0.10575609 -0.35896955 -0.21039629  0.32627289] [ 0.02096418 -0.51379226  0.10566561  0.12218714  0.6547994  -0.38983346\n",
      " -0.12946343  0.68434207 -0.52277165  0.13462314]\n",
      "\n",
      "Tanh error cuadrático medio (ECM): 1.1002665958356639\n",
      "\n",
      "# 0 Gradient out:  [2.65782338 3.74064755 5.18580848 5.35407226 5.77718184 4.78916704\n",
      " 2.01853776 2.12092298 4.86292436 1.97191136]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [-0.39506824 -0.31104311 -0.14908851 -0.3992798  -0.21396544  0.03523655\n",
      "  0.04972313 -0.38539726  0.31212893 -0.2170758 ]\n",
      "\n",
      "# 1 Gradient out:  [ -9.32445175 -14.06325689 -20.29624124 -21.06097529 -23.04510041\n",
      " -18.54075117  -6.30669066  -6.7990613  -18.86290317  -6.08277547]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [0.13649644 0.4370864  0.88807319 0.67153465 0.94147093 0.99306996\n",
      " 0.45343068 0.03878734 1.2847138  0.17730647]\n",
      "\n",
      "# 2 Gradient out:  [36.5235251  54.30221614 77.77422278 80.61595881 87.92952001 71.20680714\n",
      " 25.42138276 27.22286087 72.41607479 24.60232031]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [-1.72839391 -2.37556497 -3.17117506 -3.54066041 -3.66754916 -2.71508028\n",
      " -0.80790745 -1.32102492 -2.48786684 -1.03924862]\n",
      "\n",
      "# 3 Gradient out:  [-139.94868579 -208.64840436 -299.25312064 -310.26381756 -338.66844563\n",
      " -273.85538346  -96.80352669 -103.81677418 -278.52746697  -93.61431817]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [ 5.57631111  8.48487825 12.38366949 12.58253136 13.91835485 11.52628115\n",
      "  4.2763691   4.12354725 11.99534812  3.88121544]\n",
      "\n",
      "# 4 Gradient out:  [ 538.47369855  802.38102578 1150.53416214 1192.80027988 1301.76411556\n",
      " 1052.99065351  372.99249784  399.87769177 1070.93905073  360.76753557]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [-22.41342605 -33.24480262 -47.46695463 -49.47023216 -53.81533428\n",
      " -43.24479554 -15.08433624 -16.63980758 -43.71014527 -14.8416482 ]\n",
      "\n",
      "# 5 Gradient out:  [-2070.2845153  -3085.23968052 -4424.09190322 -4586.67440015\n",
      " -5005.89405298 -4048.92995455 -1433.59221697 -1537.04860789\n",
      " -4117.95647702 -1386.54852759]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [ 85.28131366 127.23140254 182.63987779 189.08982382 206.53748883\n",
      " 167.35333516  59.51416333  63.33573077 170.47766487  57.31185892]\n",
      "\n",
      "# 6 Gradient out:  [ 7960.72925056 11863.26267317 17011.29466573 17636.3962239\n",
      " 19248.14525726 15568.80769197  5512.90972425  5910.64088556\n",
      " 15834.21760644  5332.05463696]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [-328.7755894  -489.81653357 -702.17850285 -728.24505621 -794.64132176\n",
      " -642.43265575 -227.20428006 -244.07399081 -653.11363053 -219.9978466 ]\n",
      "\n",
      "# 7 Gradient out:  [-30610.2353305  -45616.21059228 -65411.25559583 -67814.92247472\n",
      " -74012.56808896 -59864.59926566 -21197.61926274 -22727.03424709\n",
      " -60885.14945809 -20502.16703535]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [1263.37026071 1882.83600107 2700.0804303  2799.03418857 3054.98772969\n",
      " 2471.32888265  875.37766479  938.05418631 2513.72989076  846.41308079]\n",
      "\n",
      "# 8 Gradient out:  [117701.39479121 175401.77046517 251516.99369841 260759.44308349\n",
      " 284590.21148776 230189.23553995  81508.67562581  87389.45549241\n",
      " 234113.41519125  78834.58177275]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [ -4858.67680539  -7240.40611739 -10382.17068887 -10763.95030637\n",
      " -11747.5258881   -9501.59097049  -3364.14618776  -3607.35266311\n",
      "  -9663.30000086  -3254.02032628]\n",
      "\n",
      "# 9 Gradient out:  [ -452581.19861552  -674448.64371927  -967124.10031534 -1002662.87476889\n",
      " -1094296.27618691  -885115.33539416  -313413.93380267  -336026.56738498\n",
      "  -900204.45138807  -303131.5707513 ]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [18681.60215285 27839.94797565 39921.22805081 41387.93831032\n",
      " 45170.51640945 36536.2561375  12937.5889374  13870.53843537\n",
      " 37159.38303739 12512.89602827]\n",
      "\n",
      "# 10 Gradient out:  [1740248.89385241 2593365.6042361  3718750.84103736 3855403.22170948\n",
      " 4207748.50206128 3403413.71461134 1205128.24273377 1292077.45941019\n",
      " 3461433.8409784  1165590.90300107]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [ -71834.63757025 -107049.78076821 -153503.59201226 -159144.63664345\n",
      " -173688.73882793 -140486.81094133  -49745.19782313  -53334.77504163\n",
      " -142881.50724023  -48113.41812199]\n",
      "\n",
      "# 11 Gradient out:  [ -6691542.57898619  -9971916.28375457 -14299207.0268873\n",
      " -14824657.88367686 -16179483.46525261 -13086684.02145569\n",
      "  -4633915.58217008  -4968249.65272085 -13309780.92458655\n",
      "  -4481887.9920136 ]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [276215.14120023 411623.34007901 590246.57619522 611936.00769844\n",
      " 667860.96158432 540195.93198094 191280.45072362 205080.71684041\n",
      " 549405.26095545 185004.76247823]\n",
      "\n",
      "# 12 Gradient out:  [25730078.8680157  38343653.93190676 54982796.87444215 57003241.58725695\n",
      " 62212768.03959885 50320447.0189335  17818165.80593703 19103735.0880714\n",
      " 51178291.21306258 17233594.81367783]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [-1062093.37459701 -1582759.9166719  -2269594.82918225 -2352995.56903693\n",
      " -2568035.7314662  -2077140.8723102   -735502.66571039  -788569.21370376\n",
      " -2112550.92396186  -711372.83592449]\n",
      "\n",
      "# 13 Gradient out:  [-9.89363745e+07 -1.47437640e+08 -2.11417874e+08 -2.19186815e+08\n",
      " -2.39218299e+08 -1.93490374e+08 -6.85137705e+07 -7.34569953e+07\n",
      " -1.96788926e+08 -6.62659991e+07]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [4083922.39900613 6085970.86970945 8726964.54570618 9047652.74841446\n",
      " 9874517.87645357 7986948.5314765  2828130.49547701 3032177.80391052\n",
      " 8123107.31865066 2735346.12681107]\n",
      "\n",
      "# 14 Gradient out:  [3.80426590e+08 5.66921913e+08 8.12936409e+08 8.42809263e+08\n",
      " 9.19833606e+08 7.44002230e+08 2.63446687e+08 2.82454198e+08\n",
      " 7.56685703e+08 2.54803638e+08]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [-15703352.49308114 -23401557.0989336  -33556610.25492532\n",
      " -34789710.33447    -37969142.00900544 -30711126.25346203\n",
      " -10874623.59915144 -11659221.26221667 -31234677.79732402\n",
      " -10517853.68827564]\n",
      "\n",
      "# 15 Gradient out:  [-1.46280265e+09 -2.17990776e+09 -3.12587386e+09 -3.24073988e+09\n",
      " -3.53691111e+09 -2.86081063e+09 -1.01299573e+09 -1.08608273e+09\n",
      " -2.90958066e+09 -9.79761788e+08]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [6.03819656e+07 8.99828254e+07 1.29030672e+08 1.33772142e+08\n",
      " 1.45997579e+08 1.18089320e+08 4.18147139e+07 4.48316183e+07\n",
      " 1.20102463e+08 4.04428739e+07]\n",
      "\n",
      "# 16 Gradient out:  [5.62471617e+09 8.38210295e+09 1.20194978e+10 1.24611765e+10\n",
      " 1.36000035e+10 1.10002862e+10 3.89513478e+09 4.17616626e+09\n",
      " 1.11878150e+10 3.76734481e+09]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [-2.32178564e+08 -3.45998726e+08 -4.96144100e+08 -5.14375834e+08\n",
      " -5.61384644e+08 -4.54072806e+08 -1.60784433e+08 -1.72384927e+08\n",
      " -4.61813670e+08 -1.55509484e+08]\n",
      "\n",
      "# 17 Gradient out:  [-2.16279564e+10 -3.22305610e+10 -4.62169408e+10 -4.79152679e+10\n",
      " -5.22942445e+10 -4.22979051e+10 -1.49774322e+10 -1.60580444e+10\n",
      " -4.30189840e+10 -1.44860588e+10]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [8.92764669e+08 1.33042186e+09 1.90775546e+09 1.97785947e+09\n",
      " 2.15861605e+09 1.74598443e+09 6.18242522e+08 6.62848326e+08\n",
      " 1.77574932e+09 5.97959478e+08]\n",
      "\n",
      "# 18 Gradient out:  [8.31630405e+10 1.23931794e+11 1.77711719e+11 1.84242066e+11\n",
      " 2.01079949e+11 1.62642384e+11 5.75906840e+10 6.17458151e+10\n",
      " 1.65415051e+11 5.57012727e+10]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [-3.43282661e+09 -5.11569033e+09 -7.33563271e+09 -7.60519412e+09\n",
      " -8.30023284e+09 -6.71359658e+09 -2.37724392e+09 -2.54876055e+09\n",
      " -6.82804747e+09 -2.29925229e+09]\n",
      "\n",
      "# 19 Gradient out:  [-3.19775534e+11 -4.76538081e+11 -6.83330716e+11 -7.08440968e+11\n",
      " -7.73185392e+11 -6.25386649e+11 -2.21445628e+11 -2.37422789e+11\n",
      " -6.36048007e+11 -2.14180531e+11]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [1.31997815e+10 1.96706685e+10 2.82067112e+10 2.92432190e+10\n",
      " 3.19157570e+10 2.58148802e+10 9.14089287e+09 9.80040246e+09\n",
      " 2.62549627e+10 8.84100225e+09]\n",
      "\n",
      "# 20 Gradient out:  [1.22958939e+12 1.83236710e+12 2.62751870e+12 2.72407175e+12\n",
      " 2.97302467e+12 2.40471426e+12 8.51494767e+11 9.12929572e+11\n",
      " 2.44570893e+12 8.23559280e+11]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [-5.07553253e+10 -7.56369476e+10 -1.08459432e+11 -1.12444975e+11\n",
      " -1.22721321e+11 -9.92624495e+10 -3.51482327e+10 -3.76841552e+10\n",
      " -1.00954639e+11 -3.39951040e+10]\n",
      "\n",
      "# 21 Gradient out:  [-4.72797291e+12 -7.04575209e+12 -1.01032405e+13 -1.04745028e+13\n",
      " -1.14317676e+13 -9.24652083e+12 -3.27413707e+12 -3.51036397e+12\n",
      " -9.40415206e+12 -3.16672054e+12]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [1.95162552e+11 2.90836472e+11 4.17044309e+11 4.32369374e+11\n",
      " 4.71883613e+11 3.81680402e+11 1.35150721e+11 1.44901759e+11\n",
      " 3.88187147e+11 1.30716752e+11]\n",
      "\n",
      "# 22 Gradient out:  [1.81798315e+13 2.70920727e+13 3.88486170e+13 4.02761814e+13\n",
      " 4.39570218e+13 3.55543895e+13 1.25895942e+13 1.34979254e+13\n",
      " 3.61605075e+13 1.21765600e+13]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [-7.50432030e+11 -1.11831395e+12 -1.60360378e+12 -1.66253118e+12\n",
      " -1.81446991e+12 -1.46762376e+12 -5.19676693e+11 -5.57171035e+11\n",
      " -1.49264327e+12 -5.02627356e+11]\n",
      "\n",
      "# 23 Gradient out:  [-6.99044345e+13 -1.04173464e+14 -1.49379306e+14 -1.54868525e+14\n",
      " -1.69021960e+14 -1.36712460e+14 -4.84090549e+13 -5.19017374e+13\n",
      " -1.39043083e+14 -4.68208707e+13]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [2.88553427e+12 4.30010059e+12 6.16611963e+12 6.39270511e+12\n",
      " 6.97693446e+12 5.64325414e+12 1.99824214e+12 2.14241404e+12\n",
      " 5.73945823e+12 1.93268464e+12]\n",
      "\n",
      "# 24 Gradient out:  [2.68794019e+14 4.00564059e+14 5.74387937e+14 5.95494885e+14\n",
      " 6.49917165e+14 5.25681838e+14 1.86140758e+14 1.99570695e+14\n",
      " 5.34643466e+14 1.80033929e+14]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [-1.10953526e+13 -1.65345922e+13 -2.37097415e+13 -2.45809999e+13\n",
      " -2.68274576e+13 -2.16992379e+13 -7.68356884e+12 -8.23793343e+12\n",
      " -2.20691585e+13 -7.43148950e+12]\n",
      "\n",
      "# 25 Gradient out:  [-1.03355710e+15 -1.54023452e+15 -2.20861585e+15 -2.28977553e+15\n",
      " -2.49903812e+15 -2.02133291e+15 -7.15741750e+14 -7.67382061e+14\n",
      " -2.05579184e+15 -6.92259992e+14]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [4.26634511e+13 6.35782196e+13 9.11678458e+13 9.45179772e+13\n",
      " 1.03155976e+14 8.34371297e+13 2.95445827e+13 3.16762055e+13\n",
      " 8.48595347e+13 2.85752963e+13]\n",
      "\n",
      "# 26 Gradient out:  [3.97419660e+15 5.92245441e+15 8.49249026e+15 8.80456254e+15\n",
      " 9.60921155e+15 7.77235663e+15 2.75214445e+15 2.95070992e+15\n",
      " 7.90485687e+15 2.66185324e+15]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [-1.64047969e+14 -2.44468684e+14 -3.50555323e+14 -3.63437128e+14\n",
      " -3.96651649e+14 -3.20829452e+14 -1.13603767e+14 -1.21800207e+14\n",
      " -3.26298833e+14 -1.09876702e+14]\n",
      "\n",
      "# 27 Gradient out:  [-1.52814379e+16 -2.27728088e+16 -3.26550183e+16 -3.38549874e+16\n",
      " -3.69489948e+16 -2.98859863e+16 -1.05824469e+16 -1.13459637e+16\n",
      " -3.03954715e+16 -1.02352624e+16]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [6.30791351e+14 9.40022197e+14 1.34794273e+15 1.39747538e+15\n",
      " 1.52519066e+15 1.23364188e+15 4.36825123e+14 4.68341777e+14\n",
      " 1.25467254e+15 4.22493945e+14]\n",
      "\n",
      "# 28 Gradient out:  [5.87596357e+16 8.75651857e+16 1.25563902e+17 1.30177981e+17\n",
      " 1.42074947e+17 1.14916520e+17 4.06912444e+16 4.36270918e+16\n",
      " 1.16875574e+17 3.93562629e+16]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [-2.42549623e+15 -3.61453956e+15 -5.18306092e+15 -5.37352210e+15\n",
      " -5.86460830e+15 -4.74355539e+15 -1.67966426e+15 -1.80085096e+15\n",
      " -4.82442175e+15 -1.62455853e+15]\n",
      "\n",
      "# 29 Gradient out:  [-2.25940439e+17 -3.36702504e+17 -4.82813804e+17 -5.00555691e+17\n",
      " -5.46301478e+17 -4.41872873e+17 -1.56464510e+17 -1.67753325e+17\n",
      " -4.49405757e+17 -1.51331288e+17]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [9.32643091e+15 1.38984976e+16 1.99297195e+16 2.06620740e+16\n",
      " 2.25503810e+16 1.82397487e+16 6.45858463e+15 6.92456739e+15\n",
      " 1.85506931e+16 6.24669406e+15]\n",
      "\n",
      "# 30 Gradient out:  [8.68778054e+17 1.29467637e+18 1.85649828e+18 1.92471875e+18\n",
      " 2.10061880e+18 1.69907369e+18 6.01631711e+17 6.45039055e+17\n",
      " 1.72803886e+18 5.81893627e+17]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [-3.58616569e+16 -5.34420033e+16 -7.66330412e+16 -7.94490642e+16\n",
      " -8.67099145e+16 -7.01348259e+16 -2.48343174e+16 -2.66260976e+16\n",
      " -7.13304583e+16 -2.40195634e+16]\n",
      "\n",
      "# 31 Gradient out:  [-3.34059414e+18 -4.97824302e+18 -7.13854046e+18 -7.40085935e+18\n",
      " -8.07722391e+18 -6.53321706e+18 -2.31337263e+18 -2.48028099e+18\n",
      " -6.64459291e+18 -2.23747646e+18]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [1.37893954e+17 2.05493270e+17 2.94666615e+17 3.05494686e+17\n",
      " 3.33413846e+17 2.69679911e+17 9.54920247e+16 1.02381713e+17\n",
      " 2.74277314e+17 9.23591619e+16]\n",
      "\n",
      "# 32 Gradient out:  [1.28451325e+19 1.91421611e+19 2.74488591e+19 2.84575183e+19\n",
      " 3.10582510e+19 2.51212914e+19 8.89529726e+18 9.53708729e+18\n",
      " 2.55495498e+19 8.60346404e+18]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [-5.30224874e+17 -7.90155335e+17 -1.13304148e+18 -1.17467718e+18\n",
      " -1.28203094e+18 -1.03696350e+18 -3.67182501e+17 -3.93674484e+17\n",
      " -1.05464127e+18 -3.55136129e+17]\n",
      "\n",
      "# 33 Gradient out:  [-4.93916418e+19 -7.36047498e+19 -1.05545366e+20 -1.09423826e+20\n",
      " -1.19424070e+20 -9.65954866e+19 -3.42038773e+19 -3.66716652e+19\n",
      " -9.82422104e+19 -3.30817306e+19]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [2.03880163e+18 3.03827689e+18 4.35673035e+18 4.51682648e+18\n",
      " 4.92961927e+18 3.98729478e+18 1.41187695e+18 1.51374297e+18\n",
      " 4.05526869e+18 1.36555668e+18]\n",
      "\n",
      "# 34 Gradient out:  [1.89918965e+20 2.83022338e+20 4.05839249e+20 4.20752564e+20\n",
      " 4.59205143e+20 3.71425493e+20 1.31519519e+20 1.41008569e+20\n",
      " 3.77757416e+20 1.27204681e+20]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [-7.83952673e+18 -1.16826731e+19 -1.67523429e+19 -1.73679388e+19\n",
      " -1.89551948e+19 -1.53318025e+19 -5.42889850e+18 -5.82059007e+18\n",
      " -1.55931734e+19 -5.25078945e+18]\n",
      "\n",
      "# 35 Gradient out:  [-7.30269579e+20 -1.08826732e+21 -1.56051849e+21 -1.61786263e+21\n",
      " -1.76571911e+21 -1.42819195e+21 -5.05714128e+20 -5.42201080e+20\n",
      " -1.45253924e+21 -4.89122868e+20]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [3.01442664e+19 4.49217946e+19 6.44155069e+19 6.67825740e+19\n",
      " 7.28858337e+19 5.89532960e+19 2.08750054e+19 2.23811237e+19\n",
      " 5.99583098e+19 2.01901468e+19]\n",
      "\n",
      "# 36 Gradient out:  [2.80800633e+21 4.18456638e+21 6.00044961e+21 6.22094724e+21\n",
      " 6.78947964e+21 5.49163236e+21 1.94455379e+21 2.08485210e+21\n",
      " 5.58525166e+21 1.88075767e+21]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [-1.15909649e+20 -1.72731670e+20 -2.47688191e+20 -2.56789953e+20\n",
      " -2.80257988e+20 -2.26685095e+20 -8.02678202e+19 -8.60590923e+19\n",
      " -2.30549538e+20 -7.76344268e+19]\n",
      "\n",
      "# 37 Gradient out:  [-1.07972450e+22 -1.60903442e+22 -2.30727131e+22 -2.39205627e+22\n",
      " -2.61066630e+22 -2.11162273e+22 -7.47712831e+21 -8.01659835e+21\n",
      " -2.14762089e+22 -7.23182179e+21]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [4.45691617e+20 6.64181607e+20 9.52401730e+20 9.87399496e+20\n",
      " 1.07763794e+21 8.71641377e+20 3.08642937e+20 3.30911328e+20\n",
      " 8.86500794e+20 2.98517107e+20]\n",
      "\n",
      "# 38 Gradient out:  [4.15171784e+22 6.18700132e+22 8.87183671e+22 9.19784878e+22\n",
      " 1.00384402e+23 8.11953583e+22 2.87507850e+22 3.08251358e+22\n",
      " 8.25795464e+22 2.78075412e+22]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [-1.71375738e+21 -2.55388724e+21 -3.66214090e+21 -3.79671305e+21\n",
      " -4.14369467e+21 -3.35160409e+21 -1.18678273e+21 -1.27240834e+21\n",
      " -3.40874099e+21 -1.14784725e+21]\n",
      "\n",
      "# 39 Gradient out:  [-1.59640362e+23 -2.37900351e+23 -3.41136676e+23 -3.53672375e+23\n",
      " -3.85994495e+23 -3.12209473e+23 -1.10551485e+23 -1.18527704e+23\n",
      " -3.17531903e+23 -1.06924558e+23]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [6.58967829e+21 9.82011540e+21 1.40815325e+22 1.45989845e+22\n",
      " 1.59331858e+22 1.28874676e+22 4.56337428e+21 4.89261882e+21\n",
      " 1.31071683e+22 4.41366098e+21]\n",
      "\n",
      "# 40 Gradient out:  [6.13843381e+23 9.14765876e+23 1.31172648e+24 1.35992830e+24\n",
      " 1.48421216e+24 1.20049664e+24 4.25088596e+23 4.55758467e+23\n",
      " 1.22096226e+24 4.11142466e+23]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [-2.53383941e+22 -3.77599547e+22 -5.41458027e+22 -5.61354905e+22\n",
      " -6.12657132e+22 -4.95544270e+22 -1.75469227e+22 -1.88129220e+22\n",
      " -5.03992124e+22 -1.69712506e+22]\n",
      "\n",
      "# 41 Gradient out:  [-2.36032850e+24 -3.51742486e+24 -5.04380352e+24 -5.22914742e+24\n",
      " -5.70703923e+24 -4.61610653e+24 -1.63453539e+24 -1.75246607e+24\n",
      " -4.69480019e+24 -1.58091023e+24]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [9.74302821e+22 1.45193221e+23 2.08199494e+23 2.15850170e+23\n",
      " 2.35576718e+23 1.90544901e+23 6.74707965e+22 7.23387714e+22\n",
      " 1.93793240e+23 6.52572426e+22]\n",
      "\n",
      "# 42 Gradient out:  [9.07585031e+24 1.35250756e+25 1.93942520e+25 2.01069297e+25\n",
      " 2.19445021e+25 1.77496869e+25 6.28505672e+24 6.73851955e+24\n",
      " 1.80522769e+25 6.07885918e+24]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [-3.74635418e+23 -5.58291752e+23 -8.00561210e+23 -8.29979315e+23\n",
      " -9.05831128e+23 -7.32676405e+23 -2.59436281e+23 -2.78154444e+23\n",
      " -7.45166799e+23 -2.50924803e+23]\n",
      "\n",
      "# 43 Gradient out:  [-3.48981333e+25 -5.20061347e+25 -7.45740806e+25 -7.73144433e+25\n",
      " -8.43802106e+25 -6.82504580e+25 -2.41670742e+25 -2.59107132e+25\n",
      " -6.94139663e+25 -2.33742108e+25]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [1.44053464e+24 2.14672338e+24 3.07828919e+24 3.19140663e+24\n",
      " 3.48306929e+24 2.81726098e+24 9.97575063e+23 1.06954947e+24\n",
      " 2.86528859e+24 9.64847033e+23]\n",
      "\n",
      "# 44 Gradient out:  [1.34189048e+26 1.99972120e+26 2.86749574e+26 2.97286718e+26\n",
      " 3.24455753e+26 2.62434208e+26 9.29263648e+25 9.96309428e+25\n",
      " 2.66908088e+26 8.98776752e+25]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [-5.53909203e+24 -8.25450356e+24 -1.18365269e+25 -1.22714820e+25\n",
      " -1.33929728e+25 -1.08328306e+25 -3.83583977e+24 -4.11259316e+24\n",
      " -1.10175047e+25 -3.70999513e+24]\n",
      "\n",
      "# 45 Gradient out:  [-5.15978903e+26 -7.68925606e+26 -1.10259915e+27 -1.14311620e+27\n",
      " -1.24758560e+27 -1.00910258e+27 -3.57317118e+26 -3.83097320e+26\n",
      " -1.02630539e+27 -3.45594406e+26]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [2.12987175e+25 3.17399204e+25 4.55133878e+25 4.71858616e+25\n",
      " 5.14981777e+25 4.16540109e+25 1.47494332e+25 1.58135954e+25\n",
      " 4.23641129e+25 1.42655399e+25]\n",
      "\n",
      "# 46 Gradient out:  [1.98402353e+27 2.95664510e+27 4.23967463e+27 4.39546933e+27\n",
      " 4.79717129e+27 3.88016497e+27 1.37394294e+27 1.47307204e+27\n",
      " 3.94631258e+27 1.32886719e+27]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [-8.18970630e+25 -1.22045201e+26 -1.75006443e+26 -1.81437379e+26\n",
      " -1.98018942e+26 -1.60166505e+26 -5.67139903e+25 -6.08058686e+25\n",
      " -1.62896964e+26 -5.48533412e+25]\n",
      "\n",
      "# 47 Gradient out:  [-7.62889595e+27 -1.13687854e+28 -1.63022445e+28 -1.69013006e+28\n",
      " -1.84459106e+28 -1.49198709e+28 -5.28303599e+27 -5.66420366e+27\n",
      " -1.51742193e+28 -5.10971233e+27]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [3.14907643e+26 4.69283819e+26 6.72928483e+26 6.97656487e+26\n",
      " 7.61415316e+26 6.15866489e+26 2.18074597e+26 2.33808540e+26\n",
      " 6.26365551e+26 2.10920096e+26]\n",
      "\n",
      "# 48 Gradient out:  [2.93343565e+28 4.37148451e+28 6.26848044e+28 6.49882737e+28\n",
      " 7.09275523e+28 5.73693511e+28 2.03141401e+28 2.17797923e+28\n",
      " 5.83473624e+28 1.96476822e+28]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [-1.21087155e+27 -1.80447327e+27 -2.58752041e+27 -2.68260364e+27\n",
      " -2.92776680e+27 -2.36810768e+27 -8.38532601e+26 -8.99032193e+26\n",
      " -2.40847830e+27 -8.11022371e+26]\n",
      "\n",
      "# 49 Gradient out:  [-1.12795413e+29 -1.68090751e+29 -2.41033357e+29 -2.49890574e+29\n",
      " -2.72728074e+29 -2.20594567e+29 -7.81112011e+28 -8.37468745e+28\n",
      " -2.24355181e+29 -7.55485612e+28]\n",
      "\n",
      "     Weights  out:  [-0.20081798 -0.03372281  0.17335815  0.20484983  0.30372121  0.10902643\n",
      " -0.3648753  -0.33121804  0.12019956 -0.38160025] [4.65599975e+27 6.93849575e+27 9.94944048e+27 1.03150511e+28\n",
      " 1.12577437e+28 9.10576254e+27 3.22429541e+27 3.45692627e+27\n",
      " 9.26099418e+27 3.11851406e+27]\n",
      "\n",
      "Lineal error cuadrático medio (ECM): 2.398658043503965e+58\n",
      "\n",
      "# 0 Gradient out:  [0.72884708 0.71922048 1.74028652 1.10080982 0.71632206 0.7608462\n",
      " 1.17775663 0.65957227 1.63586888 1.49310391]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [-0.1190453  -0.01072565  0.00836492 -0.29911936  0.47932976  0.0451212\n",
      "  0.01955163 -0.34847674 -0.26099716  0.23003241]\n",
      "\n",
      "# 1 Gradient out:  [-0.54393175 -0.52475567 -1.72393881 -1.04320727 -0.51889915 -0.60435181\n",
      " -1.12002028 -0.40053262 -1.58575619 -1.42781813]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.02672411  0.13311844  0.35642223 -0.0789574   0.62259417  0.19729044\n",
      "  0.25510295 -0.21656228  0.06617662  0.5286532 ]\n",
      "\n",
      "# 2 Gradient out:  [0.54689775 0.54066787 1.34280863 0.82916897 0.53880938 0.568247\n",
      " 0.89176628 0.50357048 1.26314514 1.14936661]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [-0.08206224  0.02816731  0.01163447 -0.28759885  0.51881434  0.07642008\n",
      "  0.0310989  -0.29666881 -0.25097462  0.24308957]\n",
      "\n",
      "# 3 Gradient out:  [-0.55840684 -0.53817787 -1.75753459 -1.07151525 -0.5319934  -0.62191743\n",
      " -1.14844599 -0.4064942  -1.6157356  -1.45602883]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.02731731  0.13630088  0.28019619 -0.12176506  0.62657621  0.19006948\n",
      "  0.20945215 -0.19595471  0.00165441  0.47296289]\n",
      "\n",
      "# 4 Gradient out:  [0.88234008 0.86669786 2.3223224  1.42842836 0.86197105 0.93359997\n",
      " 1.53467801 0.76901449 2.16941938 1.96828941]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [-0.08436406  0.02866531 -0.07131073 -0.33606811  0.52017753  0.065686\n",
      " -0.02023705 -0.27725355 -0.32149271  0.18175713]\n",
      "\n",
      "# 5 Gradient out:  [-0.47277841 -0.45601521 -1.51980833 -0.91374311 -0.45089722 -0.5256598\n",
      " -0.98230486 -0.34753215 -1.39770523 -1.25729172]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.09210396  0.20200488  0.39315376 -0.05038244  0.69257174  0.25240599\n",
      "  0.28669856 -0.12345066  0.11239117  0.57541501]\n",
      "\n",
      "# 6 Gradient out:  [-0.14646739 -0.13709035 -0.42614181 -0.30268954 -0.13418764 -0.1745999\n",
      " -0.31344223 -0.07268839 -0.38421604 -0.35195348]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [-0.00245172  0.11080184  0.08919209 -0.23313106  0.6023923   0.14727403\n",
      "  0.09023758 -0.19295709 -0.16714988  0.32395667]\n",
      "\n",
      "# 7 Gradient out:  [0.34522866 0.34198453 0.96740188 0.55374813 0.34104446 0.35734634\n",
      " 0.60504613 0.32531959 0.90795584 0.81729756]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [-0.0317452   0.08338377  0.00396373 -0.29366897  0.57555477  0.11235405\n",
      "  0.02754914 -0.20749476 -0.24399309  0.25356597]\n",
      "\n",
      "# 8 Gradient out:  [-0.50688102 -0.48802369 -1.53426208 -0.95814622 -0.48224514 -0.56561651\n",
      " -1.02177861 -0.36385834 -1.41000826 -1.27479511]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.03730053  0.15178068  0.1974441  -0.18291934  0.64376366  0.18382332\n",
      "  0.14855836 -0.14243085 -0.06240192  0.41702548]\n",
      "\n",
      "# 9 Gradient out:  [0.94429011 0.92617977 2.5469412  1.55780864 0.92070044 1.0033746\n",
      " 1.67492272 0.81261201 2.37533075 2.15223899]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [-0.06407567  0.05417594 -0.10940831 -0.37454859  0.54731464  0.07070001\n",
      " -0.05579736 -0.21520251 -0.34440357  0.16206646]\n",
      "\n",
      "# 10 Gradient out:  [-0.44106665 -0.42515509 -1.43827781 -0.86063571 -0.42029758 -0.49127816\n",
      " -0.92601622 -0.32222617 -1.32208252 -1.18829182]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.12478235  0.23941189  0.39997993 -0.06298686  0.73145472  0.27137493\n",
      "  0.27918719 -0.05268011  0.13066258  0.59251426]\n",
      "\n",
      "# 11 Gradient out:  [-0.33683594 -0.3232386  -0.91457238 -0.61361786 -0.31904857 -0.37836452\n",
      " -0.64488935 -0.23133421 -0.83920681 -0.76635605]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.03656902  0.15438087  0.11232436 -0.235114    0.64739521  0.1731193\n",
      "  0.09398394 -0.11712535 -0.13375393  0.35485589]\n",
      "\n",
      "# 12 Gradient out:  [0.67980083 0.66731344 1.93484964 1.14735532 0.66355582 0.72127415\n",
      " 1.24159088 0.59100599 1.80351194 1.62700825]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [-0.03079817  0.08973315 -0.07059011 -0.35783757  0.58358549  0.0974464\n",
      " -0.03499393 -0.16339219 -0.30159529  0.20158468]\n",
      "\n",
      "# 13 Gradient out:  [-0.53440961 -0.51523298 -1.69932126 -1.02896766 -0.50937291 -0.59472574\n",
      " -1.10447855 -0.39055199 -1.56254682 -1.40687958]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.105162    0.22319584  0.31637981 -0.12836651  0.71629666  0.24170123\n",
      "  0.21332425 -0.04519099  0.0591071   0.52698633]\n",
      "\n",
      "# 14 Gradient out:  [0.3454852  0.34063933 1.10196373 0.60675355 0.33921716 0.3628786\n",
      " 0.66757898 0.31448202 1.02769117 0.91845342]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [-0.00171993  0.12014925 -0.02348444 -0.33416004  0.61442208  0.12275608\n",
      " -0.00757146 -0.12330139 -0.25340226  0.24561042]\n",
      "\n",
      "# 15 Gradient out:  [-0.53414045 -0.5148593  -1.58630777 -0.99576813 -0.50894963 -0.59416856\n",
      " -1.06104889 -0.3876521  -1.45923331 -1.32071301]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.06737711  0.18827711  0.19690831 -0.21280933  0.68226551  0.1953318\n",
      "  0.12594433 -0.06040498 -0.04786403  0.4293011 ]\n",
      "\n",
      "# 16 Gradient out:  [0.91180135 0.89363608 2.52232921 1.52826065 0.88814147 0.97110245\n",
      " 1.64595797 0.77993215 2.34985824 2.12564045]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [-0.03945098  0.08530525 -0.12035325 -0.41196296  0.58047558  0.07649809\n",
      " -0.08626545 -0.1379354  -0.33971069  0.1651585 ]\n",
      "\n",
      "# 17 Gradient out:  [-0.44801961 -0.43165123 -1.4695576  -0.87833868 -0.42665355 -0.49964898\n",
      " -0.94521367 -0.32568674 -1.35040699 -1.21342446]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.14290929  0.26403247  0.3841126  -0.10631083  0.75810387  0.27071858\n",
      "  0.24292615  0.01805103  0.13026096  0.59028659]\n",
      "\n",
      "# 18 Gradient out:  [-0.30426132 -0.29228182 -0.74016205 -0.52607933 -0.28857864 -0.34044927\n",
      " -0.54713713 -0.21001901 -0.68024449 -0.62709972]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.05330537  0.17770222  0.09020108 -0.28197856  0.67277316  0.17078878\n",
      "  0.05388341 -0.04708632 -0.13982044  0.3476017 ]\n",
      "\n",
      "# 19 Gradient out:  [0.54936958 0.53919858 1.66318793 0.95755088 0.53615137 0.58361917\n",
      " 1.04249779 0.47843    1.54819683 1.39059484]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [-0.00754689  0.11924586 -0.05783133 -0.38719443  0.61505744  0.10269893\n",
      " -0.05554401 -0.08909012 -0.27586934  0.22218175]\n",
      "\n",
      "# 20 Gradient out:  [-0.561604   -0.54146712 -1.75136525 -1.07084262 -0.5353083  -0.62475835\n",
      " -1.14715861 -0.40995738 -1.61070715 -1.45230137]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.10232702  0.22708558  0.27480625 -0.19568425  0.72228771  0.21942276\n",
      "  0.15295555  0.00659588  0.03377003  0.50030072]\n",
      "\n",
      "# 21 Gradient out:  [0.64369159 0.63112794 1.91301781 1.11634306 0.62734969 0.68548506\n",
      " 1.21168365 0.55470211 1.78018653 1.60161567]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [-0.00999378  0.11879215 -0.0754668  -0.40985277  0.61522605  0.09447109\n",
      " -0.07647618 -0.0753956  -0.2883714   0.20984045]\n",
      "\n",
      "# 22 Gradient out:  [-0.5395897  -0.52011786 -1.71359698 -1.03906955 -0.51416602 -0.60078233\n",
      " -1.11496431 -0.39333117 -1.57551204 -1.41878146]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.11874454  0.24501774  0.30713677 -0.18658416  0.74069599  0.23156811\n",
      "  0.16586056  0.03554482  0.0676659   0.53016358]\n",
      "\n",
      "# 23 Gradient out:  [0.38272826 0.37614199 1.26656526 0.69540308 0.37419144 0.405714\n",
      " 0.76500317 0.33905144 1.17796075 1.05132792]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.0108266   0.14099417 -0.03558263 -0.39439807  0.63786279  0.11141164\n",
      " -0.05713231 -0.04312141 -0.2474365   0.24640729]\n",
      "\n",
      "# 24 Gradient out:  [-0.55597335 -0.53609695 -1.66359151 -1.03859831 -0.53000761 -0.61795784\n",
      " -1.10797579 -0.40519844 -1.53063204 -1.38435959]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.08737225  0.21622257  0.21773042 -0.25531745  0.71270108  0.19255444\n",
      "  0.09586833  0.02468888 -0.01184435  0.45667287]\n",
      "\n",
      "# 25 Gradient out:  [0.86923433 0.85148531 2.45791047 1.47615904 0.84611927 0.92726542\n",
      " 1.59248383 0.74070145 2.28803387 2.06668265]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [-0.02382242  0.10900317 -0.11498788 -0.46303712  0.60669955  0.06896287\n",
      " -0.12572683 -0.05635081 -0.31797076  0.17980095]\n",
      "\n",
      "# 26 Gradient out:  [-0.4604188  -0.44349207 -1.51208232 -0.90398912 -0.43832314 -0.51378282\n",
      " -0.97272706 -0.33382323 -1.38928771 -1.248345  ]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.15002445  0.27930024  0.37659421 -0.16780531  0.77592341  0.25441596\n",
      "  0.19276994  0.09178948  0.13963601  0.59313748]\n",
      "\n",
      "# 27 Gradient out:  [-0.23736763 -0.22774477 -0.48690561 -0.38547411 -0.22475529 -0.2659182\n",
      " -0.39339399 -0.16012373 -0.44759012 -0.4201035 ]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.05794069  0.19060182  0.07417775 -0.34860313  0.68825878  0.15165939\n",
      " -0.00177548  0.02502484 -0.13822153  0.34346848]\n",
      "\n",
      "# 28 Gradient out:  [0.36051633 0.35449706 1.20473112 0.65706131 0.35271923 0.38169715\n",
      " 0.72395618 0.32105281 1.12060713 0.9993612 ]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.01046716  0.14505287 -0.02320338 -0.42569795  0.64330772  0.09847575\n",
      " -0.08045427 -0.00699991 -0.22773955  0.25944778]\n",
      "\n",
      "# 29 Gradient out:  [-0.54912507 -0.52944688 -1.63515514 -1.02380262 -0.52341679 -0.61043936\n",
      " -1.09154177 -0.39970975 -1.50443827 -1.36121845]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.08257043  0.21595228  0.21774285 -0.29428569  0.71385157  0.17481518\n",
      "  0.06433696  0.05721065 -0.00361813  0.45932002]\n",
      "\n",
      "# 30 Gradient out:  [0.88629976 0.86818638 2.49622557 1.50228618 0.86270852 0.94546358\n",
      " 1.61998316 0.75495527 2.32385769 2.09967972]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [-0.02725459  0.1100629  -0.10928818 -0.49904622  0.60916821  0.05272731\n",
      " -0.15397139 -0.0227313  -0.30450578  0.18707633]\n",
      "\n",
      "# 31 Gradient out:  [-0.45444777 -0.43771185 -1.4964661  -0.89368466 -0.43260154 -0.50722247\n",
      " -0.96184389 -0.32932014 -1.37485955 -1.23517208]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.15000536  0.28370018  0.38995694 -0.19858898  0.78170992  0.24182003\n",
      "  0.17002524  0.12825975  0.16026576  0.60701228]\n",
      "\n",
      "# 32 Gradient out:  [-0.27052302 -0.25988501 -0.59865716 -0.44983608 -0.25658762 -0.30234951\n",
      " -0.46327488 -0.18589119 -0.55063254 -0.51234591]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.05911581  0.19615781  0.09066372 -0.37732591  0.69518961  0.14037553\n",
      " -0.02234354  0.06239573 -0.11470615  0.35997786]\n",
      "\n",
      "# 33 Gradient out:  [0.44209139 0.43403755 1.42033874 0.79396631 0.4316382  0.46969279\n",
      " 0.86986688 0.38728027 1.32089935 1.18155004]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.00501121  0.14418081 -0.02906772 -0.46729313  0.64387208  0.07990563\n",
      " -0.11499851  0.02521749 -0.22483266  0.25750868]\n",
      "\n",
      "# 34 Gradient out:  [-0.56606942 -0.54577419 -1.72865354 -1.06834624 -0.53956133 -0.62952662\n",
      " -1.14200672 -0.41263003 -1.59010966 -1.43597724]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.09342948  0.23098832  0.25500003 -0.30849987  0.73019972  0.17384419\n",
      "  0.05897486  0.10267354  0.03934721  0.49381869]\n",
      "\n",
      "# 35 Gradient out:  [0.81512901 0.79843194 2.34128815 1.39551646 0.79338849 0.86988081\n",
      " 1.50778146 0.6946778  2.17871794 1.96570375]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [-0.0197844   0.12183348 -0.09073068 -0.52216911  0.62228745  0.04793887\n",
      " -0.16942648  0.02014754 -0.27867472  0.20662324]\n",
      "\n",
      "# 36 Gradient out:  [-0.47941318 -0.46180682 -1.56836762 -0.93930005 -0.45642954 -0.5348923\n",
      " -1.010361   -0.34764434 -1.44108289 -1.2952264 ]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.1432414   0.28151987  0.37752695 -0.24306582  0.78096515  0.22191503\n",
      "  0.13212981  0.1590831   0.15706886  0.59976399]\n",
      "\n",
      "# 37 Gradient out:  [-0.11764987 -0.11145771 -0.1179667  -0.16536996 -0.10951207 -0.135236\n",
      " -0.15606363 -0.06579217 -0.10657333 -0.11311523]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.04735877  0.18915851  0.06385343 -0.43092583  0.68967925  0.11493657\n",
      " -0.06994239  0.08955423 -0.13114771  0.34071871]\n",
      "\n",
      "# 38 Gradient out:  [0.08357547 0.08471017 0.43360849 0.17852455 0.08511336 0.08203743\n",
      " 0.21175317 0.09754115 0.40542738 0.35128886]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.02382879  0.16686696  0.04026009 -0.46399982  0.66777683  0.08788937\n",
      " -0.10115511  0.0763958  -0.15246238  0.31809566]\n",
      "\n",
      "# 39 Gradient out:  [-0.28544472 -0.27369358 -0.71768501 -0.50464939 -0.27006285 -0.32099516\n",
      " -0.52566902 -0.1932862  -0.65840741 -0.60558256]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.04054389  0.183809    0.12698179 -0.42829491  0.6847995   0.10429686\n",
      " -0.05880448  0.09590402 -0.07137691  0.38835344]\n",
      "\n",
      "# 40 Gradient out:  [0.54205804 0.53222223 1.62602245 0.93865979 0.52927557 0.57519253\n",
      " 1.02146095 0.47339985 1.51429523 1.36084512]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [-0.01654506  0.12907028 -0.01655521 -0.52922479  0.63078693  0.04009782\n",
      " -0.16393828  0.05724678 -0.20305839  0.26723693]\n",
      "\n",
      "# 41 Gradient out:  [-0.56401118 -0.54369319 -1.76777496 -1.07886159 -0.53747972 -0.62775661\n",
      " -1.15614887 -0.41110047 -1.62554414 -1.4652173 ]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.09186655  0.23551473  0.30864928 -0.34149283  0.73664205  0.15513633\n",
      "  0.04035391  0.15192675  0.09980066  0.53940595]\n",
      "\n",
      "# 42 Gradient out:  [0.68830557 0.67477006 2.01426271 1.18507265 0.67069332 0.73311521\n",
      " 1.28407835 0.59177859 1.87480772 1.68870292]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [-0.02093568  0.12677609 -0.04490572 -0.55726515  0.6291461   0.02958501\n",
      " -0.19087587  0.06970666 -0.22530817  0.24636249]\n",
      "\n",
      "# 43 Gradient out:  [-0.52726352 -0.50810966 -1.6949839  -1.02247513 -0.50225712 -0.58752819\n",
      " -1.09827403 -0.38363114 -1.55800988 -1.40189379]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.11672543  0.2617301   0.35794683 -0.32025062  0.76328477  0.17620805\n",
      "  0.0659398   0.18806238  0.14965338  0.58410308]\n",
      "\n",
      "# 44 Gradient out:  [0.26959584 0.26589424 0.95161858 0.50015705 0.26482245 0.28339981\n",
      " 0.55596908 0.24736653 0.88582179 0.78663102]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.01127273  0.16010817  0.01895005 -0.52474565  0.66283335  0.05870241\n",
      " -0.153715    0.11133615 -0.1619486   0.30372432]\n",
      "\n",
      "# 45 Gradient out:  [-0.50016539 -0.48195492 -1.45133269 -0.92343534 -0.47636718 -0.55664137\n",
      " -0.98128418 -0.3611655  -1.3350439  -1.21064947]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.06519189  0.21328702  0.20927376 -0.42471424  0.71579784  0.11538238\n",
      " -0.04252119  0.16080946  0.01521576  0.46105052]\n",
      "\n",
      "# 46 Gradient out:  [0.89556293 0.8772679  2.51549182 1.51585863 0.87173406 0.95528474\n",
      " 1.63419435 0.76278194 2.3419474  2.11644867]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [-0.03484119  0.11689603 -0.08099278 -0.60940131  0.6205244   0.0040541\n",
      " -0.23877802  0.08857636 -0.25179302  0.21892063]\n",
      "\n",
      "# 47 Gradient out:  [-0.4513799  -0.43472418 -1.49115914 -0.88933954 -0.4296388  -0.50391673\n",
      " -0.95741747 -0.3269024  -1.36989255 -1.23045893]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.1442714   0.29234961  0.42210559 -0.30622958  0.79487121  0.19511105\n",
      "  0.08806085  0.24113275  0.21659646  0.64221036]\n",
      "\n",
      "# 48 Gradient out:  [-0.28584414 -0.27457557 -0.67048223 -0.48694612 -0.27108863 -0.31975869\n",
      " -0.50447488 -0.19684466 -0.61632925 -0.57017758]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [ 0.05399542  0.20540478  0.12387376 -0.48409749  0.70894345  0.0943277\n",
      " -0.10342265  0.17575227 -0.05738205  0.39611857]\n",
      "\n",
      "# 49 Gradient out:  [0.49649152 0.48714609 1.55467785 0.88187778 0.48435106 0.52813316\n",
      " 0.96305248 0.43179106 1.44599857 1.29593202]\n",
      "\n",
      "     Weights  out:  [-0.32839197 -0.34176265  0.2174181  -0.07612457 -0.34595626 -0.28936647\n",
      " -0.04429799 -0.44579328  0.15080039  0.08195013] [-0.00317341  0.15048966 -0.01022269 -0.58148671  0.65472572  0.03037597\n",
      " -0.20431762  0.13638334 -0.1806479   0.28208306]\n",
      "\n",
      "Tanh error cuadrático medio (ECM): 0.6769293338006472\n",
      "\n",
      "# 0 Gradient out:  [0.07213019 0.08702687 0.15411649 0.06712454 0.15354111 0.08847246\n",
      " 0.08934205 0.1012595  0.11049947 0.12551454]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [ 0.012535    0.42056617 -0.26009053  0.04893519  0.12896265 -0.00449012\n",
      " -0.2700939  -0.38998094  0.26992619  0.37263526]\n",
      "\n",
      "# 1 Gradient out:  [-0.87241931 -0.83684479 -0.60275071 -0.88449126 -0.61157817 -0.83337317\n",
      " -0.83128044 -0.3707088  -0.40903857 -0.17137644]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [ 0.02696104  0.43797154 -0.22926723  0.06236009  0.15967087  0.01320437\n",
      " -0.25222549 -0.36972904  0.29202608  0.39773817]\n",
      "\n",
      "# 2 Gradient out:  [5.85604065 5.74373294 4.77163084 5.89437797 4.82269971 5.73268811\n",
      " 5.72601492 2.93086736 3.23866788 1.8606577 ]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [-0.14752283  0.27060258 -0.34981737 -0.11453816  0.03735524 -0.15347026\n",
      " -0.41848158 -0.4438708   0.21021837  0.36346289]\n",
      "\n",
      "# 3 Gradient out:  [-41.94162698 -41.0039544  -33.42233295 -42.26131311 -33.79576154\n",
      " -40.91195455 -40.85640494 -20.57693995 -22.72149956 -12.64858785]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [1.02368531 1.41934917 0.6045088  1.06433744 1.00189518 0.99306736\n",
      " 0.72672141 0.14230267 0.85795194 0.73559443]\n",
      "\n",
      "# 4 Gradient out:  [297.72216262 291.19786393 237.98091171 299.94676832 240.62497346\n",
      " 290.55752761 290.17085958 146.42775814 161.71615984  90.39182759]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [-7.36464009 -6.78144171 -6.07995779 -7.38792519 -5.75725713 -7.18932355\n",
      " -7.44455958 -3.97308532 -3.68634797 -1.79412314]\n",
      "\n",
      "# 5 Gradient out:  [-2115.91864599 -2069.41888206 -1690.61503708 -2131.77362565\n",
      " -1709.41237429 -2064.85532537 -2062.0996493  -1040.34608424\n",
      " -1148.93061209  -641.86981056]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [52.17979243 51.45813108 41.51622455 52.60142848 42.36773757 50.92218197\n",
      " 50.58961233 25.31246631 28.656884   16.28424237]\n",
      "\n",
      "# 6 Gradient out:  [15035.4369733  14705.1467631  12013.99564446 15148.0557852\n",
      " 12147.56181625 14672.731343   14653.15745219  7392.84175498\n",
      "  8164.50412038  4561.53535529]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [-371.00393676 -362.42564534 -296.60678287 -373.75329665 -299.51473729\n",
      " -362.0488831  -361.83031753 -182.75675053 -201.12923842 -112.08971974]\n",
      "\n",
      "# 7 Gradient out:  [-106842.180851   -104495.00007553  -85371.04585946 -107642.4973581\n",
      "  -86320.17489603 -104264.64276084 -104125.54267458  -52533.46758074\n",
      "  -58016.83986444  -32413.93526782]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [2636.0834579  2578.60370728 2106.19234603 2655.85786039 2129.99762596\n",
      " 2572.4973855  2568.80117291 1295.81160046 1431.77158566  800.21735132]\n",
      "\n",
      "# 8 Gradient out:  [759220.8512677  742541.9078716  606647.59302853 764907.85830976\n",
      " 613392.10275486 740905.00061387 739916.56250086 373303.18960652\n",
      " 412268.13211278 230333.92240879]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [-18732.3527123  -18320.39630782 -14968.01682587 -18872.64161123\n",
      " -15134.03735325 -18280.43116667 -18256.307362    -9210.88191569\n",
      " -10171.59638723  -5682.56970224]\n",
      "\n",
      "# 9 Gradient out:  [-5395027.81650779 -5276507.01732941 -4310840.66796884 -5435439.76619226\n",
      " -4358767.19707777 -5264875.13231922 -5257851.27782005 -2652694.46556605\n",
      " -2929579.48904723 -1636753.83718848]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [133111.81754124 130187.9852665  106361.50177984 134108.93005072\n",
      " 107544.38319772 129900.56895611 129727.00513817  65449.75600562\n",
      "  72282.03003533  40384.21477951]\n",
      "\n",
      "# 10 Gradient out:  [38337097.11481295 37494887.79819025 30632857.99299061 38624264.60562533\n",
      " 30973424.16743669 37412231.57221238 37362320.03124813 18850061.51445786\n",
      " 20817608.09193702 11630782.0321849 ]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [-945893.74576032 -925113.41819938 -755806.63181393 -952979.02318773\n",
      " -764209.05621783 -923074.45750774 -921843.25042584 -465089.13710759\n",
      " -513633.86777412 -286966.55265818]\n",
      "\n",
      "# 11 Gradient out:  [-2.72423623e+08 -2.66438879e+08 -2.17677257e+08 -2.74464237e+08\n",
      " -2.20097322e+08 -2.65851524e+08 -2.65496852e+08 -1.33948641e+08\n",
      " -1.47930038e+08 -8.26484009e+07]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [6721525.67720227 6573864.14143867 5370764.96678419 6771873.89793733\n",
      " 5430475.77726951 6559371.85693474 6550620.75582378 3304923.16578398\n",
      " 3649887.75061328 2039189.8537788 ]\n",
      "\n",
      "# 12 Gradient out:  [1.93584377e+09 1.89331614e+09 1.54681579e+09 1.95034438e+09\n",
      " 1.56401278e+09 1.88914239e+09 1.88662209e+09 9.51839780e+08\n",
      " 1.05119166e+09 5.87299992e+08]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [-47763199.0169894  -46713911.71746448 -38164686.45850708\n",
      " -48120973.55969214 -38588988.67121261 -46610932.87999147\n",
      " -46548749.64256181 -23484805.01687797 -25936119.77924099\n",
      " -14490490.33582069]\n",
      "\n",
      "# 13 Gradient out:  [-1.37561165e+10 -1.34539149e+10 -1.09916815e+10 -1.38591579e+10\n",
      " -1.11138835e+10 -1.34242562e+10 -1.34063470e+10 -6.76377872e+09\n",
      " -7.46977374e+09 -4.17335698e+09]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [3.39405555e+08 3.31949317e+08 2.71198471e+08 3.41947903e+08\n",
      " 2.74213568e+08 3.31217545e+08 3.30775669e+08 1.66883151e+08\n",
      " 1.84302213e+08 1.02969508e+08]\n",
      "\n",
      "# 14 Gradient out:  [9.77510395e+10 9.56035937e+10 7.81069493e+10 9.84832525e+10\n",
      " 7.89753171e+10 9.53928387e+10 9.52655754e+10 4.80634488e+10\n",
      " 5.30802533e+10 2.96558977e+10]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [-2.41181774e+09 -2.35883367e+09 -1.92713783e+09 -2.42988368e+09\n",
      " -1.94856312e+09 -2.35363370e+09 -2.35049373e+09 -1.18587259e+09\n",
      " -1.30965254e+09 -7.31701888e+08]\n",
      "\n",
      "# 15 Gradient out:  [-6.94619425e+11 -6.79359663e+11 -5.55028412e+11 -6.99822534e+11\n",
      " -5.61199038e+11 -6.77862037e+11 -6.76957704e+11 -3.41539132e+11\n",
      " -3.77188573e+11 -2.10734972e+11]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [1.71383901e+10 1.67618851e+10 1.36942520e+10 1.72667668e+10\n",
      " 1.38465003e+10 1.67249340e+10 1.67026214e+10 8.42681717e+09\n",
      " 9.30639813e+09 5.19947765e+09]\n",
      "\n",
      "# 16 Gradient out:  [4.93596946e+12 4.82753351e+12 3.94403495e+12 4.97294278e+12\n",
      " 3.98788345e+12 4.81689137e+12 4.81046517e+12 2.42697895e+12\n",
      " 2.68030407e+12 1.49748387e+12]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [-1.21785495e+11 -1.19110048e+11 -9.73114304e+10 -1.22697740e+11\n",
      " -9.83933073e+10 -1.18847473e+11 -1.18688919e+11 -5.98810092e+10\n",
      " -6.61313164e+10 -3.69475168e+10]\n",
      "\n",
      "# 17 Gradient out:  [-3.50750261e+13 -3.43044797e+13 -2.80263341e+13 -3.53377588e+13\n",
      " -2.83379218e+13 -3.42288566e+13 -3.41831920e+13 -1.72461258e+13\n",
      " -1.90462555e+13 -1.06411287e+13]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [8.65408397e+11 8.46396654e+11 6.91495560e+11 8.71890817e+11\n",
      " 6.99183384e+11 8.44530801e+11 8.43404115e+11 4.25514781e+11\n",
      " 4.69929498e+11 2.62549258e+11]\n",
      "\n",
      "# 18 Gradient out:  [2.49243329e+14 2.43767822e+14 1.99155284e+14 2.51110309e+14\n",
      " 2.01369428e+14 2.43230444e+14 2.42905951e+14 1.22551065e+14\n",
      " 1.35342797e+14 7.56159188e+13]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [-6.14959683e+12 -6.01449928e+12 -4.91377126e+12 -6.19566094e+12\n",
      " -4.96840097e+12 -6.00124052e+12 -5.99323428e+12 -3.02371038e+12\n",
      " -3.33932160e+12 -1.86567647e+12]\n",
      "\n",
      "# 19 Gradient out:  [-1.77112447e+15 -1.73221548e+15 -1.41519855e+15 -1.78439124e+15\n",
      " -1.43093227e+15 -1.72839687e+15 -1.72609102e+15 -8.70848542e+14\n",
      " -9.61746657e+14 -5.37327135e+14]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [4.36990690e+13 4.27390650e+13 3.49172856e+13 4.40264008e+13\n",
      " 3.53054847e+13 4.26448482e+13 4.25879558e+13 2.14865026e+13\n",
      " 2.37292377e+13 1.32575073e+13]\n",
      "\n",
      "# 20 Gradient out:  [1.25856202e+16 1.23091328e+16 1.00564087e+16 1.26798939e+16\n",
      " 1.01682126e+16 1.22819977e+16 1.22656123e+16 6.18825454e+15\n",
      " 6.83417704e+15 3.81824958e+15]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [-3.10525825e+14 -3.03704031e+14 -2.48122424e+14 -3.12851846e+14\n",
      " -2.50880969e+14 -3.03034526e+14 -3.02630249e+14 -1.52683206e+14\n",
      " -1.68620094e+14 -9.42079198e+13]\n",
      "\n",
      "# 21 Gradient out:  [-8.94334866e+16 -8.74687652e+16 -7.14608954e+16 -9.01033962e+16\n",
      " -7.22553745e+16 -8.72759432e+16 -8.71595086e+16 -4.39737708e+16\n",
      " -4.85636997e+16 -2.71325026e+16]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [2.20659822e+15 2.15812252e+15 1.76315931e+15 2.22312694e+15\n",
      " 1.78276154e+15 2.15336501e+15 2.15049221e+15 1.08496770e+15\n",
      " 1.19821531e+15 6.69441997e+14]\n",
      "\n",
      "# 22 Gradient out:  [6.35514848e+17 6.21553527e+17 5.07801516e+17 6.40275230e+17\n",
      " 5.13447089e+17 6.20183333e+17 6.19355948e+17 3.12477858e+17\n",
      " 3.45093918e+17 1.92803713e+17]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [-1.56800991e+16 -1.53356305e+16 -1.25290198e+16 -1.57975523e+16\n",
      " -1.26683134e+16 -1.53018236e+16 -1.52814095e+16 -7.70978646e+15\n",
      " -8.51452463e+15 -4.75705852e+15]\n",
      "\n",
      "# 23 Gradient out:  [-4.51597201e+18 -4.41676278e+18 -3.60844037e+18 -4.54979931e+18\n",
      " -3.64855784e+18 -4.40702618e+18 -4.40114678e+18 -2.22046938e+18\n",
      " -2.45223928e+18 -1.37006424e+18]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [1.11422871e+17 1.08975075e+17 8.90312835e+16 1.12257494e+17\n",
      " 9.00211044e+16 1.08734843e+17 1.08589780e+17 5.47857851e+16\n",
      " 6.05042589e+16 3.38036840e+16]\n",
      "\n",
      "# 24 Gradient out:  [3.20905220e+19 3.13855407e+19 2.56415972e+19 3.23308989e+19\n",
      " 2.59266721e+19 3.13163523e+19 3.12745732e+19 1.57786676e+19\n",
      " 1.74256258e+19 9.73568406e+18]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [-7.91771532e+17 -7.74377482e+17 -6.32656791e+17 -7.97702368e+17\n",
      " -6.39690464e+17 -7.72670393e+17 -7.71639576e+17 -3.89308090e+17\n",
      " -4.29943597e+17 -2.40209165e+17]\n",
      "\n",
      "# 25 Gradient out:  [-2.28035426e+20 -2.23025825e+20 -1.82209331e+20 -2.29743546e+20\n",
      " -1.84235075e+20 -2.22534172e+20 -2.22237290e+20 -1.12123299e+20\n",
      " -1.23826593e+20 -6.91818246e+19]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [5.62633287e+18 5.50273065e+18 4.49566264e+18 5.66847742e+18\n",
      " 4.54564396e+18 5.49060007e+18 5.48327507e+18 2.76642543e+18\n",
      " 3.05518157e+18 1.70692765e+18]\n",
      "\n",
      "# 26 Gradient out:  [1.62042099e+21 1.58482274e+21 1.29478051e+21 1.63255890e+21\n",
      " 1.30917546e+21 1.58132905e+21 1.57921940e+21 7.96748780e+20\n",
      " 8.79912452e+20 4.91606426e+20]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [-3.99807523e+19 -3.91024343e+19 -3.19462035e+19 -4.02802318e+19\n",
      " -3.23013710e+19 -3.90162343e+19 -3.89641829e+19 -1.96582344e+19\n",
      " -2.17101370e+19 -1.21294373e+19]\n",
      "\n",
      "# 27 Gradient out:  [-1.15147205e+22 -1.12617591e+22 -9.20071741e+21 -1.16009726e+22\n",
      " -9.30300800e+21 -1.12369329e+22 -1.12219418e+22 -5.66170122e+21\n",
      " -6.25266273e+21 -3.49335797e+21]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [2.84103446e+20 2.77862114e+20 2.27009898e+20 2.86231549e+20\n",
      " 2.29533720e+20 2.77249576e+20 2.76879698e+20 1.39691522e+20\n",
      " 1.54272353e+20 8.61918480e+19]\n",
      "\n",
      "# 28 Gradient out:  [8.18236673e+22 8.00261223e+22 6.53803486e+22 8.24365749e+22\n",
      " 6.61072261e+22 7.98497074e+22 7.97431801e+22 4.02320800e+22\n",
      " 4.44314558e+22 2.48238210e+22]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [-2.01884065e+21 -1.97448971e+21 -1.61313358e+21 -2.03396296e+21\n",
      " -1.63106788e+21 -1.97013701e+21 -1.96750866e+21 -9.92648722e+20\n",
      " -1.09626019e+21 -6.12479746e+20]\n",
      "\n",
      "# 29 Gradient out:  [-5.81439430e+23 -5.68666066e+23 -4.64593117e+23 -5.85794755e+23\n",
      " -4.69758313e+23 -5.67412460e+23 -5.66655477e+23 -2.85889382e+23\n",
      " -3.15730169e+23 -1.76398209e+23]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [1.43458928e+22 1.40307347e+22 1.14629361e+22 1.44533520e+22\n",
      " 1.15903773e+22 1.39998045e+22 1.39811274e+22 7.05376729e+21\n",
      " 7.79003096e+21 4.35228445e+21]\n",
      "\n",
      "# 30 Gradient out:  [4.13171179e+24 4.04094419e+24 3.30140125e+24 4.16266075e+24\n",
      " 3.33810516e+24 4.03203607e+24 4.02665694e+24 2.03153153e+24\n",
      " 2.24358032e+24 1.25348664e+24]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [-1.01941993e+23 -9.97024784e+22 -8.14556873e+22 -1.02705599e+23\n",
      " -8.23612852e+22 -9.94826876e+22 -9.93499681e+22 -5.01241092e+22\n",
      " -5.53560029e+22 -3.09273573e+22]\n",
      "\n",
      "# 31 Gradient out:  [-2.93599668e+25 -2.87149717e+25 -2.34597755e+25 -2.95798902e+25\n",
      " -2.37205936e+25 -2.86516705e+25 -2.86134464e+25 -1.44360742e+25\n",
      " -1.59428941e+25 -8.90728298e+24]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [7.24400365e+23 7.08486361e+23 5.78824562e+23 7.29826552e+23\n",
      " 5.85259746e+23 7.06924526e+23 7.05981420e+23 3.56182196e+23\n",
      " 3.93360062e+23 2.19769971e+23]\n",
      "\n",
      "# 32 Gradient out:  [2.08632085e+26 2.04048747e+26 1.66705294e+26 2.10194863e+26\n",
      " 1.68558669e+26 2.03598928e+26 2.03327308e+26 1.02582823e+26\n",
      " 1.13290293e+26 6.32952019e+25]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [-5.14759299e+24 -5.03450798e+24 -4.11313053e+24 -5.18615150e+24\n",
      " -4.15885898e+24 -5.02340957e+24 -5.01670786e+24 -2.53103265e+24\n",
      " -2.79521876e+24 -1.56168663e+24]\n",
      "\n",
      "# 33 Gradient out:  [-1.48254075e+27 -1.44997152e+27 -1.18460873e+27 -1.49364585e+27\n",
      " -1.19777883e+27 -1.44677511e+27 -1.44484497e+27 -7.28954104e+26\n",
      " -8.05041449e+26 -4.49776053e+26]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [3.65788241e+25 3.57752414e+25 2.92279282e+25 3.68528211e+25\n",
      " 2.95528748e+25 3.56963761e+25 3.56487537e+25 1.79855319e+25\n",
      " 1.98628399e+25 1.10973538e+25]\n",
      "\n",
      "# 34 Gradient out:  [1.05349427e+28 1.03035056e+28 8.41783619e+27 1.06138557e+28\n",
      " 8.51142296e+27 1.02807919e+28 1.02670763e+28 5.17995188e+27\n",
      " 5.72062897e+27 3.19611111e+27]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [-2.59929325e+26 -2.54219063e+26 -2.07693819e+26 -2.61876350e+26\n",
      " -2.10002891e+26 -2.53658645e+26 -2.53320240e+26 -1.27805289e+26\n",
      " -1.41145450e+26 -7.88578569e+25]\n",
      "\n",
      "# 35 Gradient out:  [-7.48613610e+28 -7.32167676e+28 -5.98171903e+28 -7.54221168e+28\n",
      " -6.04822184e+28 -7.30553637e+28 -7.29579007e+28 -3.68087666e+28\n",
      " -4.06508210e+28 -2.27115832e+28]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [1.84705922e+27 1.80648206e+27 1.47587342e+27 1.86089478e+27\n",
      " 1.49228170e+27 1.80249973e+27 1.80009502e+27 9.08185086e+26\n",
      " 1.00298034e+27 5.60364366e+26]\n",
      "\n",
      "# 36 Gradient out:  [5.31965243e+29 5.20278754e+29 4.25061284e+29 5.35949977e+29\n",
      " 4.29786977e+29 5.19131816e+29 5.18439244e+29 2.61563298e+29\n",
      " 2.88864958e+29 1.61388635e+29]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [-1.31252130e+28 -1.28368715e+28 -1.04875646e+28 -1.32235286e+28\n",
      " -1.06041620e+28 -1.28085730e+28 -1.27914851e+28 -6.45356823e+27\n",
      " -7.12718385e+27 -3.98195227e+27]\n",
      "\n",
      "# 37 Gradient out:  [-3.78014795e+30 -3.69710369e+30 -3.02048782e+30 -3.80846349e+30\n",
      " -3.05406863e+30 -3.68895355e+30 -3.68403213e+30 -1.85867024e+30\n",
      " -2.05267598e+30 -1.14682853e+30]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [9.32678357e+28 9.12188793e+28 7.45246921e+28 9.39664669e+28\n",
      " 7.53532334e+28 9.10177903e+28 9.08963637e+28 4.58590913e+28\n",
      " 5.06458077e+28 2.82957747e+28]\n",
      "\n",
      "# 38 Gradient out:  [2.68617521e+31 2.62716392e+31 2.14636031e+31 2.70629625e+31\n",
      " 2.17022285e+31 2.62137242e+31 2.61787526e+31 1.32077209e+31\n",
      " 1.45863268e+31 8.14936984e+30]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [-6.62761754e+29 -6.48201858e+29 -5.29572872e+29 -6.67726231e+29\n",
      " -5.35460492e+29 -6.46772919e+29 -6.45910061e+29 -3.25874956e+29\n",
      " -3.59889388e+29 -2.01069931e+29]\n",
      "\n",
      "# 39 Gradient out:  [-1.90879759e+32 -1.86686413e+32 -1.52520482e+32 -1.92309561e+32\n",
      " -1.54216155e+32 -1.86274869e+32 -1.86026360e+32 -9.38541376e+31\n",
      " -1.03650519e+32 -5.79094670e+31]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [4.70958867e+30 4.60612598e+30 3.76314775e+30 4.74486627e+30\n",
      " 3.80498520e+30 4.59597192e+30 4.58984045e+30 2.31566923e+30\n",
      " 2.55737598e+30 1.42880404e+30]\n",
      "\n",
      "# 40 Gradient out:  [1.35639262e+33 1.32659468e+33 1.08381138e+33 1.36655280e+33\n",
      " 1.09586085e+33 1.32367024e+33 1.32190434e+33 6.66928019e+32\n",
      " 7.36541157e+32 4.11504991e+32]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [-3.34663631e+31 -3.27311565e+31 -2.67409486e+31 -3.37170459e+31\n",
      " -2.70382458e+31 -3.26590018e+31 -3.26154315e+31 -1.64551583e+31\n",
      " -1.81727278e+31 -1.01530894e+31]\n",
      "\n",
      "# 41 Gradient out:  [-9.63853340e+33 -9.42678907e+33 -7.70156966e+33 -9.71073171e+33\n",
      " -7.78719322e+33 -9.40600803e+33 -9.39345951e+33 -4.73919417e+33\n",
      " -5.23386552e+33 -2.92415673e+33]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [2.37812160e+32 2.32587779e+32 1.90021328e+32 2.39593514e+32\n",
      " 1.92133924e+32 2.32075047e+32 2.31765436e+32 1.16930445e+32\n",
      " 1.29135504e+32 7.21479089e+31]\n",
      "\n",
      "# 42 Gradient out:  [6.84914714e+34 6.69868151e+34 5.47273964e+34 6.90045130e+34\n",
      " 5.53358379e+34 6.68391449e+34 6.67499750e+34 3.36767399e+34\n",
      " 3.71918772e+34 2.07790739e+34]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [-1.68989452e+33 -1.65277004e+33 -1.35029260e+33 -1.70255283e+33\n",
      " -1.36530472e+33 -1.64912656e+33 -1.64692647e+33 -8.30908389e+32\n",
      " -9.17637600e+32 -5.12683438e+32]\n",
      "\n",
      "# 43 Gradient out:  [-4.86700773e+35 -4.76008677e+35 -3.88893180e+35 -4.90346449e+35\n",
      " -3.93216769e+35 -4.74959332e+35 -4.74325690e+35 -2.39307099e+35\n",
      " -2.64285684e+35 -1.47656213e+35]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [1.20083998e+34 1.17445930e+34 9.59518668e+33 1.20983498e+34\n",
      " 9.70186286e+33 1.17187024e+34 1.17030685e+34 5.90443959e+33\n",
      " 6.52073784e+33 3.64313133e+33]\n",
      "\n",
      "# 44 Gradient out:  [3.45849837e+36 3.38252028e+36 2.76347708e+36 3.48440457e+36\n",
      " 2.79420052e+36 3.37506363e+36 3.37056096e+36 1.70051756e+36\n",
      " 1.87801553e+36 1.04924586e+36]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [-8.53317549e+34 -8.34571424e+34 -6.81834494e+34 -8.59709401e+34\n",
      " -6.89414909e+34 -8.32731639e+34 -8.31620694e+34 -4.19569803e+34\n",
      " -4.63363990e+34 -2.58881113e+34]\n",
      "\n",
      "# 45 Gradient out:  [-2.45761085e+37 -2.40362077e+37 -1.96372834e+37 -2.47601981e+37\n",
      " -1.98556043e+37 -2.39832207e+37 -2.39512248e+37 -1.20838872e+37\n",
      " -1.33451887e+37 -7.45594689e+36]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [6.06367920e+35 5.93046913e+35 4.84511967e+35 6.10909974e+35\n",
      " 4.89898614e+35 5.91739561e+35 5.90950123e+35 2.98146533e+35\n",
      " 3.29266706e+35 1.83961062e+35]\n",
      "\n",
      "# 46 Gradient out:  [1.74637962e+38 1.70801424e+38 1.39542644e+38 1.75946104e+38\n",
      " 1.41094034e+38 1.70424898e+38 1.70197535e+38 8.58681689e+37\n",
      " 9.48309842e+37 5.29819997e+37]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [-4.30885378e+36 -4.21419463e+36 -3.44294471e+36 -4.34112964e+36\n",
      " -3.48122225e+36 -4.20490458e+36 -4.19929483e+36 -2.11863090e+36\n",
      " -2.33977103e+36 -1.30722832e+36]\n",
      "\n",
      "# 47 Gradient out:  [-1.24097832e+39 -1.21371586e+39 -9.91590795e+38 -1.25027398e+39\n",
      " -1.00261498e+39 -1.21104027e+39 -1.20942462e+39 -6.10179681e+38\n",
      " -6.73869496e+38 -3.76490381e+38]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [3.06187387e+37 2.99460903e+37 2.44655840e+37 3.08480911e+37\n",
      " 2.47375845e+37 2.98800751e+37 2.98402122e+37 1.50550029e+37\n",
      " 1.66264258e+37 9.28917162e+36]\n",
      "\n",
      "# 48 Gradient out:  [8.81839879e+39 8.62467161e+39 7.04624965e+39 8.88445380e+39\n",
      " 7.12458756e+39 8.60565881e+39 8.59417802e+39 4.33594017e+39\n",
      " 4.78852035e+39 2.67534272e+39]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [-2.17576926e+38 -2.12797082e+38 -1.73852575e+38 -2.19206705e+38\n",
      " -1.75785411e+38 -2.12327978e+38 -2.12044712e+38 -1.06980933e+38\n",
      " -1.18147473e+38 -6.60089047e+37]\n",
      "\n",
      "# 49 Gradient out:  [-6.26635903e+40 -6.12869639e+40 -5.00706888e+40 -6.31329776e+40\n",
      " -5.06273585e+40 -6.11518589e+40 -6.10702764e+40 -3.08112147e+40\n",
      " -3.40272520e+40 -1.90110001e+40]\n",
      "\n",
      "     Weights  out:  [ 0.43377923  0.38647314  0.15461128  0.45192305  0.16292821  0.38223507\n",
      "  0.37970684 -0.08921935 -0.0488134  -0.27834268] [1.54610283e+39 1.51213724e+39 1.23539735e+39 1.55768405e+39\n",
      " 1.24913210e+39 1.50880378e+39 1.50679089e+39 7.60207101e+38\n",
      " 8.39556597e+38 4.69059640e+38]\n",
      "\n",
      "Lineal error cuadrático medio (ECM): 3.6928437219634056e+81\n",
      "\n",
      "# 0 Gradient out:  [1.81340773 2.50797531 1.80174929 2.27313336 1.6808318  1.86097495\n",
      " 2.09794102 2.53072385 0.99979888 0.79420951]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.40960117 -0.39356841  0.31698233  0.12428524 -0.31488312  0.27420523\n",
      " -0.04149173  0.13274791  0.0673054  -0.1210012 ]\n",
      "\n",
      "# 1 Gradient out:  [-0.24360271 -0.34415542 -0.24231861 -0.30185491 -0.22917893 -0.24888902\n",
      " -0.27712073 -0.3483817  -0.14718637 -0.11068614]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.04691963  0.10802665  0.67733219  0.57891191  0.02128324  0.64640022\n",
      "  0.37809647  0.63889268  0.26726517  0.0378407 ]\n",
      "\n",
      "# 2 Gradient out:  [-0.41771735 -0.60016692 -0.41537738 -0.52372898 -0.39143117 -0.42734981\n",
      " -0.47876357 -0.60773735 -0.24214814 -0.17611632]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.09564017  0.03919557  0.62886846  0.51854093 -0.02455255  0.59662242\n",
      "  0.32267233  0.56921634  0.2378279   0.01570347]\n",
      "\n",
      "# 3 Gradient out:  [-0.93456059 -1.38639615 -0.92873923 -1.19822232 -0.86917004 -0.95852497\n",
      " -1.08644877 -1.40468333 -0.4978598  -0.33493017]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.17918364 -0.08083781  0.54579299  0.41379513 -0.10283878  0.51115245\n",
      "  0.22691961  0.44766887  0.18939827 -0.01951979]\n",
      "\n",
      "# 4 Gradient out:  [0.74506461 0.92576542 0.74059124 0.89314891 0.6935195  0.76313849\n",
      " 0.84606291 0.92911971 0.45814183 0.42836875]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.36609576 -0.35811704  0.36004514  0.17415067 -0.27667279  0.31944746\n",
      "  0.00962986  0.1667322   0.08982631 -0.08650582]\n",
      "\n",
      "# 5 Gradient out:  [-1.27396604 -1.93132769 -1.26555019 -1.65700251 -1.17948105 -1.30862383\n",
      " -1.49411967 -1.95768944 -0.64098172 -0.40319918]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.21708283 -0.17296396  0.50816339  0.35278045 -0.13796889  0.47207516\n",
      "  0.17884244  0.35255614  0.18145468 -0.00083208]\n",
      "\n",
      "# 6 Gradient out:  [2.40198443 3.38952328 2.38729614 3.01588136 2.23576107 2.46212655\n",
      " 2.77033898 3.42695859 1.34592797 1.02193705]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.47187604 -0.5592295   0.25505335  0.02137995 -0.3738651   0.21035039\n",
      " -0.11998149 -0.03898175  0.05325833 -0.08147191]\n",
      "\n",
      "# 7 Gradient out:  [-0.15729867 -0.22156668 -0.15647896 -0.19449701 -0.14809139 -0.16067326\n",
      " -0.17869788 -0.22427904 -0.09573923 -0.07238998]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [0.00852084 0.11867516 0.73251258 0.62455622 0.07328711 0.7027757\n",
      " 0.4340863  0.64640997 0.32244393 0.1229155 ]\n",
      "\n",
      "# 8 Gradient out:  [-0.2267465  -0.32249353 -0.22552207 -0.28226172 -0.21299238 -0.23178702\n",
      " -0.25869928 -0.32650611 -0.13483762 -0.10011384]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.02293889  0.07436182  0.70121679  0.58565682  0.04366884  0.67064105\n",
      "  0.39834672  0.60155416  0.30329608  0.1084375 ]\n",
      "\n",
      "# 9 Gradient out:  [-0.37881368 -0.54652872 -0.37666103 -0.47630384 -0.35463112 -0.38767481\n",
      " -0.43496347 -0.55348091 -0.21733087 -0.15666171]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.06828819  0.00986311  0.65611237  0.52920447  0.00107036  0.62428365\n",
      "  0.34660687  0.53625294  0.27632856  0.08841474]\n",
      "\n",
      "# 10 Gradient out:  [-0.82034292 -1.21377915 -0.81527394 -1.04983018 -0.76340066 -0.84120921\n",
      " -0.95256644 -1.22977351 -0.44016871 -0.29827472]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.14405093 -0.09944263  0.58078017  0.4339437  -0.06985586  0.54674868\n",
      "  0.25961418  0.42555676  0.23286238  0.0570824 ]\n",
      "\n",
      "# 11 Gradient out:  [-0.46744304 -0.83686967 -0.46402799 -0.65659933 -0.42990544 -0.48171823\n",
      " -0.56651095 -0.85411641 -0.18049417 -0.02520263]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.30811951 -0.34219846  0.41772538  0.22397767 -0.22253599  0.37850684\n",
      "  0.06910089  0.17960206  0.14482864 -0.00257255]\n",
      "\n",
      "# 12 Gradient out:  [2.30823722 3.26794999 2.29309896 2.92397051 2.13653588 2.37011978\n",
      " 2.68310889 3.30133302 1.23501395 0.93489577]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.40160812 -0.50957239  0.32491978  0.0926578  -0.30851708  0.28216319\n",
      " -0.0442013   0.00877878  0.1087298  -0.00761307]\n",
      "\n",
      "# 13 Gradient out:  [-0.09903317 -0.13862075 -0.09852931 -0.12191471 -0.09337393 -0.10110754\n",
      " -0.11219087 -0.14030075 -0.06117889 -0.04677587]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [0.06003932 0.1440176  0.78353957 0.6774519  0.11879009 0.75618715\n",
      " 0.49242047 0.66904538 0.35573259 0.17936608]\n",
      "\n",
      "# 14 Gradient out:  [-0.1252648  -0.17635602 -0.12461347 -0.15482607 -0.117949   -0.12794617\n",
      " -0.14226908 -0.17851556 -0.07634722 -0.05777884]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [0.04023269 0.11629345 0.76383371 0.65306896 0.10011531 0.73596564\n",
      " 0.4699823  0.64098523 0.34349682 0.17001091]\n",
      "\n",
      "# 15 Gradient out:  [-0.16836868 -0.23879215 -0.16746907 -0.20916998 -0.15826354 -0.17207208\n",
      " -0.19184797 -0.24175325 -0.10082963 -0.07527046]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [0.01517973 0.08102225 0.73891102 0.62210375 0.07652551 0.71037641\n",
      " 0.44152848 0.60528212 0.32822737 0.15845514]\n",
      "\n",
      "# 16 Gradient out:  [-0.24936085 -0.35721129 -0.24797938 -0.31195998 -0.23384211 -0.25504764\n",
      " -0.28540268 -0.36171255 -0.14569719 -0.10662717]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.01849401  0.03326382  0.7054172   0.58026975  0.0448728   0.67596199\n",
      "  0.40315889  0.55693147  0.30806145  0.14340105]\n",
      "\n",
      "# 17 Gradient out:  [-0.43749919 -0.63623238 -0.43494419 -0.55315237 -0.40879572 -0.4480163\n",
      " -0.50413027 -0.64442999 -0.24588726 -0.1740811 ]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.06836618 -0.03817844  0.65582133  0.51787775 -0.00189562  0.62495247\n",
      "  0.34607835  0.48458896  0.27892201  0.12207561]\n",
      "\n",
      "# 18 Gradient out:  [-1.01664583 -1.52015634 -1.01016571 -1.31037581 -0.94386165 -1.04332373\n",
      " -1.18579359 -1.54052029 -0.53032168 -0.34866365]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.15586601 -0.16542491  0.56883249  0.40724728 -0.08365477  0.5353492\n",
      "  0.2452523   0.35570296  0.22974456  0.08725939]\n",
      "\n",
      "# 19 Gradient out:  [1.54389264 2.14805511 1.53335663 1.95251551 1.42392552 1.58683932\n",
      " 1.79911382 2.16649099 0.81473847 0.64265333]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.35919518 -0.46945618  0.36679935  0.14517212 -0.2724271   0.32668446\n",
      "  0.00809358  0.0475989   0.12368022  0.01752666]\n",
      "\n",
      "# 20 Gradient out:  [-0.38998975 -0.56640771 -0.38772248 -0.49262391 -0.36451875 -0.39932246\n",
      " -0.44911761 -0.57369745 -0.21995129 -0.15618998]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.05041665 -0.03984516  0.67347067  0.53567522  0.01235801  0.64405232\n",
      "  0.36791634  0.4808971   0.28662791  0.14605733]\n",
      "\n",
      "# 21 Gradient out:  [-0.8642155  -1.28515007 -0.85879221 -1.10978218 -0.80329443 -0.88654066\n",
      " -1.00569536 -1.30223851 -0.45743432 -0.30563643]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.1284146  -0.1531267   0.59592618  0.43715044 -0.06054574  0.56418783\n",
      "  0.27809282  0.36615761  0.24263766  0.11481933]\n",
      "\n",
      "# 22 Gradient out:  [-0.0660801  -0.22784404 -0.06580054 -0.12392814 -0.06400858 -0.06751253\n",
      " -0.08636181 -0.23822521 -0.00477241  0.08348367]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.3012577  -0.41015672  0.42416773  0.215194   -0.22120463  0.3868797\n",
      "  0.07695375  0.10570991  0.15115079  0.05369205]\n",
      "\n",
      "# 23 Gradient out:  [0.58292312 0.74055879 0.57856775 0.7225598  0.53264258 0.60049485\n",
      " 0.68003809 0.74162042 0.30765176 0.28952174]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.31447372 -0.45572552  0.41100763  0.19040837 -0.23400634  0.37337719\n",
      "  0.05968139  0.05806487  0.15019631  0.07038878]\n",
      "\n",
      "# 24 Gradient out:  [-1.39311725 -2.13234904 -1.38383598 -1.82005205 -1.28902252 -1.43136694\n",
      " -1.63720254 -2.16247643 -0.69101548 -0.42057516]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.1978891  -0.30761377  0.52672118  0.33492033 -0.12747783  0.49347616\n",
      "  0.19568901  0.20638895  0.21172666  0.12829313]\n",
      "\n",
      "# 25 Gradient out:  [1.83797761 2.54600913 1.82795929 2.26545607 1.72478954 1.87904789\n",
      " 2.09159037 2.57556703 1.1098111  0.86844433]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.47651255 -0.73408358  0.24995398 -0.02909008 -0.38528233  0.20720277\n",
      " -0.1317515  -0.22610633  0.07352357  0.0441781 ]\n",
      "\n",
      "# 26 Gradient out:  [-0.93276571 -1.39783456 -0.92677733 -1.2040665  -0.86550097 -0.95741821\n",
      " -1.0890345  -1.41668981 -0.48346967 -0.31571877]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.10891703 -0.22488175  0.61554584  0.42400114 -0.04032442  0.58301235\n",
      "  0.28656657  0.28900707  0.29548579  0.21786696]\n",
      "\n",
      "# 27 Gradient out:  [0.63290594 0.84468329 0.62765435 0.80904574 0.5724696  0.65414358\n",
      " 0.75228649 0.84689386 0.29407144 0.25994468]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.29547017 -0.50444866  0.43019037  0.18318784 -0.21342462  0.39152871\n",
      "  0.06875967  0.00566911  0.19879185  0.15472321]\n",
      "\n",
      "# 28 Gradient out:  [-1.38451709 -2.11086714 -1.37537217 -1.8042953  -1.28192869 -1.4221989\n",
      " -1.62474843 -2.14058459 -0.69351474 -0.42815279]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.16888898 -0.335512    0.55572124  0.34499699 -0.0989307   0.52235742\n",
      "  0.21921697  0.17504788  0.25760614  0.20671215]\n",
      "\n",
      "# 29 Gradient out:  [1.9898349  2.76133802 1.97891018 2.45573732 1.86639975 2.03461929\n",
      " 2.266317   2.79357619 1.1960117  0.93312976]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.4457924  -0.75768543  0.28064681 -0.01586207 -0.35531643  0.23791765\n",
      " -0.10573271 -0.25306903  0.1189032   0.12108159]\n",
      "\n",
      "# 30 Gradient out:  [-0.62621937 -0.93361848 -0.62225062 -0.80566531 -0.58163104 -0.64255515\n",
      " -0.72967677 -0.94612247 -0.32876856 -0.21804049]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.04782542 -0.20541783  0.67642884  0.47528539  0.01796352  0.6448415\n",
      "  0.34753069  0.3056462   0.35810554  0.30770754]\n",
      "\n",
      "# 31 Gradient out:  [-1.41018524 -2.15939519 -1.40096973 -1.83847723 -1.30692725 -1.44819022\n",
      " -1.65376969 -2.19073031 -0.70913593 -0.4317508 ]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.17306929 -0.39214152  0.55197872  0.31415233 -0.09836269  0.51633047\n",
      "  0.20159533  0.11642171  0.29235182  0.26409944]\n",
      "\n",
      "# 32 Gradient out:  [1.70510448 2.33594766 1.69640305 2.08014108 1.60687134 1.74079663\n",
      " 1.92637279 2.36368183 1.06927881 0.85017583]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.45510634 -0.82402056  0.27178477 -0.05354312 -0.35974814  0.22669243\n",
      " -0.12915861 -0.32172435  0.15052464  0.17774928]\n",
      "\n",
      "# 33 Gradient out:  [-1.25087498 -1.90009835 -1.2426192  -1.62755615 -1.15820553 -1.28487848\n",
      " -1.46708238 -1.92662283 -0.6290917  -0.39322395]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.11408544 -0.35683103  0.61106538  0.3624851  -0.03837387  0.57485176\n",
      "  0.25611595  0.15101202  0.3643804   0.34778445]\n",
      "\n",
      "# 34 Gradient out:  [2.38465623 3.38607487 2.3698673  3.0041048  2.21731779 2.44521687\n",
      " 2.75586414 3.42493953 1.32014445 0.98961895]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.36426044 -0.7368507   0.36254154  0.03697387 -0.27001498  0.31787606\n",
      " -0.03730053 -0.23431255  0.23856206  0.26913966]\n",
      "\n",
      "# 35 Gradient out:  [-0.12662004 -0.18509227 -0.12586744 -0.16065574 -0.11816441 -0.12971772\n",
      " -0.14623736 -0.18750985 -0.07020662 -0.04909161]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [ 0.11267081 -0.05963573  0.836515    0.63779483  0.17344858  0.80691943\n",
      "  0.5138723   0.45067536  0.50259095  0.46706345]\n",
      "\n",
      "# 36 Gradient out:  [-0.17310199 -0.2544294  -0.1720535  -0.22049287 -0.16132149 -0.17741744\n",
      " -0.20042566 -0.25777716 -0.09453295 -0.06519798]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [ 0.0873468  -0.09665418  0.81134152  0.60566368  0.1498157   0.78097589\n",
      "  0.48462483  0.41317339  0.48854962  0.45724512]\n",
      "\n",
      "# 37 Gradient out:  [-0.26390443 -0.39069699 -0.26226664 -0.33788819 -0.24550198 -0.27064521\n",
      " -0.30657549 -0.39588593 -0.14121489 -0.09554317]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [ 0.0527264  -0.14754006  0.77693082  0.56156511  0.1175514   0.7454924\n",
      "  0.4445397   0.36161795  0.46964303  0.44420553]\n",
      "\n",
      "# 38 Gradient out:  [-0.48903721 -0.73145819 -0.48590136 -0.63067948 -0.45380302 -0.50194384\n",
      " -0.57074184 -0.74130451 -0.25413971 -0.16692031]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-5.44835740e-05 -2.25679456e-01  7.24477489e-01  4.93987468e-01\n",
      "  6.84510044e-02  6.91363357e-01  3.83224599e-01  2.82440769e-01\n",
      "  4.41400057e-01  4.25096894e-01]\n",
      "\n",
      "# 39 Gradient out:  [-1.21312076 -1.84356649 -1.20509232 -1.57911849 -1.12299566 -1.24618595\n",
      " -1.42328422 -1.86931651 -0.60873663 -0.37987738]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.09786193 -0.37197109  0.62729722  0.36785157 -0.0223096   0.59097459\n",
      "  0.26907623  0.13417987  0.39057211  0.39171283]\n",
      "\n",
      "# 40 Gradient out:  [2.35482008 3.36842086 2.33961516 2.98742755 2.18268161 2.41705958\n",
      " 2.73529984 3.40666075 1.26419091 0.93377553]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.34048608 -0.74068439  0.38627875  0.05202787 -0.24690873  0.3417374\n",
      " -0.01558061 -0.23968343  0.26882479  0.31573736]\n",
      "\n",
      "# 41 Gradient out:  [-0.11341619 -0.1660358  -0.1127387  -0.14405109 -0.10580429 -0.11620473\n",
      " -0.13107472 -0.16821005 -0.06263629 -0.04363887]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [ 0.13047794 -0.06700022  0.85420178  0.64951338  0.18962759  0.82514931\n",
      "  0.53147936  0.44164872  0.52166297  0.50249246]\n",
      "\n",
      "# 42 Gradient out:  [-0.15036735 -0.22118935 -0.14945414 -0.19163977 -0.14010673 -0.15412598\n",
      " -0.1741645  -0.22410435 -0.08193909 -0.0563961 ]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [ 0.1077947  -0.10020738  0.83165404  0.62070316  0.16846673  0.80190837\n",
      "  0.50526441  0.40800671  0.50913571  0.49376469]\n",
      "\n",
      "# 43 Gradient out:  [-0.21778518 -0.3223313  -0.21643475 -0.27878378 -0.20261139 -0.22334323\n",
      " -0.25296787 -0.32661278 -0.1166259  -0.07896637]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [ 0.07772123 -0.14444525  0.80176322  0.58237521  0.14044539  0.77108317\n",
      "  0.47043151  0.36318584  0.49274789  0.48248547]\n",
      "\n",
      "# 44 Gradient out:  [-0.3674451  -0.54840685 -0.3651035  -0.47317276 -0.34113389 -0.37708245\n",
      " -0.42844285 -0.55576906 -0.19207717 -0.12697672]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [ 0.03416419 -0.20891151  0.75847627  0.52661845  0.09992311  0.72641453\n",
      "  0.41983794  0.29786328  0.46942271  0.46669219]\n",
      "\n",
      "# 45 Gradient out:  [-0.816149   -1.23331982 -0.81076633 -1.05975002 -0.75568222 -0.83830645\n",
      " -0.95654004 -1.25020815 -0.41252983 -0.26225168]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.03932483 -0.31859288  0.68545557  0.4319839   0.03169633  0.65099804\n",
      "  0.33414937  0.18670947  0.43100728  0.44129685]\n",
      "\n",
      "# 46 Gradient out:  [-0.54045424 -0.84590687 -0.53857328 -0.67409554 -0.52044529 -0.548493\n",
      " -0.60327006 -0.86477209 -0.3560406  -0.21107402]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.20255463 -0.56525684  0.5233023   0.2200339  -0.11944011  0.48333675\n",
      "  0.14284136 -0.06333216  0.34850132  0.38884651]\n",
      "\n",
      "# 47 Gradient out:  [2.22226626 3.20975467 2.206981   2.84969508 2.04903122 2.28478499\n",
      " 2.60240946 3.24490234 1.13351505 0.81983831]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [-0.31064548 -0.73443822  0.41558764  0.08521479 -0.22352917  0.37363815\n",
      "  0.02218735 -0.23628658  0.2772932   0.34663171]\n",
      "\n",
      "# 48 Gradient out:  [-0.12075675 -0.17712341 -0.12003077 -0.15358064 -0.11259996 -0.12374486\n",
      " -0.13967829 -0.17945029 -0.06634565 -0.04600021]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [ 0.13380778 -0.09248728  0.85698384  0.65515381  0.18627708  0.83059515\n",
      "  0.54266924  0.41269389  0.50399621  0.51059937]\n",
      "\n",
      "# 49 Gradient out:  [-0.16301927 -0.24031682 -0.16202216 -0.20807787 -0.15181584 -0.16712321\n",
      " -0.18900146 -0.24349463 -0.08830931 -0.06043873]\n",
      "\n",
      "     Weights  out:  [ 0.05507033  0.46528573  0.05139734  0.24348734  0.01418371  0.07029202\n",
      "  0.15617402  0.49910074 -0.24050629 -0.4193061 ] [ 0.10965643 -0.12791197  0.83297769  0.62443768  0.16375708  0.80584617\n",
      "  0.51473358  0.37680383  0.49072708  0.50139933]\n",
      "\n",
      "Tanh error cuadrático medio (ECM): 1.1161716950257548\n",
      "\n",
      "# 0 Gradient out:  [0.50841939 0.24148681 0.1740686  0.42010649 0.38352414 0.30330623\n",
      " 0.49471473 0.31153618 0.17641881 0.42574186]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [-0.49779618  0.48056902 -0.25480882  0.07616153 -0.11923855  0.42461488\n",
      " -0.24977671  0.02956638 -0.14299266 -0.12006769]\n",
      "\n",
      "# 1 Gradient out:  [-0.0545721  -1.5639781  -1.82762297 -0.40698436 -0.59142281 -1.25747507\n",
      " -0.11186663 -1.20055538 -1.8176494  -0.38253125]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [-0.3961123   0.52886638 -0.2199951   0.16018283 -0.04253372  0.48527612\n",
      " -0.15083377  0.09187362 -0.1077089  -0.03491931]\n",
      "\n",
      "# 2 Gradient out:  [1.90533576 6.30370426 6.93468674 2.76266542 3.28140813 5.44841041\n",
      " 2.04157567 5.27083523 6.91089222 2.69858867]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [-0.40702672  0.21607076 -0.5855197   0.07878595 -0.16081828  0.23378111\n",
      " -0.17320709 -0.14823746 -0.47123878 -0.11142556]\n",
      "\n",
      "# 3 Gradient out:  [ -6.80477307 -27.17177281 -30.31738173 -11.05020802 -13.47909227\n",
      " -23.15570431  -7.48924188 -22.3523216  -30.19792024 -10.74252077]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [-0.02595957  1.47681161  0.80141765  0.63131904  0.49546334  1.32346319\n",
      "  0.23510804  0.90592959  0.91093966  0.42829217]\n",
      "\n",
      "# 4 Gradient out:  [ 30.127515   115.86823396 128.88308128  47.72050649  57.92087594\n",
      "  99.01370952  32.95207899  95.61257251 128.39008008  46.43586478]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [-1.38691418 -3.95754295 -5.26205869 -1.57872257 -2.20035511 -3.30767767\n",
      " -1.26274033 -3.56453473 -5.12864439 -1.72021198]\n",
      "\n",
      "# 5 Gradient out:  [-127.78177153 -494.8706814  -550.83833295 -203.40588039 -247.10255885\n",
      " -422.65637026 -139.9380425  -408.11532883 -548.71656191 -197.89465506]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [ 4.63858882 19.21610384 20.51455756  7.96537873  9.38382008 16.49506423\n",
      "  5.32767546 15.55797977 20.54937163  7.56696097]\n",
      "\n",
      "# 6 Gradient out:  [ 546.36898292 2113.16399872 2351.78579394  868.8298771  1055.30952591\n",
      " 1804.99557533  598.18663945 1742.91066115 2342.7415076   845.31851329]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [-20.91776549 -79.75803244 -89.65310903 -32.71579735 -40.03669169\n",
      " -68.03620982 -22.65993303 -66.06508599 -89.19394075 -32.01197004]\n",
      "\n",
      "# 7 Gradient out:  [ -2332.51110124  -9023.63596425 -10042.95584691  -3709.93226706\n",
      "  -4506.33351903  -7707.52343278  -2553.87308886  -7442.40687233\n",
      " -10004.31913332  -3609.51342532]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [ 88.3560311  342.87476731 380.70404976 141.05017807 171.02521349\n",
      " 292.96290525  96.97739485 282.51704624 379.35436077 137.05173262]\n",
      "\n",
      "# 8 Gradient out:  [ 9960.80497643 38532.81066319 42885.1712124  15842.24536736\n",
      " 19242.96135173 32912.88723507 10905.97763835 31780.78115966\n",
      " 42720.20002295 15413.4551888 ]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [ -378.14618915 -1461.85242554 -1627.88711962  -600.93627534\n",
      "  -730.24149032 -1248.54178131  -413.79722292 -1205.96432823\n",
      " -1621.5094659   -584.85095244]\n",
      "\n",
      "# 9 Gradient out:  [ -42534.24001209 -164542.92294274 -183128.72758268  -67649.61029814\n",
      "  -82171.43245904 -140544.5719498   -46570.40766988 -135710.2555946\n",
      " -182424.25158493  -65818.57097043]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [1614.01480613 6244.7097071  6949.14712286 2567.51279813 3118.35078003\n",
      " 5334.03566571 1767.39830475 5150.1919037  6922.53053869 2497.84008532]\n",
      "\n",
      "# 10 Gradient out:  [181630.28987437 702632.03148822 781996.89316094 288877.65424207\n",
      " 350888.74591116 600154.27611334 198865.46572768 579510.74469059\n",
      " 778988.65158571 281058.75817324]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [ -6892.83319628 -26663.87488145 -29676.59839368 -10962.40926149\n",
      " -13315.93571178 -22774.87872425  -7546.68322922 -21991.85921522\n",
      " -29562.31977829 -10665.87410877]\n",
      "\n",
      "# 11 Gradient out:  [ -775598.1624675  -3000382.45047665 -3339286.97077243 -1233566.75081194\n",
      " -1498366.85467142 -2562781.36304542  -849195.97507041 -2474629.27360383\n",
      " -3326441.14876188 -1200178.44894545]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [ 29433.22477859 113862.53141619 126722.78023851  46813.12158692\n",
      "  56861.81347045  97255.97649841  32226.40991631  93910.2897229\n",
      " 126235.41053885  45545.87752588]\n",
      "\n",
      "# 12 Gradient out:  [ 3311963.16474698 12812247.10699781 14259438.4383275   5267582.35513255\n",
      "  6398332.93319612 10943601.01669474  3626240.79975488 10567173.54151233\n",
      " 14204584.16465818  5125007.48942612]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [-125686.40771491 -486213.95867914 -541134.61391598 -199900.22857547\n",
      " -242811.55746383 -415300.29611067 -137612.78509777 -401015.56499787\n",
      " -539052.81921353 -194489.81226321]\n",
      "\n",
      "# 13 Gradient out:  [-14142760.12130274 -54710916.66592431 -60890720.08723194\n",
      " -22493654.60781704 -27322190.99438498 -46731415.41080666\n",
      " -15484790.01384215 -45123993.08445299 -60656481.0996954\n",
      " -21884830.74297203]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [ 536706.22523449 2076235.46272042 2310753.07374952  853616.24245104\n",
      " 1036855.02917539 1773419.90722828  587635.37485321 1712419.1433046\n",
      " 2301864.01371811  830511.68562201]\n",
      "\n",
      "# 14 Gradient out:  [6.03924799e+07 2.33626809e+08 2.60015834e+08 9.60525077e+07\n",
      " 1.16671346e+08 1.99552706e+08 6.61232220e+07 1.92688684e+08\n",
      " 2.59015586e+08 9.34527052e+07]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [-2291845.79902606 -8865947.87046444 -9867390.94369687 -3645114.67911237\n",
      " -4427583.1697016  -7572863.17493305 -2509322.62791522 -7312379.473586\n",
      " -9829432.20622097 -3546454.4629724 ]\n",
      "\n",
      "# 15 Gradient out:  [-2.57888246e+08 -9.97634280e+08 -1.11032082e+09 -4.10163862e+08\n",
      " -4.98210521e+08 -8.52130887e+08 -2.82359688e+08 -8.22820108e+08\n",
      " -1.10604955e+09 -3.99062174e+08]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [ 9786650.17422491 37859413.9695421  42135775.85761084 15565386.86026554\n",
      " 18906686.03790698 32337678.05771738 10715321.77798423 31225357.30677899\n",
      " 41973684.91668923 15144086.58326004]\n",
      "\n",
      "# 16 Gradient out:  [1.10123558e+09 4.26010251e+09 4.74129708e+09 1.75148362e+09\n",
      " 2.12746087e+09 3.63877325e+09 1.20573364e+09 3.51361023e+09\n",
      " 4.72305790e+09 1.70407714e+09]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [-4.17909991e+07 -1.61667442e+08 -1.79928387e+08 -6.64673856e+07\n",
      " -8.07354182e+07 -1.38088499e+08 -4.57566158e+07 -1.33338664e+08\n",
      " -1.79236225e+08 -6.46683482e+07]\n",
      "\n",
      "# 17 Gradient out:  [-4.70250126e+09 -1.81915094e+10 -2.02463087e+10 -7.47919344e+09\n",
      " -9.08469323e+09 -1.55383064e+10 -5.14872938e+09 -1.50038346e+10\n",
      " -2.01684237e+10 -7.27675806e+09]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [1.78456117e+08 6.90353060e+08 7.68331028e+08 2.83829338e+08\n",
      " 3.44756755e+08 5.89666151e+08 1.95390113e+08 5.69383381e+08\n",
      " 7.65375355e+08 2.76147079e+08]\n",
      "\n",
      "# 18 Gradient out:  [2.00806426e+10 7.76814675e+10 8.64558808e+10 3.19376864e+10\n",
      " 3.87934990e+10 6.63517476e+10 2.19861280e+10 6.40694439e+10\n",
      " 8.61232959e+10 3.10732459e+10]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [-7.62044136e+08 -2.94794882e+09 -3.28093071e+09 -1.21200935e+09\n",
      " -1.47218189e+09 -2.51799512e+09 -8.34355762e+08 -2.43138354e+09\n",
      " -3.26830938e+09 -1.17920453e+09]\n",
      "\n",
      "# 19 Gradient out:  [-8.57484529e+10 -3.31715762e+11 -3.69184302e+11 -1.36380456e+11\n",
      " -1.65656179e+11 -2.83335539e+11 -9.38852652e+10 -2.73589635e+11\n",
      " -3.67764096e+11 -1.32689118e+11]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [3.25408439e+09 1.25883447e+10 1.40102455e+10 5.17552793e+09\n",
      " 6.28651791e+09 1.07523544e+10 3.56286983e+09 1.03825052e+10\n",
      " 1.39563498e+10 5.03544465e+09]\n",
      "\n",
      "# 20 Gradient out:  [3.66163440e+11 1.41649418e+12 1.57649251e+12 5.82372453e+11\n",
      " 7.07385779e+11 1.20990073e+12 4.00909293e+11 1.16828372e+12\n",
      " 1.57042794e+12 5.66609685e+11]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [-1.38956062e+10 -5.37548076e+10 -5.98266149e+10 -2.21005633e+10\n",
      " -2.68447178e+10 -4.59147534e+10 -1.52141832e+10 -4.43354218e+10\n",
      " -5.95964694e+10 -2.15023790e+10]\n",
      "\n",
      "# 21 Gradient out:  [-1.56359281e+12 -6.04871998e+12 -6.73194560e+12 -2.48684954e+12\n",
      " -3.02068202e+12 -5.16652367e+12 -1.71196472e+12 -4.98881056e+12\n",
      " -6.70604865e+12 -2.41953930e+12]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [5.93370817e+10 2.29544028e+11 2.55471887e+11 9.43739273e+10\n",
      " 1.14632438e+11 1.96065392e+11 6.49676754e+10 1.89321323e+11\n",
      " 2.54489119e+11 9.18195581e+10]\n",
      "\n",
      "# 22 Gradient out:  [6.67686124e+12 2.58292720e+13 2.87467852e+13 1.06193564e+13\n",
      " 1.28989303e+13 2.20621133e+13 7.31043964e+12 2.13032419e+13\n",
      " 2.86361999e+13 1.03319279e+13]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [-2.53381480e+11 -9.80199968e+11 -1.09091723e+12 -4.02995980e+11\n",
      " -4.89503966e+11 -8.37239343e+11 -2.77425268e+11 -8.08440788e+11\n",
      " -1.08672061e+12 -3.92088301e+11]\n",
      "\n",
      "# 23 Gradient out:  [-2.85115637e+13 -1.10296277e+14 -1.22754655e+14 -4.53468247e+13\n",
      " -5.50810718e+13 -9.42097380e+13 -3.12170731e+13 -9.09692019e+13\n",
      " -1.22282433e+14 -4.41194462e+13]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [1.08199077e+12 4.18565443e+12 4.65843981e+12 1.72087530e+12\n",
      " 2.09028210e+12 3.57518331e+12 1.18466266e+12 3.45220759e+12\n",
      " 4.64051937e+12 1.67429727e+12]\n",
      "\n",
      "# 24 Gradient out:  [1.21750211e+14 4.70987670e+14 5.24187495e+14 1.93640220e+14\n",
      " 2.35207447e+14 4.02294858e+14 1.33303290e+14 3.88457106e+14\n",
      " 5.22171011e+14 1.88399063e+14]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [-4.62032198e+12 -1.78736009e+13 -1.98924912e+13 -7.34848964e+12\n",
      " -8.92593227e+12 -1.52667643e+13 -5.05875196e+12 -1.47416328e+13\n",
      " -1.98159673e+13 -7.14959196e+12]\n",
      "\n",
      "# 25 Gradient out:  [-5.19898314e+14 -2.01121372e+15 -2.23838786e+15 -8.26883363e+14\n",
      " -1.00438393e+15 -1.71788136e+15 -5.69232324e+14 -1.65879133e+15\n",
      " -2.22977706e+15 -8.04502548e+14]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [1.97297203e+13 7.63239331e+13 8.49450078e+13 3.13795544e+13\n",
      " 3.81155572e+13 6.51922074e+13 2.16019060e+13 6.29497884e+13\n",
      " 8.46182349e+13 3.05302206e+13]\n",
      "\n",
      "# 26 Gradient out:  [2.22007218e+15 8.58829413e+15 9.55837419e+15 3.53096116e+15\n",
      " 4.28892489e+15 7.33570493e+15 2.43073850e+15 7.08337840e+15\n",
      " 9.52160432e+15 3.43539050e+15]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [-8.42499426e+13 -3.25918812e+14 -3.62732565e+14 -1.33997118e+14\n",
      " -1.62761228e+14 -2.78384065e+14 -9.22445588e+13 -2.68808477e+14\n",
      " -3.61337178e+14 -1.30370289e+14]\n",
      "\n",
      "# 27 Gradient out:  [-9.48016249e+15 -3.66737733e+16 -4.08162136e+16 -1.50779266e+16\n",
      " -1.83145869e+16 -3.13249611e+16 -1.03797508e+16 -3.02474752e+16\n",
      " -4.06591987e+16 -1.46698204e+16]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [3.59764494e+14 1.39174001e+15 1.54894227e+15 5.72195113e+14\n",
      " 6.95023750e+14 1.18875692e+15 3.93903141e+14 1.14786720e+15\n",
      " 1.54298369e+15 5.56707810e+14]\n",
      "\n",
      "# 28 Gradient out:  [4.04822336e+16 1.56604516e+17 1.74293584e+17 6.43858320e+16\n",
      " 7.82070335e+16 1.33763993e+17 4.43236597e+16 1.29162908e+17\n",
      " 1.73623098e+17 6.26431347e+16]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [-1.53626800e+15 -5.94301464e+15 -6.61430045e+15 -2.44339022e+15\n",
      " -2.96789363e+15 -5.07623529e+15 -1.68204701e+15 -4.90162783e+15\n",
      " -6.58885606e+15 -2.37725626e+15]\n",
      "\n",
      "# 29 Gradient out:  [-1.72867421e+17 -6.68733328e+17 -7.44269267e+17 -2.74940677e+17\n",
      " -3.33960036e+17 -5.71199623e+17 -1.89271096e+17 -5.51552047e+17\n",
      " -7.41406156e+17 -2.67499003e+17]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [6.56017873e+15 2.53778886e+16 2.82444163e+16 1.04337762e+16\n",
      " 1.26735131e+16 2.16765634e+16 7.18268492e+15 2.09309538e+16\n",
      " 2.81357636e+16 1.01513707e+16]\n",
      "\n",
      "# 30 Gradient out:  [7.38179260e+17 2.85562815e+18 3.17818206e+18 1.17405295e+18\n",
      " 1.42607769e+18 2.43913927e+18 8.08226310e+17 2.35524010e+18\n",
      " 3.16595599e+18 1.14227548e+18]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [-2.80133055e+16 -1.08368777e+17 -1.20609437e+17 -4.45543593e+16\n",
      " -5.41184941e+16 -9.25633611e+16 -3.06715343e+16 -8.93794556e+16\n",
      " -1.20145468e+17 -4.33484300e+16]\n",
      "\n",
      "# 31 Gradient out:  [-3.15217649e+18 -1.21941165e+19 -1.35714877e+19 -5.01344633e+18\n",
      " -6.08964353e+18 -1.04156238e+19 -3.45129172e+18 -1.00573571e+19\n",
      " -1.35192799e+19 -4.87775003e+18]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [1.19622547e+17 4.62756852e+17 5.15026975e+17 1.90256231e+17\n",
      " 2.31097043e+17 3.95264492e+17 1.30973728e+17 3.81668564e+17\n",
      " 5.13045731e+17 1.85106666e+17]\n",
      "\n",
      "# 32 Gradient out:  [1.34604386e+19 5.20713726e+19 5.79530296e+19 2.14084417e+19\n",
      " 2.60040239e+19 4.44768447e+19 1.47377219e+19 4.29469730e+19\n",
      " 5.77300915e+19 2.08289907e+19]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [-5.10812751e+17 -1.97606645e+18 -2.19927057e+18 -8.12433035e+17\n",
      " -9.86831662e+17 -1.68786026e+18 -5.59284617e+17 -1.62980287e+18\n",
      " -2.19081025e+18 -7.90443340e+17]\n",
      "\n",
      "# 33 Gradient out:  [-5.74788271e+19 -2.22355416e+20 -2.47471295e+20 -9.14184266e+19\n",
      " -1.11042503e+20 -1.89925228e+20 -6.29330879e+19 -1.83392362e+20\n",
      " -2.46519303e+20 -8.89440523e+19]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [2.18127497e+18 8.43820807e+18 9.39133534e+18 3.46925530e+18\n",
      " 4.21397312e+18 7.20750868e+18 2.38825975e+18 6.95959173e+18\n",
      " 9.35520805e+18 3.37535480e+18]\n",
      "\n",
      "# 34 Gradient out:  [2.45446353e+20 9.49503124e+20 1.05675307e+21 3.90375387e+20\n",
      " 4.74174210e+20 8.11019585e+20 2.68737163e+20 7.83122913e+20\n",
      " 1.05268787e+21 3.79809303e+20]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [-9.31449045e+18 -3.60328751e+19 -4.01029236e+19 -1.48144300e+19\n",
      " -1.79945275e+19 -3.07775369e+19 -1.01983578e+19 -2.97188807e+19\n",
      " -3.99486526e+19 -1.44134557e+19]\n",
      "\n",
      "# 35 Gradient out:  [-1.04810615e+21 -4.05457263e+21 -4.51255182e+21 -1.66698278e+21\n",
      " -2.02482090e+21 -3.46321958e+21 -1.14756267e+21 -3.34409508e+21\n",
      " -4.49519260e+21 -1.62186344e+21]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [3.97747801e+19 1.53867750e+20 1.71247689e+20 6.32606475e+19\n",
      " 7.68403144e+19 1.31426380e+20 4.35490747e+19 1.26905702e+20\n",
      " 1.70588921e+20 6.15484050e+19]\n",
      "\n",
      "# 36 Gradient out:  [4.47562772e+21 1.73138548e+22 1.92695196e+22 7.11835758e+21\n",
      " 8.64639956e+21 1.47886562e+22 4.90032743e+21 1.42799703e+22\n",
      " 1.91953922e+22 6.92568876e+21]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [-1.69846450e+20 -6.57046775e+20 -7.31262675e+20 -2.70135909e+20\n",
      " -3.28123866e+20 -5.61217536e+20 -1.85963460e+20 -5.41913314e+20\n",
      " -7.28449599e+20 -2.62824283e+20]\n",
      "\n",
      "# 37 Gradient out:  [-1.91118462e+22 -7.39337026e+22 -8.22847917e+22 -3.03968434e+22\n",
      " -3.69218953e+22 -6.31505882e+22 -2.09254008e+22 -6.09783949e+22\n",
      " -8.19682524e+22 -2.95741081e+22]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [7.25279095e+20 2.80572418e+21 3.12264125e+21 1.15353561e+21\n",
      " 1.40115605e+21 2.39651371e+21 7.94102026e+20 2.31408074e+21\n",
      " 3.11062884e+21 1.12231347e+21]\n",
      "\n",
      "# 38 Gradient out:  [8.16114938e+22 3.15712038e+23 3.51372898e+23 1.29800741e+23\n",
      " 1.57664048e+23 2.69665933e+23 8.93557433e+22 2.60390224e+23\n",
      " 3.50021210e+23 1.26287493e+23]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [-3.09709014e+21 -1.19810163e+22 -1.33343171e+22 -4.92583308e+21\n",
      " -5.98322302e+21 -1.02336039e+22 -3.39097814e+21 -9.88159825e+21\n",
      " -1.32830216e+22 -4.79250816e+21]\n",
      "\n",
      "# 39 Gradient out:  [-3.48497778e+23 -1.34815500e+24 -1.50043417e+24 -5.54275725e+23\n",
      " -6.73257746e+23 -1.15152871e+24 -3.81567308e+23 -1.11191954e+24\n",
      " -1.49466219e+24 -5.39273436e+23]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [1.32252086e+22 5.11613913e+22 5.69402625e+22 2.10343152e+22\n",
      " 2.55495866e+22 4.36995828e+22 1.44801705e+22 4.21964465e+22\n",
      " 5.67212204e+22 2.04649905e+22]\n",
      "\n",
      "# 40 Gradient out:  [1.48815682e+24 5.75689773e+24 6.40716093e+24 2.36687076e+24\n",
      " 2.87494834e+24 4.91726324e+24 1.62937048e+24 4.74812394e+24\n",
      " 6.38251338e+24 2.30280792e+24]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [-5.64743470e+22 -2.18469609e+23 -2.43146572e+23 -8.98208297e+22\n",
      " -1.09101963e+23 -1.86606160e+23 -6.18332910e+22 -1.80187461e+23\n",
      " -2.42211217e+23 -8.73896968e+22]\n",
      "\n",
      "# 41 Gradient out:  [-6.35473413e+24 -2.45831313e+25 -2.73598882e+25 -1.01070224e+25\n",
      " -1.22766177e+25 -2.09977202e+25 -6.95774535e+24 -2.02754608e+25\n",
      " -2.72546381e+25 -9.83346101e+24]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [2.41157017e+23 9.32909936e+23 1.03828561e+24 3.83553322e+23\n",
      " 4.65887705e+23 7.96846487e+23 2.64040805e+23 7.69437327e+23\n",
      " 1.03429146e+24 3.73171887e+23]\n",
      "\n",
      "# 42 Gradient out:  [2.71360150e+25 1.04975001e+26 1.16832321e+26 4.31590540e+25\n",
      " 5.24236695e+25 8.96645618e+25 2.97109963e+25 8.65803663e+25\n",
      " 1.16382882e+26 4.19908906e+25]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [-1.02978981e+24 -3.98371632e+24 -4.43369202e+24 -1.63785117e+24\n",
      " -1.98943583e+24 -3.40269755e+24 -1.12750827e+24 -3.28565483e+24\n",
      " -4.41663617e+24 -1.59352032e+24]\n",
      "\n",
      "# 43 Gradient out:  [-1.15876337e+26 -4.48264733e+26 -4.98897917e+26 -1.84297992e+26\n",
      " -2.23859796e+26 -3.82886026e+26 -1.26872034e+26 -3.69715880e+26\n",
      " -4.96978719e+26 -1.79309695e+26]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [4.39741320e+24 1.70112838e+25 1.89327722e+25 6.99395962e+24\n",
      " 8.49529807e+24 1.45302148e+25 4.81469100e+24 1.40304184e+25\n",
      " 1.88599402e+25 6.80465781e+24]\n",
      "\n",
      "# 44 Gradient out:  [4.94815669e+26 1.91418213e+27 2.13039619e+27 7.86990135e+26\n",
      " 9.55927134e+26 1.63500168e+27 5.41769545e+26 1.57876246e+27\n",
      " 2.12220082e+27 7.65689089e+26]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [-1.87778542e+25 -7.26416627e+25 -8.08468112e+25 -2.98656387e+25\n",
      " -3.62766611e+25 -6.20469904e+25 -2.05597158e+25 -5.99127576e+25\n",
      " -8.05358036e+25 -2.90572812e+25]\n",
      "\n",
      "# 45 Gradient out:  [-2.11296415e+27 -8.17394939e+27 -9.09722764e+27 -3.36060891e+27\n",
      " -4.08200446e+27 -6.98179171e+27 -2.31346681e+27 -6.74163875e+27\n",
      " -9.06223175e+27 -3.26964908e+27]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [8.01852796e+25 3.10194764e+26 3.45232426e+26 1.27532388e+26\n",
      " 1.54908766e+26 2.64953345e+26 8.77941932e+25 2.55839734e+26\n",
      " 3.43904361e+26 1.24080537e+26]\n",
      "\n",
      "# 46 Gradient out:  [9.02278929e+27 3.49044364e+28 3.88470235e+28 1.43504877e+28\n",
      " 1.74309943e+28 2.98136792e+28 9.87897667e+27 2.87881769e+28\n",
      " 3.86975839e+28 1.39620706e+28]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [-3.42407551e+26 -1.32459511e+27 -1.47421310e+27 -5.44589394e+26\n",
      " -6.61492127e+26 -1.13140500e+27 -3.74899169e+26 -1.09248802e+27\n",
      " -1.46854199e+27 -5.29849280e+26]\n",
      "\n",
      "# 47 Gradient out:  [-3.85291565e+28 -1.49049086e+29 -1.65884739e+29 -6.12795188e+28\n",
      " -7.44339124e+28 -1.27310511e+29 -4.21852518e+28 -1.22931406e+29\n",
      " -1.65246601e+29 -5.96208985e+28]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [1.46215031e+27 5.65629217e+27 6.29519160e+27 2.32550814e+27\n",
      " 2.82470674e+27 4.83133085e+27 1.60089617e+27 4.66514737e+27\n",
      " 6.27097478e+27 2.26256484e+27]\n",
      "\n",
      "# 48 Gradient out:  [1.64527382e+29 6.36470094e+29 7.08361780e+29 2.61676084e+29\n",
      " 3.17848037e+29 5.43641931e+29 1.80139657e+29 5.24942258e+29\n",
      " 7.05636801e+29 2.54593436e+29]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [-6.24368100e+27 -2.41535250e+28 -2.68817562e+28 -9.93039562e+27\n",
      " -1.20620757e+28 -2.06307713e+28 -6.83615420e+27 -1.99211338e+28\n",
      " -2.67783455e+28 -9.66161485e+27]\n",
      "\n",
      "# 49 Gradient out:  [-7.02565587e+29 -2.71785754e+30 -3.02484974e+30 -1.11741042e+30\n",
      " -1.35727615e+30 -2.32146228e+30 -7.69233196e+29 -2.24161086e+30\n",
      " -3.01321353e+30 -1.08716607e+30]\n",
      "\n",
      "     Weights  out:  [-0.42990539  0.25165029  0.41678529 -0.21657296 -0.13764504  0.11829119\n",
      " -0.38316708  0.09592604  0.40844251 -0.22790679] [2.66617954e+28 1.03140494e+29 1.14790600e+29 4.24048212e+28\n",
      " 5.15075316e+28 8.80976149e+28 2.91917772e+28 8.50673178e+28\n",
      " 1.14349015e+29 4.12570724e+28]\n",
      "\n",
      "Lineal error cuadrático medio (ECM): 3.1822303710929007e+60\n",
      "\n",
      "# 0 Gradient out:  [ 0.18203877  0.17804675 -0.03720806 -0.04951496  0.02523977  0.36087189\n",
      "  0.33165772  0.37645488  0.3886216   0.26832786]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [ 0.043325   -0.02510508  0.2855752   0.13042441 -0.03793765 -0.30810262\n",
      " -0.28268047  0.13520881 -0.15488263  0.01757073]\n",
      "\n",
      "# 1 Gradient out:  [-0.19631768 -0.20342114 -0.57109915 -0.5896122  -0.47503081  0.08531369\n",
      "  0.04103069  0.1095211   0.12903471 -0.05483511]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [ 0.07973276  0.01050427  0.27813359  0.12052141 -0.0328897  -0.23592825\n",
      " -0.21634893  0.21049979 -0.07715831  0.0712363 ]\n",
      "\n",
      "# 2 Gradient out:  [0.67507322 0.6827996  1.02132139 1.02700731 0.97624559 0.5225839\n",
      " 0.53225526 0.5178833  0.51394507 0.56624583]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [ 0.04046922 -0.03017996  0.16391376  0.00259897 -0.12789586 -0.21886551\n",
      " -0.20814279  0.23240401 -0.05135137  0.06026928]\n",
      "\n",
      "# 3 Gradient out:  [-1.01558822 -1.03164318 -1.82511019 -1.85828432 -1.64445874 -0.47173318\n",
      " -0.54970797 -0.42884477 -0.39368521 -0.72395722]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [ 0.17548386  0.10637996  0.36817804  0.20800044  0.06735326 -0.11434873\n",
      " -0.10169174  0.33598067  0.05143764  0.17351844]\n",
      "\n",
      "# 4 Gradient out:  [1.75662268 1.78222859 2.98234387 3.01967105 2.7573195  1.0546452\n",
      " 1.13636517 1.01089283 0.97509779 1.33879629]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [-0.02763378 -0.09994867  0.003156   -0.16365643 -0.26153849 -0.20869536\n",
      " -0.21163333  0.25021171 -0.0272994   0.028727  ]\n",
      "\n",
      "# 5 Gradient out:  [-0.5649132  -0.57352983 -0.99489123 -1.01163498 -0.90227683 -0.28431011\n",
      " -0.32330931 -0.26290784 -0.24534149 -0.41167604]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [0.32369075 0.25649704 0.59962478 0.44027778 0.28992541 0.00223368\n",
      " 0.0156397  0.45239028 0.16772016 0.29648626]\n",
      "\n",
      "# 6 Gradient out:  [-1.0320315  -1.04790469 -1.82953982 -1.86167942 -1.65369925 -0.50137174\n",
      " -0.57677675 -0.45987387 -0.42579887 -0.74583072]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [ 0.21070811  0.14179108  0.40064653  0.23795079  0.10947004 -0.05462834\n",
      " -0.04902216  0.39980871  0.11865186  0.21415105]\n",
      "\n",
      "# 7 Gradient out:  [1.40395542 1.42523989 2.41351275 2.44228462 2.23540825 0.8443014\n",
      " 0.90583543 0.81176052 0.78526257 1.06323651]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [ 0.00430181 -0.06778986  0.03473857 -0.1343851  -0.22126981 -0.15490269\n",
      " -0.16437751  0.30783394  0.03349209  0.0649849 ]\n",
      "\n",
      "# 8 Gradient out:  [-0.73918439 -0.75063133 -1.31112596 -1.3335418  -1.18738525 -0.36457567\n",
      " -0.41684983 -0.33587753 -0.31232419 -0.53507929]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [0.2850929  0.21725812 0.51744112 0.35407183 0.22581184 0.01395759\n",
      " 0.01678958 0.47018604 0.1905446  0.2776322 ]\n",
      "\n",
      "# 9 Gradient out:  [-0.816838   -0.82849322 -1.42028075 -1.44820133 -1.27398961 -0.38146293\n",
      " -0.44903682 -0.34370806 -0.31250711 -0.59399941]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [ 0.13725602  0.06713185  0.25521593  0.08736347 -0.01166521 -0.05895755\n",
      " -0.06658039  0.40301054  0.12807976  0.17061635]\n",
      "\n",
      "# 10 Gradient out:  [1.70135068 1.72691118 2.92484553 2.96208253 2.70025815 1.0008368\n",
      " 1.08228254 0.95727252 0.92165991 1.28425728]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [-0.02611158 -0.09856679 -0.02884022 -0.2022768  -0.26646313 -0.13525013\n",
      " -0.15638775  0.33426892  0.06557834  0.05181647]\n",
      "\n",
      "# 11 Gradient out:  [-0.59072403 -0.60001056 -1.05418649 -1.07224147 -0.95431315 -0.28819055\n",
      " -0.33022732 -0.26513196 -0.24621425 -0.42551651]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [0.31415856 0.24681545 0.55612888 0.39013971 0.2735885  0.06491723\n",
      " 0.06006876 0.52572343 0.24991032 0.30866792]\n",
      "\n",
      "# 12 Gradient out:  [-1.05361049 -1.06947084 -1.85418827 -1.8872202  -1.67493121 -0.51369949\n",
      " -0.591749   -0.47055442 -0.43502727 -0.76506436]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [ 0.19601375  0.12681333  0.34529159  0.17569141  0.08272587  0.00727912\n",
      " -0.00597671  0.47269704  0.20066747  0.22356462]\n",
      "\n",
      "# 13 Gradient out:  [1.55056903 1.57484266 2.70870009 2.74313139 2.49902392 0.89512407\n",
      " 0.96973037 0.85544951 0.82311772 1.1570792 ]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [-0.01470835 -0.08708083 -0.02554607 -0.20175263 -0.25226037 -0.09546078\n",
      " -0.12432651  0.37858615  0.11366202  0.07055175]\n",
      "\n",
      "# 14 Gradient out:  [-0.6622744  -0.6727691  -1.18638428 -1.20687213 -1.07317781 -0.31948836\n",
      " -0.36722562 -0.29329429 -0.27180206 -0.47531842]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [0.29540546 0.2278877  0.51619395 0.34687365 0.24754442 0.08356403\n",
      " 0.06961956 0.54967605 0.27828556 0.30196759]\n",
      "\n",
      "# 15 Gradient out:  [-1.01602226 -1.03047228 -1.75402548 -1.78622778 -1.58244168 -0.50187083\n",
      " -0.57906329 -0.45885675 -0.42328476 -0.74709201]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [ 0.16295058  0.09333388  0.27891709  0.10549922  0.03290885  0.01966636\n",
      " -0.00382556  0.4910172   0.22392515  0.2069039 ]\n",
      "\n",
      "# 16 Gradient out:  [1.72746836 1.75365901 2.98435547 3.02329637 2.75112732 1.0013729\n",
      " 1.08707301 0.9553773  0.91772108 1.29780931]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [-0.04025387 -0.11276058 -0.071888   -0.25174633 -0.28357948 -0.0807078\n",
      " -0.11963822  0.39924585  0.1392682   0.0574855 ]\n",
      "\n",
      "# 17 Gradient out:  [-0.60254675 -0.61222328 -1.085551   -1.1043802  -0.98140445 -0.2871277\n",
      " -0.33095977 -0.26309056 -0.24337522 -0.4303327 ]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [0.3052398  0.23797122 0.52498309 0.35291294 0.26664598 0.11956678\n",
      " 0.09777638 0.59032131 0.32281241 0.31704736]\n",
      "\n",
      "# 18 Gradient out:  [-1.05274886 -1.06821075 -1.83662051 -1.86966948 -1.6586076  -0.51748643\n",
      " -0.59609571 -0.47384561 -0.43781004 -0.76910573]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [0.18473045 0.11552657 0.30787289 0.1320369  0.07036509 0.06214124\n",
      " 0.03158443 0.5377032  0.27413737 0.23098082]\n",
      "\n",
      "# 19 Gradient out:  [1.54311763 1.5679408  2.72931771 2.76496674 2.5131055  0.86816937\n",
      " 0.94565064 0.82691755 0.79329966 1.13936835]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [-0.02581932 -0.09811558 -0.05945121 -0.24189699 -0.26135643 -0.04135605\n",
      " -0.08763471  0.44293407  0.18657536  0.07715968]\n",
      "\n",
      "# 20 Gradient out:  [-0.68106186 -0.69201751 -1.22842739 -1.2498704  -1.11001961 -0.3226266\n",
      " -0.37260859 -0.29519732 -0.27269151 -0.48571856]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [0.2828042  0.21547258 0.48641233 0.31109636 0.24126467 0.13227782\n",
      " 0.10149541 0.60831758 0.34523529 0.30503334]\n",
      "\n",
      "# 21 Gradient out:  [-0.9772788  -0.99030442 -1.6493537  -1.68007066 -1.48815598 -0.49602341\n",
      " -0.57059599 -0.45414523 -0.41934499 -0.73014464]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [0.14659183 0.07706908 0.24072686 0.06112228 0.01926075 0.0677525\n",
      " 0.0269737  0.54927812 0.29069699 0.20788963]\n",
      "\n",
      "# 22 Gradient out:  [1.66614012 1.69204318 2.90911184 2.94759164 2.67854778 0.94835375\n",
      " 1.03298591 0.9029565  0.86580625 1.24125621]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [-0.04886393 -0.12099181 -0.08914388 -0.27489186 -0.27837044 -0.03145218\n",
      " -0.0871455   0.45844907  0.20682799  0.0618607 ]\n",
      "\n",
      "# 23 Gradient out:  [-0.64232451 -0.65275346 -1.16317221 -1.18353359 -1.05065016 -0.30165285\n",
      " -0.34907961 -0.27563795 -0.25429889 -0.45650983]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [0.2843641  0.21741683 0.49267849 0.31462647 0.25733911 0.15821857\n",
      " 0.11945168 0.63904037 0.37998924 0.31011195]\n",
      "\n",
      "# 24 Gradient out:  [-1.02802405 -1.04228552 -1.75810012 -1.79032628 -1.5871431  -0.51595\n",
      " -0.59357206 -0.47253287 -0.43652123 -0.76150072]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [0.15589919 0.08686614 0.26004404 0.07791975 0.04720908 0.097888\n",
      " 0.04963576 0.58391278 0.32912947 0.21880998]\n",
      "\n",
      "# 25 Gradient out:  [1.59995132 1.62548023 2.82366706 2.86126308 2.59767395 0.89597085\n",
      " 0.97838227 0.85186592 0.81582451 1.18208319]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [-0.04970562 -0.12159097 -0.09157598 -0.2801455  -0.27021954 -0.005302\n",
      " -0.06907865  0.48940621  0.24182522  0.06650984]\n",
      "\n",
      "# 26 Gradient out:  [-0.67553688 -0.68652906 -1.22480051 -1.24633121 -1.10592557 -0.31572857\n",
      " -0.36591558 -0.28818842 -0.26559341 -0.47948333]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [0.27028465 0.20350508 0.47315743 0.29210712 0.24931525 0.17389217\n",
      " 0.1265978  0.65977939 0.40499012 0.30292647]\n",
      "\n",
      "# 27 Gradient out:  [-0.9779398  -0.99066345 -1.63647809 -1.6670002  -1.47706977 -0.50241736\n",
      " -0.57685033 -0.46048714 -0.42556632 -0.7351595 ]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [0.13517727 0.06619927 0.22819733 0.04284087 0.02813014 0.11074646\n",
      " 0.05341468 0.60214171 0.35187144 0.20702981]\n",
      "\n",
      "# 28 Gradient out:  [1.59918459 1.62475538 2.82558841 2.86341355 2.59857223 0.89228295\n",
      " 0.97531848 0.84780453 0.81144094 1.18015658]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [-0.06041069 -0.13193342 -0.09909829 -0.29055917 -0.26728382  0.01026299\n",
      " -0.06195538  0.51004428  0.26675818  0.05999791]\n",
      "\n",
      "# 29 Gradient out:  [-0.68359382 -0.69474782 -1.24104805 -1.26292095 -1.1203219  -0.31822031\n",
      " -0.36921701 -0.29023243 -0.26726875 -0.48457858]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [0.25942623 0.19301766 0.46601939 0.28212354 0.25243063 0.18871958\n",
      " 0.13310831 0.67960519 0.42904636 0.29602923]\n",
      "\n",
      "# 30 Gradient out:  [-0.95876358 -0.9708987  -1.58977461 -1.61961053 -1.43493193 -0.49759459\n",
      " -0.57072343 -0.45627604 -0.42180303 -0.72518372]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [0.12270747 0.05406809 0.21780978 0.02953935 0.02836625 0.12507551\n",
      " 0.05926491 0.6215587  0.37559262 0.19911351]\n",
      "\n",
      "# 31 Gradient out:  [1.57319682 1.59864254 2.79322238 2.83076553 2.56767707 0.8707662\n",
      " 0.95309308 0.82670214 0.7906962  1.15646967]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [-0.06904525 -0.14011165 -0.10014514 -0.29438275 -0.25862014  0.0255566\n",
      " -0.05487978  0.53030349  0.29123201  0.05407676]\n",
      "\n",
      "# 32 Gradient out:  [-0.69870251 -0.71011195 -1.26908293 -1.2914959  -1.14543802 -0.32454754\n",
      " -0.37682499 -0.29584989 -0.27230066 -0.49501671]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [0.24559411 0.17961686 0.45849934 0.27177035 0.25491528 0.19970984\n",
      " 0.13573884 0.69564392 0.44937125 0.2853707 ]\n",
      "\n",
      "# 33 Gradient out:  [-0.9225136  -0.93367548 -1.50759923 -1.53619655 -1.36069038 -0.48616659\n",
      " -0.55681093 -0.44607541 -0.41254223 -0.70441495]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [0.10585361 0.03759447 0.20468275 0.01347118 0.02582767 0.13480033\n",
      " 0.06037384 0.63647394 0.39491112 0.18636736]\n",
      "\n",
      "# 34 Gradient out:  [1.54388817 1.56918135 2.7558403  2.79296699 2.53237088 0.8476756\n",
      " 0.92892554 0.8042484  0.76879396 1.13017199]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [-0.07864911 -0.14914063 -0.09683709 -0.29376813 -0.2463104   0.03756701\n",
      " -0.05098834  0.54725886  0.31240267  0.04548437]\n",
      "\n",
      "# 35 Gradient out:  [-0.71244456 -0.72407441 -1.29397871 -1.31685781 -1.16781593 -0.33071176\n",
      " -0.38409581 -0.30140022 -0.27734412 -0.50472982]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [0.23012853 0.16469564 0.45433097 0.26482526 0.26016377 0.20710213\n",
      " 0.13479676 0.70810854 0.46616146 0.27151877]\n",
      "\n",
      "# 36 Gradient out:  [-0.88593558 -0.89619659 -1.42822969 -1.45560965 -1.28893198 -0.47330831\n",
      " -0.54143563 -0.43449283 -0.40195599 -0.68235615]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [0.08763961 0.01988076 0.19553522 0.0014537  0.02660059 0.14095978\n",
      " 0.0579776  0.6478285  0.41069264 0.1705728 ]\n",
      "\n",
      "# 37 Gradient out:  [1.51471679 1.53984228 2.71764995 2.75428377 2.49660105 0.82571069\n",
      " 0.90567642 0.78304432 0.74824836 1.10441245]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [-0.0895475  -0.15935855 -0.09011071 -0.28966823 -0.23118581  0.04629812\n",
      " -0.05030952  0.56092993  0.33030144  0.03410157]\n",
      "\n",
      "# 38 Gradient out:  [-0.72416189 -0.73597041 -1.31472623 -1.33798063 -1.18653343 -0.33631419\n",
      " -0.39058878 -0.30650856 -0.28204439 -0.51318995]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [0.21339585 0.1486099  0.45341927 0.26118853 0.2681344  0.21144025\n",
      " 0.13082576 0.71753879 0.47995111 0.25498406]\n",
      "\n",
      "# 39 Gradient out:  [-0.85258207 -0.8620943  -1.35908303 -1.38539338 -1.2263269  -0.46027473\n",
      " -0.52612996 -0.42263678 -0.39103526 -0.66122129]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [ 0.06856348  0.00141582  0.19047403 -0.0064076   0.03082771  0.14417741\n",
      "  0.052708    0.65623708  0.42354223  0.15234607]\n",
      "\n",
      "# 40 Gradient out:  [1.48972855 1.51469065 2.68383562 2.71998067 2.46518256 0.80783664\n",
      " 0.88653066 0.76592172 0.73177439 1.08277836]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [-0.10195294 -0.17100304 -0.08134258 -0.28348628 -0.21443767  0.05212247\n",
      " -0.05251799  0.57170973  0.34533518  0.02010181]\n",
      "\n",
      "# 41 Gradient out:  [-0.73302801 -0.74496498 -1.33006526 -1.35358493 -1.20043161 -0.34083277\n",
      " -0.3957352  -0.31067919 -0.28592775 -0.51972856]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [0.19599277 0.13193509 0.45542455 0.26050986 0.27859884 0.2136898\n",
      " 0.12478814 0.72489407 0.49169006 0.23665748]\n",
      "\n",
      "# 42 Gradient out:  [-0.8267012  -0.83569556 -1.30826666 -1.33379081 -1.18020568 -0.44893258\n",
      " -0.51306909 -0.41220628 -0.38134162 -0.64390933]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [ 0.04938717 -0.01705791  0.1894115  -0.01020713  0.03851252  0.14552324\n",
      "  0.0456411   0.66275823  0.43450451  0.13271177]\n",
      "\n",
      "# 43 Gradient out:  [1.47363586 1.4984758  2.66111568 2.696889   2.44428226 0.7971313\n",
      " 0.8748605  0.75578451 0.72212589 1.0692164 ]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [-0.11595307 -0.18419702 -0.07224184 -0.27696529 -0.19752861  0.05573673\n",
      " -0.05697271  0.58031698  0.35823619  0.0039299 ]\n",
      "\n",
      "# 44 Gradient out:  [-0.73766913 -0.74966808 -1.337801   -1.36144183 -1.20749986 -0.34344931\n",
      " -0.3986356  -0.31313917 -0.28825876 -0.52326753]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [0.1787741  0.11549814 0.4599813  0.26241251 0.29132784 0.21516299\n",
      " 0.11799939 0.73147388 0.50266137 0.21777319]\n",
      "\n",
      "# 45 Gradient out:  [-0.81446144 -0.82327388 -1.28709276 -1.31229518 -1.16084627 -0.44227492\n",
      " -0.50566012 -0.40596788 -0.3754548  -0.63479243]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [ 0.03124028 -0.03443548  0.1924211  -0.00987586  0.04982787  0.14647312\n",
      "  0.03827227  0.66884604  0.44500961  0.11311968]\n",
      "\n",
      "# 46 Gradient out:  [1.47315778 1.49798497 2.65977159 2.69546366 2.44329586 0.79766497\n",
      " 0.87517194 0.75645112 0.72290697 1.06912604]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [-0.13165201 -0.19909025 -0.06499745 -0.27233489 -0.18234139  0.05801814\n",
      " -0.06285976  0.58765247  0.36991865 -0.0138388 ]\n",
      "\n",
      "# 47 Gradient out:  [-0.73552605 -0.74748688 -1.33368042 -1.35722895 -1.20386177 -0.34274129\n",
      " -0.39770347 -0.31255687 -0.28778082 -0.52185649]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [0.16297954 0.10050674 0.46695687 0.26675784 0.30631778 0.21755113\n",
      " 0.11217463 0.73894269 0.51450005 0.1999864 ]\n",
      "\n",
      "# 48 Gradient out:  [-0.82552567 -0.83466254 -1.31350241 -1.33912487 -1.18457528 -0.44498585\n",
      " -0.50921051 -0.40826826 -0.37744495 -0.64066522]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [ 0.01587434 -0.04899063  0.20022078 -0.00468795  0.06554543  0.14900288\n",
      "  0.03263394  0.67643132  0.45694388  0.0956151 ]\n",
      "\n",
      "# 49 Gradient out:  [1.4971183  1.52213428 2.6934179  2.72954727 2.47466396 0.81474745\n",
      " 0.89334362 0.77290418 0.73882287 1.08956366]\n",
      "\n",
      "     Weights  out:  [-0.08377243 -0.07716978  0.26672315  0.28553736  0.17626646 -0.36030338\n",
      " -0.30831857 -0.3929783  -0.42275451 -0.21310803] [-0.1492308  -0.21592314 -0.0624797  -0.27251293 -0.17136963  0.06000571\n",
      " -0.06920817  0.59477767  0.3814549  -0.03251794]\n",
      "\n",
      "Tanh error cuadrático medio (ECM): 0.9302156370794677\n",
      "\n",
      "# 0 Gradient out:  [2.64264255 1.01767952 2.63039036 1.57484124 2.43562391 1.21249523\n",
      " 1.03034126 2.49962204 1.60539511 1.81525275]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [ 0.19196379 -0.38283921  0.27976799  0.10176357 -0.28917404 -0.41069007\n",
      "  0.0021338  -0.33468519 -0.15237033  0.10803059]\n",
      "\n",
      "# 1 Gradient out:  [-13.35495485  -2.56174858 -13.26328643  -6.4782464  -11.7316349\n",
      "  -4.09390736  -2.65792718 -12.22435127  -6.65875205  -7.86674811]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [ 0.7204923  -0.17930331  0.80584607  0.41673181  0.19795074 -0.16819103\n",
      "  0.20820205  0.16523922  0.16870869  0.47108114]\n",
      "\n",
      "# 2 Gradient out:  [61.66176719 13.74035733 61.26603165 30.95507809 54.6671848  20.34010636\n",
      " 14.15486425 56.80171222 31.77495103 37.28930197]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [-1.95049867 -0.69165302 -1.84681122 -0.87891747 -2.14837624 -0.9869725\n",
      " -0.32338338 -2.27963104 -1.16304172 -1.10226849]\n",
      "\n",
      "# 3 Gradient out:  [-289.08274905  -62.85668032 -287.19968932 -144.32279527 -255.81125876\n",
      "  -94.25172883  -64.82965792 -265.94754667 -148.17195062 -174.03100922]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [10.38185477  2.05641844 10.40639511  5.31209815  8.78506072  3.08104877\n",
      "  2.50758947  9.08071141  5.19194849  6.35559191]\n",
      "\n",
      "# 4 Gradient out:  [1351.64108502  295.15808245 1342.86424272  675.39749595 1196.53315827\n",
      "  441.51700455  304.35356573 1243.80784822  693.39573321  814.34083439]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [-47.43469504 -10.51491762 -47.03354275 -23.5524609  -42.37719103\n",
      " -15.76929699 -10.45834211 -44.10879793 -24.44244164 -28.45060994]\n",
      "\n",
      "# 5 Gradient out:  [-6322.76435847 -1379.66731126 -6281.68010736 -3158.96011533\n",
      " -5596.75369794 -2064.72760722 -1422.71157985 -5818.00809084\n",
      " -3243.14695394 -3808.83637802]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [222.89352196  48.51669887 221.53930579 111.52703829 196.92944062\n",
      "  72.53410392  50.41237103 204.65277172 114.23670501 134.41755694]\n",
      "\n",
      "# 6 Gradient out:  [29574.3790802   6454.17428878 29382.23726615 14776.1818436\n",
      " 26178.93135167  9658.10235087  6655.48237368 27213.73189386\n",
      " 15169.97110722 17816.05173703]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [-1041.65934973  -227.41676338 -1034.79671568  -520.26498478\n",
      "  -922.42129896  -340.41141753  -234.12994494  -958.94884645\n",
      "  -534.39268578  -627.34971866]\n",
      "\n",
      "# 7 Gradient out:  [-138334.6524842   -30188.79044933 -137435.87851899  -69115.61109914\n",
      " -122451.97271478  -45175.61079285  -31130.44134024 -127292.36925326\n",
      "  -70957.55391044  -83334.51948111]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [4873.21646631 1063.41809438 4841.65073755 2434.97138394 4313.36497137\n",
      " 1591.20905265 1096.9665298  4483.79753232 2499.60153566 2935.86062875]\n",
      "\n",
      "# 8 Gradient out:  [647060.80940399 141208.77924601 642856.81846241 323288.6593872\n",
      " 572769.92843389 211309.29735161 145613.32566155 595410.80390374\n",
      " 331904.36859909 389797.8044712 ]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [-22793.71403053  -4974.33999549 -22645.52496625 -11388.15083588\n",
      " -20177.02957159  -7443.91310592  -5129.12173825 -20974.67631833\n",
      " -11691.90924643 -13731.04326748]\n",
      "\n",
      "# 9 Gradient out:  [-3026630.75333243  -660504.37414857 -3006966.53361824 -1512184.51679563\n",
      " -2679134.31809846  -988400.33996669  -681106.69473007 -2785037.23952975\n",
      " -1552484.53019977 -1823281.26819995]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [106618.44785027  23267.41585371 105925.83872623  53269.58104156\n",
      "  94376.95611519  34817.9463644   23993.54339406  98107.48446242\n",
      "  54688.96447339  64228.51762676]\n",
      "\n",
      "# 10 Gradient out:  [14157081.77817524  3089513.25295494 14065102.31093704  7073251.33565062\n",
      " 12531665.71192012  4623248.03930095  3185880.69066712 13027027.11131604\n",
      "  7261754.88580029  8528408.25743045]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [-498707.70281622 -108833.458976   -495467.46799742 -249167.32231757\n",
      " -441449.9075045  -162862.12162894 -112227.79555196 -458899.96344353\n",
      " -255807.94156656 -300427.73601323]\n",
      "\n",
      "# 11 Gradient out:  [-66219828.15063655 -14451214.88618817 -65789593.65783923\n",
      " -33085172.14524231 -58616935.13847187 -21625268.18358388\n",
      " -14901974.13649679 -60933990.90664719 -33966898.52162495\n",
      " -39891676.49083486]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [2332708.65281883  509069.19161499 2317552.99418999 1165482.94481255\n",
      " 2064883.23487952  761787.48623125  524948.34258147 2146505.45881968\n",
      " 1196543.0355935  1405253.91547286]\n",
      "\n",
      "# 12 Gradient out:  [3.09743610e+08 6.75956375e+07 3.07731186e+08 1.54756075e+08\n",
      " 2.74181037e+08 1.01152311e+08 6.97040663e+07 2.85019078e+08\n",
      " 1.58880355e+08 1.86593536e+08]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [-10911256.97730848  -2381173.78562265 -10840365.73737786\n",
      "  -5451551.48423591  -9658503.79281485  -3563266.15048552\n",
      "  -2455446.48471789 -10040292.72250976  -5596836.66873149\n",
      "  -6573081.38269411]\n",
      "\n",
      "# 13 Gradient out:  [-1.44882744e+09 -3.16178966e+08 -1.43941432e+09 -7.23872391e+08\n",
      " -1.28248331e+09 -4.73140491e+08 -3.26041154e+08 -1.33317831e+09\n",
      " -7.43163734e+08 -8.72792294e+08]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [51037465.11666116 11137953.71351575 50705871.52062812 25499663.45741169\n",
      " 45177703.60072205 16667196.02845495 11485366.78334183 46963522.87409977\n",
      " 26179234.27228107 30745625.90194191]\n",
      "\n",
      "# 14 Gradient out:  [6.77689834e+09 1.47892885e+09 6.73286839e+09 3.38591709e+09\n",
      " 5.99882274e+09 2.21311725e+09 1.52505929e+09 6.23594886e+09\n",
      " 3.47615246e+09 4.08249076e+09]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [-2.38728023e+08 -5.20978395e+07 -2.37176992e+08 -1.19274815e+08\n",
      " -2.11318958e+08 -7.79609022e+07 -5.37228640e+07 -2.19672138e+08\n",
      " -1.22453512e+08 -1.43812833e+08]\n",
      "\n",
      "# 15 Gradient out:  [-3.16989793e+10 -6.91769786e+09 -3.14930290e+10 -1.58376458e+10\n",
      " -2.80595264e+10 -1.03518681e+10 -7.13347323e+09 -2.91686851e+10\n",
      " -1.62597222e+10 -1.90958730e+10]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [1.11665164e+09 2.43687931e+08 1.10939669e+09 5.57908604e+08\n",
      " 9.88445589e+08 3.64662548e+08 2.51288994e+08 1.02751763e+09\n",
      " 5.72776979e+08 6.72685319e+08]\n",
      "\n",
      "# 16 Gradient out:  [1.48272150e+11 3.23575698e+10 1.47308816e+11 7.40806756e+10\n",
      " 1.31248589e+11 4.84209201e+10 3.33668603e+10 1.36436685e+11\n",
      " 7.60549403e+10 8.93210510e+10]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [-5.22314421e+09 -1.13985164e+09 -5.18920911e+09 -2.60962057e+09\n",
      " -4.62345969e+09 -1.70571108e+09 -1.17540565e+09 -4.80621939e+09\n",
      " -2.67916747e+09 -3.14648928e+09]\n",
      "\n",
      "# 17 Gradient out:  [-6.93543798e+11 -1.51352711e+11 -6.89037799e+11 -3.46512768e+11\n",
      " -6.13915998e+11 -2.26489120e+11 -1.56073673e+11 -6.38183346e+11\n",
      " -3.55747402e+11 -4.17799708e+11]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [2.44312858e+10 5.33166232e+09 2.42725542e+10 1.22065146e+10\n",
      " 2.16262581e+10 7.97847295e+09 5.49796641e+09 2.24811177e+10\n",
      " 1.25318206e+10 1.47177209e+10]\n",
      "\n",
      "# 18 Gradient out:  [3.24405493e+12 7.07953138e+11 3.22297810e+12 1.62081538e+12\n",
      " 2.87159546e+12 1.05940411e+12 7.30035463e+11 2.98510612e+12\n",
      " 1.66401043e+12 1.95426043e+12]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [-1.14277474e+11 -2.49388799e+10 -1.13535006e+11 -5.70960390e+10\n",
      " -1.01156941e+11 -3.73193511e+10 -2.57167681e+10 -1.05155552e+11\n",
      " -5.86176598e+10 -6.88422206e+10]\n",
      "\n",
      "# 19 Gradient out:  [-1.51740848e+13 -3.31145470e+12 -1.50754978e+13 -7.58137286e+12\n",
      " -1.34319036e+13 -4.95536854e+12 -3.41474490e+12 -1.39628503e+13\n",
      " -7.78341795e+12 -9.14106393e+12]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [5.34533513e+11 1.16651748e+11 5.31060614e+11 2.67067037e+11\n",
      " 4.73162150e+11 1.74561470e+11 1.20290324e+11 4.91865671e+11\n",
      " 2.74184426e+11 3.22009866e+11]\n",
      "\n",
      "# 20 Gradient out:  [7.09768652e+13 1.54893476e+13 7.05157239e+13 3.54619133e+13\n",
      " 6.28278029e+13 2.31787636e+13 1.59724880e+13 6.53113091e+13\n",
      " 3.64069803e+13 4.27573769e+13]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [-2.50028345e+12 -5.45639192e+11 -2.48403895e+12 -1.24920754e+12\n",
      " -2.21321856e+12 -8.16512238e+11 -5.62658655e+11 -2.30070439e+12\n",
      " -1.28249916e+12 -1.50620292e+12]\n",
      "\n",
      "# 21 Gradient out:  [-3.31994678e+14 -7.24515086e+13 -3.29837687e+14 -1.65873295e+14\n",
      " -2.93877394e+14 -1.08418794e+14 -7.47114008e+13 -3.05494008e+14\n",
      " -1.70293851e+14 -1.99997866e+14]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [1.16950896e+13 2.55223033e+12 1.16191058e+13 5.84317512e+12\n",
      " 1.03523420e+13 3.81924049e+12 2.63183896e+12 1.07615574e+13\n",
      " 5.99889689e+12 7.04527245e+12]\n",
      "\n",
      "# 22 Gradient out:  [1.55290693e+15 3.38892330e+14 1.54281760e+15 7.75873248e+14\n",
      " 1.37461313e+15 5.07129508e+14 3.49462988e+14 1.42894990e+15\n",
      " 7.96550424e+14 9.35491117e+14]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [-5.47038459e+13 -1.19380714e+13 -5.43484315e+13 -2.73314838e+13\n",
      " -4.84231367e+13 -1.78645184e+13 -1.23104412e+13 -5.03372441e+13\n",
      " -2.80598732e+13 -3.29543007e+13]\n",
      "\n",
      "# 23 Gradient out:  [-7.26373072e+15 -1.58517074e+15 -7.21653780e+15 -3.62915139e+15\n",
      " -6.42976047e+15 -2.37210107e+15 -1.63461505e+15 -6.68392103e+15\n",
      " -3.72586899e+15 -4.37576485e+15]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [2.55877540e+14 5.58403947e+13 2.54215088e+14 1.27843166e+14\n",
      " 2.26499489e+14 8.35613832e+13 5.75821565e+13 2.35452736e+14\n",
      " 1.31250212e+14 1.54143923e+14]\n",
      "\n",
      "# 24 Gradient out:  [3.39761404e+16 7.41464486e+15 3.37553953e+16 1.69753756e+16\n",
      " 3.00752400e+16 1.10955158e+16 7.64592090e+15 3.12640774e+16\n",
      " 1.74277727e+16 2.04676642e+16]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [-1.19686860e+15 -2.61193753e+14 -1.18909247e+15 -5.97987112e+14\n",
      " -1.05945260e+15 -3.90858830e+14 -2.69340854e+14 -1.10133147e+15\n",
      " -6.13923587e+14 -7.21009047e+14]\n",
      "\n",
      "# 25 Gradient out:  [-1.58923584e+17 -3.46820422e+16 -1.57891047e+17 -7.94024128e+16\n",
      " -1.40677101e+17 -5.18993362e+16 -3.57638371e+16 -1.46237894e+17\n",
      " -8.15185028e+16 -9.57376118e+16]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [5.59835948e+15 1.22173522e+15 5.56198658e+15 2.79708801e+15\n",
      " 4.95559539e+15 1.82824433e+15 1.25984333e+15 5.15148401e+15\n",
      " 2.87163096e+15 3.37252379e+15]\n",
      "\n",
      "# 26 Gradient out:  [7.43365938e+17 1.62225443e+17 7.38536242e+17 3.71405223e+17\n",
      " 6.58017912e+17 2.42759431e+17 1.67285545e+17 6.84028555e+17\n",
      " 3.81303246e+17 4.47813206e+17]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [-2.61863573e+16 -5.71467321e+15 -2.60162228e+16 -1.30833946e+16\n",
      " -2.31798247e+16 -8.55162291e+15 -5.89292409e+15 -2.40960948e+16\n",
      " -1.34320696e+16 -1.57749986e+16]\n",
      "\n",
      "# 27 Gradient out:  [-3.47709827e+18 -7.58810403e+17 -3.45450734e+18 -1.73724997e+18\n",
      " -3.07788240e+18 -1.13550857e+18 -7.82479057e+17 -3.19954733e+18\n",
      " -1.78354803e+18 -2.09464874e+18]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [1.22486830e+17 2.67304154e+16 1.21691026e+17 6.11976500e+16\n",
      " 1.08423758e+17 4.00002632e+16 2.75641849e+16 1.12709616e+17\n",
      " 6.28285795e+16 7.37876427e+16]\n",
      "\n",
      "# 28 Gradient out:  [1.62641463e+19 3.54933984e+18 1.61584771e+19 8.12599632e+18\n",
      " 1.43968119e+19 5.31134760e+18 3.66005010e+18 1.49659003e+19\n",
      " 8.34255573e+18 9.79773099e+18]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [-5.72932823e+17 -1.25031665e+17 -5.69210442e+17 -2.86252345e+17\n",
      " -5.07152723e+17 -1.87101451e+17 -1.28931626e+17 -5.27199850e+17\n",
      " -2.93881026e+17 -3.45142105e+17]\n",
      "\n",
      "# 29 Gradient out:  [-7.60756338e+19 -1.66020566e+19 -7.55813655e+19 -3.80093925e+19\n",
      " -6.73411669e+19 -2.48438576e+19 -1.71199045e+19 -7.00030808e+19\n",
      " -3.90223503e+19 -4.58289407e+19]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [2.67989643e+18 5.84836302e+17 2.66248497e+18 1.33894692e+18\n",
      " 2.37220965e+18 8.75168069e+17 6.03078393e+17 2.46598020e+18\n",
      " 1.37463012e+18 1.61440409e+18]\n",
      "\n",
      "# 30 Gradient out:  [3.55844196e+20 7.76562112e+19 3.53532253e+20 1.77789143e+20\n",
      " 3.14988679e+20 1.16207281e+20 8.00784474e+19 3.27439796e+20\n",
      " 1.82527258e+20 2.14365122e+20]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [-1.25352303e+19 -2.73557502e+18 -1.24537881e+19 -6.26293158e+18\n",
      " -1.10960237e+19 -4.09360346e+18 -2.82090250e+18 -1.15346360e+19\n",
      " -6.42983995e+18 -7.55138404e+18]\n",
      "\n",
      "# 31 Gradient out:  [-1.66446318e+21 -3.63237355e+20 -1.65364906e+21 -8.31609693e+20\n",
      " -1.47336128e+21 -5.43560196e+20 -3.74567378e+20 -1.53160145e+21\n",
      " -8.53772256e+20 -1.00269404e+21]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [5.86336088e+19 1.27956672e+19 5.82526625e+19 2.92948970e+19\n",
      " 5.19017120e+19 1.91478527e+19 1.31947870e+19 5.39533232e+19\n",
      " 3.00756117e+19 3.53216404e+19]\n",
      "\n",
      "# 32 Gradient out:  [7.78553571e+21 1.69904473e+21 7.73495258e+21 3.88985892e+21\n",
      " 6.89165549e+21 2.54250581e+21 1.75204097e+21 7.16407420e+21\n",
      " 3.99352443e+21 4.69010689e+21]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [-2.74259028e+20 -5.98518039e+19 -2.72477150e+20 -1.37027042e+20\n",
      " -2.42770544e+20 -8.95641864e+19 -6.17186887e+19 -2.52366966e+20\n",
      " -1.40678839e+20 -1.65217167e+20]\n",
      "\n",
      "# 33 Gradient out:  [-3.64168861e+22 -7.94729107e+21 -3.61802833e+22 -1.81948365e+22\n",
      " -3.22357565e+22 -1.18925849e+22 -8.19518130e+21 -3.35099965e+22\n",
      " -1.86797325e+22 -2.19380008e+22]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [1.28284811e+21 2.79957142e+20 1.27451337e+21 6.40944742e+20\n",
      " 1.13556055e+21 4.18936975e+20 2.88689506e+20 1.18044787e+21\n",
      " 6.58026046e+20 7.72804210e+20]\n",
      "\n",
      "# 34 Gradient out:  [1.70340185e+23 3.71734977e+22 1.69233474e+23 8.51064479e+22\n",
      " 1.50782928e+23 5.56276314e+22 3.83330056e+22 1.56743193e+23\n",
      " 8.73745515e+22 1.02615119e+23]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [-6.00052911e+21 -1.30950107e+21 -5.96154329e+21 -2.99802256e+21\n",
      " -5.31159074e+21 -1.95958001e+21 -1.35034675e+21 -5.52155143e+21\n",
      " -3.07792045e+21 -3.61479595e+21]\n",
      "\n",
      "# 35 Gradient out:  [-7.96767154e+23 -1.73879240e+23 -7.91590507e+23 -3.98085878e+23\n",
      " -7.05287977e+23 -2.60198552e+23 -1.79302845e+23 -7.33167148e+23\n",
      " -4.08694946e+23 -4.79982786e+23]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [2.80675079e+22 6.12519848e+21 2.78851515e+22 1.40232670e+22\n",
      " 2.48449949e+22 9.16594627e+21 6.31625437e+21 2.58270872e+22\n",
      " 1.43969899e+22 1.69082279e+22]\n",
      "\n",
      "# 36 Gradient out:  [3.72688275e+24 8.13321104e+23 3.70266895e+24 1.86204889e+24\n",
      " 3.29898840e+24 1.21708016e+24 8.38690044e+23 3.42939337e+24\n",
      " 1.91167286e+24 2.24512212e+24]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [-1.31285923e+23 -2.86506496e+22 -1.30432950e+23 -6.55939087e+22\n",
      " -1.16212601e+23 -4.28737641e+22 -2.95443146e+22 -1.20806343e+23\n",
      " -6.73419993e+22 -7.90883292e+22]\n",
      "\n",
      "# 37 Gradient out:  [-1.74325146e+25 -3.80431394e+24 -1.73192544e+25 -8.70974392e+24\n",
      " -1.54310364e+25 -5.69289914e+24 -3.92297730e+24 -1.60410064e+25\n",
      " -8.94186032e+24 -1.05015711e+25]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [6.14090627e+23 1.34013571e+23 6.10100841e+23 3.06815869e+23\n",
      " 5.43585079e+23 2.00542268e+23 1.38193694e+23 5.65072332e+23\n",
      " 3.14992572e+23 3.69936095e+23]\n",
      "\n",
      "# 38 Gradient out:  [8.15406829e+25 1.77946994e+25 8.10109078e+25 4.07398751e+25\n",
      " 7.21787576e+25 2.66285671e+25 1.83497479e+25 7.50318956e+25\n",
      " 4.18256009e+25 4.91211565e+25]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [-2.87241229e+24 -6.26849217e+23 -2.85375004e+24 -1.43513292e+24\n",
      " -2.54262220e+24 -9.38037561e+23 -6.46401765e+23 -2.64312894e+24\n",
      " -1.47337949e+24 -1.73037812e+24]\n",
      "\n",
      "# 39 Gradient out:  [-3.81406993e+26 -8.32348043e+25 -3.78928967e+26 -1.90560990e+26\n",
      " -3.37616536e+26 -1.24555269e+26 -8.58310468e+25 -3.50962105e+26\n",
      " -1.95639478e+26 -2.29764480e+26]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [1.34357243e+25 2.93209066e+24 1.33484315e+25 6.71284211e+24\n",
      " 1.18931293e+25 4.38767585e+24 3.02354781e+24 1.23632502e+25\n",
      " 6.89174068e+24 8.09385319e+24]\n",
      "\n",
      "# 40 Gradient out:  [1.78403331e+27 3.89331255e+26 1.77244233e+27 8.91350080e+26\n",
      " 1.57920321e+27 5.82607956e+26 4.01475194e+26 1.64162718e+27\n",
      " 9.15104736e+26 1.07472462e+27]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [-6.28456743e+25 -1.37148702e+25 -6.24373619e+25 -3.13993559e+25\n",
      " -5.56301779e+25 -2.05233780e+25 -1.41426615e+25 -5.78291708e+25\n",
      " -3.22361550e+25 -3.78590428e+25]\n",
      "\n",
      "# 41 Gradient out:  [-8.34482562e+27 -1.82109909e+27 -8.29060875e+27 -4.16929491e+27\n",
      " -7.38673169e+27 -2.72515192e+27 -1.87790243e+27 -7.67872015e+27\n",
      " -4.28040744e+27 -5.02703033e+27]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [2.93960988e+26 6.41513809e+25 2.92051104e+26 1.46870660e+26\n",
      " 2.60210463e+26 9.59982133e+25 6.61523772e+25 2.70496265e+26\n",
      " 1.50784792e+26 1.77085881e+26]\n",
      "\n",
      "# 42 Gradient out:  [3.90329678e+28 8.51820102e+27 3.87793681e+28 1.95018999e+28\n",
      " 3.45514781e+28 1.27469131e+28 8.78389895e+27 3.59172558e+28\n",
      " 2.00216294e+28 2.35139620e+28]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [-1.37500414e+27 -3.00068437e+26 -1.36607065e+27 -6.86988321e+26\n",
      " -1.21713587e+27 -4.49032171e+26 -3.09428109e+26 -1.26524777e+27\n",
      " -7.05296696e+26 -8.28320184e+26]\n",
      "\n",
      "# 43 Gradient out:  [-1.82576922e+29 -3.98439322e+28 -1.81390708e+29 -9.12202440e+28\n",
      " -1.61614729e+29 -5.96237563e+28 -4.10867357e+28 -1.68003162e+29\n",
      " -9.36512816e+28 -1.09986687e+29]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [6.43158942e+27 1.40357177e+27 6.38980297e+27 3.21339165e+27\n",
      " 5.69315975e+27 2.10035045e+27 1.44735168e+27 5.91820339e+27\n",
      " 3.29902918e+27 3.87447222e+27]\n",
      "\n",
      "# 44 Gradient out:  [8.54004556e+29 1.86370212e+29 8.48456033e+29 4.26683193e+29\n",
      " 7.55953785e+29 2.78890448e+29 1.92183432e+29 7.85835713e+29\n",
      " 4.38054385e+29 5.14463333e+29]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [-3.00837949e+28 -6.56521466e+27 -2.98883386e+28 -1.50306571e+28\n",
      " -2.66297861e+28 -9.82440080e+27 -6.76999545e+27 -2.76824289e+28\n",
      " -1.54312271e+28 -1.81228651e+28]\n",
      "\n",
      "# 45 Gradient out:  [-3.99461101e+30 -8.71747692e+29 -3.96865777e+30 -1.99581299e+30\n",
      " -3.53597799e+30 -1.30451161e+30 -8.98939062e+29 -3.67575087e+30\n",
      " -2.04900180e+30 -2.40640507e+30]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [1.40717116e+29 3.07088277e+28 1.39802868e+29 7.03059815e+28\n",
      " 1.24560971e+29 4.59536888e+28 3.16666910e+28 1.29484714e+29\n",
      " 7.21796499e+28 8.47698014e+28]\n",
      "\n",
      "# 46 Gradient out:  [1.86848150e+31 4.07760463e+30 1.85634185e+31 9.33542623e+30\n",
      " 1.65395565e+31 6.10186022e+30 4.20479241e+30 1.71933449e+31\n",
      " 9.58421718e+30 1.12559730e+31]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [-6.58205086e+29 -1.43640711e+29 -6.53928685e+29 -3.28856616e+29\n",
      " -5.82634627e+29 -2.14948632e+29 -1.48121121e+29 -6.05665461e+29\n",
      " -3.37620709e+29 -3.96511213e+29]\n",
      "\n",
      "# 47 Gradient out:  [-8.73983250e+31 -1.90730181e+31 -8.68304924e+31 -4.36665076e+31\n",
      " -7.73638666e+31 -2.85414848e+31 -1.96679396e+31 -8.04219656e+31\n",
      " -4.48302286e+31 -5.26498755e+31]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [3.07875791e+30 6.71880215e+29 3.05875502e+30 1.53822863e+30\n",
      " 2.72527667e+30 1.00542341e+30 6.92837361e+29 2.83300353e+30\n",
      " 1.57922273e+30 1.85468338e+30]\n",
      "\n",
      "# 48 Gradient out:  [4.08806146e+32 8.92141471e+31 4.06150106e+32 2.04250329e+32\n",
      " 3.61869912e+32 1.33502952e+32 9.19968960e+31 3.76174187e+32\n",
      " 2.09693641e+32 2.46270082e+32]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [-1.44009071e+31 -3.14272340e+30 -1.43073435e+31 -7.19507288e+30\n",
      " -1.27474966e+31 -4.70287354e+30 -3.24075057e+30 -1.32513896e+31\n",
      " -7.38682300e+30 -8.67529172e+30]\n",
      "\n",
      "# 49 Gradient out:  [-1.91219300e+33 -4.17299664e+32 -1.89976936e+33 -9.55382040e+32\n",
      " -1.69264850e+33 -6.24460793e+32 -4.30315987e+32 -1.75955683e+33\n",
      " -9.80843161e+32 -1.15192967e+33]\n",
      "\n",
      "     Weights  out:  [ 0.45723359 -0.44697486  0.44099438 -0.08505427  0.25439851 -0.25748512\n",
      " -0.43056118  0.30258063 -0.07413263 -0.00361814] [6.73603221e+31 1.47001060e+31 6.69226778e+31 3.36549930e+31\n",
      " 5.96264857e+31 2.19977169e+31 1.51586286e+31 6.19834478e+31\n",
      " 3.45519052e+31 4.05787248e+31]\n",
      "\n",
      "Lineal error cuadrático medio (ECM): 1.4710383105704202e+66\n",
      "\n",
      "# 0 Gradient out:  [1.15697581 1.64186619 0.99120579 2.39443742 2.41993558 2.95956054\n",
      " 1.18830418 1.01751667 1.3998162  3.44934555]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.02655551  0.06647106  0.4786512  -0.46781529 -0.29269829  0.03290304\n",
      " -0.1420102  -0.46896587 -0.2645043   0.00931376]\n",
      "\n",
      "# 1 Gradient out:  [-0.31246322 -0.49614181 -0.23923411 -0.72856104 -0.73632177 -0.91347981\n",
      " -0.32589896 -0.25087095 -0.41057446 -1.11683651]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.25795067  0.39484429  0.67689236  0.0110722   0.19128883  0.62481515\n",
      "  0.09565063 -0.26546254  0.01545894  0.69918287]\n",
      "\n",
      "# 2 Gradient out:  [-0.53880112 -0.8924003  -0.39584279 -1.32778391 -1.34228905 -1.67716451\n",
      " -0.56499882 -0.41852121 -0.72902441 -2.07213663]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.19545803  0.29561593  0.62904553 -0.13464001  0.04402447  0.44211919\n",
      "  0.03047084 -0.31563673 -0.06665596  0.47581557]\n",
      "\n",
      "# 3 Gradient out:  [0.88778077 1.2208984  0.7819257  1.77851825 1.79749907 2.18923484\n",
      " 0.90809456 0.79871878 1.04989108 2.51199768]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.08769781  0.11713587  0.54987698 -0.40019679 -0.22443334  0.10668629\n",
      " -0.08252892 -0.39934097 -0.21246084  0.06138825]\n",
      "\n",
      "# 4 Gradient out:  [-0.41718866 -0.67727833 -0.31311157 -1.00401108 -1.01491452 -1.26455967\n",
      " -0.43627805 -0.32964348 -0.55637726 -1.55319264]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.26525396  0.36131555  0.70626212 -0.04449314  0.13506648  0.54453325\n",
      "  0.09908999 -0.23959721 -0.00248262  0.56378778]\n",
      "\n",
      "# 5 Gradient out:  [-0.31921818 -0.58431394 -0.20019486 -0.85671658 -0.86564667 -1.0885821\n",
      " -0.34053968 -0.21921531 -0.46824675 -1.40465035]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.18181623  0.22585989  0.6436398  -0.24529536 -0.06791643  0.29162132\n",
      "  0.01183438 -0.30552591 -0.11375807  0.25314925]\n",
      "\n",
      "# 6 Gradient out:  [0.97448647 1.38537138 0.83934874 2.04707562 2.06954573 2.53932589\n",
      " 1.00028007 0.86073301 1.17739776 2.94539537]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.11797259  0.1089971   0.60360083 -0.41663867 -0.24104576  0.0739049\n",
      " -0.05627356 -0.34936897 -0.20740742 -0.02778082]\n",
      "\n",
      "# 7 Gradient out:  [-0.35021252 -0.57381189 -0.26101605 -0.85589118 -0.86530753 -1.08055157\n",
      " -0.36658493 -0.27518053 -0.4697278  -1.32822519]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.31286989  0.38607138  0.77147058 -0.00722355  0.17286338  0.58177008\n",
      "  0.14378246 -0.17722237  0.02807213  0.56129826]\n",
      "\n",
      "# 8 Gradient out:  [-0.54318626 -0.90261561 -0.39131122 -1.32042124 -1.33427635 -1.66161625\n",
      " -0.57065724 -0.41559099 -0.73962163 -2.07390066]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 2.42827382e-01  2.71308997e-01  7.19267368e-01 -1.78401786e-01\n",
      " -1.98121258e-04  3.65659763e-01  7.04654716e-02 -2.32258475e-01\n",
      " -6.58734287e-02  2.95653221e-01]\n",
      "\n",
      "# 9 Gradient out:  [1.08969474 1.56754595 0.92619658 2.30933912 2.33447256 2.86632807\n",
      " 1.12057163 0.95216941 1.329004   3.34919625]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.13419013  0.09078588  0.64100512 -0.44248604 -0.26705339  0.03333651\n",
      " -0.04366598 -0.31537667 -0.21379775 -0.11912691]\n",
      "\n",
      "# 10 Gradient out:  [-0.30435043 -0.50444192 -0.22475919 -0.75760425 -0.76605707 -0.95906905\n",
      " -0.31897382 -0.23739048 -0.41120305 -1.18033563]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.35212908  0.40429506  0.82624444  0.01938179  0.19984112  0.60660213\n",
      "  0.18044835 -0.12494279  0.05200305  0.55071234]\n",
      "\n",
      "# 11 Gradient out:  [-0.5583073  -0.92136231 -0.4077385  -1.35682178 -1.37130066 -1.70892893\n",
      " -0.58564307 -0.43179199 -0.75513754 -2.1205683 ]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.29125899  0.30340668  0.7812926  -0.13213906  0.04662971  0.41478832\n",
      "  0.11665359 -0.17242089 -0.03023756  0.31464521]\n",
      "\n",
      "# 12 Gradient out:  [0.87146613 1.27960459 0.73915503 1.94067578 1.96312987 2.43191794\n",
      " 0.8968979  0.75996794 1.07243144 2.8322785 ]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 1.79597530e-01  1.19134219e-01  6.99744903e-01 -4.03503418e-01\n",
      " -2.27630425e-01  7.30025309e-02 -4.75029349e-04 -2.58779284e-01\n",
      " -1.81265072e-01 -1.09468446e-01]\n",
      "\n",
      "# 13 Gradient out:  [-0.37620988 -0.62780382 -0.27553979 -0.94374737 -0.95429027 -1.19573352\n",
      " -0.39467548 -0.29153062 -0.51085613 -1.47493587]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.35389076  0.37505514  0.84757591 -0.01536826  0.16499555  0.55938612\n",
      "  0.17890455 -0.1067857   0.03322122  0.45698725]\n",
      "\n",
      "# 14 Gradient out:  [-0.49215826 -0.79632638 -0.35389917 -1.11486412 -1.12533183 -1.38378933\n",
      " -0.51662715 -0.37629901 -0.66280648 -1.74862672]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.27864878  0.24949437  0.79246795 -0.20411774 -0.0258625   0.32023941\n",
      "  0.09996945 -0.16509182 -0.06895001  0.16200008]\n",
      "\n",
      "# 15 Gradient out:  [1.02307345 1.49510284 0.86207772 2.22901417 2.25388242 2.77990431\n",
      " 1.0535207  0.88762463 1.25929483 3.25608809]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.18021713  0.0902291   0.72168812 -0.42709056 -0.25092887  0.04348155\n",
      " -0.00335598 -0.24035162 -0.20151131 -0.18772526]\n",
      "\n",
      "# 16 Gradient out:  [-0.32017525 -0.53906839 -0.23300664 -0.81537841 -0.8246023  -1.03542685\n",
      " -0.33618927 -0.24683898 -0.43713699 -1.27766118]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.38483182  0.38924966  0.89410366  0.01871227  0.19984761  0.59946241\n",
      "  0.20734816 -0.06282669  0.05034766  0.46349235]\n",
      "\n",
      "# 17 Gradient out:  [-0.56653424 -0.92788539 -0.41227576 -1.34621138 -1.36008114 -1.68810385\n",
      " -0.59428036 -0.43706942 -0.76436547 -2.10497548]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.32079677  0.28143599  0.84750233 -0.14436341  0.03492715  0.39237704\n",
      "  0.14011031 -0.11219449 -0.03707974  0.20796012]\n",
      "\n",
      "# 18 Gradient out:  [0.94704517 1.40502244 0.79277684 2.12335373 2.14770619 2.66142155\n",
      " 0.97635442 0.81718175 1.17541852 3.12029611]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.20748992  0.09585891  0.76504718 -0.41360569 -0.23708907  0.05475627\n",
      "  0.02125424 -0.19960837 -0.18995283 -0.21303498]\n",
      "\n",
      "# 19 Gradient out:  [-0.34201559 -0.57917967 -0.24733958 -0.87761251 -0.88757246 -1.1155024\n",
      " -0.35939683 -0.26236894 -0.46885387 -1.37834073]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.39689895  0.3768634   0.92360255  0.01106506  0.19245216  0.58704058\n",
      "  0.21652512 -0.03617202  0.04513087  0.41102424]\n",
      "\n",
      "# 20 Gradient out:  [-0.55394859 -0.893507   -0.40340662 -1.26685773 -1.27918257 -1.57694711\n",
      " -0.58071655 -0.4277754  -0.74235013 -1.97780809]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.32849584  0.26102746  0.87413464 -0.16445744  0.01493767  0.3639401\n",
      "  0.14464576 -0.08864581 -0.0486399   0.1353561 ]\n",
      "\n",
      "# 21 Gradient out:  [0.97942716 1.4525491  0.8174022  2.18503738 2.20985069 2.73547223\n",
      " 1.01003956 0.84311861 1.21656051 3.21387105]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.21770612  0.08232606  0.79345331 -0.41782899 -0.24089884  0.04855068\n",
      "  0.02850244 -0.17420089 -0.19710993 -0.26020552]\n",
      "\n",
      "# 22 Gradient out:  [-0.33577739 -0.57213036 -0.24145083 -0.86953473 -0.87946027 -1.1066123\n",
      " -0.35309737 -0.25642243 -0.46217843 -1.36851505]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.41359155  0.37283588  0.95693375  0.01917849  0.20107129  0.59564512\n",
      "  0.23051036 -0.00557717  0.04620218  0.38256869]\n",
      "\n",
      "# 23 Gradient out:  [-0.55782347 -0.89828234 -0.40647053 -1.27204615 -1.28438345 -1.582595\n",
      " -0.58469833 -0.43100168 -0.74682729 -1.98514945]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.34643607  0.25840981  0.90864358 -0.15472846  0.02517924  0.37432266\n",
      "  0.15989088 -0.05686165 -0.04623351  0.10886568]\n",
      "\n",
      "# 24 Gradient out:  [0.94031454 1.40866199 0.7805346  2.13542731 2.1600498  2.68127509\n",
      " 0.97055013 0.80586502 1.17482546 3.15387333]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.23487138  0.07875334  0.82734948 -0.40913769 -0.23169745  0.05780366\n",
      "  0.04295122 -0.14306199 -0.19559897 -0.28816421]\n",
      "\n",
      "# 25 Gradient out:  [-0.34813908 -0.59538124 -0.24927466 -0.90574898 -0.91610526 -1.15333453\n",
      " -0.36628169 -0.26497204 -0.48045432 -1.42762074]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [0.42293428 0.36048574 0.9834564  0.01794778 0.20031251 0.59405868\n",
      " 0.23706124 0.01811101 0.03936612 0.34261045]\n",
      "\n",
      "# 26 Gradient out:  [-0.54146703 -0.85882427 -0.39569296 -1.19102855 -1.2019478  -1.47131407\n",
      " -0.56709566 -0.41946606 -0.71971177 -1.85420135]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.35330647  0.2414095   0.93360146 -0.16320202  0.01709146  0.36339177\n",
      "  0.1638049  -0.0348834  -0.05672474  0.05708631]\n",
      "\n",
      "# 27 Gradient out:  [0.91797111 1.3844217  0.75905599 2.10867141 2.13320932 2.6525661\n",
      " 0.94806285 0.78423524 1.15146566 3.12291125]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.24501306  0.06964464  0.85446287 -0.40140773 -0.2232981   0.06912896\n",
      "  0.05038577 -0.11877661 -0.20066709 -0.31375397]\n",
      "\n",
      "# 28 Gradient out:  [-0.35579573 -0.60993735 -0.25403319 -0.92844623 -0.93907283 -1.18264823\n",
      " -0.37446228 -0.27019499 -0.49186775 -1.46481773]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [0.42860728 0.34652898 1.00627407 0.02032655 0.20334376 0.59964218\n",
      " 0.23999834 0.03807044 0.02962604 0.31082828]\n",
      "\n",
      "# 29 Gradient out:  [-0.52662718 -0.82539413 -0.38583379 -1.12586864 -1.13570824 -1.38277209\n",
      " -0.55119227 -0.40890218 -0.69599622 -1.74903098]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.35744814  0.22454151  0.95546743 -0.16536269  0.0155292   0.36311254\n",
      "  0.16510589 -0.01596856 -0.06874751  0.01786474]\n",
      "\n",
      "# 30 Gradient out:  [0.88647249 1.34781248 0.73025281 2.06703222 2.09140524 2.60663379\n",
      " 0.91612366 0.75496378 1.11702411 3.0702889 ]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.2521227   0.05946269  0.87830067 -0.39053642 -0.21161245  0.08655812\n",
      "  0.05486743 -0.09774899 -0.20794676 -0.33194146]\n",
      "\n",
      "# 31 Gradient out:  [-0.36498331 -0.62625402 -0.2602121  -0.95315929 -0.96406467 -1.21418709\n",
      " -0.38419251 -0.27685698 -0.50494066 -1.50452346]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [0.4294172  0.32902518 1.02435123 0.02287002 0.2066686  0.60788488\n",
      " 0.23809217 0.05324376 0.01545807 0.28211632]\n",
      "\n",
      "# 32 Gradient out:  [-0.50582299 -0.78227997 -0.37160497 -1.04642637 -1.0550329  -1.27627583\n",
      " -0.52904359 -0.39370533 -0.66430627 -1.6216194 ]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.35642054  0.20377438  0.97230881 -0.16776183  0.01385567  0.36504746\n",
      "  0.16125366 -0.00212764 -0.08553007 -0.01878837]\n",
      "\n",
      "# 33 Gradient out:  [0.84932826 1.30262047 0.69739645 2.0142981  2.03842519 2.54734345\n",
      " 0.87827654 0.72136623 1.07520586 3.00038176]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.25525594  0.04731839  0.89798782 -0.37704711 -0.19715091  0.10979229\n",
      "  0.05544494 -0.0808687  -0.21839132 -0.34311225]\n",
      "\n",
      "# 34 Gradient out:  [-0.37540838 -0.64381895 -0.26761916 -0.97914689 -0.99033199 -1.24701665\n",
      " -0.39516125 -0.2847492  -0.51925665 -1.54553842]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.42512159  0.30784248  1.03746711  0.02581251  0.21053413  0.61926098\n",
      "  0.23110025  0.06340454 -0.00335015  0.2569641 ]\n",
      "\n",
      "# 35 Gradient out:  [-0.47806383 -0.7290105  -0.35198855 -0.95339874 -0.96065898 -1.15334022\n",
      " -0.4996767  -0.37285357 -0.62385944 -1.47376888]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.35003991  0.17907869  0.98394328 -0.17001687  0.01246773  0.36985765\n",
      "  0.152068    0.0064547  -0.10720148 -0.05214358]\n",
      "\n",
      "# 36 Gradient out:  [0.80405669 1.24465578 0.65863569 1.94391087 1.96763138 2.46630117\n",
      " 0.83192159 0.68149219 1.02264204 2.90298869]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.25442715  0.03327659  0.91354557 -0.36069661 -0.17966407  0.13918961\n",
      "  0.05213266 -0.06811601 -0.23197336 -0.34689736]\n",
      "\n",
      "# 37 Gradient out:  [-0.38920708 -0.66614513 -0.27780942 -1.01154179 -1.02306131 -1.2875869\n",
      " -0.40960947 -0.29551992 -0.53770245 -1.59588995]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.41523848  0.28220775  1.04527271  0.02808556  0.21386221  0.63244984\n",
      "  0.21851698  0.06818243 -0.02744496  0.23370038]\n",
      "\n",
      "# 38 Gradient out:  [-0.43373063 -0.64940704 -0.31966672 -0.82096378 -0.82643904 -0.98078839\n",
      " -0.45303579 -0.33866869 -0.56169505 -1.26556458]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.33739707  0.14897872  0.98971082 -0.1742228   0.00924995  0.37493246\n",
      "  0.13659509  0.00907844 -0.13498545 -0.08547761]\n",
      "\n",
      "# 39 Gradient out:  [0.72854395 1.14252707 0.59583576 1.8131449  1.83592038 2.31169541\n",
      " 0.7542415  0.61655315 0.9321917  2.71559707]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.25065094  0.01909731  0.92577748 -0.33841555 -0.15603786  0.17877478\n",
      "  0.04598793 -0.05865529 -0.24732446 -0.33859053]\n",
      "\n",
      "# 40 Gradient out:  [-0.41755436 -0.71126709 -0.29899018 -1.0762116  -1.08837969 -1.36819295\n",
      " -0.43924325 -0.31785523 -0.57522335 -1.69584948]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.39635973  0.24760273  1.04494463  0.02421343  0.21114622  0.64111387\n",
      "  0.19683623  0.06465534 -0.06088612  0.20452889]\n",
      "\n",
      "# 41 Gradient out:  [-0.310945   -0.43984307 -0.22782876 -0.48576287 -0.48700207 -0.54937486\n",
      " -0.3244082  -0.24196833 -0.39446519 -0.7441813 ]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.31284886  0.10534931  0.9851466  -0.19102889 -0.00652972  0.36747528\n",
      "  0.10898758  0.00108429 -0.17593079 -0.13464101]\n",
      "\n",
      "# 42 Gradient out:  [0.44957873 0.74151565 0.36940044 1.26354909 1.28137336 1.64287155\n",
      " 0.46600193 0.3814787  0.5870254  1.90570457]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.25065986  0.01738069  0.93958084 -0.28818147 -0.10393014  0.2576003\n",
      "  0.04410594 -0.04730937 -0.25482383 -0.28347727]\n",
      "\n",
      "# 43 Gradient out:  [-0.54154542 -0.90307078 -0.39137155 -1.33726151 -1.35170043 -1.68814928\n",
      " -0.5687708  -0.41540067 -0.73752113 -2.09837817]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.34057561  0.16568382  1.01346093 -0.03547165  0.15234454  0.58617461\n",
      "  0.13730633  0.02898637 -0.13741875  0.09766365]\n",
      "\n",
      "# 44 Gradient out:  [0.63039472 0.99533801 0.51893819 1.60746258 1.62829243 2.0587589\n",
      " 0.65233623 0.53617036 0.80731451 2.40570655]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.23226652 -0.01493033  0.93518662 -0.30292395 -0.11799555  0.24854476\n",
      "  0.02355217 -0.05409377 -0.28492297 -0.32201199]\n",
      "\n",
      "# 45 Gradient out:  [-0.466067   -0.78699921 -0.33577581 -1.18322643 -1.19643122 -1.50082204\n",
      " -0.48985745 -0.35653078 -0.63867464 -1.86004713]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.35834547  0.18413727  1.03897426  0.01856857  0.20766294  0.66029654\n",
      "  0.15401941  0.0531403  -0.12346007  0.15912932]\n",
      "\n",
      "# 46 Gradient out:  [-0.00320429  0.04528128  0.01227738  0.24336726  0.25032903  0.3690499\n",
      " -0.00422573  0.00896817  0.00584277  0.36516883]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.26513207  0.02673743  0.9718191  -0.21807672 -0.03162331  0.36013213\n",
      "  0.05604792 -0.01816585 -0.251195   -0.2128801 ]\n",
      "\n",
      "# 47 Gradient out:  [-0.27545121 -0.41381533 -0.19269351 -0.48203301 -0.48403999 -0.56120408\n",
      " -0.28916559 -0.20655235 -0.36257038 -0.75994688]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.26449121  0.03579368  0.97427458 -0.16940327  0.0184425   0.43394211\n",
      "  0.05520278 -0.01637222 -0.25002645 -0.13984634]\n",
      "\n",
      "# 48 Gradient out:  [0.50721921 0.79627446 0.42592028 1.30996767 1.32750373 1.6835836\n",
      " 0.52365815 0.43831828 0.64384032 1.94677164]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.20940097 -0.04696938  0.93573587 -0.26580987 -0.0783655   0.32170129\n",
      " -0.00263034 -0.05768269 -0.32254052 -0.29183571]\n",
      "\n",
      "# 49 Gradient out:  [-0.53339998 -0.89122161 -0.38643106 -1.32655723 -1.34104878 -1.67702668\n",
      " -0.560145   -0.40988701 -0.72665186 -2.08034282]\n",
      "\n",
      "     Weights  out:  [-0.32791273 -0.13797154 -0.44641777  0.04328334  0.04923701  0.19736441\n",
      " -0.31033336 -0.42413597 -0.21594816  0.47322934] [ 0.31084481  0.11228551  1.02091993 -0.00381634  0.18713525  0.65841801\n",
      "  0.10210129  0.02998097 -0.19377246  0.09751861]\n",
      "\n",
      "Tanh error cuadrático medio (ECM): 0.5527171274831062\n",
      "\n",
      "# 0 Gradient out:  [-0.44105604 -0.0593219  -0.40153654 -0.60681467 -0.36061322 -0.31673302\n",
      " -0.42044623 -0.33463979 -0.30760624 -0.39150296]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-0.43811567  0.23822534  0.4226243   0.31653961 -0.01918496  0.34575488\n",
      "  0.02228247 -0.15736619  0.25059002 -0.33845507]\n",
      "\n",
      "# 1 Gradient out:  [2.04628513 0.66756048 1.88012773 2.37429418 1.61532477 1.29494714\n",
      " 1.96831584 1.41609379 1.24133882 1.82513454]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-0.52632688  0.22636096  0.34231699  0.19517667 -0.0913076   0.28240827\n",
      " -0.06180678 -0.22429415  0.18906877 -0.41675567]\n",
      "\n",
      "# 2 Gradient out:  [ -8.91537895  -2.5573669   -8.17779138 -10.75827928  -7.09944637\n",
      "  -5.8195835   -8.56016986  -6.30933244  -5.59756946  -7.94708726]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-0.11706985  0.35987305  0.71834254  0.67003551  0.23175735  0.5413977\n",
      "  0.33185639  0.05892461  0.43733653 -0.05172876]\n",
      "\n",
      "# 3 Gradient out:  [39.4190221  11.6432472  36.169239   47.1531782  31.321362   25.54061623\n",
      " 37.86304358 27.74626067 24.54653934 35.13940551]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-1.90014564 -0.15160033 -0.91721574 -1.48162035 -1.18813192 -0.622519\n",
      " -1.38017758 -1.20294187 -0.68217736 -1.64114621]\n",
      "\n",
      "# 4 Gradient out:  [-173.68311757  -50.98344266 -159.35507922 -208.16915188 -138.07810502\n",
      " -112.73326638 -166.81385084 -122.40984924 -108.366385   -154.82801317]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [5.98365878 2.17704911 6.31663206 7.94901529 5.07614048 4.48560425\n",
      " 6.19243113 4.34631026 4.22713051 5.38673489]\n",
      "\n",
      "# 5 Gradient out:  [765.88674651 225.1227127  702.71203711 917.55386133 608.80124666\n",
      " 496.90942568 735.60809729 539.62308668 477.63917043 682.73804081]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-28.75296474  -8.01963942 -25.55438378 -33.68481509 -22.53948052\n",
      " -18.06104903 -27.17033904 -20.13565959 -17.44614649 -25.57886774]\n",
      "\n",
      "# 6 Gradient out:  [-3376.66901976  -992.24112597 -3098.13647958 -4045.74611767\n",
      " -2684.18803266 -2191.00775602 -3243.16363089 -2379.2810313\n",
      " -2106.06261433 -3010.08605427]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [124.42438456  37.00490312 114.98802364 149.82595718  99.22076881\n",
      "  81.32083611 119.95128042  87.78895775  78.08168759 110.96874042]\n",
      "\n",
      "# 7 Gradient out:  [14887.84199444  4375.09827626 13659.78715743 17837.42586503\n",
      " 11834.58397742  9660.00105873 14299.22351307 10490.14930191\n",
      "  9285.4604671  13271.55786033]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-550.90941939 -161.44332207 -504.63927228 -659.32326635 -437.61683772\n",
      " -356.8807151  -528.68144576 -388.06724851 -343.13083527 -491.04847043]\n",
      "\n",
      "# 8 Gradient out:  [-65640.29549245 -19289.48562371 -60225.81552217 -78645.36679282\n",
      " -52178.61252521 -42591.04343133 -63045.07410799 -46251.10959063\n",
      " -40939.71416122 -58514.13035779]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [2426.6589795   713.57633318 2227.31815921 2908.16190665 1929.29995776\n",
      " 1575.11949665 2331.16325686 1709.96261187 1513.96125815 2163.26310164]\n",
      "\n",
      "# 9 Gradient out:  [289407.87232429  85047.53983421 265535.44728838 346746.80097831\n",
      " 230055.25742001 187783.55304833 277965.55858398 203920.82128332\n",
      " 180502.8315326  257988.61937287]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-10701.40011899  -3144.32079156  -9817.84494523 -12820.91145191\n",
      "  -8506.42254728  -6943.08918962 -10277.85156474  -7540.25930626\n",
      "  -6673.9815741   -9539.56296992]\n",
      "\n",
      "# 10 Gradient out:  [-1275997.76656084  -374973.90534738 -1170744.37148752 -1528805.18792855\n",
      " -1014312.50035336  -827936.92315275 -1225548.65698394  -899086.00486462\n",
      "  -795836.27669553 -1137470.46078084]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [47180.17434587 13865.18717528 43289.24451245 56528.44874375\n",
      " 37504.62893672 30613.62142005 45315.26015205 33243.90495041\n",
      " 29426.58473243 42058.16090465]\n",
      "\n",
      "# 11 Gradient out:  [5625868.06499479 1653258.39587298 5161806.34761208 6740494.39134142\n",
      " 4472098.87573351 3650369.70119987 5403438.19036952 3964065.7116218\n",
      " 3508838.08791576 5015101.82039007]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-208019.3789663   -61129.59389419 -190859.62978505 -249232.58884196\n",
      " -165357.87113395 -134973.7632105  -199794.47124473 -146573.29602252\n",
      " -129740.67060668 -185435.93125152]\n",
      "\n",
      "# 12 Gradient out:  [-24804424.73503589  -7289207.93865918 -22758378.89828983\n",
      " -29718807.13315003 -19717462.13365708 -16094462.3745714\n",
      " -23823732.49921124 -17477546.49838229 -15470450.20150372\n",
      " -22111559.37048387]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [ 917154.23403266  269522.0852804   841501.63973736 1098866.28942632\n",
      "  729061.90401275  595100.17702948  880893.16682917  646239.84630185\n",
      "  572026.94697647  817584.4328265 ]\n",
      "\n",
      "# 13 Gradient out:  [1.09362588e+08 3.21380825e+07 1.00341582e+08 1.31030076e+08\n",
      " 8.69341944e+07 7.09604060e+07 1.05038721e+08 7.70584172e+07\n",
      " 6.82091393e+07 9.74897576e+07]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-4043730.71297452 -1188319.50245144 -3710174.1399206  -4844895.13720368\n",
      " -3214430.52271867 -2623792.2978848  -3883853.33301308 -2849269.45337461\n",
      " -2522063.09332427 -3604727.44127028]\n",
      "\n",
      "# 14 Gradient out:  [-4.82179117e+08 -1.41696649e+08 -4.42405545e+08 -5.77710964e+08\n",
      " -3.83292439e+08 -3.12864084e+08 -4.63115207e+08 -3.39750186e+08\n",
      " -3.00733763e+08 -4.29831866e+08]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [17828786.85906801  5239297.00262854 16358142.20564054 21361119.97004602\n",
      " 14172408.36144109 11568288.89812026 17123890.78226528 12562413.98584262\n",
      " 11119764.7729086  15893224.07182889]\n",
      "\n",
      "# 15 Gradient out:  [2.12592537e+09 6.24739834e+08 1.95056389e+09 2.54712483e+09\n",
      " 1.68993450e+09 1.37941622e+09 2.04187269e+09 1.49795691e+09\n",
      " 1.32593369e+09 1.89512660e+09]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-78607036.45012727 -23100032.77945348 -72122966.69517942\n",
      " -94181072.91519791 -62486079.50923505 -51004527.93500356\n",
      " -75499150.57177585 -55387623.1799132  -49026987.81606279\n",
      " -70073149.06705481]\n",
      "\n",
      "# 16 Gradient out:  [-9.37319461e+09 -2.75447488e+09 -8.60002668e+09 -1.12302609e+10\n",
      " -7.45091296e+09 -6.08183940e+09 -9.00260673e+09 -6.60448473e+09\n",
      " -5.84603519e+09 -8.35560394e+09]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [3.46578038e+08 1.01847934e+08 3.17989811e+08 4.15243892e+08\n",
      " 2.75500820e+08 2.24878716e+08 3.32875387e+08 2.44203759e+08\n",
      " 2.16159751e+08 3.08952171e+08]\n",
      "\n",
      "# 17 Gradient out:  [4.13263693e+10 1.21444663e+10 3.79174757e+10 4.95141657e+10\n",
      " 3.28510389e+10 2.68148002e+10 3.96924492e+10 2.91191410e+10\n",
      " 2.57751407e+10 3.68398170e+10]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-1.52806088e+09 -4.49047043e+08 -1.40201552e+09 -1.83080830e+09\n",
      " -1.21468177e+09 -9.91489163e+08 -1.46764596e+09 -1.07669319e+09\n",
      " -9.53047288e+08 -1.36216862e+09]\n",
      "\n",
      "# 18 Gradient out:  [-1.82207761e+11 -5.35448929e+10 -1.67177965e+11 -2.18307715e+11\n",
      " -1.44840070e+11 -1.18226324e+11 -1.75003815e+11 -1.28386150e+11\n",
      " -1.13642470e+11 -1.62426574e+11]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [6.73721298e+09 1.97984622e+09 6.18147961e+09 8.07202485e+09\n",
      " 5.35552601e+09 4.37147089e+09 6.47084388e+09 4.74713501e+09\n",
      " 4.20198085e+09 6.00579479e+09]\n",
      "\n",
      "# 19 Gradient out:  [8.03353130e+11 2.36079172e+11 7.37086835e+11 9.62517652e+11\n",
      " 6.38599164e+11 5.21259284e+11 7.71590967e+11 5.66053912e+11\n",
      " 5.01049094e+11 7.16137972e+11]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-2.97043392e+10 -8.72913235e+09 -2.72541135e+10 -3.55895182e+10\n",
      " -2.36124881e+10 -1.92737938e+10 -2.85299191e+10 -2.09300951e+10\n",
      " -1.85265131e+10 -2.64795200e+10]\n",
      "\n",
      "# 20 Gradient out:  [-3.54198003e+12 -1.04087192e+12 -3.24981226e+12 -4.24373564e+12\n",
      " -2.81558060e+12 -2.29822964e+12 -3.40194081e+12 -2.49572894e+12\n",
      " -2.20912301e+12 -3.15744883e+12]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [1.30966287e+11 3.84867020e+10 1.20163253e+11 1.56914012e+11\n",
      " 1.04107345e+11 8.49780630e+10 1.25788274e+11 9.22806872e+10\n",
      " 8.16833058e+10 1.16748074e+11]\n",
      "\n",
      "# 21 Gradient out:  [1.56165727e+13 4.58919920e+12 1.43284064e+13 1.87106097e+13\n",
      " 1.24138811e+13 1.01328833e+13 1.49991404e+13 1.10036567e+13\n",
      " 9.74001260e+12 1.39211765e+13]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-5.77429720e+11 -1.69687681e+11 -5.29799199e+11 -6.91833115e+11\n",
      " -4.59008775e+11 -3.74667865e+11 -5.54599888e+11 -4.06865100e+11\n",
      " -3.60141297e+11 -5.14741691e+11]\n",
      "\n",
      "# 22 Gradient out:  [-6.88533929e+13 -2.02337569e+13 -6.31738740e+13 -8.24949871e+13\n",
      " -5.47327414e+13 -4.46758330e+13 -6.61311371e+13 -4.85150688e+13\n",
      " -4.29436680e+13 -6.13783992e+13]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [2.54588482e+12 7.48152160e+11 2.33588208e+12 3.05028883e+12\n",
      " 2.02376745e+12 1.65190879e+12 2.44522820e+12 1.79386624e+12\n",
      " 1.58786122e+12 2.26949360e+12]\n",
      "\n",
      "# 23 Gradient out:  [3.03574273e+14 8.92105356e+13 2.78533302e+14 3.63719996e+14\n",
      " 2.41316390e+14 1.96975530e+14 2.91571861e+14 2.13902702e+14\n",
      " 1.89338423e+14 2.70617063e+14]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-1.12247938e+13 -3.29859922e+12 -1.02988927e+13 -1.34487086e+13\n",
      " -8.92278083e+12 -7.28325781e+12 -1.07809992e+13 -7.90914752e+12\n",
      " -7.00087239e+12 -1.00061862e+13]\n",
      "\n",
      "# 24 Gradient out:  [-1.33845749e+15 -3.93328817e+14 -1.22805197e+15 -1.60363969e+15\n",
      " -1.06396279e+15 -8.68464151e+14 -1.28553891e+15 -9.43095969e+14\n",
      " -8.34792184e+14 -1.19314931e+15]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [4.94900609e+13 1.45435079e+13 4.54077678e+13 5.92952906e+13\n",
      " 3.93404972e+13 3.21118482e+13 4.75333730e+13 3.48713928e+13\n",
      " 3.08668122e+13 4.41172263e+13]\n",
      "\n",
      "# 25 Gradient out:  [5.90125255e+15 1.73418483e+15 5.41447516e+15 7.07043957e+15\n",
      " 4.69100674e+15 3.82905421e+15 5.66793480e+15 4.15810553e+15\n",
      " 3.68059467e+15 5.26058949e+15]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-2.18201437e+14 -6.41222554e+13 -2.00202627e+14 -2.61432647e+14\n",
      " -1.73452060e+14 -1.41580982e+14 -2.09574410e+14 -1.53747801e+14\n",
      " -1.36091625e+14 -1.94512636e+14]\n",
      "\n",
      "# 26 Gradient out:  [-2.60185937e+16 -7.64601248e+15 -2.38723946e+16 -3.11735336e+16\n",
      " -2.06826259e+16 -1.68822813e+16 -2.49898969e+16 -1.83330670e+16\n",
      " -1.62277240e+16 -2.31939134e+16]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [9.62049073e+14 2.82714711e+14 8.82692405e+14 1.15265527e+15\n",
      " 7.64749288e+14 6.24229860e+14 9.24012551e+14 6.77873305e+14\n",
      " 6.00027309e+14 8.57605263e+14]\n",
      "\n",
      "# 27 Gradient out:  [1.14715853e+17 3.37112317e+16 1.05253271e+17 1.37443958e+17\n",
      " 9.11895965e+16 7.44338961e+16 1.10180334e+17 8.08304031e+16\n",
      " 7.15479558e+16 1.02261851e+17]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-4.24166967e+15 -1.24648778e+15 -3.89178651e+15 -5.08205145e+15\n",
      " -3.37177588e+15 -2.75222641e+15 -4.07396683e+15 -2.98874010e+15\n",
      " -2.64551748e+15 -3.78117742e+15]\n",
      "\n",
      "# 28 Gradient out:  [-5.05781636e+17 -1.48632656e+17 -4.64061160e+17 -6.05989739e+17\n",
      " -4.02054487e+17 -3.28178685e+17 -4.85784554e+17 -3.56380853e+17\n",
      " -3.15454588e+17 -4.50872004e+17]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [1.87015009e+16 5.49575857e+15 1.71588678e+16 2.24067401e+16\n",
      " 1.48661434e+16 1.21345528e+16 1.79620999e+16 1.31773405e+16\n",
      " 1.16640737e+16 1.66711928e+16]\n",
      "\n",
      "# 29 Gradient out:  [2.22998877e+18 6.55320658e+17 2.04604339e+18 2.67180580e+18\n",
      " 1.77265627e+18 1.44693822e+18 2.14182173e+18 1.57128144e+18\n",
      " 1.39083774e+18 1.98789247e+18]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-8.24548263e+16 -2.42307727e+16 -7.56533643e+16 -9.87912077e+16\n",
      " -6.55447539e+16 -5.35011842e+16 -7.91948109e+16 -5.80988301e+16\n",
      " -5.14268440e+16 -7.35032079e+16]\n",
      "\n",
      "# 30 Gradient out:  [-9.83200961e+18 -2.88930558e+18 -9.02099534e+18 -1.17799788e+19\n",
      " -7.81563286e+18 -6.37954357e+18 -9.44328157e+18 -6.92777223e+18\n",
      " -6.13219682e+18 -8.76460819e+18]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [3.63542927e+17 1.06833359e+17 3.33555314e+17 4.35569953e+17\n",
      " 2.88986500e+17 2.35886460e+17 3.49169535e+17 2.56157459e+17\n",
      " 2.26740704e+17 3.24075285e+17]\n",
      "\n",
      "# 31 Gradient out:  [4.33492824e+19 1.27389342e+19 3.97735245e+19 5.19378689e+19\n",
      " 3.44590872e+19 2.81273765e+19 4.16353824e+19 3.05445140e+19\n",
      " 2.70368259e+19 3.86431148e+19]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-1.60285899e+18 -4.71027758e+17 -1.47064375e+18 -1.92042580e+18\n",
      " -1.27414007e+18 -1.04002225e+18 -1.53948678e+18 -1.12939699e+18\n",
      " -9.99698660e+17 -1.42884635e+18]\n",
      "\n",
      "# 32 Gradient out:  [-1.91126775e+20 -5.61658989e+19 -1.75361276e+20 -2.28993811e+20\n",
      " -1.51929947e+20 -1.24013466e+20 -1.83570198e+20 -1.34670613e+20\n",
      " -1.19205234e+20 -1.70377305e+20]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [7.06699749e+18 2.07675909e+18 6.48406114e+18 8.46714799e+18\n",
      " 5.61767736e+18 4.58545304e+18 6.78758970e+18 4.97950581e+18\n",
      " 4.40766652e+18 6.29977660e+18]\n",
      "\n",
      "# 33 Gradient out:  [8.42677019e+20 2.47635175e+20 7.73167009e+20 1.00963260e+21\n",
      " 6.69858397e+20 5.46774766e+20 8.09360108e+20 5.93762077e+20\n",
      " 5.25575294e+20 7.51192705e+20]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-3.11583575e+19 -9.15642070e+18 -2.85881940e+19 -3.73316142e+19\n",
      " -2.47683121e+19 -2.02172401e+19 -2.99264499e+19 -2.19546168e+19\n",
      " -1.94333802e+19 -2.77756843e+19]\n",
      "\n",
      "# 34 Gradient out:  [-3.71535887e+21 -1.09182228e+21 -3.40888957e+21 -4.45146519e+21\n",
      " -2.95340241e+21 -2.41072728e+21 -3.56846477e+21 -2.61789410e+21\n",
      " -2.31725891e+21 -3.31200498e+21]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [1.37377046e+20 4.03706142e+19 1.26045208e+20 1.64594905e+20\n",
      " 1.09203367e+20 8.91377131e+19 1.31945572e+20 9.67977985e+19\n",
      " 8.56816785e+19 1.22462857e+20]\n",
      "\n",
      "# 35 Gradient out:  [1.63809991e+22 4.81383910e+21 1.50297775e+22 1.96264883e+22\n",
      " 1.30215368e+22 1.06288848e+22 1.57333438e+22 1.15422823e+22\n",
      " 1.02167832e+22 1.46026138e+22]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-6.05694727e+20 -1.77993841e+20 -5.55732707e+20 -7.25698133e+20\n",
      " -4.81477114e+20 -3.93007742e+20 -5.81747382e+20 -4.26781022e+20\n",
      " -3.77770103e+20 -5.39938138e+20]\n",
      "\n",
      "# 36 Gradient out:  [-7.22237453e+22 -2.12241931e+22 -6.62662157e+22 -8.65330914e+22\n",
      " -5.74118923e+22 -4.68627013e+22 -6.93682360e+22 -5.08898665e+22\n",
      " -4.50457474e+22 -6.43828530e+22]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [2.67050510e+21 7.84773978e+20 2.45022279e+21 3.19959953e+21\n",
      " 2.12283025e+21 1.73276922e+21 2.56492137e+21 1.88167544e+21\n",
      " 1.66558654e+21 2.38058462e+21]\n",
      "\n",
      "# 37 Gradient out:  [3.18434141e+23 9.35773639e+22 2.92167422e+23 3.81523978e+23\n",
      " 2.53128753e+23 2.06617422e+23 3.05844214e+23 2.24373173e+23\n",
      " 1.98606481e+23 2.83863685e+23]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-1.17742440e+22 -3.46006464e+21 -1.08030204e+22 -1.41070187e+22\n",
      " -9.35954821e+21 -7.63977104e+21 -1.13087258e+22 -8.29629786e+21\n",
      " -7.34356294e+21 -1.04959860e+22]\n",
      "\n",
      "# 38 Gradient out:  [-1.40397457e+24 -4.12582141e+23 -1.28816474e+24 -1.68213736e+24\n",
      " -1.11604344e+24 -9.10975205e+23 -1.34846565e+24 -9.89260228e+23\n",
      " -8.75655005e+23 -1.25155360e+24]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [5.19125842e+22 1.52554081e+22 4.76304641e+22 6.21977768e+22\n",
      " 4.12662024e+22 3.36837133e+22 4.98601170e+22 3.65783368e+22\n",
      " 3.23777332e+22 4.62767510e+22]\n",
      "\n",
      "# 39 Gradient out:  [6.19011705e+24 1.81907265e+24 5.67951206e+24 7.41653541e+24\n",
      " 4.92063008e+24 4.01648524e+24 5.94537847e+24 4.36164352e+24\n",
      " 3.86075865e+24 5.51809374e+24]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-2.28882331e+23 -6.72610201e+22 -2.10002484e+23 -2.74229695e+23\n",
      " -1.81942485e+23 -1.48511328e+23 -2.19833013e+23 -1.61273709e+23\n",
      " -1.42753268e+23 -2.04033970e+23]\n",
      "\n",
      "# 40 Gradient out:  [-2.72921959e+25 -8.02028244e+24 -2.50409410e+25 -3.26994685e+25\n",
      " -2.16950340e+25 -1.77086638e+25 -2.62131447e+25 -1.92304650e+25\n",
      " -1.70220661e+25 -2.43292484e+25]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [1.00914108e+24 2.96553510e+23 9.25899928e+23 1.20907739e+24\n",
      " 8.02183531e+23 6.54785720e+23 9.69242682e+23 7.11054995e+23\n",
      " 6.29398462e+23 8.99584777e+23]\n",
      "\n",
      "# 41 Gradient out:  [1.20331159e+26 3.53613862e+25 1.10405387e+26 1.44171797e+26\n",
      " 9.56532993e+25 7.80774125e+25 1.15573627e+26 8.47870265e+25\n",
      " 7.50502063e+25 1.07267537e+26]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-4.44929810e+24 -1.30750298e+24 -4.08228827e+24 -5.33081631e+24\n",
      " -3.53682328e+24 -2.88694705e+24 -4.27338626e+24 -3.13503801e+24\n",
      " -2.77501475e+24 -3.96626490e+24]\n",
      "\n",
      "# 42 Gradient out:  [-5.30539492e+26 -1.55908179e+26 -4.86776811e+26 -6.35652750e+26\n",
      " -4.21734930e+26 -3.44242931e+26 -5.09563559e+26 -3.73825586e+26\n",
      " -3.30895994e+26 -4.72942050e+26]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [1.96169336e+25 5.76477426e+24 1.79987891e+25 2.35035431e+25\n",
      " 1.55938366e+25 1.27285354e+25 1.88413392e+25 1.38223673e+25\n",
      " 1.22350265e+25 1.74872426e+25]\n",
      "\n",
      "# 43 Gradient out:  [2.33914603e+27 6.87398403e+26 2.14619659e+27 2.80258988e+27\n",
      " 1.85942725e+27 1.51776540e+27 2.24666325e+27 1.64819519e+27\n",
      " 1.45891882e+27 2.08519919e+27]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-8.64909648e+25 -2.54168616e+25 -7.93565732e+25 -1.03627007e+26\n",
      " -6.87531495e+25 -5.61200507e+25 -8.30713726e+25 -6.09427500e+25\n",
      " -5.39441722e+25 -7.71011674e+25]\n",
      "\n",
      "# 44 Gradient out:  [-1.03132835e+28 -3.03073621e+27 -9.46257029e+27 -1.23566051e+28\n",
      " -8.19820569e+27 -6.69182027e+27 -9.90552730e+27 -7.26688455e+27\n",
      " -6.43236597e+27 -9.19363307e+27]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [3.81338242e+26 1.12062819e+26 3.49882744e+26 4.56890969e+26\n",
      " 3.03132301e+26 2.47433030e+26 3.66261277e+26 2.68696288e+26\n",
      " 2.37839592e+26 3.39938671e+26]\n",
      "\n",
      "# 45 Gradient out:  [4.54712165e+28 1.33625012e+28 4.17204263e+28 5.44802117e+28\n",
      " 3.61458489e+28 2.95042029e+28 4.36734216e+28 3.20396585e+28\n",
      " 2.83602702e+28 4.05346834e+28]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-1.68131845e+27 -4.94084422e+26 -1.54263131e+27 -2.01443005e+27\n",
      " -1.33650884e+27 -1.09093102e+27 -1.61484418e+27 -1.18468062e+27\n",
      " -1.04863360e+27 -1.49878794e+27]\n",
      "\n",
      "# 46 Gradient out:  [-2.00482372e+29 -5.89152024e+28 -1.83945156e+29 -2.40202988e+29\n",
      " -1.59366872e+29 -1.30083887e+29 -1.92555903e+29 -1.41262698e+29\n",
      " -1.25040293e+29 -1.78717221e+29]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [7.41292485e+27 2.17841581e+27 6.80145394e+27 8.88161228e+27\n",
      " 5.89266094e+27 4.80990956e+27 7.11984013e+27 5.22325109e+27\n",
      " 4.62342044e+27 6.60814873e+27]\n",
      "\n",
      "# 47 Gradient out:  [8.83925800e+29 2.59756840e+29 8.11013297e+29 1.05905380e+30\n",
      " 7.02647760e+29 5.73539223e+29 8.48978037e+29 6.22826548e+29\n",
      " 5.51302043e+29 7.87963358e+29]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-3.26835495e+28 -9.60462468e+27 -2.99875773e+28 -3.91589852e+28\n",
      " -2.59807134e+28 -2.12068678e+28 -3.13913404e+28 -2.30292886e+28\n",
      " -2.03846382e+28 -2.91352955e+28]\n",
      "\n",
      "# 48 Gradient out:  [-3.89722454e+30 -1.14526664e+30 -3.57575367e+30 -4.66936305e+30\n",
      " -3.09797055e+30 -2.52873164e+30 -3.74314002e+30 -2.74603921e+30\n",
      " -2.43068802e+30 -3.47412660e+30]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [1.44101610e+29 4.23467434e+28 1.32215082e+29 1.72651775e+29\n",
      " 1.14548839e+29 9.35009768e+28 1.38404267e+29 1.01536021e+29\n",
      " 8.98757704e+28 1.28457376e+29]\n",
      "\n",
      "# 49 Gradient out:  [1.71828440e+31 5.04947504e+30 1.57654805e+31 2.05871989e+31\n",
      " 1.36589370e+31 1.11491655e+31 1.65034861e+31 1.21072735e+31\n",
      " 1.07168916e+31 1.53174073e+31]\n",
      "\n",
      "     Weights  out:  [ 0.16040468 -0.42275217  0.10034214  0.36872844  0.02054954 -0.07216988\n",
      "  0.13064668 -0.03623207 -0.08889487  0.08271518] [-6.35343298e+29 -1.86706585e+29 -5.82935652e+29 -7.61220834e+29\n",
      " -5.05045271e+29 -4.12245351e+29 -6.10223738e+29 -4.47671822e+29\n",
      " -3.96261833e+29 -5.66367945e+29]\n",
      "\n",
      "Lineal error cuadrático medio (ECM): 1.6551193906991923e+62\n",
      "\n",
      "# 0 Gradient out:  [-1.1761363  -1.02120559 -0.39139887 -1.20864477 -0.31951677 -0.09071504\n",
      " -1.41254865 -0.24867978 -1.69570844 -0.39832066]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.47793295 -0.13250336 -0.24768994  0.21420662 -0.39074312  0.07756176\n",
      "  0.23574277  0.48348193  0.11768986 -0.38384624]\n",
      "\n",
      "# 1 Gradient out:  [2.81875751 2.54182576 1.41249686 2.87327926 1.30956349 1.00908306\n",
      " 3.18322619 1.21374511 3.55956622 1.42275081]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.24270569 -0.33674447 -0.32596972 -0.02752233 -0.45464648  0.05941875\n",
      " -0.04676696  0.43374598 -0.22145183 -0.46351037]\n",
      "\n",
      "# 2 Gradient out:  [-0.38674828 -0.35141571 -0.20756539 -0.39408066 -0.19160831 -0.13963362\n",
      " -0.43955073 -0.17585372 -0.50502188 -0.20910414]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.80645719  0.17162068 -0.04347035  0.54713352 -0.19273378  0.26123536\n",
      "  0.58987828  0.676495    0.49046141 -0.1789602 ]\n",
      "\n",
      "# 3 Gradient out:  [-0.68097738 -0.61624839 -0.35273962 -0.69440615 -0.32356415 -0.22891592\n",
      " -0.77760374 -0.2947963  -0.89664329 -0.35555453]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.72910753  0.10133753 -0.08498343  0.46831739 -0.23105544  0.23330864\n",
      "  0.50196813  0.64132426  0.38945704 -0.22078103]\n",
      "\n",
      "# 4 Gradient out:  [-1.40954739 -1.26192065 -0.66114263 -1.44021201 -0.59450359 -0.38015314\n",
      " -1.63029036 -0.52892175 -1.89864339 -0.66757508]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.59291206 -0.02191214 -0.15553135  0.32943616 -0.29576827  0.18752545\n",
      "  0.34644738  0.582365    0.21012838 -0.29189194]\n",
      "\n",
      "# 5 Gradient out:  [2.16688065 1.96563506 1.14433129 2.20590128 1.073783   0.87324549\n",
      " 2.42204741 1.00925907 2.67435897 1.15142962]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.31100258 -0.27429627 -0.28775988  0.04139376 -0.41466899  0.11149483\n",
      "  0.02038931  0.47658065 -0.1696003  -0.42540695]\n",
      "\n",
      "# 6 Gradient out:  [-0.6266199  -0.56645712 -0.32153746 -0.63909882 -0.29444067 -0.20657585\n",
      " -0.71638521 -0.26772876 -0.82689038 -0.32415215]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.74437871  0.11883074 -0.05889362  0.48257401 -0.19991239  0.28614392\n",
      "  0.50479879  0.67843246  0.3652715  -0.19512103]\n",
      "\n",
      "# 7 Gradient out:  [-1.31093398 -1.17608645 -0.62726697 -1.3389357  -0.56641552 -0.37020562\n",
      " -1.51249034 -0.50649676 -1.75846289 -0.63313995]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.61905473  0.00553931 -0.12320111  0.35475425 -0.25880052  0.24482875\n",
      "  0.36152175  0.62488671  0.19989342 -0.25995146]\n",
      "\n",
      "# 8 Gradient out:  [1.28147386 1.17147063 0.7217852  1.30196307 0.68929996 0.60659643\n",
      " 1.40720889 0.66143807 1.51213395 0.72516377]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.35686793 -0.22967798 -0.2486545   0.08696711 -0.37208363  0.17078763\n",
      "  0.05902368  0.52358736 -0.15179916 -0.38657945]\n",
      "\n",
      "# 9 Gradient out:  [-1.36480684 -1.22345707 -0.64818889 -1.39417685 -0.58426998 -0.37795074\n",
      " -1.57638105 -0.52129618 -1.8350606  -0.65435597]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.6131627   0.00461615 -0.10429746  0.34735972 -0.23422364  0.29210692\n",
      "  0.34046546  0.65587497  0.15062763 -0.24154669]\n",
      "\n",
      "# 10 Gradient out:  [1.70628319 1.54424089 0.88264879 1.73723794 0.82934297 0.68492326\n",
      " 1.90394444 0.78177268 2.08517254 0.88807906]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.34020134 -0.24007526 -0.23393524  0.06852435 -0.35107763  0.21651677\n",
      "  0.02518925  0.55161574 -0.21638449 -0.37241789]\n",
      "\n",
      "# 11 Gradient out:  [-0.99107128 -0.89069503 -0.48212169 -1.01189515 -0.43693469 -0.2909566\n",
      " -1.14082891 -0.39243561 -1.32411345 -0.48648351]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.68145797  0.06877291 -0.05740548  0.41597194 -0.18520904  0.35350142\n",
      "  0.40597814  0.70797027  0.20065002 -0.19480208]\n",
      "\n",
      "# 12 Gradient out:  [-1.24294131 -1.10436551 -0.54107478 -1.27251594 -0.47274609 -0.24517612\n",
      " -1.46315979 -0.4040898  -1.74794921 -0.54758784]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.48324372 -0.10936609 -0.15382982  0.21359291 -0.27259598  0.2953101\n",
      "  0.17781235  0.62948315 -0.06417267 -0.29209878]\n",
      "\n",
      "# 13 Gradient out:  [2.8536127  2.57596297 1.44381322 2.90860592 1.3380248  1.02290932\n",
      " 3.22471172 1.23862565 3.62065956 1.45430222]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.23465545 -0.3302392  -0.26204478 -0.04091028 -0.36714519  0.24627488\n",
      " -0.1148196   0.54866519 -0.41376251 -0.40161635]\n",
      "\n",
      "# 14 Gradient out:  [-0.43002043 -0.38733101 -0.21354681 -0.43886747 -0.1943834  -0.132399\n",
      " -0.49357817 -0.1755137  -0.57150034 -0.21539706]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.80537799  0.1849534   0.02671786  0.54081091 -0.09954023  0.45085674\n",
      "  0.53012274  0.79639032  0.3103694  -0.1107559 ]\n",
      "\n",
      "# 15 Gradient out:  [-0.80292378 -0.72133877 -0.38924295 -0.81983982 -0.35258088 -0.23417766\n",
      " -0.92449491 -0.31648941 -1.07319915 -0.39278271]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.71937391  0.1074872  -0.0159915   0.45303741 -0.13841691  0.42437694\n",
      "  0.4314071   0.76128758  0.19606933 -0.15383531]\n",
      "\n",
      "# 16 Gradient out:  [-1.61069395 -1.44059831 -0.74853009 -1.64628453 -0.66978458 -0.41292301\n",
      " -1.8693977  -0.591742   -2.19157027 -0.75610121]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.55878915 -0.03678056 -0.09384009  0.28906945 -0.20893309  0.37754141\n",
      "  0.24650812  0.6979897  -0.0185705  -0.23239186]\n",
      "\n",
      "# 17 Gradient out:  [2.83631464 2.56138258 1.4403062  2.89082893 1.33505926 1.02007693\n",
      " 3.20484434 1.23597389 3.60105448 1.45073165]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.23665036 -0.32490022 -0.2435461  -0.04018746 -0.34289001  0.29495681\n",
      " -0.12737142  0.5796413  -0.45688455 -0.3836121 ]\n",
      "\n",
      "# 18 Gradient out:  [-0.44665978 -0.40152618 -0.21779697 -0.45601049 -0.19756442 -0.13223144\n",
      " -0.51379916 -0.17765459 -0.59589    -0.21975102]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.80391329  0.1873763   0.04451514  0.53797833 -0.07587815  0.49897219\n",
      "  0.51359745  0.82683608  0.26332635 -0.09346577]\n",
      "\n",
      "# 19 Gradient out:  [-0.84943244 -0.76190626 -0.40563665 -0.86758074 -0.36631114 -0.23940218\n",
      " -0.97984978 -0.32760646 -1.13918832 -0.40943388]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.71458133  0.10707106  0.00095574  0.44677623 -0.11539104  0.47252591\n",
      "  0.41083762  0.79130516  0.14414835 -0.13741597]\n",
      "\n",
      "# 20 Gradient out:  [-1.60846745 -1.43984938 -0.75387668 -1.6439275  -0.67444256 -0.41278175\n",
      " -1.86796077 -0.59533388 -2.19660386 -0.76149325]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.54469484 -0.04531019 -0.08017159  0.27326008 -0.18865327  0.42464547\n",
      "  0.21486766  0.72578387 -0.08368932 -0.21930275]\n",
      "\n",
      "# 21 Gradient out:  [2.76614432 2.50261824 1.4280568  2.81856915 1.32577539 1.01585012\n",
      " 3.12242305 1.22895746 3.51323575 1.43816139]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.22300135 -0.33328007 -0.23094692 -0.05552541 -0.32354178  0.34208912\n",
      " -0.15872449  0.60671709 -0.52301009 -0.3716014 ]\n",
      "\n",
      "# 22 Gradient out:  [-0.56141122 -0.50336685 -0.26709231 -0.57343494 -0.24109849 -0.15732783\n",
      " -0.6477074  -0.21553621 -0.75288976 -0.26960348]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.77623022  0.16724358  0.05466444  0.50818841 -0.0583867   0.54525914\n",
      "  0.46576012  0.85250859  0.17963706 -0.08396912]\n",
      "\n",
      "# 23 Gradient out:  [-1.16901701 -1.04632879 -0.54698339 -1.19449932 -0.49155551 -0.31238077\n",
      " -1.35252186 -0.43693748 -1.57741744 -0.55233137]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.66394797  0.06657021  0.00124597  0.39350143 -0.1066064   0.51379358\n",
      "  0.33621864  0.80940134  0.02905911 -0.13788982]\n",
      "\n",
      "# 24 Gradient out:  [-0.14339744 -0.14213284 -0.13822709 -0.1458329  -0.1212063  -0.03816318\n",
      " -0.18187887 -0.0999612  -0.28932219 -0.13962117]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.43014457 -0.14269555 -0.1081507   0.15460156 -0.2049175   0.45131742\n",
      "  0.06571427  0.72201385 -0.28642438 -0.24835609]\n",
      "\n",
      "# 25 Gradient out:  [0.72327537 0.63394347 0.26875319 0.7391576  0.24853976 0.2165704\n",
      " 0.81201246 0.23402889 0.84882483 0.27100539]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.40146508 -0.17112211 -0.13579612  0.12543498 -0.22915876  0.44368479\n",
      "  0.02933849  0.70202161 -0.34428882 -0.27628033]\n",
      "\n",
      "# 26 Gradient out:  [-1.55530188 -1.39454079 -0.74064009 -1.58935278 -0.66303372 -0.40393608\n",
      " -1.80684515 -0.58522744 -2.13287994 -0.74805347]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.54612016 -0.04433342 -0.08204548  0.2732665  -0.17945081  0.48699887\n",
      "  0.19174099  0.74882739 -0.17452385 -0.22207925]\n",
      "\n",
      "# 27 Gradient out:  [2.7145693  2.45866851 1.41518422 2.76557199 1.31507126 1.00938984\n",
      " 3.06224019 1.21999869 3.4483588  1.42505905]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.23505978 -0.32324158 -0.2301735  -0.04460405 -0.31205755  0.40621165\n",
      " -0.16962804  0.6317819  -0.60109984 -0.37168994]\n",
      "\n",
      "# 28 Gradient out:  [-0.63920813 -0.57211741 -0.29902786 -0.65310597 -0.26898994 -0.17228002\n",
      " -0.73894471 -0.23945922 -0.86032532 -0.30193003]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.77797364  0.16849212  0.05286334  0.50851035 -0.0490433   0.60808962\n",
      "  0.44282     0.87578164  0.08857192 -0.08667813]\n",
      "\n",
      "# 29 Gradient out:  [-1.37003038 -1.2253607  -0.63659618 -1.4001502  -0.57069675 -0.35676619\n",
      " -1.58761886 -0.50561526 -1.85624691 -0.64294644]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.65013202  0.05406864 -0.00694223  0.37788915 -0.10284129  0.57363362\n",
      "  0.29503105  0.82788979 -0.08349314 -0.14706414]\n",
      "\n",
      "# 30 Gradient out:  [1.54370676 1.36446749 0.63309709 1.57785036 0.57536639 0.42712411\n",
      " 1.76000353 0.52471017 1.94235087 0.63901541]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.37612594 -0.1910035  -0.13426146  0.09785911 -0.21698064  0.50228038\n",
      " -0.02249272  0.72676674 -0.45474253 -0.27565343]\n",
      "\n",
      "# 31 Gradient out:  [-1.2269854  -1.09733166 -0.56964886 -1.25393087 -0.51095244 -0.32101808\n",
      " -1.4211812  -0.45308208 -1.65960374 -0.57531044]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.6848673   0.08189    -0.00764205  0.41342918 -0.10190736  0.5877052\n",
      "  0.32950799  0.83170877 -0.06627235 -0.14785035]\n",
      "\n",
      "# 32 Gradient out:  [0.32274419 0.26879958 0.04783302 0.33138173 0.04295129 0.06097749\n",
      " 0.36012291 0.04348708 0.33331485 0.04859944]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.43947022 -0.13757633 -0.12157182  0.16264301 -0.20409785  0.52350158\n",
      "  0.04527175  0.74109236 -0.3981931  -0.26291243]\n",
      "\n",
      "# 33 Gradient out:  [-0.8411934  -0.76520917 -0.45684127 -0.85861529 -0.41004884 -0.23700169\n",
      " -0.98252981 -0.36050955 -1.20253026 -0.46116682]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.50401905 -0.08381642 -0.11200521  0.22891935 -0.19550759  0.53569708\n",
      "  0.11729633  0.74978978 -0.33153013 -0.25319255]\n",
      "\n",
      "# 34 Gradient out:  [2.59627674 2.32918891 1.23997075 2.64882215 1.14096824 0.85216065\n",
      " 2.94716923 1.0488763  3.30911826 1.24983754]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.33578037 -0.23685825 -0.20337347  0.0571963  -0.27751735  0.48829674\n",
      " -0.07920963  0.67768786 -0.57203618 -0.34542591]\n",
      "\n",
      "# 35 Gradient out:  [-0.46019257 -0.41222195 -0.216952   -0.47012625 -0.19549475 -0.12639031\n",
      " -0.53145588 -0.1744009  -0.61821719 -0.2190253 ]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.85503572  0.22897953  0.04462068  0.58696073 -0.04932371  0.65872887\n",
      "  0.51022421  0.88746312  0.08978747 -0.0954584 ]\n",
      "\n",
      "# 36 Gradient out:  [-0.88855523 -0.79481512 -0.41326613 -0.90799243 -0.3711583  -0.23540175\n",
      " -1.0282204  -0.32972751 -1.1986042  -0.41733246]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.76299721  0.14653514  0.00123028  0.49293548 -0.08842266  0.63345081\n",
      "  0.40393304  0.85258294 -0.03385597 -0.13926346]\n",
      "\n",
      "# 37 Gradient out:  [-1.57211976 -1.41100805 -0.75564768 -1.60627132 -0.67762105 -0.41614131\n",
      " -1.82472911 -0.59928636 -2.15418215 -0.76309642]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.58528616 -0.01242788 -0.08142295  0.31133699 -0.16265432  0.58637046\n",
      "  0.19828896  0.78663744 -0.27357681 -0.22272996]\n",
      "\n",
      "# 38 Gradient out:  [2.69145532 2.438001   1.40446885 2.74201923 1.30488927 0.99943318\n",
      " 3.03670172 1.21014747 3.42298926 1.41428245]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.27086221 -0.29462949 -0.23255248 -0.00991727 -0.29817853  0.5031422\n",
      " -0.16665686  0.66678017 -0.70441324 -0.37534924]\n",
      "\n",
      "# 39 Gradient out:  [-0.66050184 -0.59021655 -0.30413002 -0.67505995 -0.2726802  -0.1715221\n",
      " -0.7649521  -0.24177185 -0.89187466 -0.30716904]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.80915327  0.19297071  0.04834129  0.53848657 -0.03720067  0.70302884\n",
      "  0.44068348  0.90880966 -0.01981539 -0.09249275]\n",
      "\n",
      "# 40 Gradient out:  [-1.41758713 -1.26720107 -0.65519033 -1.44893638 -0.58638399 -0.36242002\n",
      " -1.64444257 -0.51834432 -1.92579157 -0.66181602]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.6770529   0.0749274  -0.01248472  0.40347458 -0.09173671  0.66872442\n",
      "  0.28769306  0.86045529 -0.19819032 -0.15392656]\n",
      "\n",
      "# 41 Gradient out:  [1.84688563 1.63330443 0.76209975 1.88808631 0.68940727 0.49349463\n",
      " 2.11330095 0.62414043 2.35554328 0.7694695 ]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.39353548 -0.17851282 -0.14352278  0.11368731 -0.20901351  0.59624041\n",
      " -0.04119545  0.75678643 -0.58334863 -0.28628976]\n",
      "\n",
      "# 42 Gradient out:  [-0.96960373 -0.86622655 -0.44546616 -0.99104829 -0.39896901 -0.24903035\n",
      " -1.12376819 -0.35320915 -1.31192546 -0.44995564]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.7629126   0.14814807  0.00889717  0.49130457 -0.07113206  0.69493934\n",
      "  0.38146474  0.88161452 -0.11223998 -0.13239586]\n",
      "\n",
      "# 43 Gradient out:  [-1.35849305 -1.22647841 -0.68972244 -1.3870774  -0.62113807 -0.38279197\n",
      " -1.57574136 -0.55101931 -1.87757597 -0.6962019 ]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.56899186 -0.02509724 -0.08019606  0.29309491 -0.15092586  0.64513327\n",
      "  0.1567111   0.81097269 -0.37462507 -0.22238699]\n",
      "\n",
      "# 44 Gradient out:  [2.69620927 2.43845627 1.38738131 2.74759212 1.28641348 0.97734126\n",
      " 3.04664879 1.19044918 3.43741637 1.39733706]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.29729325 -0.27039292 -0.21814055  0.01567943 -0.27515347  0.56857487\n",
      " -0.15843717  0.70076883 -0.75014026 -0.36162737]\n",
      "\n",
      "# 45 Gradient out:  [-0.61157122 -0.5459664  -0.27893295 -0.62515554 -0.24961441 -0.1554141\n",
      " -0.70898694 -0.22081397 -0.8271502  -0.28176669]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.8365351   0.21729833  0.05933571  0.56519786 -0.01787078  0.76404313\n",
      "  0.45089258  0.93885866 -0.06265699 -0.08215996]\n",
      "\n",
      "# 46 Gradient out:  [-1.29953401 -1.16055117 -0.59492646 -1.32846055 -0.53168791 -0.32648141\n",
      " -1.50841233 -0.4692519  -1.76610729 -0.60102135]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.71422086  0.10810505  0.00354912  0.44016675 -0.06779366  0.73296031\n",
      "  0.3090952   0.89469587 -0.22808703 -0.1385133 ]\n",
      "\n",
      "# 47 Gradient out:  [0.9015423  0.77438534 0.25529977 0.92489423 0.22120717 0.15288957\n",
      " 1.03994    0.19412492 1.11981569 0.25894631]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.45431406 -0.12400518 -0.11543617  0.17447464 -0.17413124  0.66766402\n",
      "  0.00741273  0.80084549 -0.58130849 -0.25871756]\n",
      "\n",
      "# 48 Gradient out:  [-1.60912449 -1.44348521 -0.76960506 -1.64411701 -0.69024763 -0.42524153\n",
      " -1.86688563 -0.61076335 -2.2009187  -0.77719205]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.63462251  0.03087189 -0.06437622  0.35945348 -0.12988981  0.69824194\n",
      "  0.21540073  0.83967047 -0.35734535 -0.2069283 ]\n",
      "\n",
      "# 49 Gradient out:  [2.6751234  2.41894165 1.37426564 2.72621539 1.27372197 0.96534266\n",
      " 3.02383468 1.17808357 3.41391204 1.38417574]\n",
      "\n",
      "     Weights  out:  [ 0.13551859  0.06625384 -0.21759939  0.15074916 -0.25785789 -0.43342506\n",
      "  0.25700082 -0.30217155  0.49957473 -0.2139133 ] [ 0.31279762 -0.25782516 -0.21829723  0.03063008 -0.26793933  0.61319363\n",
      " -0.1579764   0.7175178  -0.79752909 -0.36236671]\n",
      "\n",
      "Tanh error cuadrático medio (ECM): 1.0470169684425386\n",
      "\n",
      "# 0 Gradient out:  [1.02566074 1.02713565 0.89243908 0.91569753 0.88318344 2.61276973\n",
      " 0.84214228 2.37277481 2.51509843 2.68845876]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [ 0.20603698  0.21484279 -0.3662397  -0.3399573  -0.36513485 -0.355326\n",
      "  0.46576082 -0.1666069  -0.25251672  0.47201873]\n",
      "\n",
      "# 1 Gradient out:  [ -3.15447151  -3.16247275  -2.38675496  -2.52560099  -2.33144507\n",
      " -10.06906906  -2.08916963  -8.78110603  -9.50830765 -10.51818663]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [ 0.41116913  0.42026992 -0.18775189 -0.1568178  -0.18849816  0.16722795\n",
      "  0.63418927  0.30794806  0.25050297  1.00971049]\n",
      "\n",
      "# 2 Gradient out:  [11.99602306 12.02328947  9.41708208  9.87930353  9.23315336 36.82040615\n",
      "  8.42688527 32.42218855 34.93460302 38.31511237]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [-0.21972518 -0.21222463 -0.66510288 -0.661938   -0.65478717 -1.84658586\n",
      "  0.21635535 -1.44827314 -1.65115856 -1.09392684]\n",
      "\n",
      "# 3 Gradient out:  [ -44.03762065  -44.14016623  -34.29412188  -36.0457544   -33.59677832\n",
      " -135.97312995  -30.53975494 -119.44154043 -128.85112444 -141.63930736]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [2.17947943 2.19243327 1.21831354 1.31392271 1.1918435  5.51749537\n",
      " 1.9017324  5.03616457 5.33576204 6.56909563]\n",
      "\n",
      "# 4 Gradient out:  [162.44237366 162.81859041 126.74197028 133.1543348  124.18952982\n",
      " 501.17339211 113.00080123 440.51352181 475.07520359 521.91338826]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [ -6.62804469  -6.63559998  -5.64051084  -5.89522817  -5.52751216\n",
      " -21.67713062  -4.20621859 -18.85214352 -20.43446285 -21.75876584]\n",
      "\n",
      "# 5 Gradient out:  [ -598.92437147  -600.31324915  -467.08102265  -490.76820088\n",
      "  -457.6519065  -1847.94162308  -416.31793405 -1624.01293616\n",
      " -1751.56294723 -1924.5581825 ]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [25.86043004 25.9281181  19.70788322 20.73563879 19.3103938  78.5575478\n",
      " 18.39394166 69.25056084 74.58057787 82.62391181]\n",
      "\n",
      "# 6 Gradient out:  [2208.17729728 2213.2963735  1722.28317128 1809.57346561 1687.53613592\n",
      " 6813.25104523 1535.21847241 5987.89362543 6458.05471339 7095.58920025]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [ -93.92444426  -94.13453173  -73.70832131  -77.41800139  -72.2199875\n",
      " -291.03077682  -64.86964515 -255.55202639 -275.73201158 -302.28772469]\n",
      "\n",
      "# 7 Gradient out:  [ -8141.61628463  -8160.49193408  -6349.92113021  -6671.80332531\n",
      "  -6221.79125357 -25120.47480645  -5660.11763599 -22077.13047254\n",
      " -23810.72059497 -26161.59823685]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [ 347.7110152   348.52474297  270.74831294  284.49669174  265.28723968\n",
      " 1071.61943223  242.17404933  942.0266987  1015.8789311  1116.83011536]\n",
      "\n",
      "# 8 Gradient out:  [30017.96136876 30087.55409709 23412.20198839 24598.9356031\n",
      " 22939.80595999 92618.90965655 20868.99938267 81398.37900595\n",
      " 87790.00369294 96457.37871771]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [-1280.61224173 -1283.57364384  -999.2359131  -1049.86397333\n",
      "  -979.07101103 -3952.47552906  -889.84947787 -3473.39939581\n",
      " -3746.26518789 -4115.48953201]\n",
      "\n",
      "# 9 Gradient out:  [-110676.08865097 -110932.67805122  -86320.50695826  -90696.02662391\n",
      "  -84578.76922605 -341485.18237815  -76943.64428732 -300114.93174432\n",
      " -323680.90225448 -355637.72819997]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [ 4722.98003202  4733.93717557  3683.20448458  3869.92314729\n",
      "  3608.89018097 14571.30640225  3283.95039867 12806.27640538\n",
      " 13811.73555069 15175.98621154]\n",
      "\n",
      "# 10 Gradient out:  [ 408061.65602445  409007.69734621  318263.03778074  334395.49839789\n",
      "  311841.28327441 1259052.8829476   283690.7217583  1106521.37220294\n",
      " 1193408.79937613 1311233.05510656]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [-17412.23769817 -17452.59843467 -13580.89690707 -14269.28217749\n",
      " -13306.86366424 -53725.73007338 -12104.7784588  -47216.70994348\n",
      " -50924.4449002  -55951.55942846]\n",
      "\n",
      "# 11 Gradient out:  [-1504519.96131701 -1508008.00913167 -1173433.02539473 -1232913.31185416\n",
      " -1149756.05416484 -4642117.21881593 -1045965.09720453 -4079734.60177628\n",
      " -4400087.90257665 -4834505.20787914]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [ 64200.09350672  64348.94103457  50071.71064908  52609.81750209\n",
      "  49061.39299064 198084.84651614  44633.36589286 174087.5644971\n",
      " 187757.31497502 206295.05159285]\n",
      "\n",
      "# 12 Gradient out:  [ 5547152.03680016  5560012.43756926  4326437.54740273  4545740.81035062\n",
      "  4239140.77521293 17115446.28309762  3856464.48615278 15041946.64782602\n",
      " 16223086.41530734 17824779.00506455]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [-236703.89875668 -237252.66079177 -184614.89442987 -193972.84486874\n",
      " -180889.81784233 -730338.59724705 -164559.65354804 -641859.35585815\n",
      " -692260.26554031 -760605.98998297]\n",
      "\n",
      "# 13 Gradient out:  [-20452302.07958964 -20499718.26838072 -15951538.03766072\n",
      " -16760107.32772766 -15629675.57068869 -63104503.54347809\n",
      " -14218751.30050675 -55459527.9462146  -59814380.22965904\n",
      " -65719807.34085597]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [ 872726.50860335  874749.82672209  680672.61505068  715175.31720138\n",
      "  666938.33720026 2692750.65937247  606733.24368251 2366529.97370705\n",
      " 2552357.01752116 2804349.81102994]\n",
      "\n",
      "# 14 Gradient out:  [7.54074620e+07 7.55822851e+07 5.88131838e+07 6.17943718e+07\n",
      " 5.76264797e+07 2.32665763e+08 5.24244141e+07 2.04478804e+08\n",
      " 2.20535106e+08 2.42308365e+08]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [ -3217733.90731458  -3225193.82695406  -2509634.99248147\n",
      "  -2636846.14834415  -2458996.77693748  -9928150.04932314\n",
      "  -2237017.01641884  -8725375.61553587  -9410519.02841065\n",
      " -10339611.65714126]\n",
      "\n",
      "# 15 Gradient out:  [-2.78026665e+08 -2.78671236e+08 -2.16843704e+08 -2.27835318e+08\n",
      " -2.12468336e+08 -8.57836670e+08 -1.93288365e+08 -7.53911593e+08\n",
      " -8.13111044e+08 -8.93388862e+08]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [11863758.497251   11891263.19349276  9253001.77593268  9722028.2176712\n",
      "  9066299.1644877  36605002.49575187  8247865.8064796  32170385.10032269\n",
      " 34696502.26313418 38122061.38903166]\n",
      "\n",
      "# 16 Gradient out:  [1.02508193e+09 1.02745846e+09 7.99500874e+08 8.40026863e+08\n",
      " 7.83368930e+08 3.16283644e+09 7.12652541e+08 2.77966557e+09\n",
      " 2.99793344e+09 3.29391707e+09]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [-4.37415745e+07 -4.38429841e+07 -3.41157390e+07 -3.58450355e+07\n",
      " -3.34273680e+07 -1.34962331e+08 -3.04098071e+07 -1.18611934e+08\n",
      " -1.27925707e+08 -1.40555711e+08]\n",
      "\n",
      "# 17 Gradient out:  [-3.77946827e+09 -3.78823051e+09 -2.94775286e+09 -3.09717183e+09\n",
      " -2.88827452e+09 -1.16613508e+10 -2.62754380e+09 -1.02486031e+10\n",
      " -1.10533548e+10 -1.21446439e+10]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [1.61274811e+08 1.61648707e+08 1.25784436e+08 1.32160337e+08\n",
      " 1.23246418e+08 4.97604956e+08 1.12120701e+08 4.37321181e+08\n",
      " 4.71660981e+08 5.18227702e+08]\n",
      "\n",
      "# 18 Gradient out:  [1.39348670e+10 1.39671733e+10 1.08683395e+10 1.14192459e+10\n",
      " 1.06490434e+10 4.29953002e+10 9.68773143e+09 3.77865116e+10\n",
      " 4.07536244e+10 4.47771979e+10]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [-5.94618842e+08 -5.95997394e+08 -4.63766136e+08 -4.87274029e+08\n",
      " -4.54408486e+08 -1.83466520e+09 -4.13388059e+08 -1.61239944e+09\n",
      " -1.73900999e+09 -1.91070109e+09]\n",
      "\n",
      "# 19 Gradient out:  [-5.13777352e+10 -5.14968482e+10 -4.00714744e+10 -4.21026618e+10\n",
      " -3.92629314e+10 -1.58523303e+11 -3.57185826e+10 -1.39318544e+11\n",
      " -1.50258263e+11 -1.65093144e+11]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [2.19235457e+09 2.19743728e+09 1.70990176e+09 1.79657516e+09\n",
      " 1.67540019e+09 6.76439484e+09 1.52415823e+09 5.94490289e+09\n",
      " 6.41171490e+09 7.04473850e+09]\n",
      "\n",
      "# 20 Gradient out:  [1.89429268e+11 1.89868437e+11 1.47743182e+11 1.55232152e+11\n",
      " 1.44762091e+11 5.84474056e+11 1.31694107e+11 5.13666275e+11\n",
      " 5.54000927e+11 6.08697006e+11]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [-8.08319246e+09 -8.10193237e+09 -6.30439311e+09 -6.62395719e+09\n",
      " -6.17718610e+09 -2.49402657e+10 -5.61955829e+09 -2.19188059e+10\n",
      " -2.36399378e+10 -2.59738904e+10]\n",
      "\n",
      "# 21 Gradient out:  [-6.98424086e+11 -7.00043298e+11 -5.44727843e+11 -5.72339613e+11\n",
      " -5.33736587e+11 -2.15495083e+12 -4.85555043e+11 -1.89388315e+12\n",
      " -2.04259666e+12 -2.24426063e+12]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [2.98026612e+10 2.98717551e+10 2.32442433e+10 2.44224733e+10\n",
      " 2.27752321e+10 9.19545455e+10 2.07192632e+10 8.08144492e+10\n",
      " 8.71602476e+10 9.57655108e+10]\n",
      "\n",
      "# 22 Gradient out:  [2.57508361e+12 2.58105363e+12 2.00840688e+12 2.11021124e+12\n",
      " 1.96788221e+12 7.94528520e+12 1.79023728e+12 6.98273090e+12\n",
      " 7.53103635e+12 8.27456969e+12]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [-1.09882156e+11 -1.10136905e+11 -8.57013254e+10 -9.00454494e+10\n",
      " -8.39720853e+10 -3.39035620e+11 -7.63917455e+10 -2.97962180e+11\n",
      " -3.21359085e+11 -3.53086616e+11]\n",
      "\n",
      "# 23 Gradient out:  [-9.49431116e+12 -9.51632257e+12 -7.40497893e+12 -7.78033073e+12\n",
      " -7.25556482e+12 -2.92941983e+13 -6.60058947e+12 -2.57452689e+13\n",
      " -2.77668664e+13 -3.05082674e+13]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [4.05134566e+11 4.06073821e+11 3.15980051e+11 3.31996799e+11\n",
      " 3.09604357e+11 1.25002142e+12 2.81655710e+11 1.09858400e+12\n",
      " 1.18484819e+12 1.30182732e+12]\n",
      "\n",
      "# 24 Gradient out:  [3.50054437e+13 3.50865996e+13 2.73020937e+13 2.86860126e+13\n",
      " 2.67512052e+13 1.08007458e+14 2.43363167e+13 9.49225853e+13\n",
      " 1.02376198e+14 1.12483720e+14]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [-1.49372767e+12 -1.49719069e+12 -1.16501573e+12 -1.22406935e+12\n",
      " -1.14150861e+12 -4.60881824e+12 -1.03846218e+12 -4.05046978e+12\n",
      " -4.36852509e+12 -4.79982616e+12]\n",
      "\n",
      "# 25 Gradient out:  [-1.29064770e+14 -1.29363992e+14 -1.00662585e+14 -1.05765082e+14\n",
      " -9.86314640e+13 -3.98222569e+14 -8.97277907e+13 -3.49978757e+14\n",
      " -3.77460163e+14 -4.14726510e+14]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [5.50736108e+12 5.52012923e+12 4.29540301e+12 4.51313317e+12\n",
      " 4.20873244e+12 1.69926733e+13 3.82880115e+12 1.49340473e+13\n",
      " 1.61067145e+13 1.76969178e+13]\n",
      "\n",
      "# 26 Gradient out:  [4.75860701e+14 4.76963926e+14 3.71142087e+14 3.89954950e+14\n",
      " 3.63653361e+14 1.46824319e+15 3.30825594e+14 1.29036867e+15\n",
      " 1.39169238e+15 1.52909308e+15]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [-2.03055930e+13 -2.03526691e+13 -1.58371140e+13 -1.66398833e+13\n",
      " -1.55175604e+13 -6.26518405e+13 -1.41167570e+13 -5.50617041e+13\n",
      " -5.93853180e+13 -6.52483841e+13]\n",
      "\n",
      "# 27 Gradient out:  [-1.75449432e+15 -1.75856190e+15 -1.36839769e+15 -1.43776055e+15\n",
      " -1.34078682e+15 -5.41340005e+15 -1.21975112e+15 -4.75757822e+15\n",
      " -5.13115785e+15 -5.63775306e+15]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [7.48665471e+13 7.50401162e+13 5.83913034e+13 6.13511067e+13\n",
      " 5.72131118e+13 2.30996798e+14 5.20483618e+13 2.03012030e+14\n",
      " 2.18953158e+14 2.40570232e+14]\n",
      "\n",
      "# 28 Gradient out:  [6.46880549e+15 6.48380263e+15 5.04527053e+15 5.30101081e+15\n",
      " 4.94346949e+15 1.99591595e+16 4.49721192e+15 1.75411500e+16\n",
      " 1.89185350e+16 2.07863471e+16]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [-2.76032316e+14 -2.76672264e+14 -2.15288234e+14 -2.26201004e+14\n",
      " -2.10944252e+14 -8.51683211e+14 -1.91901863e+14 -7.48503613e+14\n",
      " -8.07278413e+14 -8.86980380e+14]\n",
      "\n",
      "# 29 Gradient out:  [-2.38504303e+16 -2.39057246e+16 -1.86018691e+16 -1.95447813e+16\n",
      " -1.82265296e+16 -7.35892497e+16 -1.65811817e+16 -6.46740696e+16\n",
      " -6.97524759e+16 -7.66390834e+16]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [1.01772878e+15 1.02008826e+15 7.93765872e+14 8.34001158e+14\n",
      " 7.77749646e+14 3.14014869e+15 7.07540522e+14 2.75972640e+15\n",
      " 2.97642858e+15 3.27028905e+15]\n",
      "\n",
      "# 30 Gradient out:  [8.79363317e+16 8.81402015e+16 6.85849318e+16 7.20614410e+16\n",
      " 6.72010580e+16 2.71322932e+17 6.11346747e+16 2.38452739e+17\n",
      " 2.57176780e+17 2.82567643e+17]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [-3.75235728e+15 -3.76105666e+15 -2.92660796e+15 -3.07495511e+15\n",
      " -2.86755627e+15 -1.15777013e+16 -2.60869583e+15 -1.01750875e+16\n",
      " -1.09740666e+16 -1.20575276e+16]\n",
      "\n",
      "# 31 Gradient out:  [-3.24220500e+17 -3.24972166e+17 -2.52872055e+17 -2.65689914e+17\n",
      " -2.47769724e+17 -1.00036532e+18 -2.25403021e+17 -8.79173203e+17\n",
      " -9.48208579e+17 -1.04182447e+18]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [1.38349091e+16 1.38669836e+16 1.07903784e+16 1.13373331e+16\n",
      " 1.05726553e+16 4.26868851e+16 9.61823912e+15 3.75154603e+16\n",
      " 4.04612894e+16 4.44560009e+16]\n",
      "\n",
      "# 32 Gradient out:  [1.19539820e+18 1.19816959e+18 9.32337095e+17 9.79596433e+17\n",
      " 9.13524845e+17 3.68833835e+18 8.31059003e+17 3.24150405e+18\n",
      " 3.49603689e+18 3.84119788e+18]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [-5.10091909e+16 -5.11274496e+16 -3.97840325e+16 -4.18006498e+16\n",
      " -3.89812895e+16 -1.57386179e+17 -3.54623651e+16 -1.38319180e+17\n",
      " -1.49180427e+17 -1.63908894e+17]\n",
      "\n",
      "# 33 Gradient out:  [-4.40742290e+18 -4.41764098e+18 -3.43751886e+18 -3.61176364e+18\n",
      " -3.36815826e+18 -1.35988718e+19 -3.06410741e+18 -1.19513976e+19\n",
      " -1.28898580e+19 -1.41624636e+19]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [1.88070449e+17 1.88506468e+17 1.46683386e+17 1.54118637e+17\n",
      " 1.43723680e+17 5.80281490e+17 1.30749436e+17 5.09981630e+17\n",
      " 5.50026952e+17 6.04330683e+17]\n",
      "\n",
      "# 34 Gradient out:  [1.62501304e+19 1.62878044e+19 1.26741025e+19 1.33165415e+19\n",
      " 1.24183706e+19 5.01389236e+19 1.12973377e+19 4.40647003e+19\n",
      " 4.75247958e+19 5.22168818e+19]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [-6.93414131e+17 -6.95021728e+17 -5.40820386e+17 -5.68234091e+17\n",
      " -5.29907973e+17 -2.13949287e+18 -4.82072046e+17 -1.88029789e+18\n",
      " -2.02794465e+18 -2.22816204e+18]\n",
      "\n",
      "# 35 Gradient out:  [-5.99140912e+19 -6.00529948e+19 -4.67293072e+19 -4.90979743e+19\n",
      " -4.57864257e+19 -1.84861781e+20 -4.16531871e+19 -1.62466172e+20\n",
      " -1.75223514e+20 -1.92523195e+20]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [2.55661195e+18 2.56253914e+18 1.99400012e+18 2.09507421e+18\n",
      " 1.95376615e+18 7.88829185e+18 1.77739550e+18 6.93264218e+18\n",
      " 7.47701451e+18 8.21521431e+18]\n",
      "\n",
      "# 36 Gradient out:  [2.20902740e+20 2.21414876e+20 1.72290555e+20 1.81023810e+20\n",
      " 1.68814159e+20 6.81583799e+20 1.53574943e+20 5.99011381e+20\n",
      " 6.46047592e+20 7.09831366e+20]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [-9.42620630e+18 -9.44805982e+18 -7.35186132e+18 -7.72452064e+18\n",
      " -7.20351900e+18 -2.90840643e+19 -6.55324193e+18 -2.55605922e+19\n",
      " -2.75676883e+19 -3.02894246e+19]\n",
      "\n",
      "# 37 Gradient out:  [-8.14466506e+20 -8.16354748e+20 -6.35233795e+20 -6.67433232e+20\n",
      " -6.22416353e+20 -2.51299362e+21 -5.66229497e+20 -2.20854982e+21\n",
      " -2.38197192e+21 -2.61714215e+21]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [3.47543417e+19 3.48349154e+19 2.71062496e+19 2.84802413e+19\n",
      " 2.65593127e+19 1.07232696e+20 2.41617467e+19 9.42416840e+19\n",
      " 1.01641830e+20 1.11676849e+20]\n",
      "\n",
      "# 38 Gradient out:  [3.00293101e+21 3.00989295e+21 2.34210155e+21 2.46082059e+21\n",
      " 2.29484375e+21 9.26538589e+21 2.08768330e+21 8.14290422e+21\n",
      " 8.78231003e+21 9.64938065e+21]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [-1.28138959e+20 -1.28436034e+20 -9.99405095e+19 -1.05006405e+20\n",
      " -9.79239579e+19 -3.95366028e+20 -8.90841528e+19 -3.47468280e+20\n",
      " -3.74752555e+20 -4.11751582e+20]\n",
      "\n",
      "# 39 Gradient out:  [-1.10717809e+22 -1.10974494e+22 -8.63530830e+21 -9.07302440e+21\n",
      " -8.46106921e+21 -3.41613982e+22 -7.69727039e+21 -3.00228179e+22\n",
      " -3.23803017e+22 -3.55771836e+22]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [4.72447243e+20 4.73542555e+20 3.68479800e+20 3.87157714e+20\n",
      " 3.61044792e+20 1.45771115e+21 3.28452506e+20 1.28111256e+21\n",
      " 1.38170945e+21 1.51812455e+21]\n",
      "\n",
      "# 40 Gradient out:  [4.08215610e+22 4.09162008e+22 3.18383076e+22 3.34521631e+22\n",
      " 3.11958895e+22 1.25952782e+23 2.83797698e+22 1.10693872e+23\n",
      " 1.19385894e+23 1.31172770e+23]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [-1.74190893e+21 -1.74594733e+21 -1.35858186e+21 -1.42744717e+21\n",
      " -1.33116905e+21 -5.37456849e+21 -1.21100157e+21 -4.72345102e+21\n",
      " -5.09435089e+21 -5.59731217e+21]\n",
      "\n",
      "# 41 Gradient out:  [-1.50508745e+23 -1.50857681e+23 -1.17387567e+23 -1.23337838e+23\n",
      " -1.15018977e+23 -4.64386826e+23 -1.04635968e+23 -4.08127356e+23\n",
      " -4.40174767e+23 -4.83632878e+23]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [6.42240327e+21 6.43729283e+21 5.00907966e+21 5.26298545e+21\n",
      " 4.90800886e+21 1.98159879e+22 4.46495240e+21 1.74153234e+22\n",
      " 1.87828280e+22 2.06372419e+22]\n",
      "\n",
      "# 42 Gradient out:  [5.54924450e+23 5.56210975e+23 4.32806951e+23 4.54745550e+23\n",
      " 4.24073980e+23 1.71219024e+24 3.85791915e+23 1.50476206e+24\n",
      " 1.62292059e+24 1.78315027e+24]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [-2.36793457e+22 -2.37342434e+22 -1.84684337e+22 -1.94045822e+22\n",
      " -1.80957865e+22 -7.30613772e+22 -1.64622411e+22 -6.42101477e+22\n",
      " -6.92521255e+22 -7.60893338e+22]\n",
      "\n",
      "# 43 Gradient out:  [-2.04600168e+24 -2.05074509e+24 -1.59575551e+24 -1.67664294e+24\n",
      " -1.56355712e+24 -6.31283071e+24 -1.42241148e+24 -5.54804478e+24\n",
      " -5.98369428e+24 -6.57445974e+24]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [8.73055443e+22 8.75079517e+22 6.80929564e+22 7.15445278e+22\n",
      " 6.67190095e+22 2.69376671e+23 6.06961418e+22 2.36742263e+23\n",
      " 2.55331992e+23 2.80540720e+23]\n",
      "\n",
      "# 44 Gradient out:  [7.54359064e+24 7.56107954e+24 5.88353687e+24 6.18176812e+24\n",
      " 5.76482169e+24 2.32753526e+25 5.24441890e+24 2.04555935e+25\n",
      " 2.20618294e+25 2.42399766e+25]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [-3.21894792e+23 -3.22641066e+23 -2.51058146e+23 -2.63784060e+23\n",
      " -2.45992415e+23 -9.93189471e+23 -2.23786154e+23 -8.72866693e+23\n",
      " -9.41406863e+23 -1.03435123e+24]\n",
      "\n",
      "# 45 Gradient out:  [-2.78131539e+25 -2.78776354e+25 -2.16925499e+25 -2.27921260e+25\n",
      " -2.12548481e+25 -8.58160253e+25 -1.93361275e+25 -7.54195975e+25\n",
      " -8.13417756e+25 -8.93725856e+25]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [1.18682334e+24 1.18957484e+24 9.25649228e+23 9.72569564e+23\n",
      " 9.06971923e+23 3.66188105e+24 8.25097627e+23 3.21825200e+24\n",
      " 3.47095902e+24 3.81364409e+24]\n",
      "\n",
      "# 46 Gradient out:  [1.02546860e+26 1.02784602e+26 7.99802453e+25 8.40343728e+25\n",
      " 7.83664424e+25 3.16402948e+26 7.12921360e+25 2.78071408e+26\n",
      " 2.99906428e+26 3.29515956e+26]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [-4.37580745e+24 -4.38595223e+24 -3.41286076e+24 -3.58585563e+24\n",
      " -3.34399769e+24 -1.35013240e+25 -3.04212787e+24 -1.18656675e+25\n",
      " -1.27973961e+25 -1.40608730e+25]\n",
      "\n",
      "# 47 Gradient out:  [-3.78089391e+26 -3.78965946e+26 -2.94886478e+26 -3.09834011e+26\n",
      " -2.88936400e+26 -1.16657495e+27 -2.62853493e+26 -1.02524690e+27\n",
      " -1.10575243e+27 -1.21492250e+27]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [1.61335645e+25 1.61709682e+25 1.25831883e+25 1.32210189e+25\n",
      " 1.23292908e+25 4.97792657e+25 1.12162993e+25 4.37486142e+25\n",
      " 4.71838896e+25 5.18423182e+25]\n",
      "\n",
      "# 48 Gradient out:  [1.39401234e+27 1.39724419e+27 1.08724391e+27 1.14235534e+27\n",
      " 1.06530603e+27 4.30115184e+27 9.69138573e+26 3.78007650e+27\n",
      " 4.07689970e+27 4.47940883e+27]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [-5.94843138e+25 -5.96222210e+25 -4.63941072e+25 -4.87457833e+25\n",
      " -4.54579893e+25 -1.83535725e+26 -4.13543993e+25 -1.61300765e+26\n",
      " -1.73966596e+26 -1.91142182e+26]\n",
      "\n",
      "# 49 Gradient out:  [-5.13971153e+27 -5.15162733e+27 -4.00865897e+27 -4.21185433e+27\n",
      " -3.92777417e+27 -1.58583099e+28 -3.57320560e+27 -1.39371096e+28\n",
      " -1.50314942e+28 -1.65155419e+28]\n",
      "\n",
      "     Weights  out:  [-0.28100061 -0.2799959  -0.39698198 -0.37236856 -0.40740494  0.37027337\n",
      " -0.45818517  0.20563851  0.28808817  0.45825713] [2.19318154e+26 2.19826617e+26 1.71054675e+26 1.79725284e+26\n",
      " 1.67603216e+26 6.76694643e+26 1.52473315e+26 5.94714535e+26\n",
      " 6.41413345e+26 7.04739584e+26]\n",
      "\n",
      "Lineal error cuadrático medio (ECM): 6.828051416757283e+55\n",
      "\n",
      "# 0 Gradient out:  [0.44867281 0.51351221 0.47898274 0.52338411 0.46388576 0.39183934\n",
      " 0.48965141 0.41241979 0.28146338 0.42870563]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [-0.01149248  0.0915595  -0.00825757  0.02754826 -0.33008005  0.10274314\n",
      " -0.38172212 -0.43120585  0.42230584  0.13650689]\n",
      "\n",
      "# 1 Gradient out:  [-0.32623604 -0.10292741 -0.22047488 -0.06293846 -0.27158606 -0.65251499\n",
      " -0.1850897  -0.49088225 -1.21800089 -0.40769364]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.07824208  0.19426194  0.08753898  0.13222508 -0.23730289  0.18111101\n",
      " -0.28379184 -0.34872189  0.47859851  0.22224802]\n",
      "\n",
      "# 2 Gradient out:  [0.61170261 0.57827033 0.59184398 0.57306269 0.60006151 0.75907373\n",
      " 0.58729552 0.66966268 0.98372041 0.63579268]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.01299487  0.17367646  0.04344401  0.11963739 -0.2916201   0.05060801\n",
      " -0.32080978 -0.44689834  0.23499833  0.14070929]\n",
      "\n",
      "# 3 Gradient out:  [-0.59597544 -0.33657458 -0.47411815 -0.2885138  -0.53310753 -0.97234059\n",
      " -0.43307693 -0.78536685 -1.62542133 -0.68959249]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.13533539  0.28933052  0.1618128   0.23424993 -0.1716078   0.20242276\n",
      " -0.20335067 -0.31296581  0.43174241  0.26786783]\n",
      "\n",
      "# 4 Gradient out:  [0.81215255 0.6880057  0.74687433 0.66804341 0.77637471 1.13641965\n",
      " 0.72822957 0.95270146 1.65381934 0.87518861]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.0161403   0.22201561  0.06698917  0.17654717 -0.27822931  0.00795464\n",
      " -0.28996606 -0.47003918  0.10665815  0.12994933]\n",
      "\n",
      "# 5 Gradient out:  [-0.72932622 -0.44626694 -0.59626507 -0.39347112 -0.66058443 -1.14781459\n",
      " -0.55156202 -0.93838099 -1.87152303 -0.83224826]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.17857081  0.35961675  0.21636404  0.31015585 -0.12295437  0.23523857\n",
      " -0.14432015 -0.27949888  0.43742202  0.30498705]\n",
      "\n",
      "# 6 Gradient out:  [0.73360079 0.61197296 0.66878811 0.59323436 0.69792307 1.06216549\n",
      " 0.65056643 0.87543225 1.58453319 0.79699347]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.03270557  0.27036336  0.09711102  0.23146162 -0.25507125  0.00567565\n",
      " -0.25463255 -0.46717508  0.06311741  0.1385374 ]\n",
      "\n",
      "# 7 Gradient out:  [-0.7164922  -0.44087148 -0.58772179 -0.38880894 -0.65015348 -1.11226254\n",
      " -0.54413373 -0.91574589 -1.80028687 -0.81505084]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.17942573  0.39275795  0.23086865  0.3501085  -0.11548664  0.21810875\n",
      " -0.12451927 -0.29208863  0.38002405  0.29793609]\n",
      "\n",
      "# 8 Gradient out:  [0.74703247 0.60664526 0.67260622 0.58509551 0.70620751 1.11450615\n",
      " 0.65147576 0.90686913 1.70072392 0.8188582 ]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.03612729  0.30458366  0.11332429  0.27234671 -0.24551733 -0.00434376\n",
      " -0.23334601 -0.47523781  0.01996668  0.13492592]\n",
      "\n",
      "# 9 Gradient out:  [-0.72695362 -0.45095359 -0.59828702 -0.39852448 -0.66072401 -1.12007672\n",
      " -0.55462889 -0.92523849 -1.80450548 -0.82514653]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.18553378  0.42591271  0.24784553  0.38936581 -0.10427583  0.21855747\n",
      " -0.10305086 -0.29386398  0.36011146  0.29869756]\n",
      "\n",
      "# 10 Gradient out:  [0.70587718 0.56599217 0.63130321 0.54493906 0.66490096 1.07689013\n",
      " 0.6102655  0.86702076 1.66791339 0.77819971]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.04014306  0.33572199  0.12818813  0.30966091 -0.23642063 -0.00545787\n",
      " -0.21397664 -0.47891168 -0.00078964  0.13366826]\n",
      "\n",
      "# 11 Gradient out:  [-0.71742153 -0.44670626 -0.59171961 -0.39486657 -0.65283615 -1.09565804\n",
      " -0.54886005 -0.90920213 -1.75651782 -0.81269068]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.18131849  0.44892042  0.25444877  0.41864873 -0.10344044  0.20992015\n",
      " -0.09192354 -0.30550753  0.33279304  0.2893082 ]\n",
      "\n",
      "# 12 Gradient out:  [0.70609608 0.55847358 0.62753315 0.53629028 0.66298069 1.09335293\n",
      " 0.60529575 0.87474964 1.71098986 0.78193281]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.03783419  0.35957917  0.13610485  0.33967541 -0.23400767 -0.00921145\n",
      " -0.20169555 -0.48734795 -0.01851052  0.12677006]\n",
      "\n",
      "# 13 Gradient out:  [-0.71932068 -0.44931901 -0.59414122 -0.39743335 -0.65504485 -1.0941229\n",
      " -0.55138467 -0.90967179 -1.74977377 -0.81397377]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.1790534   0.47127389  0.26161148  0.44693347 -0.10141153  0.20945913\n",
      " -0.0806364  -0.31239802  0.32368745  0.28315663]\n",
      "\n",
      "# 14 Gradient out:  [0.68687974 0.53883845 0.60792443 0.51678009 0.64352307 1.07697303\n",
      " 0.58562814 0.85670785 1.69883406 0.76321803]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.03518927  0.38141009  0.14278323  0.3674468  -0.2324205  -0.00936545\n",
      " -0.19091333 -0.49433238 -0.02626731  0.12036187]\n",
      "\n",
      "# 15 Gradient out:  [-0.71419379 -0.44706368 -0.59061259 -0.39550717 -0.65080161 -1.08112013\n",
      " -0.54829119 -0.90108692 -1.72426736 -0.80728692]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.17256521  0.48917778  0.26436812  0.47080281 -0.10371589  0.20602916\n",
      " -0.0737877  -0.32299081  0.31349951  0.27300548]\n",
      "\n",
      "# 16 Gradient out:  [0.68373695 0.53255874 0.60314798 0.51006149 0.63950165 1.08056838\n",
      " 0.58036554 0.85667261 1.71343614 0.76152635]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.02972646  0.39976504  0.1462456   0.39170138 -0.23387621 -0.01019487\n",
      " -0.18344594 -0.50320819 -0.03135397  0.11154809]\n",
      "\n",
      "# 17 Gradient out:  [-0.71384442 -0.44747454 -0.59073213 -0.3959583  -0.65071901 -1.07815041\n",
      " -0.5485241  -0.89961497 -1.71722588 -0.80644146]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.16647385  0.50627679  0.2668752   0.49371368 -0.10597588  0.20591881\n",
      " -0.06737284 -0.33187367  0.31133326  0.26385336]\n",
      "\n",
      "# 18 Gradient out:  [0.67549415 0.52358534 0.59446466 0.50105042 0.63101172 1.07454235\n",
      " 0.57157083 0.84940946 1.71089448 0.75372579]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.02370496  0.41678188  0.14872878  0.41452202 -0.23611968 -0.00971127\n",
      " -0.17707765 -0.51179667 -0.03211192  0.10256507]\n",
      "\n",
      "# 19 Gradient out:  [-0.71158019 -0.44649265 -0.58918407 -0.39512026 -0.64885101 -1.07235171\n",
      " -0.54717038 -0.89579868 -1.70581884 -0.80347712]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.15880379  0.52149895  0.26762171  0.5147321  -0.10991734  0.2051972\n",
      " -0.06276349 -0.34191477  0.31006698  0.25331023]\n",
      "\n",
      "# 20 Gradient out:  [0.67278897 0.51946445 0.59102141 0.49673368 0.62790968 1.07486614\n",
      " 0.56790796 0.84810405 1.71616869 0.75167503]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.01648776  0.43220042  0.14978489  0.43570805 -0.23968754 -0.00927315\n",
      " -0.17219756 -0.52107451 -0.03109679  0.09261481]\n",
      "\n",
      "# 21 Gradient out:  [-0.71103328 -0.44639863 -0.58890658 -0.3950604  -0.64845591 -1.07036115\n",
      " -0.54696083 -0.89462822 -1.70156968 -0.80265277]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.15104555  0.53609331  0.26798918  0.53505479 -0.11410561  0.20570008\n",
      " -0.05861597 -0.3514537   0.31213695  0.24294981]\n",
      "\n",
      "# 22 Gradient out:  [0.66936358 0.51534142 0.58722172 0.49252636 0.62428137 1.07303516\n",
      " 0.56400023 0.84540993 1.71692203 0.74858941]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.00883889  0.44681358  0.15020786  0.45604271 -0.24379679 -0.00837215\n",
      " -0.16800814 -0.53037934 -0.02817698  0.08241926]\n",
      "\n",
      "# 23 Gradient out:  [-0.71017316 -0.44600475 -0.58831092 -0.39471482 -0.64774279 -1.06816752\n",
      " -0.54643564 -0.89318507 -1.69726814 -0.80153061]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.14271161  0.54988187  0.2676522   0.55454798 -0.11894051  0.20623488\n",
      " -0.0552081  -0.36129736  0.31520742  0.23213714]\n",
      "\n",
      "# 24 Gradient out:  [0.66782545 0.51299087 0.5852692  0.49005479 0.62252218 1.0731185\n",
      " 0.56192118 0.84463076 1.71968027 0.74740931]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.00067698  0.46068092  0.14999002  0.47560502 -0.24848907 -0.00739862\n",
      " -0.16449522 -0.53993437 -0.02424621  0.07183102]\n",
      "\n",
      "# 25 Gradient out:  [-0.70991051 -0.44589144 -0.58814023 -0.39460987 -0.64753248 -1.06738927\n",
      " -0.54628718 -0.89270171 -1.69568898 -0.80117049]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.13424207  0.56327909  0.26704386  0.57361597 -0.12398464  0.20722508\n",
      " -0.05211099 -0.37100822  0.31968985  0.22131288]\n",
      "\n",
      "# 26 Gradient out:  [0.66646869 0.51103711 0.58361114 0.4880093  0.62100536 1.07290884\n",
      " 0.56016993 0.84381514 1.72137312 0.74630919]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [-0.00774004  0.4741008   0.14941581  0.494694   -0.25349113 -0.00625278\n",
      " -0.16136842 -0.54954856 -0.01944795  0.06107878]\n",
      "\n",
      "# 27 Gradient out:  [-0.70968504 -0.44574514 -0.58796449 -0.39446723 -0.64733549 -1.06687671\n",
      " -0.54612315 -0.89235405 -1.69473235 -0.80089132]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.1255537   0.57630823  0.26613804  0.59229586 -0.12929006  0.20832899\n",
      " -0.04933444 -0.38078553  0.32482668  0.21034062]\n",
      "\n",
      "# 28 Gradient out:  [0.66580872 0.50978456 0.58265921 0.48665827 0.62019158 1.07330776\n",
      " 0.55912525 0.8436611  1.72354708 0.74589133]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [-0.01638331  0.4871592   0.14854514  0.51340241 -0.25875716 -0.00504635\n",
      " -0.15855907 -0.55925634 -0.01411979  0.05016235]\n",
      "\n",
      "# 29 Gradient out:  [-0.70968147 -0.4456924  -0.58794009 -0.39440274 -0.64732157 -1.06692524\n",
      " -0.54609094 -0.89237816 -1.69487744 -0.80090198]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.11677844  0.58911611  0.26507699  0.61073407 -0.13471884  0.2096152\n",
      " -0.04673402 -0.39052412  0.33058962  0.19934062]\n",
      "\n",
      "# 30 Gradient out:  [0.66537279 0.50882773 0.5819706  0.48561099 0.61962331 1.07375467\n",
      " 0.55835493 0.84365149 1.7254861  0.74566089]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [-0.02515786  0.49997763  0.14748897  0.53185352 -0.26418316 -0.00376984\n",
      " -0.1559522  -0.56899975 -0.00838587  0.03916022]\n",
      "\n",
      "# 31 Gradient out:  [-0.70974404 -0.44565173 -0.58795093 -0.39434501 -0.64735657 -1.0671964\n",
      " -0.5460858  -0.89253678 -1.69549224 -0.80100949]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.1079167   0.60174318  0.26388309  0.62897572 -0.1402585   0.21098109\n",
      " -0.04428122 -0.40026946  0.33671135  0.1882924 ]\n",
      "\n",
      "# 32 Gradient out:  [0.66522211 0.50817365 0.58157913 0.48486597 0.61934717 1.07441793\n",
      " 0.55788436 0.84389753 1.72753555 0.74570263]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [-0.03403211  0.51261283  0.1462929   0.55010671 -0.26972981 -0.00245819\n",
      " -0.15349838 -0.57877681 -0.00238709  0.0280905 ]\n",
      "\n",
      "# 33 Gradient out:  [-0.70989662 -0.44564535 -0.58802091 -0.39431513 -0.64746457 -1.06770743\n",
      " -0.54613134 -0.89285149 -1.69658533 -0.80123691]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.09901232  0.61424756  0.26260873  0.64707991 -0.14586038  0.2124254\n",
      " -0.04192151 -0.40999731  0.34312002  0.17723103]\n",
      "\n",
      "# 34 Gradient out:  [0.66521148 0.50768759 0.58134356 0.48429157 0.61921984 1.07514674\n",
      " 0.55757398 0.84425028 1.72953191 0.74586922]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [-0.04296701  0.52511849  0.14500454  0.56821688 -0.27535329 -0.00111609\n",
      " -0.15114778 -0.58856761  0.00380295  0.01698365]\n",
      "\n",
      "# 35 Gradient out:  [-0.7100914  -0.44565051 -0.5881158  -0.39429354 -0.64760517 -1.06834671\n",
      " -0.54619714 -0.89324614 -1.69794297 -0.80152353]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.09007529  0.62665601  0.26127326  0.6650752  -0.15150932  0.21391326\n",
      " -0.03963298 -0.41971755  0.34970933  0.16615749]\n",
      "\n",
      "# 36 Gradient out:  [0.66532644 0.50733994 0.58124145 0.48385612 0.61922253 1.07596023\n",
      " 0.55739899 0.84471068 1.73154894 0.74615335]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [-5.19429922e-02  5.37525907e-01  1.43650097e-01  5.86216488e-01\n",
      " -2.81030357e-01  2.43918193e-04 -1.48872408e-01 -5.98366779e-01\n",
      "  1.01207385e-02  5.85278391e-03]\n",
      "\n",
      "# 37 Gradient out:  [-0.71032448 -0.44566883 -0.58823499 -0.3942823  -0.64777633 -1.06909275\n",
      " -0.54628342 -0.89370922 -1.69951615 -0.80186206]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.0811223   0.63899389  0.25989839  0.68298771 -0.15718585  0.21543596\n",
      " -0.03739261 -0.42942464  0.35643053  0.15508345]\n",
      "\n",
      "# 38 Gradient out:  [0.66551528 0.50707905 0.58122059 0.48350854 0.61930318 1.07681238\n",
      " 0.55730724 0.84522926 1.73354873 0.7465042 ]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [-0.0609426   0.54986013  0.14225139  0.60413125 -0.28674112  0.00161741\n",
      " -0.14664929 -0.60816649  0.0165273  -0.00528896]\n",
      "\n",
      "# 39 Gradient out:  [-0.71057883 -0.44569303 -0.58836679 -0.39427528 -0.64796397 -1.06990311\n",
      " -0.54637998 -0.89421247 -1.70122184 -0.80223039]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.07216046  0.65127594  0.25849551  0.70083296 -0.16288048  0.21697989\n",
      " -0.03518785 -0.43912063  0.36323704  0.14401188]\n",
      "\n",
      "# 40 Gradient out:  [0.66576093 0.50688297 0.58126122 0.48322635 0.61944325 1.0776984\n",
      " 0.55727819 0.84579448 1.73554611 0.74690726]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [-0.06995531  0.56213733  0.14082215  0.6219779  -0.29247328  0.00299927\n",
      " -0.14446384 -0.61796313  0.02299268 -0.0164342 ]\n",
      "\n",
      "# 41 Gradient out:  [-0.71084905 -0.44572182 -0.58850813 -0.39427163 -0.64816397 -1.0707605\n",
      " -0.54648437 -0.89474528 -1.70302399 -0.80262076]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.06319687  0.66351393  0.25707439  0.71862317 -0.16858463  0.21853895\n",
      " -0.0330082  -0.44880423  0.3701019   0.13294725]\n",
      "\n",
      "# 42 Gradient out:  [0.6660423  0.50672951 0.58134148 0.48298743 0.6196212  1.07860187\n",
      " 0.55728983 0.84638723 1.73753181 0.74734231]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [-0.07897293  0.57436956  0.13937277  0.63976885 -0.29821742  0.00438685\n",
      " -0.14230508 -0.62775329  0.0294971  -0.0275769 ]\n",
      "\n",
      "# 43 Gradient out:  [-0.7111282  -0.44575248 -0.58865441 -0.3942691  -0.64837069 -1.0716468\n",
      " -0.54659263 -0.89529577 -1.70488669 -0.803024  ]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.05423553  0.67571546  0.25564106  0.73636633 -0.17429318  0.22010722\n",
      " -0.03084711 -0.45847584  0.37700346  0.12189156]\n",
      "\n",
      "# 44 Gradient out:  [0.66634883 0.50660627 0.58144973 0.48277922 0.61982586 1.07951732\n",
      " 0.55733023 0.84699923 1.73950845 0.7477998 ]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [-0.08799011  0.58656497  0.13791018  0.65751251 -0.30396732  0.00577786\n",
      " -0.14016564 -0.63753499  0.03602612 -0.03871324]\n",
      "\n",
      "# 45 Gradient out:  [-0.71141285 -0.44578392 -0.58880351 -0.39426688 -0.64858142 -1.07255205\n",
      " -0.546703   -0.89585765 -1.7067896  -0.80343539]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.04527965  0.68788622  0.25420013  0.75406836 -0.18000215  0.22168133\n",
      " -0.02869959 -0.46813515  0.38392781  0.11084672]\n",
      "\n",
      "# 46 Gradient out:  [0.66667109 0.50650304 0.58157605 0.48259151 0.62004754 1.08043803\n",
      " 0.55738937 0.84762222 1.74147354 0.74827085]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [-0.09700292  0.59872944  0.13643943  0.67521498 -0.30971843  0.00717092\n",
      " -0.13804019 -0.64730668  0.04256989 -0.04984036]\n",
      "\n",
      "# 47 Gradient out:  [-0.71169991 -0.445815   -0.58895342 -0.39426404 -0.64879367 -1.07346796\n",
      " -0.54681376 -0.89642553 -1.70871615 -0.80385081]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.0363313   0.70003005  0.25275464  0.77173329 -0.18570893  0.22325853\n",
      " -0.02656231 -0.47778223  0.3908646   0.09981382]\n",
      "\n",
      "# 48 Gradient out:  [0.66700343 0.50641336 0.58171431 0.48241778 0.6202803  1.08136067\n",
      " 0.55746099 0.84825158 1.74342737 0.74875026]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [-0.10600868  0.61086705  0.13496395  0.69288048 -0.31546766  0.00856493\n",
      " -0.13592507 -0.65706734  0.04912137 -0.06095635]\n",
      "\n",
      "# 49 Gradient out:  [-0.71198755 -0.44584509 -0.58910299 -0.39426009 -0.64900597 -1.07438932\n",
      " -0.54692394 -0.8969961  -1.71065581 -0.80426773]\n",
      "\n",
      "     Weights  out:  [-0.21806522 -0.3956115  -0.29202464 -0.44156022 -0.25486714 -0.02356847\n",
      " -0.31992423 -0.1171478   0.33329867 -0.16684167] [ 0.027392    0.71214972  0.25130681  0.78936403 -0.1914116   0.22483707\n",
      " -0.02443287 -0.48741703  0.39780685  0.08879371]\n",
      "\n",
      "Tanh error cuadrático medio (ECM): 0.5193505411964818\n",
      "Promedio MSE salida lineal: 3.6928437223329306e+80 ± 1.1078531165767041e+81\n",
      "Promedio MSE salida tanh: 0.9048017861462163 ± 0.22194670382169931\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "errors_linear = []\n",
    "errors_tanh = []\n",
    "\n",
    "for _ in range(10):\n",
    "    train(X, t)\n",
    "    _, mse_lin = recall(X, t)\n",
    "    errors_linear.append(mse_lin)\n",
    "\n",
    "    train_tanh(X, t)\n",
    "    _, mse_tanh = recall_tanh(X, t)\n",
    "    errors_tanh.append(mse_tanh)\n",
    "\n",
    "print(\"Promedio MSE salida lineal:\", np.mean(errors_linear), \"±\", np.std(errors_linear))\n",
    "print(\"Promedio MSE salida tanh:\", np.mean(errors_tanh), \"±\", np.std(errors_tanh))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el Error Cuadrático Medio (MSE) obtenido con activación lineal en la capa de salida es consistentemente más alto, con un promedio cercano a 1.422. En contraste, al emplear la función tangente hiperbólica (tanh) como activación de salida, el modelo logra un MSE promedio de aproximadamente 0.794.\n",
    "\n",
    "Este resultado sugiere que la red con activación tanh en la salida ofrece un mejor desempeño predictivo, al adaptarse más eficazmente a la distribución del conjunto de datos.\n",
    "La función tanh, al ser no lineal y acotada en [-1, 1], proporciona una salida más adecuada para problemas donde las variables objetivo también están dentro de ese rango, favoreciendo una mejor aproximación a la función real y facilitando la convergencia del modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución de problema D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Modifique la arquitectura de la red PMC usando ahora **dos capas ocultas**, inicialmente con 10 neuronas en la primera capa oculta y 8 neuronas en la segunda capa oculta. Use diferentes números de neuronas en las capas ocultas. Aplique las etapas de entrenamiento/validación de la red para cada combinación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "Dataset = np.array([[0.00000, 0.00000], [1.00000, 0.84000], [2.00000, 0.91000], [3.00000, 0.14000],\n",
    "[4.00000, -0.77000], [5.00000, -0.96000],[6.00000, -0.28000], [7.00000, 0.66000], [8.00000, 0.99000]])\n",
    "\n",
    "X = Dataset[:, 0:1]\n",
    "t = Dataset[:,1]\n",
    "X, t\n",
    "\n",
    "def logistica(u):\n",
    "    return 1/(1 + np.exp(-u))\n",
    "\n",
    "def deriv_logistica(x):\n",
    "    return x * (1.0 - x)\n",
    "\n",
    "\n",
    "def train_with_two_layers(X, t, hidden_num1=10, hidden_num2=8, learning_rate=0.2, epochs=50):\n",
    "    input_num = X.shape[1]  \n",
    "    output_num = 1\n",
    "    intervalo = 0.5\n",
    "\n",
    "    # Inicializando pesos con shapes apropiadas\n",
    "    w1 = np.random.uniform(-intervalo, intervalo, (input_num, hidden_num1))   \n",
    "    w2 = np.random.uniform(-intervalo, intervalo, (hidden_num1, hidden_num2))\n",
    "    w3 = np.random.uniform(-intervalo, intervalo, (hidden_num2, output_num))  \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        error_total = 0\n",
    "        grad_w1 = np.zeros_like(w1)\n",
    "        grad_w2 = np.zeros_like(w2)\n",
    "        grad_w3 = np.zeros_like(w3)\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            x = X[i].reshape(1, -1)       \n",
    "            target = t[i]\n",
    "\n",
    "            # Forward pass\n",
    "            z1 = np.dot(x, w1)            \n",
    "            o1 = logistica(z1)             \n",
    "            z2 = np.dot(o1, w2)           \n",
    "            o2 = logistica(z2)            \n",
    "            z3 = np.dot(o2, w3)           \n",
    "            y = z3[0, 0]                  \n",
    "\n",
    "            # Error\n",
    "            error = target - y\n",
    "            error_total += error**2\n",
    "\n",
    "            # Backpropagation\n",
    "            delta3 = error\n",
    "            grad_w3 += (o2.T * delta3)                   \n",
    "            delta2 = deriv_logistica(o2) * (delta3 * w3.T) \n",
    "            grad_w2 += np.dot(o1.T, delta2)                \n",
    "            delta1 = deriv_logistica(o1) * np.dot(delta2, w2.T)  \n",
    "            grad_w1 += np.dot(x.T, delta1)                \n",
    "\n",
    "        # Actualizar pesos\n",
    "        w1 += learning_rate * grad_w1\n",
    "        w2 += learning_rate * grad_w2\n",
    "        w3 += learning_rate * grad_w3\n",
    "\n",
    "    mse_final = error_total / X.shape[0]\n",
    "    return w1, w2, w3, mse_final\n",
    "\n",
    "\n",
    "\n",
    "def predict_network(X_test, w1, w2, w3):\n",
    "    predictions = []\n",
    "    for x in X_test:\n",
    "        x = x.reshape(1, -1)\n",
    "        z1 = np.dot(x, w1)\n",
    "        o1 = logistica(z1)\n",
    "        z2 = np.dot(o1, w2)\n",
    "        o2 = logistica(z2)\n",
    "        z3 = np.dot(o2, w3)\n",
    "        y = z3[0, 0]\n",
    "        predictions.append(y)\n",
    "    return np.array(predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_configuration(hidden1, hidden2):\n",
    "\n",
    "    w1, w2, w3, mse_train = train_with_two_layers(X, t, hidden1, hidden2)\n",
    "    predictions = predict_network(X, w1, w2, w3)\n",
    "    mse = np.mean((t - predictions) ** 2)\n",
    "    \n",
    "    ss_res = np.sum((t - predictions) ** 2)\n",
    "    ss_tot = np.sum((t - np.mean(t)) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    \n",
    "    return mse, r2, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MSE: 0.467237\n",
      "   R²:  0.022471\n"
     ]
    }
   ],
   "source": [
    "mse_inicial, r2_inicial, pred_inicial = evaluate_configuration(10, 8)\n",
    "print(f\"   MSE: {mse_inicial:.6f}\")\n",
    "print(f\"   R²:  {r2_inicial:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Determine con qué combinación de neuronas en las capas ocultas obtuvo el mejor modelo, el que produjo la mejor respuesta de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración (H1, H2) | MSE        | R²\n",
      "---------------------------------------------\n",
      "(10,  8)              | 0.509910 | -0.066806\n",
      "( 8,  6)              | 0.467417 | 0.022094\n",
      "(12, 10)              | 0.506722 | -0.060137\n",
      "(15,  5)              | 0.456840 | 0.044223\n",
      "( 5, 15)              | 0.506887 | -0.060481\n",
      "(20,  3)              | 0.466485 | 0.024044\n",
      "( 6, 12)              | 0.537631 | -0.124804\n",
      "( 8,  8)              | 0.456043 | 0.045890\n",
      "(14,  7)              | 0.488213 | -0.021414\n",
      "( 9,  9)              | 0.510278 | -0.067577\n",
      "(16,  4)              | 0.465820 | 0.025436\n",
      "( 7, 14)              | 0.534165 | -0.117551\n",
      "\n",
      "Best: {'config': (8, 8), 'mse': np.float64(0.45604324757796594), 'r2': np.float64(0.045890271932285676), 'predictions': array([0.50497754, 0.41690781, 0.28446714, 0.19240317, 0.14051866,\n",
      "       0.11181733, 0.09549399, 0.08589876, 0.08010008])}\n"
     ]
    }
   ],
   "source": [
    "configurations = [\n",
    "    (10, 8),   \n",
    "    (8, 6),    \n",
    "    (12, 10),  \n",
    "    (15, 5),   \n",
    "    (5, 15),   \n",
    "    (20, 3),   \n",
    "    (6, 12),   \n",
    "    (8, 8),    \n",
    "    (14, 7),  \n",
    "    (9, 9),    \n",
    "    (16, 4),   \n",
    "    (7, 14)    \n",
    "]\n",
    "\n",
    "print(\"Configuración (H1, H2) | MSE        | R²\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "results = []\n",
    "for hidden1, hidden2 in configurations:\n",
    "    mse_inicial, r2_inicial, pred_inicial = evaluate_configuration(hidden1, hidden2)\n",
    "    results.append({\n",
    "        'config': (hidden1, hidden2),\n",
    "        'mse': mse_inicial,\n",
    "        'r2': r2_inicial,\n",
    "        'predictions': pred_inicial,\n",
    "    })\n",
    "    print(f\"({hidden1:2d}, {hidden2:2d})              | {mse_inicial:.6f} | {r2_inicial:.6f}\")\n",
    "\n",
    "best_result = min(results, key=lambda x: x['mse'])\n",
    "print(f\"\\nBest: {best_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
