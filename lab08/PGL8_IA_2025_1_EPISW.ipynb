{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GnUElm5_e8m"
      },
      "source": [
        "# Práctica de Laboratorio 8 - Inteligencia Artificial 2025-1 Sección 1 EPISW-FISI\n",
        "## Implementación de una red PMC-BP con Python y Numpy\n",
        "### Prof. Rolando A. Maguiña Pérez"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky22d26K_e8n"
      },
      "source": [
        "## Introducción\n",
        "La Práctica Guiada de Laboratorio (PGL) 8 a realizarse el Jueves 05 de Junio del presente año, tratará sobre la red Perceptrón Multicapa con su algoritmo de aprendizaje llamado Backpropagation. Esta red se aplicará para resolver problemas genéricos de clasificación y de regresión.\n",
        "\n",
        "Se desea abordar el problema de la aproximación de una función mediante una Perceptrón Multicapa-Backpropagation (PMC-BP). Inicialmente se presenta la implementación del algoritmo de entrenamiento de esta red (presentado en las sesiones de teoría), con el lenguaje `Python` y sus bibliotecas `Numpy` y `Matplotlib`. Posteriormente, **se propondrán algunos ejercicios cuyas soluciones se podrán obtener en grupos de hasta 4 alumnos**, y deberán enviarse para su respectiva revisión (ver sección 'Instrucciones para el envío' en este mismo cuaderno).  \n",
        "\n",
        "Requiere: numpy, matplotlib\n",
        "\n",
        "Nomenclatura:\n",
        "- Z: número de instancias (muestras) en el conjunto de datos\n",
        "- N: número de atributos o variables de entrada\n",
        "- M: número de atributos o variables de salida\n",
        "- t: vector de salidas esperadas o targets\n",
        "- y: vector de salidas estimadas por la red.\n",
        "\n",
        "### Paso previo\n",
        "Importamos las bibliotecas de Python requeridas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "5r_BRXlK_e8n"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKy9zmzb_e8p"
      },
      "source": [
        "## Dataset\n",
        "El primer paso consiste en obtener el arreglo conteniendo los pares entrada-salida (instancias) a usar en el entrenamiento/validación de la red PMC-BP a implementar; dicho arreglo se denominará 'Dataset'. El tamaño de dicho arreglo es de $Z \\times d$, donde $Z$ es el número de instancias (muestras) y $d$ es el número de características o atributos considerados para el problema abordado (incluye los atributos de entrada y los de salida)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "lHAeppdW_e8q",
        "outputId": "be4a459f-13d9-425f-bd6d-6e0cbbe7d8cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.  ,  0.  ],\n",
              "       [ 1.  ,  0.84],\n",
              "       [ 2.  ,  0.91],\n",
              "       [ 3.  ,  0.14],\n",
              "       [ 4.  , -0.77],\n",
              "       [ 5.  , -0.96],\n",
              "       [ 6.  , -0.28],\n",
              "       [ 7.  ,  0.66],\n",
              "       [ 8.  ,  0.99]])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Dataset = np.array([[0.00000, 0.00000], [1.00000, 0.84000], [2.00000, 0.91000], [3.00000, 0.14000],\n",
        "[4.00000, -0.77000], [5.00000, -0.96000],[6.00000, -0.28000], [7.00000, 0.66000], [8.00000, 0.99000]])\n",
        "Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "PQUmblTn_e8q",
        "outputId": "339662ed-f65c-4cb2-d5ba-a944a8775d4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9, 2)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Dataset.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xJFV52G_e8q"
      },
      "source": [
        "## Data para el entrenamiento/validación de la red\n",
        "Como sabemos, a partir del dataset obtenido, se deben determinar los conjuntos de datos a emplear en el entrenamiento y en la validación de la red PMC-BP. Enseguida, se deben obtener dos arreglos: uno con los vectores de entrada a usar en el entrenamiento, y el segundo, con los respectivos vectores de salida. Análogamente, se deben determinar los arreglos con los vectores de entrada y de salida, a usar en la validación del entrenamiento. **Sin embargo, para el problema planteado, el dataset se usará tanto para el entrenamiento como para la validación**.\n",
        "\n",
        "Separando los valores de entrada de los de salida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Hr48ISV7_e8q",
        "outputId": "649fd8d4-c634-4166-8853-9208bad639a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([0., 1., 2., 3., 4., 5., 6., 7., 8.]),\n",
              " array([ 0.  ,  0.84,  0.91,  0.14, -0.77, -0.96, -0.28,  0.66,  0.99]))"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = Dataset[:,0]\n",
        "t = Dataset[:,1]\n",
        "X, t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "L0tmqcxX_e8r",
        "outputId": "c5dd6b48-055e-4a0e-a4b4-5ba76e3800f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((9,), (9,))"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape, t.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "sxiXCKVT_e8r",
        "outputId": "dc3bdc08-c4cd-47c4-a353-61323d72eba7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x1ccb3879910>]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(4, 4))\n",
        "plt.plot(X,t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQJsVNIL_e8r"
      },
      "source": [
        "## Normalización de los datos\n",
        "Antes de iniciar algún cálculo, sabemos que debemos tener en cuenta las diferencias que existen en las unidades de nuestros datos. Se requiere que los datos de nuestras variables estén en el mismo orden de magnitud, y en un buen número de casos es necesario normalizarlos; de esta manera nuestro modelo trabajará con unidades normalizadas. A pesar de lo indicado, incluso sabedores que hay varios procedimientos de normalización, en este caso, **no vamos a normalizar inicialmente nuestros datos**.\n",
        "\n",
        "## Diseño de la red\n",
        "Inicialmente se considera una topología de la red como la mostrada en la figura, vale decir, con 10 neuronas ocultas. Como función de activación de las neuronas ocultas se usará la logística sigmoidea y en las neuronas de salida, dado que se trata de un problema de aproximación de funciones, se usará una función lineal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "WGsNXQEa_e8r",
        "outputId": "855b611b-4ff4-4ed2-bdaa-cf13deb780df"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'D:\\\\Cursos\\\\Redes Neuronales\\\\2021-2\\\\arquit-red_aprox-fc_2021-2.png'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m----> 2\u001b[0m i \u001b[38;5;241m=\u001b[39m Image(filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCursos\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mRedes Neuronales\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m2021-2\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124marquit-red_aprox-fc_2021-2.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m i\n",
            "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\Lib\\site-packages\\IPython\\core\\display.py:970\u001b[0m, in \u001b[0;36mImage.__init__\u001b[1;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata, alt)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munconfined \u001b[38;5;241m=\u001b[39m unconfined\n\u001b[0;32m    969\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malt \u001b[38;5;241m=\u001b[39m alt\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28msuper\u001b[39m(Image, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(data\u001b[38;5;241m=\u001b[39mdata, url\u001b[38;5;241m=\u001b[39murl, filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[0;32m    971\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mmetadata)\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m, {}):\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\Lib\\site-packages\\IPython\\core\\display.py:327\u001b[0m, in \u001b[0;36mDisplayObject.__init__\u001b[1;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 327\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreload()\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data()\n",
            "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\Lib\\site-packages\\IPython\\core\\display.py:1005\u001b[0m, in \u001b[0;36mImage.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed:\n\u001b[1;32m-> 1005\u001b[0m     \u001b[38;5;28msuper\u001b[39m(Image,\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mreload()\n\u001b[0;32m   1006\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretina:\n\u001b[0;32m   1007\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retina_shape()\n",
            "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\Lib\\site-packages\\IPython\\core\\display.py:353\u001b[0m, in \u001b[0;36mDisplayObject.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_flags \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 353\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_flags, encoding\u001b[38;5;241m=\u001b[39mencoding) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    354\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;66;03m# Deferred import\u001b[39;00m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\Cursos\\\\Redes Neuronales\\\\2021-2\\\\arquit-red_aprox-fc_2021-2.png'"
          ]
        }
      ],
      "source": [
        "from IPython.display import Image\n",
        "i = Image(filename='D:\\\\Cursos\\\\Redes Neuronales\\\\2021-2\\\\arquit-red_aprox-fc_2021-2.png')\n",
        "i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkStZNAt_e8s"
      },
      "source": [
        "## Inicialización de los pesos y biases de la red\n",
        "Según el algoritmo, los parámetros libres de la red se inicializan a valores aleatorios pequeños, los cuales pueden estar en el rangos: [-0.5,0.5] o [-1,1] o en torno de cero. A continuación se presenta el código para inicializarlos, aplicado al **problema planteado**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVovH8l6_e8s"
      },
      "outputs": [],
      "source": [
        "# Implementación básica sin funciones\n",
        "intervalo = 0.5\n",
        "capa_entrada = 1\n",
        "capa_oculta = 10\n",
        "capa_salida = 1\n",
        "\n",
        "w1 = np.random.uniform(-intervalo, intervalo, capa_oculta)\n",
        "\n",
        "w2 = np.random.uniform(-intervalo, intervalo, capa_oculta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZ0RMbRe_e8s",
        "outputId": "f683c42b-d53b-4b2e-ea4a-14907601f2eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 0.31363851, -0.14824543, -0.11532856, -0.47448722,  0.30202055,\n",
              "        -0.07598017,  0.36598791, -0.46703207,  0.15857095, -0.43671307]),\n",
              " array([ 0.16887422, -0.3305602 ,  0.02856265, -0.0367157 ,  0.03012444,\n",
              "         0.28213003,  0.36947367, -0.12383828,  0.18071988,  0.46923731]))"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w1, w2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmCcNM_d_e8s",
        "outputId": "9d457a8a-6bf1-4af0-b0c6-588ff5716fa7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((10,), (10,))"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w1.shape, w2.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBsY50rR_e8t"
      },
      "source": [
        "### Definición de la función logística sigmoidea\n",
        "Sabemos que la expresión matemática de la función logística sigmoidea `f(n)` es:\n",
        "\n",
        "                         f(u) =  1/1 + exp(-u)\n",
        "\n",
        "donde `u` es el vector de entradas netas. A partir de dicho parámetro, es posible calcular la función logistica sigmoidea; en la sgte celda se presenta el respectivo código."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epFEjYWl_e8t"
      },
      "outputs": [],
      "source": [
        "# Funcion de activacion Logistica Sigmoidea para la unidad de salida\n",
        "def logistica(u):\n",
        "    return 1/(1 + np.exp(-u))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Th5dgmub_e8t"
      },
      "source": [
        "Supongamos que se desea aplicar esta función al arreglo 'a'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAEvUwwY_e8t",
        "outputId": "8437d4cb-1c63-4f29-c846-8e595401d360"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0. ,  0.6, -0.8]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = np.array([[0, 0.6, -0.8]])\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iHeZAXi_e8t",
        "outputId": "c8eae3ea-8366-4e37-df4a-31a00e9f57e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.5       , 0.64565631, 0.31002552]])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logistica(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4M6Vnr-_e8t"
      },
      "source": [
        "A continuación se presenta la implementación de la derivada de la función logística sigmoidea:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XH0afOY_e8u"
      },
      "outputs": [],
      "source": [
        "def deriv_logistica(x):\n",
        "    return x * (1.0 - x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQBQqCLR_e8u",
        "outputId": "7b7de73a-c865-432a-c424-840452937c46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-4.8576"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "deriv_logistica(-1.76)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPor0YoF_e8u"
      },
      "source": [
        "## Implementación\n",
        "Luego de haber determinado la topología de la red neuronal, la implementaremos en el lenguaje de programación `Python` con la ayuda de su biblioteca `Numpy`. Enseguida, se efectuarán las sgtes actividades:\n",
        "\n",
        "- Construiremos el algoritmo de aprendizaje de nuestra red PMC, Backpropagation, mediante la función `train()`. Dentro de ella se instancian constantes y variables importantes como globales, de modo que estos valores sean accesibles para toda la función.\n",
        "- Aplicaremos dicho algoritmo de aprendizaje para resolver el problema de aproximación de una función planteado; para tal efecto, se usará el conjunto de datos disponible.\n",
        "\n",
        "En las sgtes celdas se presentan las líneas de código correspondientes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6M-xeAvc_e8u"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NETtXa7d_e8u"
      },
      "outputs": [],
      "source": [
        "Dataset = np.array([[0.00000, 0.00000], [1.00000, 0.84000], [2.00000, 0.91000], [3.00000, 0.14000],\n",
        "[4.00000, -0.77000], [5.00000, -0.96000],[6.00000, -0.28000], [7.00000, 0.66000], [8.00000, 0.99000]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YVIEN_G_e8v",
        "outputId": "09e186ca-8f01-4101-f9fc-2c82d36c0d54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([0., 1., 2., 3., 4., 5., 6., 7., 8.]),\n",
              " array([ 0.  ,  0.84,  0.91,  0.14, -0.77, -0.96, -0.28,  0.66,  0.99]))"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = Dataset[:,0]\n",
        "t = Dataset[:,1]\n",
        "X, t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nIZHvFq_e8v"
      },
      "outputs": [],
      "source": [
        "def train(X, t, learning_rate=0.2, epochs=50):\n",
        "    global input_num\n",
        "    global hidden_num\n",
        "    global w1\n",
        "    global w2\n",
        "\n",
        "    input_num = 1\n",
        "    hidden_num = 10\n",
        "    output_num = 1\n",
        "    intervalo = 0.5\n",
        "\n",
        "    # inicializando los pesos\n",
        "    w1 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
        "\n",
        "    w2 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        gradient_out = 0.0                 # gradientes para la capa de salida y la capa oculta\n",
        "        gradient_hidden = []\n",
        "\n",
        "        for i in range(X.shape[0]):\n",
        "        # propagacion hacia adelante\n",
        "            x = X[i]\n",
        "\n",
        "            u1 = x * w1\n",
        "            o = logistica(u1)\n",
        "            u2 = o.dot(w2)\n",
        "            y = u2\n",
        "\n",
        "        # backpropagation\n",
        "            delta_hidden_s = []           # inicializamos los delta_j a lista vacía\n",
        "            gradient_hidden_s = []       # inicializamos los gradientes de neurs ocultas a lista vacía\n",
        "\n",
        "            delta_out_s = t[i] - y     # cálculo del único delta_k (f'(u) = 1 pq fc de activ es lineal)\n",
        "            gradient_out_s = delta_out_s * o     # error por la salida de la capa anterior\n",
        "\n",
        "            for j in range(hidden_num):\n",
        "\n",
        "                delta_hidden_s.append(deriv_logistica(u1[j]) * w2[j] * delta_out_s)\n",
        "                gradient_hidden_s.append(delta_hidden_s[j] * x)\n",
        "\n",
        "\n",
        "            gradient_out = gradient_out + gradient_out_s\n",
        "            gradient_hidden = gradient_hidden + gradient_hidden_s\n",
        "\n",
        "\n",
        "        print(\"\\n#\", epoch, \"Gradient out: \",gradient_out),\n",
        "        print(\"\\n     Weights  out: \", w1, w2)\n",
        "\n",
        "        # Ahora actualizando pesos\n",
        "        w2 = w2 + learning_rate * gradient_out\n",
        "\n",
        "        for j in range(hidden_num):\n",
        "            w1[j] = w1[j] + learning_rate * gradient_hidden[j]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJgS7qCi_e8v",
        "outputId": "dc1f053a-dec7-40d4-fa7f-6db8b843e96a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "# 0 Gradient out:  [4.55032902 3.99588928 2.18558607 3.57836834 5.68981355 1.58579721\n",
            " 6.1969063  6.14822678 6.55633718 3.62899824]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [ 0.15432564 -0.39507629  0.3918821  -0.33849019  0.28772399  0.01785262\n",
            " -0.40524365 -0.02617312 -0.34005255 -0.3608523 ]\n",
            "\n",
            "# 1 Gradient out:  [-23.55619843 -20.69470758 -10.98868836 -18.54201844 -29.71057124\n",
            "  -7.38907647 -32.69695894 -32.40267715 -34.87905876 -18.80398552]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [1.06439144 0.40410157 0.82899931 0.37718348 1.4256867  0.33501206\n",
            " 0.83413761 1.20347224 0.97121488 0.36494735]\n",
            "\n",
            "# 2 Gradient out:  [123.62970742 108.58078662  57.91034397  97.25731722 155.71418452\n",
            "  39.50420171 171.03719075 169.53429574 182.17011454  98.63434998]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [-3.64684824 -3.73483995 -1.36873836 -3.33122021 -4.51642755 -1.14280324\n",
            " -5.70525418 -5.27706319 -6.00459687 -3.39584976]\n",
            "\n",
            "# 3 Gradient out:  [-647.22525137 -568.49088855 -303.01051265 -509.24992985 -815.37230649\n",
            " -206.17869457 -895.92810755 -888.01968073 -954.52485388 -516.45510756]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [21.07909324 17.98131738 10.21333044 16.12024324 26.62640936  6.75803711\n",
            " 28.50218397 28.62979596 30.42942604 16.33102024]\n",
            "\n",
            "# 4 Gradient out:  [3389.89269928 2977.4499164  1587.13764084 2667.119295   4270.42798071\n",
            " 1080.43508898 4692.01905624 4650.6376908  4998.61446751 2704.86226686]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [-108.36595703  -95.71686033  -50.3887721   -85.72974273 -136.44805194\n",
            "  -34.47770181 -150.68343754 -148.97414019 -160.47554474  -86.96000127]\n",
            "\n",
            "# 5 Gradient out:  [-17753.34293285 -15593.40102456  -8312.0204617  -13968.21759582\n",
            " -22364.95162301  -5657.89571931 -24573.2001143  -24356.44120969\n",
            " -26179.18914395 -14165.87632252]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [569.61258282 499.77312295 267.03875607 447.69411627 717.6375442\n",
            " 181.60931599 787.72037371 781.15339797 839.24734876 454.0124521 ]\n",
            "\n",
            "# 6 Gradient out:  [ 92978.1766448   81665.99404378  43531.88180506  73154.47964563\n",
            " 117130.08938137  29632.0892401  128694.86515302 127559.68917889\n",
            " 137105.48155934  74189.66956426]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [-2981.05600375 -2618.90708197 -1395.36533627 -2345.9494029\n",
            " -3755.3527804   -949.96982787 -4126.91964915 -4090.13484397\n",
            " -4396.59048003 -2379.1628124 ]\n",
            "\n",
            "# 7 Gradient out:  [-486945.850371   -427701.72090288 -227985.46948305 -383125.24501586\n",
            " -613434.47061135 -155188.95656804 -674001.88434517 -668056.69637034\n",
            " -718050.3137083  -388546.73932261]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [15614.57932521 13714.29172679  7311.01102474 12284.94652623\n",
            " 19670.66509587  4976.44802015 21612.05338145 21421.80299181\n",
            " 23024.50583184 12458.77110045]\n",
            "\n",
            "# 8 Gradient out:  [2550237.00666104 2239963.03357524 1194007.39028284 2006506.64657669\n",
            " 3212684.2333405   812757.29737248 3529888.11810303 3498751.96563441\n",
            " 3760578.63469579 2034900.15242493]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [ -81774.59074899  -71826.05245379  -38286.08287187  -64340.10247694\n",
            " -103016.2290264   -26061.34329346 -113188.32348758 -112189.53628226\n",
            " -120585.55690982  -65250.57676407]\n",
            "\n",
            "# 9 Gradient out:  [-13356121.92257883 -11731152.66981859  -6253265.28684436\n",
            " -10508493.07565057 -16825495.96048642  -4256578.78265215\n",
            " -18486759.0087647  -18323692.46181834 -19694933.54753455\n",
            " -10657195.764902  ]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [428272.81058322 376166.55426126 200515.3951847  336961.2268384\n",
            " 539520.6176417  136490.11618103 592789.30013303 587560.85684463\n",
            " 631530.17002934 341729.45372091]\n",
            "\n",
            "# 10 Gradient out:  [6.99487913e+07 6.14384889e+07 3.27496521e+07 5.50351659e+07\n",
            " 8.81186254e+07 2.22925896e+07 9.68190056e+07 9.59649922e+07\n",
            " 1.03146467e+08 5.58139529e+07]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [-2242951.57393254 -1970063.97970245 -1050137.66218417 -1764737.38829172\n",
            " -2825578.57445558  -714825.6403494  -3104562.50161991 -3077177.63551904\n",
            " -3307456.53947757 -1789709.69925949]\n",
            "\n",
            "# 11 Gradient out:  [-3.66336382e+08 -3.21766157e+08 -1.71516746e+08 -2.88230622e+08\n",
            " -4.61495586e+08 -1.16750932e+08 -5.07061289e+08 -5.02588643e+08\n",
            " -5.40199521e+08 -2.92309291e+08]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [11746806.68328201 10317633.79371253  5499792.76277061  9242295.79556745\n",
            " 14798146.50818412  3743692.28171349 16259238.61606238 16115820.79802267\n",
            " 17321836.84039783  9373080.8754226 ]\n",
            "\n",
            "# 12 Gradient out:  [1.91857990e+09 1.68515635e+09 8.98268908e+08 1.50952377e+09\n",
            " 2.41694846e+09 6.11448940e+08 2.65558553e+09 2.63216135e+09\n",
            " 2.82913736e+09 1.53088461e+09]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [-61520469.75787799 -54035597.57639053 -28803556.49492902\n",
            " -48403828.52395044 -77500970.73903395 -19606494.21521056\n",
            " -85153019.14001736 -84401907.73553213 -90718067.40678012\n",
            " -49088777.32394538]\n",
            "\n",
            "# 13 Gradient out:  [-1.00480024e+10 -8.82551464e+09 -4.70442128e+09 -7.90569025e+09\n",
            " -1.26580623e+10 -3.20228539e+09 -1.39078543e+10 -1.37851770e+10\n",
            " -1.48167813e+10 -8.01756142e+09]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [3.22195510e+08 2.82995673e+08 1.50850225e+08 2.53500926e+08\n",
            " 4.05888722e+08 1.02683294e+08 4.45964087e+08 4.42030363e+08\n",
            " 4.75109404e+08 2.57088145e+08]\n",
            "\n",
            "# 14 Gradient out:  [5.26234802e+10 4.62210575e+10 2.46380336e+10 4.14037457e+10\n",
            " 6.62929074e+10 1.67710353e+10 7.28383284e+10 7.21958418e+10\n",
            " 7.75985684e+10 4.19896383e+10]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [-1.68740496e+09 -1.48210726e+09 -7.90034031e+08 -1.32763712e+09\n",
            " -2.12572373e+09 -5.37773785e+08 -2.33560677e+09 -2.31500504e+09\n",
            " -2.48824686e+09 -1.34642414e+09]\n",
            "\n",
            "# 15 Gradient out:  [-2.75600122e+11 -2.42069301e+11 -1.29034511e+11 -2.16840036e+11\n",
            " -3.47189757e+11 -8.78334033e+10 -3.81469490e+11 -3.78104654e+11\n",
            " -4.06399858e+11 -2.19908478e+11]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [8.83729108e+09 7.76210425e+09 4.13757270e+09 6.95311202e+09\n",
            " 1.11328577e+10 2.81643327e+09 1.22320589e+10 1.21241633e+10\n",
            " 1.30314668e+10 7.05150353e+09]\n",
            "\n",
            "# 16 Gradient out:  [1.44337521e+12 1.26776732e+12 6.75780600e+11 1.13563641e+12\n",
            " 1.81830504e+12 4.60001819e+11 1.99783513e+12 1.98021279e+12\n",
            " 2.12840066e+12 1.15170648e+12]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [-4.62827332e+10 -4.06517559e+10 -2.16693296e+10 -3.64148952e+10\n",
            " -5.83050937e+10 -1.47502474e+10 -6.40618390e+10 -6.34967674e+10\n",
            " -6.82485048e+10 -3.69301920e+10]\n",
            "\n",
            "# 17 Gradient out:  [-7.55925648e+12 -6.63956141e+12 -3.53920369e+12 -5.94756432e+12\n",
            " -9.52284204e+12 -2.40912529e+12 -1.04630785e+13 -1.03707866e+13\n",
            " -1.11468774e+13 -6.03172660e+12]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [2.42392309e+11 2.12901709e+11 1.13486790e+11 1.90712387e+11\n",
            " 3.05355914e+11 7.72501164e+10 3.35505188e+11 3.32545790e+11\n",
            " 3.57431628e+11 1.93411104e+11]\n",
            "\n",
            "# 18 Gradient out:  [3.95893999e+13 3.47727654e+13 1.85355465e+13 3.11486325e+13\n",
            " 4.98731063e+13 1.26170907e+13 5.47973205e+13 5.43139686e+13\n",
            " 5.83785175e+13 3.15894080e+13]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [-1.26945899e+12 -1.11501057e+12 -5.94353948e+11 -9.98800476e+11\n",
            " -1.59921249e+12 -4.04574942e+11 -1.75711052e+12 -1.74161154e+12\n",
            " -1.87194385e+12 -1.01293422e+12]\n",
            "\n",
            "# 19 Gradient out:  [-2.07337929e+14 -1.82112212e+14 -9.70745161e+13 -1.63131873e+14\n",
            " -2.61195841e+14 -6.60783307e+13 -2.86984976e+14 -2.84453561e+14\n",
            " -3.05740450e+14 -1.65440306e+14]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [6.64842100e+12 5.83954250e+12 3.11275536e+12 5.23092603e+12\n",
            " 8.37540877e+12 2.11884320e+12 9.20235359e+12 9.12118219e+12\n",
            " 9.80375965e+12 5.30494737e+12]\n",
            "\n",
            "# 20 Gradient out:  [1.08587190e+15 9.53759565e+14 5.08399451e+14 8.54355582e+14\n",
            " 1.36793700e+15 3.46065975e+14 1.50300006e+15 1.48974252e+15\n",
            " 1.60122639e+15 8.66445325e+14]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [-3.48191649e+13 -3.05828998e+13 -1.63021479e+13 -2.73954486e+13\n",
            " -4.38637594e+13 -1.10968229e+13 -4.81946415e+13 -4.77695301e+13\n",
            " -5.13443303e+13 -2.77831138e+13]\n",
            "\n",
            "# 21 Gradient out:  [-5.68693721e+15 -4.99503740e+15 -2.66259376e+15 -4.47443805e+15\n",
            " -7.16417083e+15 -1.81241956e+15 -7.87152424e+15 -7.80209172e+15\n",
            " -8.38595594e+15 -4.53775455e+15]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [1.82355215e+14 1.60169013e+14 8.53777423e+13 1.43475668e+14\n",
            " 2.29723640e+14 5.81163720e+13 2.52405371e+14 2.50178974e+14\n",
            " 2.68900947e+14 1.45505951e+14]\n",
            "\n",
            "# 22 Gradient out:  [2.97836741e+16 2.61600508e+16 1.39445579e+16 2.34335636e+16\n",
            " 3.75202541e+16 9.49201853e+15 4.12248112e+16 4.08611786e+16\n",
            " 4.39189971e+16 2.37651653e+16]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [-9.55032227e+14 -8.38838467e+14 -4.47141011e+14 -7.51411942e+14\n",
            " -1.20311053e+15 -3.04367539e+14 -1.32189948e+15 -1.31023937e+15\n",
            " -1.40829024e+15 -7.62044959e+14]\n",
            "\n",
            "# 23 Gradient out:  [-1.55983302e+17 -1.37005632e+17 -7.30305526e+16 -1.22726451e+17\n",
            " -1.96501382e+17 -4.97116772e+16 -2.15902919e+17 -2.13998499e+17\n",
            " -2.30012931e+17 -1.24463118e+17]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [5.00170260e+15 4.39317169e+15 2.34177056e+15 3.93530078e+15\n",
            " 6.30094030e+15 1.59403617e+15 6.92306276e+15 6.86199636e+15\n",
            " 7.37550918e+15 3.99098810e+15]\n",
            "\n",
            "# 24 Gradient out:  [8.16917026e+17 7.17527018e+17 3.82476208e+17 6.42743974e+17\n",
            " 1.02911865e+18 2.60350403e+17 1.13072853e+18 1.12075469e+18\n",
            " 1.20462561e+18 6.51839261e+17]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [-2.61949578e+16 -2.30079547e+16 -1.22643400e+16 -2.06099894e+16\n",
            " -3.29993361e+16 -8.34829927e+15 -3.62575210e+16 -3.59377035e+16\n",
            " -3.86270771e+16 -2.09016355e+16]\n",
            "\n",
            "# 25 Gradient out:  [-4.27836454e+18 -3.75783838e+18 -2.00310753e+18 -3.36618401e+18\n",
            " -5.38970860e+18 -1.36350926e+18 -5.92186073e+18 -5.86962565e+18\n",
            " -6.30887509e+18 -3.41381792e+18]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [1.37188447e+17 1.20497449e+17 6.42309017e+16 1.07938805e+17\n",
            " 1.72824393e+17 4.37217813e+16 1.89888186e+17 1.88213235e+17\n",
            " 2.02298044e+17 1.09466217e+17]\n",
            "\n",
            "# 26 Gradient out:  [2.24066858e+19 1.96805819e+19 1.04906911e+19 1.76294064e+19\n",
            " 2.82270260e+19 7.14098186e+18 3.10140175e+19 3.07404515e+19\n",
            " 3.30408923e+19 1.78788751e+19]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [-7.18484460e+17 -6.31070226e+17 -3.36390604e+17 -5.65297996e+17\n",
            " -9.05117328e+17 -2.28980071e+17 -9.94483961e+17 -9.85711895e+17\n",
            " -1.05947697e+18 -5.73297367e+17]\n",
            "\n",
            "# 27 Gradient out:  [-1.17348478e+20 -1.03071305e+20 -5.49419336e+19 -9.23288717e+19\n",
            " -1.47830812e+20 -3.73988087e+19 -1.62426866e+20 -1.60994144e+20\n",
            " -1.73042031e+20 -9.36353913e+19]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [3.76285270e+18 3.30504615e+18 1.76174763e+18 2.96058329e+18\n",
            " 4.74028788e+18 1.19921630e+18 5.20831954e+18 5.16237841e+18\n",
            " 5.54870148e+18 3.00247766e+18]\n",
            "\n",
            "# 28 Gradient out:  [6.14578411e+20 5.39805881e+20 2.87742344e+20 4.83545523e+20\n",
            " 7.74220738e+20 1.95865347e+20 8.50663315e+20 8.43159851e+20\n",
            " 9.06257144e+20 4.90388038e+20]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [-1.97068430e+19 -1.73092148e+19 -9.22663909e+18 -1.55051911e+19\n",
            " -2.48258745e+19 -6.28054543e+18 -2.72770537e+19 -2.70364505e+19\n",
            " -2.90597048e+19 -1.57246006e+19]\n",
            "\n",
            "# 29 Gradient out:  [-3.21867509e+21 -2.82707578e+21 -1.50696656e+21 -2.53242857e+21\n",
            " -4.05475519e+21 -1.02578760e+21 -4.45510088e+21 -4.41580368e+21\n",
            " -4.74625733e+21 -2.56826425e+21]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [1.03208839e+20 9.06519614e+19 4.83218298e+19 8.12039135e+19\n",
            " 1.30018273e+20 3.28925240e+19 1.42855609e+20 1.41595520e+20\n",
            " 1.52191724e+20 8.23530070e+19]\n",
            "\n",
            "# 30 Gradient out:  [1.68568715e+22 1.48059844e+22 7.89229761e+21 1.32628556e+22\n",
            " 2.12355971e+22 5.37226321e+21 2.33322908e+22 2.31264832e+22\n",
            " 2.48571378e+22 1.34505345e+22]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [-5.40526178e+20 -4.74763194e+20 -2.53071482e+20 -4.25281801e+20\n",
            " -6.80932764e+20 -1.72264996e+20 -7.48164566e+20 -7.41565215e+20\n",
            " -7.97059743e+20 -4.31299842e+20]\n",
            "\n",
            "# 31 Gradient out:  [-8.82829455e+22 -7.75420228e+22 -4.13336057e+22 -6.94603362e+22\n",
            " -1.11215243e+23 -2.81356609e+22 -1.22196064e+23 -1.21118207e+23\n",
            " -1.30182005e+23 -7.04432496e+22]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [2.83084813e+21 2.48643369e+21 1.32538804e+21 2.22728933e+21\n",
            " 3.56618665e+21 9.02187646e+20 3.91829359e+21 3.88373142e+21\n",
            " 4.17436781e+21 2.25880707e+21]\n",
            "\n",
            "# 32 Gradient out:  [4.62356165e+23 4.06103717e+23 2.16472698e+23 3.63778241e+23\n",
            " 5.82457380e+23 1.47352313e+23 6.39966229e+23 6.34321265e+23\n",
            " 6.81790265e+23 3.68925964e+23]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [-1.48257410e+22 -1.30219709e+22 -6.94133309e+21 -1.16647779e+22\n",
            " -1.86768619e+22 -4.72494453e+21 -2.05209193e+22 -2.03399100e+22\n",
            " -2.18620333e+22 -1.18298429e+22]\n",
            "\n",
            "# 33 Gradient out:  [-2.42145549e+24 -2.12684971e+24 -1.13371259e+24 -1.90518238e+24\n",
            " -3.05045056e+24 -7.71714743e+23 -3.35163637e+24 -3.32207252e+24\n",
            " -3.57067756e+24 -1.93214208e+24]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [7.76454920e+22 6.81987724e+22 3.63532065e+22 6.10908703e+22\n",
            " 9.78146141e+22 2.47455182e+22 1.07472326e+23 1.06524343e+23\n",
            " 1.14496020e+23 6.19553498e+22]\n",
            "\n",
            "# 34 Gradient out:  [1.26816665e+25 1.11387547e+25 5.93748884e+24 9.97783678e+24\n",
            " 1.59758446e+25 4.04163077e+24 1.75532174e+25 1.73983854e+25\n",
            " 1.87003817e+25 1.01190303e+25]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [-4.06645607e+23 -3.57171169e+23 -1.90389311e+23 -3.19945606e+23\n",
            " -5.12275498e+23 -1.29597430e+23 -5.62854948e+23 -5.57890161e+23\n",
            " -5.99639491e+23 -3.24473065e+23]\n",
            "\n",
            "# 35 Gradient out:  [-6.64165278e+25 -5.83359774e+25 -3.10958652e+25 -5.22560085e+25\n",
            " -8.36688244e+25 -2.11668617e+25 -9.19298541e+25 -9.11189665e+25\n",
            " -9.79377923e+25 -5.29954683e+25]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [2.12968770e+24 1.87057977e+24 9.97108457e+23 1.67562175e+24\n",
            " 2.68289343e+24 6.78728723e+23 2.94778854e+24 2.92178692e+24\n",
            " 3.14043685e+24 1.69933299e+24]\n",
            "\n",
            "# 36 Gradient out:  [3.47837183e+26 3.05517658e+26 1.62855520e+26 2.73675595e+26\n",
            " 4.38191052e+26 1.10855262e+26 4.81455785e+26 4.77208998e+26\n",
            " 5.12920608e+26 2.77548301e+26]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [-1.11536179e+25 -9.79661570e+24 -5.22206458e+24 -8.77557994e+24\n",
            " -1.40508714e+25 -3.55464363e+24 -1.54381823e+25 -1.53020064e+25\n",
            " -1.64471216e+25 -8.89976067e+24]\n",
            "\n",
            "# 37 Gradient out:  [-1.82169574e+27 -1.60005958e+27 -8.52908261e+26 -1.43329607e+27\n",
            " -2.29489777e+27 -5.80572084e+26 -2.52148418e+27 -2.49924287e+27\n",
            " -2.68627201e+27 -1.45357823e+27]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [5.84138188e+25 5.13069159e+25 2.73490393e+25 4.59595391e+25\n",
            " 7.35873390e+25 1.86164087e+25 8.08529746e+25 8.01397931e+25\n",
            " 8.61369999e+25 4.66098995e+25]\n",
            "\n",
            "# 38 Gradient out:  [9.54059986e+27 8.37984514e+27 4.46685813e+27 7.50646990e+27\n",
            " 1.20188574e+28 3.04057687e+27 1.32055376e+28 1.30890552e+28\n",
            " 1.40685657e+28 7.61269182e+27]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [-3.05925330e+26 -2.68705000e+26 -1.43232613e+26 -2.40699675e+26\n",
            " -3.85392214e+26 -9.74980081e+25 -4.23443861e+26 -4.19708781e+26\n",
            " -4.51117401e+26 -2.44105747e+26]\n",
            "\n",
            "# 39 Gradient out:  [-4.99661077e+28 -4.38869936e+28 -2.33938659e+28 -3.93129456e+28\n",
            " -6.29452582e+28 -1.59241341e+28 -6.91601495e+28 -6.85501071e+28\n",
            " -7.36800077e+28 -3.98692519e+28]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [1.60219464e+27 1.40726403e+27 7.50139012e+26 1.26059431e+27\n",
            " 2.01837926e+27 5.10617366e+26 2.21766365e+27 2.19810226e+27\n",
            " 2.36259575e+27 1.27843262e+27]\n",
            "\n",
            "# 40 Gradient out:  [2.61682908e+29 2.29845322e+29 1.22518546e+29 2.05890081e+29\n",
            " 3.29657422e+29 8.33980054e+28 3.62206101e+29 3.59011182e+29\n",
            " 3.85877539e+29 2.08803573e+29]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [-8.39102690e+27 -7.37013468e+27 -3.92863418e+27 -6.60199482e+27\n",
            " -1.05706724e+28 -2.67420945e+27 -1.16143662e+28 -1.15119192e+28\n",
            " -1.23734058e+28 -6.69541777e+27]\n",
            "\n",
            "# 41 Gradient out:  [-1.37048787e+30 -1.20374780e+30 -6.41655134e+29 -1.07828922e+30\n",
            " -1.72648455e+30 -4.36772717e+29 -1.89694876e+30 -1.88021630e+30\n",
            " -2.02092101e+30 -1.09354778e+30]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [4.39455548e+28 3.85989297e+28 2.05750751e+28 3.45760213e+28\n",
            " 5.53608119e+28 1.40053916e+28 6.08268540e+28 6.02903173e+28\n",
            " 6.48021021e+28 3.50652968e+28]\n",
            "\n",
            "# 42 Gradient out:  [7.17753029e+30 6.30427784e+30 3.36048152e+30 5.64722511e+30\n",
            " 9.04195901e+30 2.28746965e+30 9.93471557e+30 9.84708422e+30\n",
            " 1.05839841e+31 5.72713739e+30]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [-2.30152019e+29 -2.02150631e+29 -1.07755952e+29 -1.81081822e+29\n",
            " -2.89936098e+29 -7.33491517e+28 -3.18562898e+29 -3.15752943e+29\n",
            " -3.39382100e+29 -1.83644259e+29]\n",
            "\n",
            "# 43 Gradient out:  [-3.75902204e+31 -3.30168155e+31 -1.75995413e+31 -2.95756936e+31\n",
            " -4.73546217e+31 -1.19799548e+31 -5.20301737e+31 -5.15712301e+31\n",
            " -5.54305279e+31 -2.99942108e+31]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [1.20535404e+30 1.05870494e+30 5.64340352e+29 9.48363201e+29\n",
            " 1.51845570e+30 3.84144778e+29 1.66838022e+30 1.65366390e+30\n",
            " 1.77741471e+30 9.61783218e+29]\n",
            "\n",
            "# 44 Gradient out:  [1.96867810e+32 1.72915937e+32 9.21724619e+31 1.54894065e+32\n",
            " 2.48006013e+32 6.27415172e+31 2.72492852e+32 2.70089268e+32\n",
            " 2.90301215e+32 1.57085926e+32]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [-6.31269004e+30 -5.54465817e+30 -2.95556791e+30 -4.96677552e+30\n",
            " -7.95246864e+30 -2.01184618e+30 -8.73765453e+30 -8.66058212e+30\n",
            " -9.30869088e+30 -5.03705894e+30]\n",
            "\n",
            "# 45 Gradient out:  [-1.03103771e+33 -9.05596759e+32 -4.82726372e+32 -8.11212464e+32\n",
            " -1.29885912e+33 -3.28590387e+32 -1.42710179e+33 -1.41451373e+33\n",
            " -1.52036790e+33 -8.22691700e+32]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [3.30608720e+31 2.90385292e+31 1.54789245e+31 2.60120374e+31\n",
            " 4.16487339e+31 1.05364573e+31 4.57609158e+31 4.53572716e+31\n",
            " 4.87515521e+31 2.63801263e+31]\n",
            "\n",
            "# 46 Gradient out:  [5.39975912e+33 4.74279876e+33 2.52813851e+33 4.24848856e+33\n",
            " 6.80239562e+33 1.72089627e+33 7.47402920e+33 7.40810288e+33\n",
            " 7.96248321e+33 4.30860771e+33]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [-1.73146669e+32 -1.52080823e+32 -8.10663500e+31 -1.36230455e+32\n",
            " -2.18123090e+32 -5.51816202e+31 -2.39659443e+32 -2.37545474e+32\n",
            " -2.55322028e+32 -1.38158214e+32]\n",
            "\n",
            "# 47 Gradient out:  [-2.82796627e+34 -2.48390245e+34 -1.32403877e+34 -2.22502190e+34\n",
            " -3.56255620e+34 -9.01269202e+33 -3.91430469e+34 -3.87977770e+34\n",
            " -4.17011822e+34 -2.25650756e+34]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [9.06805155e+32 7.96478930e+32 4.24561352e+32 7.13467256e+32\n",
            " 1.14235603e+33 2.88997633e+32 1.25514640e+33 1.24407510e+33\n",
            " 1.33717461e+33 7.23563328e+32]\n",
            "\n",
            "# 48 Gradient out:  [1.48106481e+35 1.30087142e+35 6.93426668e+34 1.16529029e+35\n",
            " 1.86578485e+35 4.72013444e+34 2.05000286e+35 2.03192036e+35\n",
            " 2.18397773e+35 1.18177998e+35]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [-4.74912738e+33 -4.17132597e+33 -2.22351619e+33 -3.73657655e+33\n",
            " -5.98275637e+33 -1.51354077e+33 -6.57346299e+33 -6.51548031e+33\n",
            " -7.00306183e+33 -3.78945178e+33]\n",
            "\n",
            "# 49 Gradient out:  [-7.75664474e+35 -6.81293448e+35 -3.63161982e+35 -6.10286787e+35\n",
            " -9.77150370e+35 -2.47203268e+35 -1.07362918e+36 -1.06415899e+36\n",
            " -1.14379460e+36 -6.18922781e+35]\n",
            "\n",
            "     Weights  out:  [ 0.06344919 -0.00187795 -0.26144234 -0.05084979  0.23101741 -0.44071259\n",
            "  0.35373613  0.3391126   0.49485115 -0.04481661] [2.48721688e+34 2.18461025e+34 1.16450172e+34 1.95692293e+34\n",
            " 3.13329406e+34 7.92672812e+33 3.44265942e+34 3.41229268e+34\n",
            " 3.66764928e+34 1.98461479e+34]\n"
          ]
        }
      ],
      "source": [
        "train(X, t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KIURxgz_e8v"
      },
      "source": [
        "## Ejercicios\n",
        "### Ejercicio A  (3 puntos)\n",
        "1. Obtenga, a partir del código presentado para el entrenamiento de la PMC-BP, el algoritmo de recuerdo de la red.\n",
        "2. Aplique ahora dicho algoritmo de recuerdo en la etapa denominada *Validación* para el mismo problema de regresión. Determine el error cuadrático de la red en cada época y grafique sus resultados.\n",
        "\n",
        "### Ejercicio B  (5 puntos)\n",
        "1. Use la función tangente hiperbólica en lugar de la lineal en la capa de salida para abordar el mismo problema. Con ese objetivo defina la(s) función(nes) que se requieran e insértelas en el código de modo que la red funcione correctamente. Mantenga inalterada la arquitectura de la red.\n",
        "2. A partir de las modificaciones pedidas, entrene nuevamente la red al mismo problema de regresión. Enseguida aplique el algoritmo de recuerdo.\n",
        "3. Compare los resultados que obtenga con los obtenidos con la red PMC-BP que usaba una función lineal en la salida.\n",
        "\n",
        "### Ejercicio C (4 puntos)\n",
        "1. Modifique la arquitectura de la red PMC usando ahora 4, 6, 8 y 12 neuronas en la capa oculta. Aplique las etapas de entrenamiento/validación de la red.\n",
        "2. Determine el mejor modelo, indicando específicamente con cuántas neuronas ocultas obtuvo la mejor respuesta de la red.\n",
        "\n",
        "### Ejercicio D (8 puntos)\n",
        "1. Modifique la arquitectura de la red PMC usando ahora **dos capas ocultas**, inicialmente con 10 neuronas en la primera capa oculta y 8 neuronas en la segunda capa oculta. Use diferentes números de neuronas en las capas ocultas. Aplique las etapas de entrenamiento/validación de la red para cada combinación.\n",
        "2. Determine con qué combinación de neuronas en las capas ocultas obtuvo el mejor modelo, el que produjo la mejor respuesta de la red.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIjpy3jH_e8v"
      },
      "source": [
        "## Instrucciones para el envío de la solución\n",
        "La solución de la \"Práctica de Laboratorio 8 IA 2025-1 EPISW\" deberá enviarse al correo electrónico rmaguinacursos@gmail.com, hasta las 23:59 h del Domingo 08 de Junio del 2025 en un cuaderno computacional interactivo (archivo con extensión .ipynb).\n",
        "\n",
        "El documento deberá tener las sgtes características:\n",
        "- Nombre del archivo: solPGL8_IA_2025-1_EPISW_nombre-apellidos_integrantes.ipynb.\n",
        "- Todas las preguntas de la Práctica deben responderse en el mismo cci (**Sugerencia**: obtener una copia de este documento y desarrollar en ellas las respectivas soluciones); la solución a cada pregunta debe registrarse en una celda debajo del planteamiento de la misma, mencionando explícitamente como subtítulo: \\\"Solución del ejercicio n\\\", donde \\\"n\\\" corresponde al número del ejercicio.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Solución del ejercicio B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Algoritmo de entramiento con tanh como función de activación de salida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def deriv_tanh(u):\n",
        "    return 1 - np.tanh(u) ** 2\n",
        "\n",
        "def train_tanh(X, t, learning_rate=0.2, epochs=50):\n",
        "    global input_num\n",
        "    global hidden_num\n",
        "    global w1\n",
        "    global w2\n",
        "\n",
        "    input_num = 1\n",
        "    hidden_num = 10\n",
        "    output_num = 1\n",
        "    intervalo = 0.5\n",
        "\n",
        "    # inicializando los pesos\n",
        "    w1 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
        "\n",
        "    w2 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        gradient_out = 0.0                 \n",
        "        gradient_hidden = []\n",
        "\n",
        "        for i in range(X.shape[0]):\n",
        "        # propagacion hacia adelante\n",
        "            x = X[i]\n",
        "\n",
        "            u1 = x * w1\n",
        "            o = logistica(u1)\n",
        "            u2 = o.dot(w2)\n",
        "            y = np.tanh(u2)  #Función de activación tanh para la salida\n",
        "\n",
        "        # backpropagation\n",
        "            delta_hidden_s = []           \n",
        "            gradient_hidden_s = []       \n",
        "\n",
        "            delta_out_s = (t[i] - y)* deriv_tanh(u2)     \n",
        "            gradient_out_s = delta_out_s * o     \n",
        "\n",
        "            for j in range(hidden_num):\n",
        "\n",
        "                delta_hidden_s.append(deriv_logistica(u1[j]) * w2[j] * delta_out_s)\n",
        "                gradient_hidden_s.append(delta_hidden_s[j] * x)\n",
        "\n",
        "\n",
        "            gradient_out = gradient_out + gradient_out_s\n",
        "            gradient_hidden = gradient_hidden + gradient_hidden_s\n",
        "\n",
        "\n",
        "        print(\"\\n#\", epoch, \"Gradient out: \",gradient_out),\n",
        "        print(\"\\n     Weights  out: \", w1, w2)\n",
        "\n",
        "        # Ahora actualizando pesos\n",
        "        w2 = w2 + learning_rate * gradient_out\n",
        "\n",
        "        for j in range(hidden_num):\n",
        "            w1[j] = w1[j] + learning_rate * gradient_hidden[j]\n",
        "\n",
        "def recall_tanh(X, t):\n",
        "    predictions = []\n",
        "    for i in range(X.shape[0]):\n",
        "        x = X[i]\n",
        "        u1 = x * w1\n",
        "        o = logistica(u1)\n",
        "        u2 = o.dot(w2)\n",
        "        y = np.tanh(u2)  # Activación en salida\n",
        "        predictions.append(y)\n",
        "\n",
        "    predictions = np.array(predictions)\n",
        "    mse = np.mean((predictions - t)**2)\n",
        "    print(\"\\nTanh error cuadrático medio (ECM):\", mse)\n",
        "\n",
        "    return predictions, mse\n",
        "\n",
        "def recall(X, t):\n",
        "    predictions = []\n",
        "    for i in range(X.shape[0]):\n",
        "        x = X[i]\n",
        "        u1 = x * w1\n",
        "        o = logistica(u1)\n",
        "        u2 = o.dot(w2)\n",
        "        y = u2  # salida lineal\n",
        "        predictions.append(y)\n",
        "\n",
        "    predictions = np.array(predictions)\n",
        "    mse = np.mean((predictions - t)**2)\n",
        "    print(\"\\nLineal error cuadrático medio (ECM):\", mse)\n",
        "\n",
        "    return predictions, mse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hallando por cada algoritmo el promedio de sus MSE de 10 entrenamientos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "# 0 Gradient out:  [-0.30212572 -1.58649243 -1.33859348 -0.81874667 -0.19067526 -1.71732829\n",
            " -1.14505589 -0.17059909 -0.90466491 -1.50675992]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.34889113  0.38083148  0.04620543  0.47276791 -0.34887285 -0.01869391\n",
            " -0.22296936 -0.16979309  0.16439634  0.06628098]\n",
            "\n",
            "# 1 Gradient out:  [1.10587404 3.15440942 2.81212633 1.88418706 0.96370972 3.31982755\n",
            " 2.49042089 0.93639162 2.04326017 3.05130954]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.28846599  0.06353299 -0.22151326  0.30901858 -0.3870079  -0.36215957\n",
            " -0.45198054 -0.20391291 -0.01653664 -0.235071  ]\n",
            "\n",
            "# 2 Gradient out:  [-0.16040196 -0.48086076 -0.42190965 -0.28680935 -0.13411334 -0.51151357\n",
            " -0.37296714 -0.12921825 -0.30946312 -0.46223415]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.5096408   0.69441487  0.340912    0.68585599 -0.19426595  0.30180595\n",
            "  0.04610364 -0.01663458  0.39211539  0.37519091]\n",
            "\n",
            "# 3 Gradient out:  [-0.28583354 -0.93422593 -0.81503666 -0.54151794 -0.23308015 -0.99584585\n",
            " -0.71593881 -0.2233117  -0.58737968 -0.89661974]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.4775604   0.59824272  0.25653007  0.62849412 -0.22108862  0.19950323\n",
            " -0.02848979 -0.04247823  0.33022277  0.28274408]\n",
            "\n",
            "# 4 Gradient out:  [-0.47178081 -1.91358611 -1.64221293 -1.04578907 -0.35069899 -2.05535067\n",
            " -1.42333315 -0.32856673 -1.1451237  -1.82714877]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 4.20393696e-01  4.11397536e-01  9.35227434e-02  5.20190536e-01\n",
            " -2.67704652e-01  3.34061088e-04 -1.71677554e-01 -8.71405723e-02\n",
            "  2.12746835e-01  1.03420130e-01]\n",
            "\n",
            "# 5 Gradient out:  [1.08699669 3.00506044 2.68111715 1.8187436  0.94938666 3.1646436\n",
            " 2.38101682 0.92274732 1.9663047  2.90672953]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.32603753  0.02868031 -0.23491984  0.31103272 -0.33784445 -0.41073607\n",
            " -0.45634418 -0.15285392 -0.0162779  -0.26200962]\n",
            "\n",
            "# 6 Gradient out:  [-0.20557882 -0.66943281 -0.58423634 -0.38843343 -0.16782725 -0.71350881\n",
            " -0.51333237 -0.16082434 -0.42127312 -0.64255555]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.54343687  0.6296924   0.30130359  0.67478144 -0.14796712  0.22219265\n",
            "  0.01985918  0.03169555  0.37698304  0.31933628]\n",
            "\n",
            "# 7 Gradient out:  [-0.41384511 -1.49850783 -1.29836874 -0.84221441 -0.32544732 -1.60188846\n",
            " -1.13272573 -0.30915555 -0.91860964 -1.43529902]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 5.02321108e-01  4.95805840e-01  1.84456317e-01  5.97094757e-01\n",
            " -1.81532567e-01  7.94908856e-02 -8.28072938e-02 -4.69321545e-04\n",
            "  2.92728412e-01  1.90825172e-01]\n",
            "\n",
            "# 8 Gradient out:  [0.50696473 1.59430878 1.44401378 0.89297216 0.4617539  1.64858979\n",
            " 1.26442593 0.45321483 0.99019372 1.55478157]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.41955209  0.19610427 -0.07521743  0.42865187 -0.24662203 -0.24088681\n",
            " -0.30935244 -0.06230043  0.10900648 -0.09623463]\n",
            "\n",
            "# 9 Gradient out:  [-0.37227725 -1.33234659 -1.15552489 -0.7511588  -0.29421684 -1.42361683\n",
            " -1.00883358 -0.27981323 -0.8189157  -1.27654296]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.52094503  0.51496603  0.21358533  0.60724631 -0.15427125  0.08883115\n",
            " -0.05646725  0.02834254  0.30704523  0.21472168]\n",
            "\n",
            "# 10 Gradient out:  [0.04855723 0.05098715 0.09013584 0.01534346 0.08361648 0.01143969\n",
            " 0.07898793 0.09010091 0.03172261 0.06970984]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.44648958  0.24849671 -0.01751965  0.45701455 -0.21311462 -0.19589222\n",
            " -0.25823397 -0.02762011  0.14326209 -0.04058691]\n",
            "\n",
            "# 11 Gradient out:  [-0.05322697 -0.28656881 -0.20692872 -0.17695965 -0.00133669 -0.34581772\n",
            " -0.18128602  0.00829766 -0.17842649 -0.25551132]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.45620103  0.25869414  0.00050752  0.46008324 -0.19639132 -0.19360428\n",
            " -0.24243638 -0.00959993  0.14960661 -0.02664494]\n",
            "\n",
            "# 12 Gradient out:  [0.34775674 1.17747432 1.07381402 0.63278182 0.32394367 1.20706689\n",
            " 0.93366671 0.31954241 0.7114585  1.15265739]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.44555563  0.20138038 -0.04087823  0.42469131 -0.19665866 -0.26276782\n",
            " -0.27869359 -0.00794039  0.11392131 -0.07774721]\n",
            "\n",
            "# 13 Gradient out:  [-0.47755424 -1.80079721 -1.55464607 -1.00186578 -0.36802805 -1.92883643\n",
            " -1.35309406 -0.3478507  -1.09424614 -1.72274939]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.51510698  0.43687524  0.17388458  0.55124767 -0.13186993 -0.02135444\n",
            " -0.09196025  0.05596809  0.25621301  0.15278427]\n",
            "\n",
            "# 14 Gradient out:  [1.05277912 3.18599683 2.83638599 1.85737148 0.91170883 3.35061969\n",
            " 2.49940739 0.88468891 2.02578707 3.08198357]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.41959614  0.0767158  -0.13704464  0.35087452 -0.20547554 -0.40712173\n",
            " -0.36257906 -0.01360205  0.03736378 -0.19176561]\n",
            "\n",
            "# 15 Gradient out:  [-0.09380092 -0.30241511 -0.26411516 -0.17602448 -0.07678871 -0.32226338\n",
            " -0.23222847 -0.07362538 -0.19080186 -0.29032988]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.63015196  0.71391517  0.43023256  0.72234881 -0.02313377  0.26300221\n",
            "  0.13730242  0.16333573  0.4425212   0.42463111]\n",
            "\n",
            "# 16 Gradient out:  [-0.14252022 -0.47784548 -0.41632617 -0.27464761 -0.1152921  -0.50963713\n",
            " -0.36504915 -0.11024081 -0.29841629 -0.45844943]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.61139177  0.65343215  0.37740953  0.68714392 -0.03849151  0.19854953\n",
            "  0.09085673  0.14861065  0.40436082  0.36656513]\n",
            "\n",
            "# 17 Gradient out:  [-0.26155508 -0.93104013 -0.80811539 -0.52543553 -0.20733945 -0.99440787\n",
            " -0.70573474 -0.19731659 -0.5728423  -0.89229437]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.58288773  0.55786305  0.2941443   0.63221439 -0.06154993  0.09662211\n",
            "  0.0178469   0.12656249  0.34467756  0.27487524]\n",
            "\n",
            "# 18 Gradient out:  [-0.51218711 -1.95158338 -1.67801109 -1.08754713 -0.38752718 -2.09699431\n",
            " -1.46038661 -0.3644986  -1.18566362 -1.86388143]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.53057671  0.37165502  0.13252122  0.52712729 -0.10301782 -0.10225947\n",
            " -0.12330005  0.08709917  0.23010911  0.09641637]\n",
            "\n",
            "# 19 Gradient out:  [1.09791655 2.92320106 2.61060871 1.79802682 0.96068098 3.08150534\n",
            " 2.32649828 0.93377522 1.93674382 2.82731349]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.42813929 -0.01866165 -0.203081    0.30961786 -0.18052326 -0.52165833\n",
            " -0.41537737  0.01419945 -0.00702362 -0.27635992]\n",
            "\n",
            "# 20 Gradient out:  [-0.21122876 -0.77130551 -0.66862074 -0.43185513 -0.16603094 -0.82414459\n",
            " -0.58292603 -0.15767787 -0.47157556 -0.7389669 ]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [0.6477226  0.56597856 0.31904074 0.66922322 0.01161294 0.09464274\n",
            " 0.04992228 0.2009545  0.38032515 0.28910278]\n",
            "\n",
            "# 21 Gradient out:  [-0.46200716 -1.76753251 -1.52418032 -0.97973429 -0.35318428 -1.89462866\n",
            " -1.32549611 -0.33307967 -1.07068047 -1.69026245]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.60547685  0.41171746  0.18531659  0.5828522  -0.02159325 -0.07018618\n",
            " -0.06666292  0.16941892  0.28601003  0.1413094 ]\n",
            "\n",
            "# 22 Gradient out:  [0.91230376 2.97214491 2.63741813 1.68674643 0.77945581 3.12751726\n",
            " 2.31114519 0.75411707 1.85051589 2.87316128]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.51307542  0.05821096 -0.11951947  0.38690534 -0.09223011 -0.44911191\n",
            " -0.33176214  0.10280299  0.07187394 -0.19674309]\n",
            "\n",
            "# 23 Gradient out:  [-0.10972401 -0.38847484 -0.33742439 -0.21948205 -0.08722073 -0.41476759\n",
            " -0.29476684 -0.08305326 -0.23927561 -0.3723999 ]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [0.69553617 0.65263994 0.40796416 0.72425463 0.06366106 0.17639154\n",
            " 0.13046689 0.2536264  0.44197712 0.37788917]\n",
            "\n",
            "# 24 Gradient out:  [-0.18593377 -0.68550627 -0.59398112 -0.38266866 -0.14568614 -0.73256292\n",
            " -0.51752442 -0.13824898 -0.41812516 -0.65669398]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [0.67359137 0.57494497 0.34047928 0.68035822 0.04621691 0.09343802\n",
            " 0.07151353 0.23701575 0.39412199 0.30340919]\n",
            "\n",
            "# 25 Gradient out:  [-0.40209423 -1.54931768 -1.33690608 -0.85580675 -0.30780983 -1.65950517\n",
            " -1.16191511 -0.2904022  -0.93631    -1.48210675]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.63640461  0.43784371  0.22168305  0.60382448  0.01707968 -0.05307456\n",
            " -0.03199136  0.20936595  0.31049696  0.17207039]\n",
            "\n",
            "# 26 Gradient out:  [0.401142   1.77117379 1.57433033 0.89391999 0.34081745 1.84422097\n",
            " 1.34966888 0.32995741 1.01326912 1.7181635 ]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.55598577  0.12798018 -0.04569816  0.43266313 -0.04448228 -0.3849756\n",
            " -0.26437438  0.15128551  0.12323496 -0.12435096]\n",
            "\n",
            "# 27 Gradient out:  [-0.33023389 -1.25970126 -1.08857238 -0.69699275 -0.25473127 -1.34798352\n",
            " -0.94653286 -0.24079749 -0.76261042 -1.20570893]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.63621417  0.48221494  0.2691679   0.61144713  0.02368121 -0.0161314\n",
            "  0.0055594   0.217277    0.32588879  0.21928174]\n",
            "\n",
            "# 28 Gradient out:  [-0.25499275 -0.63845272 -0.52821205 -0.44055845 -0.18481692 -0.7179198\n",
            " -0.48086339 -0.17125297 -0.45150002 -0.59689826]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.57016739  0.23027468  0.05145343  0.47204858 -0.02726505 -0.28572811\n",
            " -0.18374718  0.1691175   0.1733667  -0.02186005]\n",
            "\n",
            "# 29 Gradient out:  [0.65831585 2.44180915 2.16606957 1.31666987 0.55900451 2.55944571\n",
            " 1.87934146 0.54047836 1.46414905 2.36315031]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.51916884  0.10258414 -0.05418898  0.38393689 -0.06422843 -0.42931206\n",
            " -0.27991985  0.1348669   0.0830667  -0.1412397 ]\n",
            "\n",
            "# 30 Gradient out:  [-0.17618626 -0.64084956 -0.55570643 -0.35918543 -0.13870475 -0.6846618\n",
            " -0.48460106 -0.13177385 -0.39215988 -0.6140401 ]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [0.65083201 0.59094597 0.37902493 0.64727086 0.04757247 0.08257708\n",
            " 0.09594844 0.24296258 0.37589651 0.33139036]\n",
            "\n",
            "# 31 Gradient out:  [-0.37157649 -1.42188836 -1.22803236 -0.78643204 -0.28582767 -1.52213206\n",
            " -1.06765585 -0.27000183 -0.86038538 -1.36064834]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.61559476  0.46277606  0.26788365  0.57543378  0.01983152 -0.05435528\n",
            " -0.00097177  0.21660781  0.29746453  0.20858234]\n",
            "\n",
            "# 32 Gradient out:  [0.09752736 0.72211347 0.65885822 0.2992937  0.09616251 0.72660069\n",
            " 0.54891085 0.0964535  0.3644783  0.7108348 ]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.54127946  0.17839839  0.02227717  0.41814737 -0.03733401 -0.35878169\n",
            " -0.21450294  0.16260744  0.12538745 -0.06354733]\n",
            "\n",
            "# 33 Gradient out:  [-0.50500529 -1.85589534 -1.59144139 -1.05165133 -0.38000842 -2.00108822\n",
            " -1.38943284 -0.35672972 -1.14060978 -1.76979738]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.56078493  0.32282108  0.15404882  0.47800611 -0.01810151 -0.21346155\n",
            " -0.10472077  0.18189814  0.19828311  0.07861963]\n",
            "\n",
            "# 34 Gradient out:  [1.08061112 2.80357337 2.50556171 1.74403338 0.9468969  2.95729938\n",
            " 2.23837052 0.92047868 1.87380931 2.71149547]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.45978387 -0.04835799 -0.16423946  0.26767584 -0.09410319 -0.6136792\n",
            " -0.38260734  0.1105522  -0.02983884 -0.27533984]\n",
            "\n",
            "# 35 Gradient out:  [-0.25307324 -0.97761897 -0.84466842 -0.53858422 -0.1946326  -1.0459724\n",
            " -0.73382029 -0.18385009 -0.58991842 -0.93574621]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.6759061   0.51235669  0.33687288  0.61648252  0.09527619 -0.02221932\n",
            "  0.06506676  0.29464793  0.34492302  0.26695925]\n",
            "\n",
            "# 36 Gradient out:  [-0.51953572 -1.90657825 -1.63671882 -1.07937495 -0.39227447 -2.05432699\n",
            " -1.42889649 -0.36850487 -1.17140777 -1.81893126]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.62529145  0.31683289  0.1679392   0.50876568  0.05634967 -0.2314138\n",
            " -0.0816973   0.25787791  0.22693933  0.07981001]\n",
            "\n",
            "# 37 Gradient out:  [1.07027694 2.79850573 2.49850847 1.7366643  0.93445808 2.95441894\n",
            " 2.23088349 0.90752647 1.86641559 2.70555681]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.5213843  -0.06448276 -0.15940457  0.29289069 -0.02210523 -0.6422792\n",
            " -0.3674766   0.18417694 -0.00734222 -0.28397624]\n",
            "\n",
            "# 38 Gradient out:  [-0.23916822 -0.9567675  -0.82517596 -0.52186938 -0.18144301 -1.02430972\n",
            " -0.71535531 -0.17080341 -0.57274305 -0.91534621]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.73543969  0.49521839  0.34029713  0.64022355  0.16478639 -0.05139541\n",
            "  0.0787001   0.36568223  0.3659409   0.25713512]\n",
            "\n",
            "# 39 Gradient out:  [-0.51682815 -1.90163541 -1.63207959 -1.07588549 -0.38923452 -2.04963846\n",
            " -1.42467657 -0.36533377 -1.16772584 -1.81402459]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.68760605  0.30386489  0.17526194  0.53584967  0.12849779 -0.25625736\n",
            " -0.06437096  0.33152155  0.25139229  0.07406588]\n",
            "\n",
            "# 40 Gradient out:  [1.03659171 2.78812878 2.4838824  1.71214554 0.89850132 2.94657218\n",
            " 2.21273458 0.8710836  1.84356996 2.69380247]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.58424042 -0.07646219 -0.15115398  0.32067257  0.05065088 -0.66618505\n",
            " -0.34930628  0.2584548   0.01784712 -0.28873904]\n",
            "\n",
            "# 41 Gradient out:  [-0.22451841 -0.92646506 -0.7978418  -0.50096876 -0.1682188  -0.99236535\n",
            " -0.69037802 -0.157853   -0.55077005 -0.88600353]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.79155876  0.48116356  0.3456225   0.66310168  0.23035115 -0.07687061\n",
            "  0.09324064  0.43267152  0.38656111  0.25002146]\n",
            "\n",
            "# 42 Gradient out:  [-0.50505311 -1.88915247 -1.62062055 -1.063063   -0.37821506 -2.03627209\n",
            " -1.41309117 -0.3544357  -1.1552204  -1.80200008]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.74665508  0.29587055  0.18605414  0.56290793  0.19670739 -0.27534368\n",
            " -0.04483496  0.40110092  0.2764071   0.07282075]\n",
            "\n",
            "# 43 Gradient out:  [0.9708857  2.76254651 2.45262213 1.66079414 0.83133153 2.92284729\n",
            " 2.17484262 0.8036884  1.79574344 2.66673306]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.64564446 -0.08195994 -0.13806997  0.35029533  0.12106437 -0.6825981\n",
            " -0.3274532   0.33021378  0.04536302 -0.28757927]\n",
            "\n",
            "# 44 Gradient out:  [-0.21102624 -0.89322402 -0.76831895 -0.47961305 -0.15647066 -0.9571071\n",
            " -0.66384093 -0.14643612 -0.52805145 -0.8539568 ]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.8398216   0.47054936  0.35245445  0.68245416  0.28733068 -0.09802864\n",
            "  0.10751533  0.49095146  0.40451171  0.24576734]\n",
            "\n",
            "# 45 Gradient out:  [-0.48701937 -1.86375318 -1.59798718 -1.04090612 -0.36217405 -2.00863424\n",
            " -1.3911794  -0.33878284 -1.13311592 -1.77771674]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.79761635  0.29190456  0.19879066  0.58653155  0.25603655 -0.28945006\n",
            " -0.02525286  0.46166424  0.29890142  0.07497599]\n",
            "\n",
            "# 46 Gradient out:  [0.87531087 2.70536477 2.39183805 1.57736359 0.73692578 2.86479167\n",
            " 2.10709768 0.70969254 1.71641075 2.60910011]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.70021247 -0.08084608 -0.12080677  0.37835032  0.18360174 -0.69117691\n",
            " -0.30348874  0.39390767  0.07227824 -0.28056736]\n",
            "\n",
            "# 47 Gradient out:  [-0.2045203  -0.8820244  -0.75803242 -0.47121286 -0.15044141 -0.94536661\n",
            " -0.65425062 -0.14050209 -0.51933812 -0.84305937]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.87527465  0.46022687  0.35756084  0.69382304  0.33098689 -0.11821857\n",
            "  0.1179308   0.53584618  0.41556039  0.24125266]\n",
            "\n",
            "# 48 Gradient out:  [-0.47617793 -1.8404618  -1.57706087 -1.02509097 -0.35236156 -1.98412617\n",
            " -1.37213947 -0.32915092 -1.11645207 -1.75517954]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.83437059  0.283822    0.20595435  0.59958047  0.30089861 -0.3072919\n",
            " -0.01291933  0.50774576  0.31169276  0.07264078]\n",
            "\n",
            "# 49 Gradient out:  [0.80325056 2.63045044 2.31927242 1.50259298 0.66764265 2.78697801\n",
            " 2.03435686 0.64107065 1.64216088 2.53531801]\n",
            "\n",
            "     Weights  out:  [-0.35903762  0.32954707  0.18081846 -0.06791612 -0.4647426   0.44286497\n",
            "  0.08508216 -0.48938243 -0.02758821  0.2760401 ] [ 0.739135   -0.08427037 -0.10945782  0.39456228  0.2304263  -0.70411713\n",
            " -0.28734722  0.44191558  0.08840235 -0.27839512]\n",
            "\n",
            "Lineal error cuadrático medio (ECM): 2.4235061672486706\n",
            "\n",
            "# 0 Gradient out:  [-1.98252553 -0.33954405 -1.93171986 -0.39380665 -0.46373867 -0.95628884\n",
            " -0.8660354  -1.22981013 -1.82841981 -0.39164052]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.35128693  0.34030614 -0.0135779   0.15911283  0.21084769  0.04214927\n",
            " -0.45620102 -0.19096599  0.40716873  0.43483938]\n",
            "\n",
            "# 1 Gradient out:  [3.47011905 0.98107969 3.40703197 1.04775517 1.13243168 1.85266993\n",
            " 1.69806059 2.35864446 3.28171402 1.04512687]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [-0.04521817  0.27239733 -0.39992188  0.0803515   0.11809996 -0.1491085\n",
            " -0.6294081  -0.43692801  0.04148477  0.35651128]\n",
            "\n",
            "# 2 Gradient out:  [-0.80831154 -0.1624345  -0.79005766 -0.18190773 -0.20706351 -0.39842777\n",
            " -0.36104061 -0.51543279 -0.75288234 -0.18113086]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.64880564  0.46861327  0.28148452  0.28990253  0.34458629  0.22142549\n",
            " -0.28979599  0.03480088  0.69782758  0.56553665]\n",
            "\n",
            "# 3 Gradient out:  [-1.72233264 -0.32330061 -1.68220067 -0.36612648 -0.42144378 -0.83682663\n",
            " -0.75652484 -1.08683737 -1.60045961 -0.36441751]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.48714333  0.43612637  0.12347299  0.25352099  0.30317359  0.14173993\n",
            " -0.36200411 -0.06828568  0.54725111  0.52931048]\n",
            "\n",
            "# 4 Gradient out:  [1.11360057 0.23767074 1.10497837 0.24690642 0.2603564  0.50277398\n",
            " 0.4354723  0.74240558 1.08498791 0.24652758]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.1426768   0.37146625 -0.21296715  0.18029569  0.21888484 -0.02562539\n",
            " -0.51330908 -0.28565315  0.22715919  0.45642698]\n",
            "\n",
            "# 5 Gradient out:  [-2.15332728 -0.39538573 -2.10018843 -0.45206485 -0.5249574  -1.04950737\n",
            " -0.95130403 -1.35058924 -1.99249153 -0.44980594]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.36539691  0.41900039  0.00802852  0.22967698  0.27095611  0.0749294\n",
            " -0.42621462 -0.13717204  0.44415677  0.5057325 ]\n",
            "\n",
            "# 6 Gradient out:  [3.45722281 0.95757371 3.39356226 1.02481995 1.11007432 1.83316037\n",
            " 1.67802769 2.34083557 3.267384   1.02217134]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [-0.06526854  0.33992325 -0.41200916  0.13926401  0.16596464 -0.13497207\n",
            " -0.61647542 -0.40728989  0.04565846  0.41577131]\n",
            "\n",
            "# 7 Gradient out:  [-0.77502207 -0.14731252 -0.75735706 -0.16616326 -0.19054124 -0.37653681\n",
            " -0.3401519  -0.49044984 -0.72133175 -0.16541086]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.62617602  0.53143799  0.26670329  0.344228    0.3879795   0.23166\n",
            " -0.28086989  0.06087723  0.69913526  0.62020558]\n",
            "\n",
            "# 8 Gradient out:  [-1.630802   -0.29651996 -1.5925619  -0.33732373 -0.39002286 -0.78611762\n",
            " -0.70948449 -1.02479175 -1.5146887  -0.33569561]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.4711716   0.50197548  0.11523188  0.31099534  0.34987125  0.15635264\n",
            " -0.34890026 -0.03721274  0.55486891  0.58712341]\n",
            "\n",
            "# 9 Gradient out:  [ 0.29931384  0.00493637  0.30809867 -0.00418684 -0.01366656  0.05851705\n",
            "  0.02487526  0.19160398  0.32202959 -0.0038457 ]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.1450112   0.44267149 -0.2032805   0.2435306   0.27186668 -0.00087088\n",
            " -0.49079716 -0.24217109  0.25193117  0.51998428]\n",
            "\n",
            "# 10 Gradient out:  [-0.86229066 -0.19429812 -0.83025074 -0.22827221 -0.27033901 -0.47964043\n",
            " -0.4536814  -0.53965853 -0.76814133 -0.22693522]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.20487397  0.44365877 -0.14166076  0.24269323  0.26913337  0.01083253\n",
            " -0.48582211 -0.20385029  0.31633709  0.51921514]\n",
            "\n",
            "# 11 Gradient out:  [2.72869835 0.61008702 2.68406286 0.65750328 0.7194061  1.32747724\n",
            " 1.18803728 1.79457229 2.59242653 0.65561518]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.03241584  0.40479914 -0.30771091  0.19703879  0.21506557 -0.08509556\n",
            " -0.57655839 -0.311782    0.16270882  0.4738281 ]\n",
            "\n",
            "# 12 Gradient out:  [-0.98810567 -0.18741354 -0.9654989  -0.21153717 -0.24272575 -0.48004854\n",
            " -0.43371058 -0.62499695 -0.91940946 -0.21057437]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.57815551  0.52681655  0.22910166  0.32853944  0.35894679  0.18039989\n",
            " -0.33895093  0.04713246  0.68119413  0.60495113]\n",
            "\n",
            "# 13 Gradient out:  [-2.08311523 -0.38073915 -2.03276775 -0.43443541 -0.50356409 -1.0102488\n",
            " -0.91396977 -1.30760453 -1.93062286 -0.43229515]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.38053438  0.48933384  0.03600188  0.28623201  0.31040164  0.08439018\n",
            " -0.42569305 -0.07786693  0.49731224  0.56283626]\n",
            "\n",
            "# 14 Gradient out:  [3.2968675  0.80805514 3.23774607 0.87065904 0.95094831 1.66916481\n",
            " 1.51121174 2.1905836  3.11891416 0.86818214]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [-0.03608867  0.41318601 -0.37055167  0.19934493  0.20968882 -0.11765958\n",
            " -0.608487   -0.33938784  0.11118767  0.47637723]\n",
            "\n",
            "# 15 Gradient out:  [-0.70253193 -0.13193721 -0.68650052 -0.14904564 -0.17117605 -0.3402349\n",
            " -0.30713808 -0.44388669 -0.65379662 -0.14836271]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.62328483  0.57479704  0.27699754  0.37347673  0.39987848  0.21617338\n",
            " -0.30624466  0.09872888  0.7349705   0.65001366]\n",
            "\n",
            "# 16 Gradient out:  [-1.43267334 -0.25818622 -1.39924322 -0.29386163 -0.33997066 -0.68843768\n",
            " -0.62076212 -0.8995801  -1.33110727 -0.29243779]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.48277845  0.5484096   0.13969744  0.3436676   0.36564327  0.1481264\n",
            " -0.36767227  0.00995154  0.60421117  0.62034111]\n",
            "\n",
            "# 17 Gradient out:  [-1.14124744 -0.26347064 -1.10331784 -0.30366013 -0.35353439 -0.62395045\n",
            " -0.58548523 -0.72412786 -1.02965637 -0.30207898]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.19624378  0.49677235 -0.1401512   0.28489528  0.29764914  0.01043887\n",
            " -0.4918247  -0.16996448  0.33798972  0.56185356]\n",
            "\n",
            "# 18 Gradient out:  [3.13620727 0.72702517 3.08078044 0.78578381 0.86155088 1.55602446\n",
            " 1.401638   2.06756264 2.9686402  0.78345414]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [-0.03200571  0.44407822 -0.36081477  0.22416325  0.22694226 -0.11435122\n",
            " -0.60892174 -0.31479005  0.13205845  0.50143776]\n",
            "\n",
            "# 19 Gradient out:  [-0.78034567 -0.14421723 -0.76247165 -0.1632935  -0.18797416 -0.37647512\n",
            " -0.33958572 -0.49197881 -0.72599932 -0.16253193]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.59523575  0.58948326  0.25534132  0.38132002  0.39925244  0.19685367\n",
            " -0.32859414  0.09872248  0.72578649  0.65812859]\n",
            "\n",
            "# 20 Gradient out:  [-1.64306066 -0.29319772 -1.6043303  -0.33452321 -0.38788835 -0.78864432\n",
            " -0.71115648 -1.02991017 -1.52547296 -0.33287437]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 4.39166611e-01  5.60639813e-01  1.02846986e-01  3.48661317e-01\n",
            "  3.61657604e-01  1.21558645e-01 -3.96511287e-01  3.26717829e-04\n",
            "  5.80586622e-01  6.25622202e-01]\n",
            "\n",
            "# 21 Gradient out:  [ 0.36865995 -0.005394    0.37613579 -0.01306128 -0.02037996  0.075271\n",
            "  0.03632164  0.22584396  0.38687815 -0.01278207]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.11055448  0.50200027 -0.21801907  0.28175668  0.28407993 -0.03617022\n",
            " -0.53874258 -0.20565532  0.27549203  0.55904733]\n",
            "\n",
            "# 22 Gradient out:  [-1.01153909 -0.23340856 -0.97637289 -0.27067866 -0.31687205 -0.55824224\n",
            " -0.52573582 -0.6392759  -0.90815728 -0.26921239]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.18428647  0.50092147 -0.14279192  0.27914442  0.28000394 -0.02111602\n",
            " -0.53147825 -0.16048652  0.35286766  0.55649091]\n",
            "\n",
            "# 23 Gradient out:  [2.98609986 0.67567155 2.93482115 0.73008847 0.80064184 1.46560416\n",
            " 1.31592018 1.96373752 2.83039257 0.72792659]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [-0.01802135  0.45423976 -0.33806649  0.22500869  0.21662953 -0.13276447\n",
            " -0.63662542 -0.2883417   0.1712362   0.50264844]\n",
            "\n",
            "# 24 Gradient out:  [-0.84207703 -0.15754525 -0.82280297 -0.17811365 -0.20471417 -0.40756726\n",
            " -0.36790208 -0.53172262 -0.78349343 -0.17729266]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.57919862  0.58937407  0.24889774  0.37102638  0.3767579   0.16035636\n",
            " -0.37344138  0.1044058   0.73731472  0.64823375]\n",
            "\n",
            "# 25 Gradient out:  [-1.80254229 -0.32455543 -1.75985303 -0.37010001 -0.42887189 -0.86789359\n",
            " -0.78331986 -1.13077923 -1.67300726 -0.36828327]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.41078322  0.55786502  0.08433714  0.33540365  0.33581507  0.07884291\n",
            " -0.4470218  -0.00193872  0.58061603  0.61277522]\n",
            "\n",
            "# 26 Gradient out:  [1.65375089 0.28681979 1.63313968 0.30891841 0.33939315 0.72633357\n",
            " 0.6289992  1.06234712 1.58799059 0.3080213 ]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.05027476  0.49295393 -0.26763346  0.26138365  0.25004069 -0.09473581\n",
            " -0.60368577 -0.22809457  0.24601458  0.53911857]\n",
            "\n",
            "# 27 Gradient out:  [-1.96600964 -0.35578937 -1.91902862 -0.40590492 -0.470509   -0.94920821\n",
            " -0.85752145 -1.23344218 -1.82356665 -0.40390653]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.38102494  0.55031789  0.05899447  0.32316733  0.31791932  0.05053091\n",
            " -0.47788593 -0.01562515  0.5636127   0.60072283]\n",
            "\n",
            "# 28 Gradient out:  [2.76432196 0.59504127 2.71824164 0.64400672 0.70793596 1.33115303\n",
            " 1.18883106 1.80712991 2.62361236 0.64205638]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [-0.01217699  0.47916002 -0.32481125  0.24198635  0.22381752 -0.13931074\n",
            " -0.64939022 -0.26231358  0.19889937  0.51994152]\n",
            "\n",
            "# 29 Gradient out:  [-0.9921901  -0.18352416 -0.96937984 -0.2078669  -0.2393475  -0.47904341\n",
            " -0.43223152 -0.62548172 -0.9228591  -0.20689523]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.5406874   0.59816827  0.21883708  0.37078769  0.36540471  0.12691987\n",
            " -0.41162401  0.0991124   0.72362184  0.6483528 ]\n",
            "\n",
            "# 30 Gradient out:  [-2.08883165 -0.3783421  -2.03808132 -0.4324577  -0.50207895 -1.01120999\n",
            " -0.91459326 -1.30944448 -1.93520769 -0.43030139]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.34224938  0.56146344  0.02496111  0.32921431  0.31753521  0.03111119\n",
            " -0.49807031 -0.02598395  0.53905002  0.60697375]\n",
            "\n",
            "# 31 Gradient out:  [3.26828948 0.78235834 3.20912405 0.8450112  0.92535948 1.64288875\n",
            " 1.48524229 2.16309056 3.09020629 0.8425323 ]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [-0.07551695  0.48579502 -0.38265516  0.24272277  0.21711942 -0.17113081\n",
            " -0.68098896 -0.28787284  0.15200848  0.52091347]\n",
            "\n",
            "# 32 Gradient out:  [-0.74123529 -0.13542466 -0.72423002 -0.15357443 -0.17706025 -0.35656966\n",
            " -0.32142425 -0.46663328 -0.68952341 -0.1528498 ]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.57814095  0.64226669  0.25916965  0.41172501  0.40219132  0.15744694\n",
            " -0.38394051  0.14474527  0.77004974  0.68941993]\n",
            "\n",
            "# 33 Gradient out:  [-1.53826534 -0.27171136 -1.50208695 -0.31031746 -0.36019666 -0.73609521\n",
            " -0.66323849 -0.96318971 -1.42838028 -0.30877684]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.42989389  0.61518176  0.11432365  0.38101012  0.36677926  0.08613301\n",
            " -0.44822536  0.05141861  0.63214506  0.65884997]\n",
            "\n",
            "# 34 Gradient out:  [-0.45928866 -0.16421656 -0.43458151 -0.19022431 -0.22124272 -0.32140702\n",
            " -0.31968073 -0.30177154 -0.38879431 -0.18921492]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.12224082  0.56083949 -0.18609374  0.31894663  0.29473993 -0.06108603\n",
            " -0.58087306 -0.14121933  0.346469    0.59709461]\n",
            "\n",
            "# 35 Gradient out:  [1.67387962 0.28218041 1.65272064 0.30487466 0.33616946 0.73044945\n",
            " 0.63157676 1.07139611 1.6063608  0.30395307]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.03038309  0.52799617 -0.27301004  0.28090177  0.25049139 -0.12536744\n",
            " -0.6448092  -0.20157364  0.26871014  0.55925162]\n",
            "\n",
            "# 36 Gradient out:  [-1.95963855 -0.35287976 -1.91278201 -0.40286198 -0.46729438 -0.94493135\n",
            " -0.85341478 -1.22868858 -1.81757344 -0.40086893]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.36515901  0.58443226  0.05753408  0.3418767   0.31772528  0.02072245\n",
            " -0.51849385  0.01270559  0.5899823   0.62004223]\n",
            "\n",
            "# 37 Gradient out:  [2.70941484 0.57006452 2.66446957 0.61784489 0.68035398 1.29476805\n",
            " 1.15400064 1.76604641 2.57194207 0.61594022]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [-0.0267687   0.5138563  -0.32502232  0.2613043   0.2242664  -0.16826382\n",
            " -0.68917681 -0.23303213  0.22646761  0.53986845]\n",
            "\n",
            "# 38 Gradient out:  [-1.04060211 -0.1908165  -1.01661854 -0.21641172 -0.24951204 -0.50141668\n",
            " -0.45224017 -0.65522187 -0.9677044  -0.21539004]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.51511427  0.62786921  0.2078716   0.38487328  0.3603372   0.09068979\n",
            " -0.45837668  0.12017715  0.74085603  0.66305649]\n",
            "\n",
            "# 39 Gradient out:  [-2.13876279 -0.38854429 -2.086192   -0.44458574 -0.51658069 -1.03800845\n",
            " -0.93974051 -1.34035964 -1.97981244 -0.44235387]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.30699385  0.58970591  0.00454789  0.34159094  0.31043479 -0.00959354\n",
            " -0.54882471 -0.01086722  0.54731515  0.61997848]\n",
            "\n",
            "# 40 Gradient out:  [3.37186088 0.85163837 3.30929601 0.91778724 1.00200696 1.73041636\n",
            " 1.57268961 2.24826694 3.18464869 0.9151775 ]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [-0.12075871  0.51199705 -0.41269051  0.25267379  0.20711865 -0.21719523\n",
            " -0.73677282 -0.27893915  0.15135266  0.53150771]\n",
            "\n",
            "# 41 Gradient out:  [-0.75700511 -0.1358095  -0.73958276 -0.15440599 -0.17847659 -0.36255457\n",
            " -0.32650913 -0.47543875 -0.70401219 -0.15366343]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.55361347  0.68232472  0.24916869  0.43623124  0.40752005  0.12888804\n",
            " -0.42223489  0.17071424  0.7882824   0.71454321]\n",
            "\n",
            "# 42 Gradient out:  [-1.57975123 -0.27557186 -1.54243034 -0.3153957  -0.36683809 -0.75396227\n",
            " -0.67900584 -0.98749067 -1.46641396 -0.3138066 ]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.40221245  0.65516282  0.10125214  0.40535004  0.37182473  0.05637713\n",
            " -0.48753672  0.07562649  0.64747996  0.68381052]\n",
            "\n",
            "# 43 Gradient out:  [-0.16356534 -0.12458795 -0.14474656 -0.144275   -0.1668808  -0.19205195\n",
            " -0.20636511 -0.12031613 -0.11139379 -0.14352067]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.0862622   0.60004845 -0.20723393  0.3422709   0.29845711 -0.09441533\n",
            " -0.62333789 -0.12187165  0.35419717  0.6210492 ]\n",
            "\n",
            "# 44 Gradient out:  [0.72593805 0.06348673 0.72557794 0.06414537 0.06749815 0.24775998\n",
            " 0.19163007 0.45314404 0.72054074 0.06409415]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.05354913  0.57513086 -0.23618324  0.3134159   0.26508095 -0.13282572\n",
            " -0.66461091 -0.14593487  0.33191841  0.59234507]\n",
            "\n",
            "# 45 Gradient out:  [-1.7910564  -0.35319334 -1.74165259 -0.40573427 -0.47231095 -0.90556729\n",
            " -0.83068351 -1.12610831 -1.64329796 -0.40365186]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.19873674  0.58782821 -0.09106766  0.32624498  0.27858058 -0.08327372\n",
            " -0.6262849  -0.05530607  0.47602656  0.6051639 ]\n",
            "\n",
            "# 46 Gradient out:  [3.39689329 0.91743788 3.33305617 0.98483348 1.07008621 1.78742768\n",
            " 1.6340549  2.28877834 3.206878   0.9821815 ]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [-0.15947454  0.51718954 -0.43939817  0.24509812  0.18411839 -0.26438718\n",
            " -0.7924216  -0.28052773  0.14736696  0.52443353]\n",
            "\n",
            "# 47 Gradient out:  [-0.85364487 -0.151784   -0.83393603 -0.17282123 -0.20004949 -0.40806075\n",
            " -0.36736067 -0.53547451 -0.79369941 -0.17198122]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.51990412  0.70067711  0.22721306  0.44206482  0.39813563  0.09309836\n",
            " -0.46561062  0.17722794  0.78874256  0.72086983]\n",
            "\n",
            "# 48 Gradient out:  [-1.82520048 -0.31889142 -1.78152275 -0.36548311 -0.42556807 -0.87309557\n",
            " -0.78704549 -1.14034212 -1.69273639 -0.3636251 ]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [ 0.34917514  0.67032031  0.06042585  0.40750057  0.35812573  0.01148621\n",
            " -0.53908275  0.07013304  0.63000268  0.68647359]\n",
            "\n",
            "# 49 Gradient out:  [1.73922149 0.25770822 1.71635998 0.28228306 0.31629446 0.7372378\n",
            " 0.63260543 1.09681715 1.66599235 0.28128237]\n",
            "\n",
            "     Weights  out:  [ 0.47447494 -0.46006565  0.42401751 -0.40894672 -0.3538319  -0.08877332\n",
            " -0.13041017  0.03367436  0.34219491 -0.41082189] [-0.01586495  0.60654203 -0.2958787   0.33440395  0.27301212 -0.16313291\n",
            " -0.69649185 -0.15793539  0.2914554   0.61374856]\n",
            "\n",
            "Tanh error cuadrático medio (ECM): 0.8219370404374469\n",
            "\n",
            "# 0 Gradient out:  [-0.4938281  -0.53843896 -1.72512751 -1.80650595 -0.43277205 -0.70813567\n",
            " -0.88081359 -1.88477718 -1.71015051 -0.47739801]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.23326126  0.16480109 -0.32267817  0.25493424  0.35090753  0.11179848\n",
            " -0.11209592  0.21480418  0.26286773  0.28036709]\n",
            "\n",
            "# 1 Gradient out:  [1.12570659 1.17927092 3.04148836 3.13769845 1.05359784 1.39981132\n",
            " 1.66539392 3.23185861 3.02354403 1.10622361]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.13449564  0.05711329 -0.66770367 -0.10636695  0.26435312 -0.02982866\n",
            " -0.28825864 -0.16215126 -0.07916238  0.18488749]\n",
            "\n",
            "# 2 Gradient out:  [-0.21636382 -0.23412744 -0.78656798 -0.81833716 -0.19254141 -0.30535468\n",
            " -0.38509334 -0.8482542  -0.78061422 -0.20990244]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.35963695  0.29296748 -0.059406    0.52117273  0.47507268  0.25013361\n",
            "  0.04482014  0.48422047  0.52554643  0.40613221]\n",
            "\n",
            "# 3 Gradient out:  [-0.47033132 -0.51149962 -1.7445321  -1.81853849 -0.4148291  -0.6744099\n",
            " -0.85271561 -1.88863188 -1.73072799 -0.45530849]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.31636419  0.24614199 -0.2167196   0.3575053   0.4365644   0.18906267\n",
            " -0.03219853  0.31456963  0.36942359  0.36415172]\n",
            "\n",
            "# 4 Gradient out:  [0.75411617 0.80055677 2.68401689 2.76466464 0.69371687 1.00511046\n",
            " 1.27292589 2.83986732 2.66849759 0.73756009]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.22229793  0.14384207 -0.56562602 -0.0062024   0.35359858  0.05418069\n",
            " -0.20274165 -0.06315675  0.02327799  0.27309002]\n",
            "\n",
            "# 5 Gradient out:  [-0.18319848 -0.19807289 -0.66148754 -0.68808543 -0.16325394 -0.25774877\n",
            " -0.32462916 -0.71313195 -0.65650222 -0.17778861]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.37312116  0.30395342 -0.02882264  0.54673053  0.49234196  0.25520279\n",
            "  0.05184353  0.50481671  0.55697751  0.42060204]\n",
            "\n",
            "# 6 Gradient out:  [-0.38246752 -0.41558447 -1.42782177 -1.48717901 -0.33795503 -0.54758707\n",
            " -0.6938296  -1.54319553 -1.41672    -0.37040473]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.33648146  0.26433884 -0.16112015  0.40911345  0.45969117  0.20365303\n",
            " -0.0130823   0.36219032  0.42567706  0.38504432]\n",
            "\n",
            "# 7 Gradient out:  [-0.02440564 -0.02675179  0.39863638  0.3903439  -0.01810377 -0.01312389\n",
            "  0.04496317  0.37812703  0.39948585 -0.02303366]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.25998796  0.18122195 -0.4466845   0.11167764  0.39210016  0.09413562\n",
            " -0.15184823  0.05355122  0.14233306  0.31096338]\n",
            "\n",
            "# 8 Gradient out:  [-0.35865617 -0.39050269 -1.04063869 -1.10043674 -0.31375907 -0.50240233\n",
            " -0.59846957 -1.15988349 -1.02992138 -0.34671368]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.25510683  0.17587159 -0.36695722  0.18974642  0.38847941  0.09151084\n",
            " -0.14285559  0.12917662  0.22223023  0.30635665]\n",
            "\n",
            "# 9 Gradient out:  [0.97862433 1.03265825 3.08142849 3.17667356 0.90726762 1.26366946\n",
            " 1.55540337 3.26738058 3.06335169 0.95918878]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.1833756   0.09777105 -0.57508496 -0.03034092  0.32572759 -0.00896963\n",
            " -0.26254951 -0.10280007  0.01624596  0.23701391]\n",
            "\n",
            "# 10 Gradient out:  [-0.13348989 -0.14376974 -0.46410815 -0.48249898 -0.11969946 -0.1849989\n",
            " -0.23121976 -0.49983952 -0.46066268 -0.1297502 ]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [0.37910046 0.3043027  0.04120074 0.60499379 0.50718112 0.24376427\n",
            " 0.04853117 0.55067604 0.6289163  0.42885167]\n",
            "\n",
            "# 11 Gradient out:  [-0.23854135 -0.25804186 -0.86344143 -0.8983277  -0.21238138 -0.33618066\n",
            " -0.4235677  -0.93119403 -0.85690537 -0.23144687]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.35240249  0.27554876 -0.05162089  0.50849399  0.48324123  0.20676448\n",
            "  0.00228722  0.45070814  0.53678376  0.40290163]\n",
            "\n",
            "# 12 Gradient out:  [-0.51309011 -0.55806251 -1.88367837 -1.96470216 -0.45232152 -0.73503267\n",
            " -0.92686995 -2.04163755 -1.86859599 -0.49665655]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.30469422  0.22394038 -0.22430918  0.32882845  0.44076495  0.13952835\n",
            " -0.08242632  0.26446933  0.36540269  0.35661225]\n",
            "\n",
            "# 13 Gradient out:  [1.02450317 1.07996247 3.11230545 3.21079098 0.95070661 1.31356881\n",
            " 1.6031576  3.3055896  3.09374168 1.00446667]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.20207619  0.11232788 -0.60104485 -0.06411198  0.35030065 -0.00747818\n",
            " -0.26780031 -0.14385818 -0.00831651  0.25728094]\n",
            "\n",
            "# 14 Gradient out:  [-0.14175242 -0.15322873 -0.51158856 -0.53210429 -0.12636875 -0.19930763\n",
            " -0.25102017 -0.55141853 -0.50774225 -0.1375792 ]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [0.40697683 0.32832038 0.02141624 0.57804622 0.54044197 0.25523558\n",
            " 0.05283121 0.51725974 0.61043182 0.45817428]\n",
            "\n",
            "# 15 Gradient out:  [-0.26623201 -0.28900425 -0.99482969 -1.03556494 -0.23568593 -0.38022502\n",
            " -0.48213187 -1.07391987 -0.987197   -0.25794745]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.37862634  0.29767463 -0.08090148  0.47162536  0.51516822  0.21537405\n",
            "  0.00262717  0.40697604  0.50888338  0.43065844]\n",
            "\n",
            "# 16 Gradient out:  [-0.5408825  -0.58818475 -1.89877354 -1.98478618 -0.47635847 -0.77029075\n",
            " -0.96045096 -2.06746851 -1.88289838 -0.52350017]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.32537994  0.23987378 -0.27986741  0.26451237  0.46803104  0.13932905\n",
            " -0.0937992   0.19219206  0.31144397  0.37906895]\n",
            "\n",
            "# 17 Gradient out:  [1.08792013 1.14118655 2.96734206 3.06338116 1.01593529 1.35906583\n",
            " 1.61949303 3.1579903  2.94949306 1.06850345]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.21720344  0.12223683 -0.65962212 -0.13244487  0.37275934 -0.0147291\n",
            " -0.2858894  -0.22130164 -0.0651357   0.27436891]\n",
            "\n",
            "# 18 Gradient out:  [-0.21960194 -0.23910032 -0.84637506 -0.88121771 -0.19347505 -0.31736447\n",
            " -0.40503755 -0.91396941 -0.83984016 -0.21251272]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.43478747  0.35047414 -0.06615371  0.48023136  0.5759464   0.25708407\n",
            "  0.03800921  0.41029642  0.52476291  0.4880696 ]\n",
            "\n",
            "# 19 Gradient out:  [-0.49034207 -0.5345196  -1.8231325  -1.90289596 -0.43051668 -0.70764645\n",
            " -0.89417976 -1.97892206 -1.80831451 -0.47417893]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.39086708  0.30265408 -0.23542872  0.30398782  0.53725139  0.19361117\n",
            " -0.0429983   0.22750254  0.35679488  0.44556706]\n",
            "\n",
            "# 20 Gradient out:  [0.82972208 0.88138154 2.8230333  2.91423961 0.76138831 1.10144877\n",
            " 1.37801378 3.00127262 2.80574868 0.8111223 ]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.29279866  0.19575016 -0.60005522 -0.07659137  0.45114805  0.05208188\n",
            " -0.22183425 -0.16828187 -0.00486802  0.35073128]\n",
            "\n",
            "# 21 Gradient out:  [-0.17968586 -0.19567852 -0.6957049  -0.72426445 -0.15827071 -0.25996509\n",
            " -0.33214427 -0.75108628 -0.69034522 -0.17387353]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.45874308  0.37202646 -0.03544856  0.50625655  0.60342571  0.27237164\n",
            "  0.05376851  0.43197265  0.55628171  0.51295573]\n",
            "\n",
            "# 22 Gradient out:  [-0.38913839 -0.42484759 -1.50574941 -1.56984194 -0.34107322 -0.5666998\n",
            " -0.72294282 -1.63043667 -1.49377731 -0.37612028]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.42280591  0.33289076 -0.17458954  0.36140367  0.57177157  0.22037862\n",
            " -0.01266035  0.28175539  0.41821267  0.47818103]\n",
            "\n",
            "# 23 Gradient out:  [0.06395071 0.07541324 1.00108192 1.01669364 0.0523396  0.14803752\n",
            " 0.27807285 1.02582443 0.99731389 0.0603948 ]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.34497823  0.24792124 -0.47573942  0.04743528  0.50355693  0.10703866\n",
            " -0.15724891 -0.04433194  0.1194572   0.40295697]\n",
            "\n",
            "# 24 Gradient out:  [-0.53979169 -0.58689354 -1.87540021 -1.96124068 -0.4753942  -0.76737459\n",
            " -0.95440354 -2.04405018 -1.85958976 -0.52246017]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.35776837  0.26300389 -0.27552304  0.25077401  0.51402485  0.13664616\n",
            " -0.10163434  0.16083295  0.31891998  0.41503593]\n",
            "\n",
            "# 25 Gradient out:  [1.06411881 1.11725849 2.93342599 3.02931906 0.9922425  1.33430027\n",
            " 1.59329803 3.1239255  2.91561845 1.04473884]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.24981004  0.14562518 -0.65060308 -0.14147413  0.41894601 -0.01682875\n",
            " -0.29251505 -0.24797709 -0.05299797  0.3105439 ]\n",
            "\n",
            "# 26 Gradient out:  [-0.22289998 -0.24317661 -0.87466484 -0.91089166 -0.19573518 -0.32457588\n",
            " -0.41575291 -0.94492891 -0.86786918 -0.21552848]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.4626338   0.36907688 -0.06391788  0.46438968  0.61739451  0.2500313\n",
            "  0.02614456  0.37680801  0.53012572  0.51949166]\n",
            "\n",
            "# 27 Gradient out:  [-0.49930951 -0.54448315 -1.84259239 -1.9243548  -0.43798168 -0.72054749\n",
            " -0.90855975 -2.00256372 -1.82743751 -0.48275763]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.4180538   0.32044156 -0.23885085  0.28221135  0.57824747  0.18511612\n",
            " -0.05700602  0.18782223  0.35655188  0.47638597]\n",
            "\n",
            "# 28 Gradient out:  [0.85394369 0.90632904 2.82355858 2.91661404 0.78421561 1.12686535\n",
            " 1.40006335 3.00623358 2.80602339 0.83501442]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.3181919   0.21154493 -0.60736933 -0.10265961  0.49065114  0.04100663\n",
            " -0.23871797 -0.21269051 -0.00893562  0.37983444]\n",
            "\n",
            "# 29 Gradient out:  [-0.1909587  -0.20851608 -0.75736073 -0.78870691 -0.16745401 -0.27910327\n",
            " -0.35834011 -0.81812662 -0.75147672 -0.18457847]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.48898064  0.39281074 -0.04265761  0.4806632   0.64749426  0.2663797\n",
            "  0.0412947   0.3885562   0.55226906  0.54683733]\n",
            "\n",
            "# 30 Gradient out:  [-0.42590827 -0.46550428 -1.64444972 -1.7157093  -0.3724651  -0.62184556\n",
            " -0.79237189 -1.78333449 -1.6311718  -0.41144986]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.4507889   0.35110752 -0.19412976  0.32292181  0.61400346  0.21055904\n",
            " -0.03037333  0.22493088  0.40197372  0.50992163]\n",
            "\n",
            "# 31 Gradient out:  [0.36079813 0.39376566 1.93951275 1.99453594 0.31962645 0.549472\n",
            " 0.76882283 2.04265282 1.92852639 0.34931397]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.36560724  0.25800666 -0.5230197  -0.02022005  0.53951044  0.08618993\n",
            " -0.18884771 -0.13173602  0.07573936  0.42763166]\n",
            "\n",
            "# 32 Gradient out:  [-0.35615676 -0.38887153 -1.3872047  -1.44584564 -0.31218124 -0.51921822\n",
            " -0.66347963 -1.5011863  -1.37623764 -0.34423975]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.43776687  0.3367598  -0.13511715  0.37868714  0.60343573  0.19608433\n",
            " -0.03508314  0.27679454  0.46144463  0.49749446]\n",
            "\n",
            "# 33 Gradient out:  [-0.18623082 -0.19508008  0.06662261  0.0458965  -0.17059951 -0.20494722\n",
            " -0.17028273  0.0203637   0.0696605  -0.18240436]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.36653552  0.25898549 -0.41255809  0.08951801  0.54099948  0.09224069\n",
            " -0.16777907 -0.02344272  0.18619711  0.42864651]\n",
            "\n",
            "# 34 Gradient out:  [-0.12640385 -0.13314038  0.17143998  0.15490597 -0.11391963 -0.13596272\n",
            " -0.09517187  0.13411043  0.17376504 -0.12339237]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.32928935  0.21996947 -0.39923357  0.09869731  0.50687958  0.05125124\n",
            " -0.20183561 -0.01936998  0.20012921  0.39216563]\n",
            "\n",
            "# 35 Gradient out:  [-0.19863545 -0.21425654 -0.24559502 -0.27741243 -0.17470077 -0.2556529\n",
            " -0.26306557 -0.3117743  -0.24030065 -0.19246602]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.30400858  0.1933414  -0.36494558  0.12967851  0.48409565  0.0240587\n",
            " -0.22086999  0.00745211  0.23488222  0.36748716]\n",
            "\n",
            "# 36 Gradient out:  [0.23948248 0.25475349 1.24100072 1.26447183 0.22196871 0.33902776\n",
            " 0.47764239 1.28299957 1.23594425 0.23442338]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.26428149  0.15049009 -0.41406458  0.07419602  0.4491555  -0.02707188\n",
            " -0.2734831  -0.05490275  0.18682209  0.32899396]\n",
            "\n",
            "# 37 Gradient out:  [-0.51752301 -0.56286828 -1.90453271 -1.98616511 -0.45629872 -0.74157117\n",
            " -0.93571133 -2.06357372 -1.88932608 -0.50096057]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.31217799  0.20144079 -0.16586444  0.32709039  0.49354924  0.04073367\n",
            " -0.17795462  0.20169716  0.43401094  0.37587863]\n",
            "\n",
            "# 38 Gradient out:  [1.06093985 1.1172199  3.17073256 3.27075192 0.9859924  1.35386378\n",
            " 1.64650533 3.36710963 3.1518929  1.04059722]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.20867339  0.08886713 -0.54677098 -0.07014263  0.4022895  -0.10758056\n",
            " -0.36509689 -0.21101758  0.05614572  0.27568652]\n",
            "\n",
            "# 39 Gradient out:  [-0.13769685 -0.14862447 -0.48936308 -0.50890758 -0.12304138 -0.19246757\n",
            " -0.24163416 -0.52732542 -0.48570056 -0.13372208]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.42086135  0.31231111  0.08737553  0.58400775  0.59948798  0.16319219\n",
            " -0.03579582  0.46240434  0.6865243   0.48380596]\n",
            "\n",
            "# 40 Gradient out:  [-0.25288055 -0.27413439 -0.93347033 -0.97149211 -0.2243693  -0.35928527\n",
            " -0.45446697 -1.00730409 -0.92634659 -0.24514822]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.39332198  0.28258622 -0.01049708  0.48222623  0.5748797   0.12469868\n",
            " -0.08412265  0.35693926  0.58938419  0.45706155]\n",
            "\n",
            "# 41 Gradient out:  [-0.53475996 -0.58199048 -1.9406658  -2.02606808 -0.47070194 -0.76624277\n",
            " -0.96306883 -2.10754778 -1.92482158 -0.51746291]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.34274587  0.22775934 -0.19719115  0.28792781  0.53000585  0.05284162\n",
            " -0.17501605  0.15547844  0.40411487  0.4080319 ]\n",
            "\n",
            "# 42 Gradient out:  [1.08174461 1.1366747  3.06002806 3.15857358 1.0078878  1.36347983\n",
            " 1.63772125 3.25488972 3.04162796 1.06177963]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.23579388  0.11136124 -0.58532431 -0.1172858   0.43586546 -0.10040693\n",
            " -0.36762981 -0.26603112  0.01915056  0.30453932]\n",
            "\n",
            "# 43 Gradient out:  [-0.18222046 -0.19791948 -0.68790012 -0.71595342 -0.16118474 -0.26096555\n",
            " -0.33168753 -0.74233381 -0.68263864 -0.17651281]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.4521428   0.33869618  0.0266813   0.51442891  0.63744302  0.17228904\n",
            " -0.04008556  0.38494683  0.62747615  0.51689525]\n",
            "\n",
            "# 44 Gradient out:  [-0.39081103 -0.42601003 -1.49628284 -1.55941888 -0.3434639  -0.56605513\n",
            " -0.72072418 -1.61905842 -1.4844824  -0.37798398]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.41569871  0.29911229 -0.11089872  0.37123823  0.60520607  0.12009593\n",
            " -0.10642307  0.23648007  0.49094842  0.48159268]\n",
            "\n",
            "# 45 Gradient out:  [0.07228342 0.08169269 0.92120539 0.93346672 0.06318097 0.14482171\n",
            " 0.26243366 0.93999551 0.91812159 0.06943717]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.3375365   0.21391028 -0.41015529  0.05935445  0.53651329  0.0068849\n",
            " -0.2505679  -0.08733162  0.19405194  0.40599589]\n",
            "\n",
            "# 46 Gradient out:  [-0.53914157 -0.58633842 -1.87716149 -1.96312564 -0.47465111 -0.76725062\n",
            " -0.95466115 -2.04591809 -1.86131952 -0.52177994]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.35199319  0.23024882 -0.22591421  0.2460478   0.54914948  0.03584924\n",
            " -0.19808117  0.10066748  0.37767626  0.41988332]\n",
            "\n",
            "# 47 Gradient out:  [1.09088085 1.14373369 2.94866707 3.04403659 1.0193967  1.35956485\n",
            " 1.61698164 3.13809181 2.93095562 1.07160576]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.24416487  0.11298114 -0.60134651 -0.14657733  0.45421926 -0.11760088\n",
            " -0.3890134  -0.30851613  0.00541236  0.31552733]\n",
            "\n",
            "# 48 Gradient out:  [-0.23357508 -0.25443882 -0.90328605 -0.94057848 -0.20561106 -0.33813529\n",
            " -0.43181392 -0.97564638 -0.89629342 -0.22598824]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.46234105  0.34172787 -0.0116131   0.46222998  0.6580986   0.15431209\n",
            " -0.06561708  0.31910223  0.59160348  0.52984849]\n",
            "\n",
            "# 49 Gradient out:  [-0.51649788 -0.56282621 -1.88995193 -1.97383235 -0.45358062 -0.74320411\n",
            " -0.93544923 -2.05408257 -1.87440918 -0.49951913]\n",
            "\n",
            "     Weights  out:  [-0.34483815 -0.31365224  0.33683119  0.40001332 -0.39225871 -0.21088055\n",
            " -0.11903972  0.47529957  0.32630097 -0.35698964] [ 0.41562603  0.29084011 -0.19227031  0.27411429  0.61697639  0.08668503\n",
            " -0.15197986  0.12397295  0.41234479  0.48465084]\n",
            "\n",
            "Lineal error cuadrático medio (ECM): 1.055149032814128\n",
            "\n",
            "# 0 Gradient out:  [2.49817586 2.12484982 2.50479918 2.37273462 2.39795871 3.00065817\n",
            " 0.72374597 0.71673123 3.09041754 0.7642118 ]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [-0.21848072  0.35601988 -0.03613576  0.02545433  0.12849994 -0.38670103\n",
            "  0.21654791  0.31431356 -0.27103387 -0.15634518]\n",
            "\n",
            "# 1 Gradient out:  [-0.22584528 -0.19496629 -0.22643434 -0.2150226  -0.21715249 -0.27838733\n",
            " -0.06707538 -0.06624777 -0.28920559 -0.07192591]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [ 0.28115445  0.78098984  0.46482408  0.50000125  0.60809168  0.21343061\n",
            "  0.36129711  0.45765981  0.34704964 -0.00350282]\n",
            "\n",
            "# 2 Gradient out:  [-0.34867343 -0.29989024 -0.34960354 -0.33158059 -0.33494499 -0.4314491\n",
            " -0.09818814 -0.09689374 -0.4483996  -0.10578221]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [ 0.2359854   0.74199658  0.41953721  0.45699673  0.56466118  0.15775314\n",
            "  0.34788203  0.44441025  0.28920852 -0.017888  ]\n",
            "\n",
            "# 3 Gradient out:  [-0.65772657 -0.56266914 -0.65953842 -0.62442478 -0.63098025 -0.81857117\n",
            " -0.17040379 -0.16791571 -0.85125102 -0.18502625]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [ 0.16625071  0.68201854  0.3496165   0.39068061  0.49767218  0.07146332\n",
            "  0.3282444   0.4250315   0.1995286  -0.03904444]\n",
            "\n",
            "# 4 Gradient out:  [-1.5716831  -1.33561809 -1.57621488 -1.48862789 -1.50494274 -1.97860396\n",
            " -0.35425344 -0.34798765 -2.06134851 -0.39120184]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [ 0.0347054   0.56948471  0.21770882  0.26579566  0.37147613 -0.09225091\n",
            "  0.29416365  0.39144836  0.0292784  -0.07604969]\n",
            "\n",
            "# 5 Gradient out:  [2.71175922 2.34821047 2.71836912 2.58788805 2.61261556 3.25008314\n",
            " 0.92409141 0.91558522 3.35753274 0.9728729 ]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [-0.27963122  0.30236109 -0.09753416 -0.03192992  0.07048758 -0.48797171\n",
            "  0.22331296  0.32185083 -0.3829913  -0.15429006]\n",
            "\n",
            "# 6 Gradient out:  [-0.28033765 -0.24066002 -0.28109396 -0.26643725 -0.26917349 -0.34760338\n",
            " -0.07667915 -0.07562832 -0.36136594 -0.08284459]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [0.26272062 0.77200318 0.44613967 0.48564769 0.5930107  0.16204492\n",
            " 0.40813124 0.50496788 0.28851524 0.04028452]\n",
            "\n",
            "# 7 Gradient out:  [-0.47670232 -0.40760265 -0.47801893 -0.45249959 -0.4572644  -0.59354347\n",
            " -0.12250295 -0.12069244 -0.61730603 -0.13313855]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [0.20665309 0.72387118 0.38992088 0.43236024 0.539176   0.09252424\n",
            " 0.39279541 0.48984221 0.21624206 0.0237156 ]\n",
            "\n",
            "# 8 Gradient out:  [-1.05876893 -0.90040253 -1.06179066 -1.00325175 -1.01417697 -1.32712525\n",
            " -0.24685924 -0.2427392  -1.38138969 -0.27111213]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [ 0.11131263  0.64235065  0.29431709  0.34186032  0.44772312 -0.02618445\n",
            "  0.36829482  0.46570372  0.09278085 -0.00291211]\n",
            "\n",
            "# 9 Gradient out:  [-0.18450881 -0.18728023 -0.18484922 -0.18122569 -0.18144731 -0.288019\n",
            " -0.07694303 -0.07423969 -0.32336866 -0.09289716]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [-0.10044116  0.46227014  0.08195896  0.14120997  0.24488772 -0.2916095\n",
            "  0.31892297  0.41715588 -0.18349709 -0.05713453]\n",
            "\n",
            "# 10 Gradient out:  [1.04637656 0.85442184 1.0495328  0.98456686 0.99727672 1.23371865\n",
            " 0.21615959 0.21457744 1.25429489 0.22526491]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [-0.13734292  0.4248141   0.04498911  0.10496483  0.20859826 -0.3492133\n",
            "  0.30353437  0.40230795 -0.24817082 -0.07571397]\n",
            "\n",
            "# 11 Gradient out:  [-1.46029603 -1.24030557 -1.46451044 -1.3829922  -1.3981867  -1.83734206\n",
            " -0.3279696  -0.32216437 -1.91391129 -0.3621753 ]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [ 0.07193239  0.59569847  0.25489567  0.30187821  0.40805361 -0.10246957\n",
            "  0.34676628  0.44522343  0.00268816 -0.03066098]\n",
            "\n",
            "# 12 Gradient out:  [2.66362085 2.27492213 2.6706014  2.53210581 2.55845587 3.21180698\n",
            " 0.78634804 0.77825339 3.31494023 0.83296592]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [-0.22012681  0.34763735 -0.03800641  0.02527977  0.12841627 -0.46993798\n",
            "  0.28117236  0.38079056 -0.3800941  -0.10309604]\n",
            "\n",
            "# 13 Gradient out:  [-0.20865541 -0.17920724 -0.20921682 -0.19833789 -0.20036876 -0.25862304\n",
            " -0.05743567 -0.05665309 -0.26886577 -0.06202556]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [0.31259736 0.80262178 0.49611387 0.53170093 0.64010744 0.17242341\n",
            " 0.43844197 0.53644124 0.28289395 0.06349714]\n",
            "\n",
            "# 14 Gradient out:  [-0.31354582 -0.26849371 -0.31440433 -0.2977652  -0.30087184 -0.38981041\n",
            " -0.08246334 -0.08127614 -0.40537225 -0.08943226]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [0.27086628 0.76678033 0.4542705  0.49203335 0.60003369 0.12069881\n",
            " 0.42695484 0.52511062 0.22912079 0.05109203]\n",
            "\n",
            "# 15 Gradient out:  [-0.56353227 -0.48059451 -0.56511233 -0.53448474 -0.54020361 -0.70361902\n",
            " -0.13864999 -0.1364875  -0.73203009 -0.15136066]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [0.20815711 0.71308159 0.39138964 0.43248031 0.53985932 0.04273672\n",
            " 0.41046217 0.50885539 0.14804634 0.03320557]\n",
            "\n",
            "# 16 Gradient out:  [-1.337007   -1.1349767  -1.34087118 -1.26608123 -1.2800287  -1.68169011\n",
            " -0.29879936 -0.29349905 -1.75156018 -0.33001797]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [ 0.09545066  0.61696268  0.27836717  0.32558336  0.4318186  -0.09798708\n",
            "  0.38273217  0.48155789  0.00164032  0.00293344]\n",
            "\n",
            "# 17 Gradient out:  [2.15523964 1.80823228 2.16133982 2.039243   2.06263151 2.60478229\n",
            " 0.52748092 0.52157975 2.68087247 0.56164691]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [-0.17195074  0.38996734  0.01019294  0.07236711  0.17581286 -0.4343251\n",
            "  0.3229723   0.42285808 -0.34867171 -0.06307015]\n",
            "\n",
            "# 18 Gradient out:  [-0.377753   -0.32288837 -0.37879828 -0.35853739 -0.36232048 -0.47052164\n",
            " -0.09650189 -0.09506248 -0.48940517 -0.10495532]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [0.25909719 0.7516138  0.4424609  0.48021571 0.58833916 0.08663136\n",
            " 0.42846848 0.52717403 0.18750278 0.04925923]\n",
            "\n",
            "# 19 Gradient out:  [-0.74733993 -0.63595051 -0.74946254 -0.70832152 -0.71600292 -0.93548097\n",
            " -0.1768292  -0.17393561 -0.97354325 -0.19384908]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [ 0.18354659  0.68703613  0.36670124  0.40850824  0.51587507 -0.00747297\n",
            "  0.4091681   0.50816154  0.08962175  0.02826817]\n",
            "\n",
            "# 20 Gradient out:  [-1.67564003 -1.42565199 -1.68048835 -1.58715414 -1.60448275 -2.12043948\n",
            " -0.37045384 -0.3634293  -2.21299739 -0.41183484]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [ 0.0340786   0.55984602  0.21680874  0.26684393  0.37267448 -0.19456917\n",
            "  0.37380226  0.47337441 -0.1050869  -0.01050165]\n",
            "\n",
            "# 21 Gradient out:  [2.25613468 1.98502529 2.26114224 2.16292912 2.18144737 2.68423042\n",
            " 0.88833801 0.88088118 2.77699975 0.93076182]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [-0.30104941  0.27471563 -0.11928894 -0.0505869   0.05177793 -0.61865706\n",
            "  0.2997115   0.40068855 -0.54768638 -0.09286862]\n",
            "\n",
            "# 22 Gradient out:  [-0.99998647 -0.84732517 -1.00289822 -0.94648104 -0.9570116  -1.2582863\n",
            " -0.21781839 -0.21386043 -1.31042907 -0.24111996]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [ 0.15017753  0.67172068  0.33293951  0.38199893  0.48806741 -0.08181098\n",
            "  0.4773791   0.57686479  0.00771357  0.09328375]\n",
            "\n",
            "# 23 Gradient out:  [-0.68035024 -0.61507533 -0.68195717 -0.65356513 -0.6584457  -0.89284214\n",
            " -0.2287951  -0.22427698 -0.95116446 -0.25517989]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [-0.04981976  0.50225565  0.13235987  0.19270272  0.29666509 -0.33346824\n",
            "  0.43381542  0.5340927  -0.25437224  0.04505976]\n",
            "\n",
            "# 24 Gradient out:  [2.44386083 2.06558982 2.45062212 2.3162149  2.34182575 2.96697766\n",
            " 0.63003441 0.62255235 3.06275004 0.67322586]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [-0.18588981  0.37924058 -0.00403157  0.06198969  0.16497595 -0.51203667\n",
            "  0.3880564   0.48923731 -0.44460513 -0.00597622]\n",
            "\n",
            "# 25 Gradient out:  [-0.28520488 -0.2431081  -0.28600655 -0.27046488 -0.27336723 -0.35626407\n",
            " -0.06955837 -0.06845845 -0.37069979 -0.07601943]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [0.30288235 0.79235855 0.48609286 0.52523267 0.6333411  0.08135887\n",
            " 0.51406328 0.61374778 0.16794488 0.12866895]\n",
            "\n",
            "# 26 Gradient out:  [-0.49157135 -0.41771116 -0.49297763 -0.46571187 -0.47080399 -0.61603014\n",
            " -0.11357859 -0.11166479 -0.64119278 -0.12483211]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [0.24584138 0.74373693 0.42889155 0.4711397  0.57866765 0.01010605\n",
            " 0.50015161 0.60005609 0.09380492 0.11346507]\n",
            "\n",
            "# 27 Gradient out:  [-1.11303684 -0.94272135 -1.11628799 -1.05331472 -1.06506592 -1.40189674\n",
            " -0.23967871 -0.23524845 -1.46027277 -0.26576437]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [ 0.14752711  0.6601947   0.33029602  0.37799733  0.48450685 -0.11309998\n",
            "  0.47743589  0.57772313 -0.03443364  0.08849864]\n",
            "\n",
            "# 28 Gradient out:  [ 0.28542918  0.1905702   0.28675356  0.25741972  0.2634562   0.31000332\n",
            " -0.04534665 -0.04411442  0.29502914 -0.05240542]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [-0.07508026  0.47165043  0.10703842  0.16733438  0.27149367 -0.39347932\n",
            "  0.42950015  0.53067344 -0.32648819  0.03534577]\n",
            "\n",
            "# 29 Gradient out:  [-0.94985451 -0.83666346 -0.9523239  -0.90683022 -0.91496251 -1.22868917\n",
            " -0.26988997 -0.26455355 -1.29803531 -0.30114162]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [-0.01799442  0.50976446  0.16438914  0.21881833  0.32418491 -0.33147866\n",
            "  0.42043082  0.52185056 -0.26748236  0.02486468]\n",
            "\n",
            "# 30 Gradient out:  [2.60147488 2.23578535 2.6081165  2.47695178 2.50181744 3.14087116\n",
            " 0.80574595 0.79725311 3.24816786 0.8544525 ]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [-0.20796532  0.34243177 -0.02607564  0.03745228  0.14119241 -0.57721649\n",
            "  0.36645283  0.46893985 -0.52708942 -0.03536364]\n",
            "\n",
            "# 31 Gradient out:  [-0.30631372 -0.26072878 -0.30718166 -0.2903539  -0.2934966  -0.38319357\n",
            " -0.0728961  -0.07170863 -0.3987864  -0.07987348]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [0.31232965 0.78958884 0.49554766 0.53284264 0.64155589 0.05095774\n",
            " 0.52760202 0.62839047 0.12254415 0.13552686]\n",
            "\n",
            "# 32 Gradient out:  [-0.54690211 -0.4640749  -0.54847907 -0.51790364 -0.52361395 -0.68640269\n",
            " -0.12313869 -0.12099794 -0.71456488 -0.13573069]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [ 0.25106691  0.73744308  0.43411133  0.47477186  0.58285657 -0.02568098\n",
            "  0.5130228   0.61404874  0.04278687  0.11955216]\n",
            "\n",
            "# 33 Gradient out:  [-1.29002408 -1.0920585  -1.29381022 -1.22052848 -1.23419504 -1.62770002\n",
            " -0.27275406 -0.26755777 -1.69617341 -0.30335288]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [ 0.14168649  0.64462811  0.32441551  0.37119113  0.47813378 -0.16296151\n",
            "  0.48839506  0.58984915 -0.10012611  0.09240602]\n",
            "\n",
            "# 34 Gradient out:  [1.73544822 1.42587085 1.74081033 1.63281965 1.6536038  2.11139207\n",
            " 0.31432793 0.30996258 2.16864866 0.33981155]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [-0.11631833  0.4262164   0.06565347  0.12708543  0.23129478 -0.48850152\n",
            "  0.43384425  0.5363376  -0.43936079  0.03173545]\n",
            "\n",
            "# 35 Gradient out:  [-0.70488263 -0.59763323 -0.70692537 -0.66732469 -0.67471965 -0.88566571\n",
            " -0.15606347 -0.15329301 -0.92213469 -0.17236557]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [ 0.23077132  0.71139058  0.41381554  0.45364936  0.56201554 -0.0662231\n",
            "  0.49670983  0.59833012 -0.00563106  0.09969776]\n",
            "\n",
            "# 36 Gradient out:  [-1.64787462 -1.3995554  -1.6526763  -1.56013498 -1.57733265 -2.08614525\n",
            " -0.35505552 -0.34813598 -2.17717381 -0.39577584]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [ 0.08979479  0.59186393  0.27243046  0.32018443  0.42707161 -0.24335625\n",
            "  0.46549714  0.56767152 -0.190058    0.06522464]\n",
            "\n",
            "# 37 Gradient out:  [2.37291748 2.07201737 2.37846175 2.26961427 2.29015375 2.84359088\n",
            " 0.86052643 0.85242777 2.94451619 0.90664196]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [-0.23978013  0.31195285 -0.0581048   0.00815743  0.11160508 -0.6605853\n",
            "  0.39448603  0.49804432 -0.62549276 -0.01393052]\n",
            "\n",
            "# 38 Gradient out:  [-0.70115592 -0.59290207 -0.70321713 -0.66325299 -0.6707166  -0.88334825\n",
            " -0.14759919 -0.1448169  -0.92000209 -0.16397814]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [ 0.23480336  0.72635632  0.41758755  0.46208029  0.56963583 -0.09186712\n",
            "  0.56659132  0.66852987 -0.03658952  0.16739787]\n",
            "\n",
            "# 39 Gradient out:  [-1.63330712 -1.38649707 -1.63808597 -1.54603289 -1.56313251 -2.0709249\n",
            " -0.34582177 -0.3388677  -2.16228649 -0.38671487]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [ 0.09457218  0.60777591  0.27694412  0.32942969  0.43549251 -0.26853677\n",
            "  0.53707148  0.63956649 -0.22058994  0.13460224]\n",
            "\n",
            "# 40 Gradient out:  [2.33043214 2.02878898 2.33599391 2.22683381 2.24742772 2.80369085\n",
            " 0.81236605 0.80418024 2.90560876 0.85895506]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [-0.23208925  0.3304765  -0.05067307  0.02022311  0.12286601 -0.68272175\n",
            "  0.46790713  0.57179295 -0.65304724  0.05725927]\n",
            "\n",
            "# 41 Gradient out:  [-0.72797161 -0.61415306 -0.73013844 -0.68812346 -0.69597049 -0.91932951\n",
            " -0.14627326 -0.14336038 -0.95773484 -0.16342884]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [ 0.23399718  0.73623429  0.41652571  0.46558987  0.57235155 -0.12198358\n",
            "  0.63038034  0.732629   -0.07192549  0.22905028]\n",
            "\n",
            "# 42 Gradient out:  [-1.63566848 -1.39043025 -1.6404441  -1.54865735 -1.56567623 -2.07851588\n",
            " -0.34685857 -0.33969611 -2.17238689 -0.3889239 ]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [ 0.08840286  0.61340368  0.27049802  0.32796518  0.43315745 -0.30584948\n",
            "  0.60112569  0.70395692 -0.26347245  0.19636451]\n",
            "\n",
            "# 43 Gradient out:  [2.20783111 1.92704818 2.21303329 2.11113257 2.13032704 2.65717511\n",
            " 0.7830644  0.77505721 2.75639272 0.82852163]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [-0.23873084  0.33531763 -0.0575908   0.01823371  0.1200222  -0.72155266\n",
            "  0.53175397  0.6360177  -0.69794983  0.11857973]\n",
            "\n",
            "# 44 Gradient out:  [-0.96378149 -0.81148269 -0.96668517 -0.91041451 -0.92091914 -1.2208615\n",
            " -0.18437636 -0.18046097 -1.27251588 -0.2074453 ]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [ 0.20283538  0.72072727  0.38501586  0.44046022  0.54608761 -0.19011763\n",
            "  0.68836685  0.79102914 -0.14667129  0.28428406]\n",
            "\n",
            "# 45 Gradient out:  [-0.8599283  -0.77544038 -0.86192313 -0.82618894 -0.83241449 -1.11438959\n",
            " -0.29603468 -0.29047901 -1.18500869 -0.328175  ]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [ 0.01007909  0.55843073  0.19167883  0.25837732  0.36190378 -0.43428993\n",
            "  0.65149158  0.75493695 -0.40117446  0.242795  ]\n",
            "\n",
            "# 46 Gradient out:  [2.26518727 1.91169374 2.2715738  2.14517315 2.16917606 2.77513539\n",
            " 0.54428161 0.53655319 2.87340117 0.5887542 ]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [-0.16190657  0.40334265  0.0192942   0.09313953  0.19542089 -0.65716785\n",
            "  0.59228464  0.69684115 -0.6381762   0.17716   ]\n",
            "\n",
            "# 47 Gradient out:  [-0.49686154 -0.41867057 -0.49834836 -0.46950553 -0.47489446 -0.62782757\n",
            " -0.09781342 -0.09582608 -0.65403641 -0.10951918]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [ 0.29113088  0.7856814   0.47360896  0.52217416  0.6292561  -0.10214077\n",
            "  0.70114097  0.80415179 -0.06349597  0.29491084]\n",
            "\n",
            "# 48 Gradient out:  [-1.12956859 -0.95147681 -1.13297008 -1.06709809 -1.07938808 -1.43190139\n",
            " -0.21618748 -0.21156022 -1.49291903 -0.24344485]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [ 0.19175857  0.70194729  0.37393929  0.42827306  0.53427721 -0.22770629\n",
            "  0.68157828  0.78498657 -0.19430325  0.273007  ]\n",
            "\n",
            "# 49 Gradient out:  [ 0.41355368  0.27714588  0.41560212  0.37170697  0.38054138  0.48508567\n",
            " -0.09974934 -0.09862639  0.47327696 -0.105733  ]\n",
            "\n",
            "     Weights  out:  [ 0.15539786  0.05301091  0.15750253  0.11797171  0.12516907  0.40308117\n",
            " -0.48445816 -0.4920217   0.48839335 -0.44367633] [-0.03415514  0.51165193  0.14734527  0.21485344  0.31839959 -0.51408657\n",
            "  0.63834079  0.74267453 -0.49288705  0.22431803]\n",
            "\n",
            "Tanh error cuadrático medio (ECM): 0.5437400432583718\n",
            "\n",
            "# 0 Gradient out:  [-0.65330732 -0.88918418 -1.60977224 -0.63381686 -0.42555728 -0.68490426\n",
            " -1.63899683 -1.73382916 -1.19950039 -0.53508214]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.49782837 -0.32909439  0.49337416  0.11585635 -0.28503834  0.19224249\n",
            "  0.19658671  0.32890022  0.15593343  0.40909426]\n",
            "\n",
            "# 1 Gradient out:  [0.79688154 0.99702281 1.70585387 0.78343003 0.66412188 0.81970206\n",
            " 1.72523021 1.7815613  1.32961619 0.72212076]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.36716691 -0.50693122  0.17141971 -0.01090702 -0.3701498   0.05526163\n",
            " -0.13121266 -0.01786561 -0.08396665  0.30207783]\n",
            "\n",
            "# 2 Gradient out:  [-0.60422004 -0.81955792 -1.47837385 -0.58645447 -0.39673368 -0.63302891\n",
            " -1.50500612 -1.59138887 -1.10354495 -0.49650345]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.52654322 -0.30752666  0.51259049  0.14577899 -0.23732542  0.21920205\n",
            "  0.21383338  0.33844665  0.18195659  0.44650198]\n",
            "\n",
            "# 3 Gradient out:  [0.28326347 0.32793744 0.54472792 0.28213345 0.29090853 0.28594143\n",
            " 0.54575771 0.54355652 0.44384092 0.28216334]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.40569921 -0.47143825  0.21691572  0.02848809 -0.31667216  0.09259626\n",
            " -0.08716784  0.02016887 -0.0387524   0.34720129]\n",
            "\n",
            "# 4 Gradient out:  [-0.5472282  -0.76705691 -1.40560837 -0.52800363 -0.31367512 -0.57804177\n",
            " -1.43471221 -1.53149977 -1.03277717 -0.42819524]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.4623519  -0.40585076  0.3258613   0.08491478 -0.25849045  0.14978455\n",
            "  0.0219837   0.12888018  0.05001579  0.40363396]\n",
            "\n",
            "# 5 Gradient out:  [1.36517644 1.76248074 3.08124491 1.33565928 1.04590509 1.41411151\n",
            " 3.12465838 3.25861757 2.35987143 1.19338536]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.35290626 -0.55926214  0.04473963 -0.02068594 -0.32122547  0.0341762\n",
            " -0.26495874 -0.17741977 -0.15653965  0.31799491]\n",
            "\n",
            "# 6 Gradient out:  [-0.27657486 -0.37299219 -0.66969485 -0.26867365 -0.18467607 -0.28940477\n",
            " -0.68152623 -0.71979652 -0.50136925 -0.22878035]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.62594155 -0.20676599  0.66098861  0.24644591 -0.11204445  0.3169985\n",
            "  0.35997294  0.47430374  0.31543464  0.55667198]\n",
            "\n",
            "# 7 Gradient out:  [-0.5353043  -0.72764069 -1.31678916 -0.51945782 -0.35035388 -0.5610079\n",
            " -1.34053942 -1.41753719 -0.98179426 -0.43926515]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.57062658 -0.28136443  0.52704964  0.19271118 -0.14897967  0.25911754\n",
            "  0.22366769  0.33034444  0.21516079  0.51091591]\n",
            "\n",
            "# 8 Gradient out:  [-0.30157938 -0.41997197 -0.72253879 -0.28987288 -0.14782124 -0.31991124\n",
            " -0.74060505 -0.80364353 -0.53367044 -0.22606114]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.46356572 -0.42689257  0.26369181  0.08881962 -0.21905045  0.14691596\n",
            " -0.04444019  0.046837    0.01880193  0.42306288]\n",
            "\n",
            "# 9 Gradient out:  [0.92136914 1.20430403 2.17817453 0.90149751 0.71812697 0.95474619\n",
            " 2.20705584 2.29310238 1.65443948 0.80877351]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.40324984 -0.51088696  0.11918405  0.03084504 -0.24861469  0.08293372\n",
            " -0.1925612  -0.11389171 -0.08793215  0.37785065]\n",
            "\n",
            "# 10 Gradient out:  [-0.4717223  -0.64166661 -1.16298914 -0.45774536 -0.30880053 -0.49440168\n",
            " -1.18393086 -1.25176837 -0.86677444 -0.38707045]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.58752367 -0.27002616  0.55481895  0.21114454 -0.1049893   0.27388295\n",
            "  0.24884997  0.34472877  0.24295574  0.53960535]\n",
            "\n",
            "# 11 Gradient out:  [-0.61746033 -0.84145127 -1.49034345 -0.5977891  -0.37693587 -0.64895654\n",
            " -1.52015352 -1.61963141 -1.11095365 -0.49535596]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.49317921 -0.39835948  0.32222113  0.11959547 -0.1667494   0.17500262\n",
            "  0.01206379  0.0943751   0.06960085  0.46219126]\n",
            "\n",
            "# 12 Gradient out:  [1.37171839 1.77075981 3.090152   1.34189668 1.04716343 1.42109069\n",
            " 3.13406829 3.27008682 2.36710557 1.19765941]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 3.69687145e-01 -5.66649731e-01  2.41524378e-02  3.76506226e-05\n",
            " -2.42136578e-01  4.52113100e-02 -2.91966912e-01 -2.29551188e-01\n",
            " -1.52589875e-01  3.63120073e-01]\n",
            "\n",
            "# 13 Gradient out:  [-0.28532238 -0.38859702 -0.70647267 -0.27686359 -0.18703341 -0.29905969\n",
            " -0.71913714 -0.76008081 -0.52615529 -0.23417395]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.64403082 -0.21249777  0.64218284  0.26841699 -0.03270389  0.32942945\n",
            "  0.33484675  0.42446618  0.32083124  0.60265196]\n",
            "\n",
            "# 14 Gradient out:  [-0.56388082 -0.77064167 -1.40276965 -0.54680719 -0.36426001 -0.59156194\n",
            " -1.42836947 -1.51145283 -1.04299891 -0.46031343]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.58696635 -0.29021717  0.5008883   0.21304427 -0.07011057  0.26961751\n",
            "  0.19101932  0.27245001  0.21560018  0.55581717]\n",
            "\n",
            "# 15 Gradient out:  [-0.11063865 -0.13325787 -0.1215125  -0.10611202 -0.03347071 -0.11707728\n",
            " -0.12901808 -0.15963451 -0.10549371 -0.07682984]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.47419018 -0.44434551  0.22033437  0.10368283 -0.14296258  0.15130512\n",
            " -0.09465457 -0.02984055  0.0070004   0.46375448]\n",
            "\n",
            "# 16 Gradient out:  [0.16211288 0.2282267  0.52290036 0.15967787 0.16066506 0.16708024\n",
            " 0.52574014 0.52794601 0.38115816 0.15448616]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.45206245 -0.47099708  0.19603187  0.08246043 -0.14965672  0.12788966\n",
            " -0.12045819 -0.06176745 -0.01409834  0.44838851]\n",
            "\n",
            "# 17 Gradient out:  [-0.52866291 -0.71194299 -1.22398826 -0.5119395  -0.31859755 -0.55523784\n",
            " -1.2494928  -1.33601596 -0.91900776 -0.42341786]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.48448503 -0.42535174  0.30061194  0.114396   -0.11752371  0.16130571\n",
            " -0.01531016  0.04382175  0.06213329  0.47928574]\n",
            "\n",
            "# 18 Gradient out:  [1.28524092 1.67084501 2.95461576 1.25672214 0.97812251 1.33256995\n",
            " 2.99652142 3.12547418 2.2533776  1.11961097]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.37875245 -0.56774034  0.05581429  0.0120081  -0.18124322  0.05025814\n",
            " -0.26520872 -0.22338144 -0.12166826  0.39460217]\n",
            "\n",
            "# 19 Gradient out:  [-0.29095099 -0.3971031  -0.72382378 -0.28225648 -0.18993264 -0.30507117\n",
            " -0.73684105 -0.77892341 -0.53848577 -0.23837868]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.63580063 -0.23357134  0.64673745  0.26335253  0.01438128  0.31677213\n",
            "  0.33409556  0.40171339  0.32900726  0.61852436]\n",
            "\n",
            "# 20 Gradient out:  [-0.57888327 -0.79195571 -1.44284503 -0.56127081 -0.37279669 -0.60743198\n",
            " -1.46925755 -1.55502089 -1.07224623 -0.4720047 ]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.57761043 -0.31299196  0.50197269  0.20690124 -0.02360524  0.2557579\n",
            "  0.18672735  0.24592871  0.22131011  0.57084863]\n",
            "\n",
            "# 21 Gradient out:  [0.00359469 0.02662474 0.18550961 0.0046013  0.04189586 0.00294762\n",
            " 0.18321429 0.16891759 0.11991141 0.0166494 ]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.46183378 -0.4713831   0.21340368  0.09464707 -0.09816458  0.1342715\n",
            " -0.10712416 -0.06507547  0.00686086  0.47644769]\n",
            "\n",
            "# 22 Gradient out:  [-0.21454857 -0.27477067 -0.38447185 -0.20712762 -0.10538828 -0.22575046\n",
            " -0.39626093 -0.44029764 -0.30115188 -0.16367586]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.46255272 -0.46605815  0.25050561  0.09556733 -0.08978541  0.13486103\n",
            " -0.0704813  -0.03129195  0.03084314  0.47977757]\n",
            "\n",
            "# 23 Gradient out:  [0.50810435 0.6861533  1.33475645 0.49678852 0.40540046 0.52758665\n",
            " 1.35082187 1.39523888 0.99486102 0.447368  ]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.419643   -0.52101229  0.17361124  0.05414181 -0.11086306  0.08971094\n",
            " -0.14973348 -0.11935148 -0.02938723  0.4470424 ]\n",
            "\n",
            "# 24 Gradient out:  [-0.7168388  -0.97823827 -1.7681972  -0.69494986 -0.45813343 -0.75222397\n",
            " -1.80109915 -1.90859902 -1.31601194 -0.58333478]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.52126387 -0.38378163  0.44056253  0.15349951 -0.02978297  0.19522827\n",
            "  0.12043089  0.1596963   0.16958497  0.536516  ]\n",
            "\n",
            "# 25 Gradient out:  [1.18642255 1.5529533  2.78178275 1.15960432 0.90080347 1.23104096\n",
            " 2.82109958 2.94126354 2.11276253 1.03147611]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.37789611 -0.57942928  0.08692309  0.01450954 -0.12140966  0.04478347\n",
            " -0.23978894 -0.2220235  -0.09361742  0.41984904]\n",
            "\n",
            "# 26 Gradient out:  [-0.31983106 -0.43711826 -0.79794988 -0.31021943 -0.2081162  -0.335439\n",
            " -0.81234157 -0.85887805 -0.59321693 -0.26170192]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.61518062 -0.26883862  0.64327964  0.24643041  0.05875104  0.29099166\n",
            "  0.32443098  0.36622921  0.32893509  0.62614426]\n",
            "\n",
            "# 27 Gradient out:  [-0.64387515 -0.88059956 -1.60111679 -0.62422068 -0.41307767 -0.6757042\n",
            " -1.63061532 -1.72660829 -1.1901367  -0.52439405]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.55121441 -0.35626227  0.48368966  0.18438652  0.0171278   0.22390386\n",
            "  0.16196266  0.19445359  0.2102917   0.57380388]\n",
            "\n",
            "# 28 Gradient out:  [0.56112307 0.767069   1.50467605 0.54763041 0.43426879 0.5841788\n",
            " 1.52396949 1.57853629 1.11516795 0.4875063 ]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.42243938 -0.53238218  0.1634663   0.05954238 -0.06548774  0.08876302\n",
            " -0.1641604  -0.15086806 -0.02773564  0.46892507]\n",
            "\n",
            "# 29 Gradient out:  [-0.68713443 -0.93871225 -1.70167235 -0.66615512 -0.43992608 -0.72107795\n",
            " -1.73318416 -1.83594728 -1.26570307 -0.55937853]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.53466399 -0.37896838  0.46440151  0.16906847  0.02136602  0.20559878\n",
            "  0.14063349  0.1648392   0.19529795  0.56642633]\n",
            "\n",
            "# 30 Gradient out:  [0.93370587 1.24374838 2.30307339 0.91169198 0.70664114 0.97059169\n",
            " 2.33513688 2.43121685 1.73142794 0.8083962 ]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.39723711 -0.56671083  0.12406704  0.03583744 -0.06661919  0.06138319\n",
            " -0.20600334 -0.20235026 -0.05784266  0.45455062]\n",
            "\n",
            "# 31 Gradient out:  [-0.44423963 -0.6086616  -1.11319896 -0.43072325 -0.28677245 -0.46617417\n",
            " -1.13344854 -1.19902296 -0.82656511 -0.36239705]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.58397828 -0.31796116  0.58468172  0.21817584  0.07470904  0.25550153\n",
            "  0.26102404  0.28389311  0.28844292  0.61622986]\n",
            "\n",
            "# 32 Gradient out:  [-0.69347154 -0.93387619 -1.63612824 -0.67253184 -0.43832903 -0.72704897\n",
            " -1.66782295 -1.77332436 -1.22725813 -0.56379736]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.49513035 -0.43969348  0.36204193  0.13203119  0.01735455  0.1622667\n",
            "  0.03433433  0.04408852  0.1231299   0.54375045]\n",
            "\n",
            "# 33 Gradient out:  [1.36799384 1.765137   3.07347378 1.33814708 1.04117675 1.41734266\n",
            " 3.11748006 3.25427814 2.35524396 1.19330441]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.35643605 -0.62646872  0.03481628 -0.00247518 -0.07031126  0.0168569\n",
            " -0.29923026 -0.31057636 -0.12232172  0.43099098]\n",
            "\n",
            "# 34 Gradient out:  [-0.30148448 -0.41463616 -0.76289616 -0.29221807 -0.19387578 -0.31653433\n",
            " -0.7767688  -0.82160473 -0.56533858 -0.24546382]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.63003481 -0.27344132  0.64951104  0.26515423  0.13792409  0.30032544\n",
            "  0.32426575  0.34027927  0.34872707  0.66965186]\n",
            "\n",
            "# 35 Gradient out:  [-0.60849886 -0.8348239  -1.52435141 -0.58972943 -0.38827045 -0.63890184\n",
            " -1.55251596 -1.64412068 -1.13123444 -0.4944471 ]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.56973792 -0.35636855  0.49693181  0.20671062  0.09914893  0.23701857\n",
            "  0.16891199  0.17595833  0.23565935  0.6205591 ]\n",
            "\n",
            "# 36 Gradient out:  [0.23432303 0.35817226 0.84083848 0.22752285 0.1863026  0.24651049\n",
            " 0.85010584 0.87207096 0.59532709 0.20129405]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.44803814 -0.52333333  0.19206152  0.08876473  0.02149485  0.1092382\n",
            " -0.1415912  -0.15286581  0.00941246  0.52166968]\n",
            "\n",
            "# 37 Gradient out:  [-0.68871247 -0.92317161 -1.60428414 -0.66816088 -0.43698767 -0.72162437\n",
            " -1.6354267  -1.73941317 -1.20661315 -0.56112074]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.49490275 -0.45169888  0.36022922  0.1342693   0.05875537  0.1585403\n",
            "  0.02842997  0.02154838  0.12847788  0.56192849]\n",
            "\n",
            "# 38 Gradient out:  [1.35724999 1.75313886 3.05730002 1.3274952  1.03138433 1.40644567\n",
            " 3.10117172 3.23756365 2.34135096 1.18308829]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.35716026 -0.6363332   0.03937239  0.00063713 -0.02864217  0.01421543\n",
            " -0.29865537 -0.32633425 -0.11284475  0.44970434]\n",
            "\n",
            "# 39 Gradient out:  [-0.30404869 -0.41914107 -0.77337071 -0.29462372 -0.1946149  -0.31935631\n",
            " -0.78748048 -0.83307933 -0.57242583 -0.2470723 ]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.62861026 -0.28570543  0.65083239  0.26613617  0.1776347   0.29550456\n",
            "  0.32157897  0.32117848  0.35542544  0.686322  ]\n",
            "\n",
            "# 40 Gradient out:  [-0.61565965 -0.84520021 -1.54389108 -0.59660226 -0.39183793 -0.64652175\n",
            " -1.57249368 -1.66557687 -1.14537144 -0.4998046 ]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.56780052 -0.36953364  0.49615825  0.20721142  0.13871172  0.2316333\n",
            "  0.16408288  0.15456261  0.24094028  0.63690754]\n",
            "\n",
            "# 41 Gradient out:  [0.28911966 0.43761603 0.99889664 0.2803931  0.21961905 0.30446763\n",
            " 1.01102236 1.04199814 0.70955785 0.24467294]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.44466859 -0.53857368  0.18738003  0.08789097  0.06034413  0.10232895\n",
            " -0.15041586 -0.17855276  0.01186599  0.53694662]\n",
            "\n",
            "# 42 Gradient out:  [-0.72566452 -0.97729706 -1.71829643 -0.70393809 -0.46243803 -0.76056369\n",
            " -1.75113457 -1.86004818 -1.28861329 -0.59152994]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.50249252 -0.45105048  0.38715936  0.14396959  0.10426794  0.16322247\n",
            "  0.05178861  0.02984687  0.15377756  0.58588121]\n",
            "\n",
            "# 43 Gradient out:  [1.34694621 1.74158931 3.04147397 1.3172784  1.02193238 1.39599531\n",
            " 3.08521973 3.22124409 2.32782743 1.17327149]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.35735962 -0.64650989  0.04350008  0.00318198  0.01178033  0.01110973\n",
            " -0.2984383  -0.34216277 -0.1039451   0.46757522]\n",
            "\n",
            "# 44 Gradient out:  [-0.30751546 -0.42484506 -0.78594636 -0.29790727 -0.19596635 -0.32312075\n",
            " -0.80033027 -0.84681264 -0.58109951 -0.24943333]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.62674886 -0.29819203  0.65179487  0.26663766  0.21616681  0.2903088\n",
            "  0.31860565  0.30208605  0.36162039  0.70222952]\n",
            "\n",
            "# 45 Gradient out:  [-0.62452123 -0.85769459 -1.56666716 -0.60513602 -0.3965845  -0.65590517\n",
            " -1.59576906 -1.69054357 -1.16206412 -0.50660735]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.56524576 -0.38316104  0.4946056   0.2070562   0.17697354  0.22568464\n",
            "  0.15853959  0.13272352  0.24540049  0.65234285]\n",
            "\n",
            "# 46 Gradient out:  [0.35786557 0.5342652  1.18387757 0.34693333 0.26343939 0.37682264\n",
            " 1.19928417 1.24068275 0.84511374 0.3002698 ]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.44034152 -0.55469996  0.18127217  0.086029    0.09765664  0.09450361\n",
            " -0.16061422 -0.20538519  0.01298766  0.55102138]\n",
            "\n",
            "# 47 Gradient out:  [-0.73783944 -0.99925693 -1.77788276 -0.71556121 -0.47058252 -0.77372072\n",
            " -1.81147807 -1.92222952 -1.32894926 -0.6009821 ]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.51191463 -0.44784692  0.41804768  0.15541566  0.15034452  0.16986814\n",
            "  0.07924261  0.04275136  0.18201041  0.61107534]\n",
            "\n",
            "# 48 Gradient out:  [1.29069542 1.68138545 2.97350738 1.26150802 0.97307943 1.33902097\n",
            " 3.01648711 3.14958989 2.26549403 1.12035718]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.36434674 -0.6476983   0.06247113  0.01230342  0.05622801  0.01512399\n",
            " -0.283053   -0.34169454 -0.08377944  0.49087892]\n",
            "\n",
            "# 49 Gradient out:  [-0.30760097 -0.4255413  -0.7885275  -0.2979432  -0.19548715 -0.32328701\n",
            " -0.80298543 -0.84970459 -0.58261288 -0.24922123]\n",
            "\n",
            "     Weights  out:  [-0.22887062 -0.10604739  0.23919573 -0.24051849 -0.3962591  -0.21063555\n",
            "  0.25725079  0.32271895  0.0341226  -0.30558745] [ 0.62248583 -0.31142121  0.6571726   0.26460502  0.2508439   0.28292819\n",
            "  0.32024442  0.28822343  0.36931936  0.71495036]\n",
            "\n",
            "Lineal error cuadrático medio (ECM): 1.2376370560396794\n",
            "\n",
            "# 0 Gradient out:  [ 0.08532689  0.21771147 -0.30663919  0.05977025 -0.13230412 -0.41881984\n",
            " -0.28468766 -0.47233554 -0.46491672 -0.1343236 ]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.438092    0.18772846  0.12554415 -0.48954724  0.43002505  0.46558596\n",
            " -0.23491535  0.41720676 -0.3625889  -0.12336047]\n",
            "\n",
            "# 1 Gradient out:  [0.80652713 0.71195716 1.36147786 0.83159728 1.11225869 1.45289439\n",
            " 1.3377108  1.48499169 1.48071765 1.1157307 ]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.42102662  0.23127075  0.06421631 -0.47759319  0.40356423  0.38182199\n",
            " -0.29185288  0.32273965 -0.45557225 -0.15022519]\n",
            "\n",
            "# 2 Gradient out:  [-0.50446874 -0.36842107 -0.99121604 -0.53253754 -0.77396058 -1.10909749\n",
            " -0.96639934 -1.16308081 -1.15554058 -0.77667581]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.2597212   0.37366219  0.33651188 -0.31127374  0.62601596  0.67240087\n",
            " -0.02431072  0.61973799 -0.15942872  0.07292095]\n",
            "\n",
            "# 3 Gradient out:  [-0.16511042  0.00379885 -0.68560906 -0.1980284  -0.45390469 -0.82897406\n",
            " -0.65715059 -0.89741298 -0.88785929 -0.45664619]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.36061495  0.29997797  0.13826867 -0.41778125  0.47122385  0.45058137\n",
            " -0.21759059  0.38712183 -0.39053683 -0.08241421]\n",
            "\n",
            "# 4 Gradient out:  [1.39657894 1.09479137 2.77448698 1.46677807 2.15740904 3.04988663\n",
            " 2.7102494  3.16128745 3.14612586 2.16559245]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.39363703  0.30073774  0.00114686 -0.45738693  0.38044291  0.28478656\n",
            " -0.34902071  0.20763923 -0.56810869 -0.17374345]\n",
            "\n",
            "# 5 Gradient out:  [-0.08969438 -0.07182338 -0.15265736 -0.09334409 -0.12455973 -0.16806157\n",
            " -0.14943628 -0.17521548 -0.17421044 -0.12491017]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.11432124  0.51969602  0.55604426 -0.16403131  0.81192472  0.89476389\n",
            "  0.19302917  0.83989672  0.06111648  0.25937504]\n",
            "\n",
            "# 6 Gradient out:  [-0.11830375 -0.09379916 -0.20482995 -0.123315   -0.16621594 -0.22596619\n",
            " -0.20040602 -0.23576501 -0.2343893  -0.16669773]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.13226012  0.50533134  0.52551279 -0.18270013  0.78701277  0.86115157\n",
            "  0.16314192  0.80485363  0.02627439  0.23439301]\n",
            "\n",
            "# 7 Gradient out:  [-0.1699458  -0.13277777 -0.30159491 -0.17756137 -0.24284152 -0.33368446\n",
            " -0.29486933 -0.34852402 -0.34644262 -0.24357498]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.15592087  0.48657151  0.4845468  -0.20736313  0.75376958  0.81595834\n",
            "  0.12306071  0.75770063 -0.02060347  0.20105346]\n",
            "\n",
            "# 8 Gradient out:  [-0.28136351 -0.21426773 -0.52014432 -0.29515285 -0.41357294 -0.57816084\n",
            " -0.50795958 -0.60488147 -0.60113967 -0.41490427]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.18991003  0.46001595  0.42422782 -0.24287541  0.70520128  0.74922145\n",
            "  0.06408685  0.68799582 -0.08989199  0.15233847]\n",
            "\n",
            "# 9 Gradient out:  [-0.57200153 -0.40899786 -1.15575783 -0.60566423 -0.89520137 -1.29707504\n",
            " -1.12599319 -1.36168562 -1.35266836 -0.89845739]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.24618273  0.41716241  0.32019895 -0.30190598  0.62248669  0.63358928\n",
            " -0.03750507  0.56701953 -0.21011993  0.06935761]\n",
            "\n",
            "# 10 Gradient out:  [0.53315289 0.498063   0.86407177 0.54570129 0.714931   0.903578\n",
            " 0.85146332 0.91223376 0.91123883 0.71713102]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.36058304  0.33536284  0.08904739 -0.42303882  0.44344642  0.37417427\n",
            " -0.26270371  0.2946824  -0.4806536  -0.11033386]\n",
            "\n",
            "# 11 Gradient out:  [-0.72039599 -0.4869772  -1.55187196 -0.76854544 -1.18078555 -1.75422218\n",
            " -1.50933788 -1.84667282 -1.83378872 -1.18541111]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.25395246  0.43497544  0.26186174 -0.31389856  0.58643262  0.55488987\n",
            " -0.09241104  0.47712915 -0.29840583  0.03309234]\n",
            "\n",
            "# 12 Gradient out:  [1.4784698  1.14594359 2.91269696 1.55352606 2.27084462 3.21204788\n",
            " 2.84454853 3.33733437 3.32013683 2.27925683]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.39803166  0.33758    -0.04851265 -0.46760765  0.35027551  0.20404543\n",
            " -0.39427862  0.10779459 -0.66516358 -0.20398988]\n",
            "\n",
            "# 13 Gradient out:  [-0.11356589 -0.08909144 -0.20017572 -0.11857743 -0.16152323 -0.22129906\n",
            " -0.1957503  -0.23107627 -0.22970437 -0.1620057 ]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.1023377   0.56676871  0.53402674 -0.15690244  0.80444443  0.84645501\n",
            "  0.17463109  0.77526146 -0.00113621  0.25186148]\n",
            "\n",
            "# 14 Gradient out:  [-0.16247015 -0.12568086 -0.29302996 -0.17001663 -0.23476117 -0.32480972\n",
            " -0.28636375 -0.33948557 -0.33742813 -0.23548884]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.12505088  0.54895043  0.49399159 -0.18061793  0.77213979  0.80219519\n",
            "  0.13548103  0.72904621 -0.04707708  0.21946034]\n",
            "\n",
            "# 15 Gradient out:  [-0.26760077 -0.20217172 -0.50076326 -0.2810579  -0.39669746 -0.55735913\n",
            " -0.48887    -0.58340136 -0.57975568 -0.39799784]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.15754491  0.52381425  0.4353856  -0.21462125  0.72518755  0.73723325\n",
            "  0.07820828  0.6611491  -0.11456271  0.17236258]\n",
            "\n",
            "# 16 Gradient out:  [-0.54835874 -0.39255523 -1.10616283 -0.58052487 -0.85719044 -1.24121346\n",
            " -1.077722   -1.30299202 -1.29436747 -0.86030179]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.21106506  0.48337991  0.33523295 -0.27083283  0.64584806  0.62576143\n",
            " -0.01956572  0.54446882 -0.23051384  0.09276301]\n",
            "\n",
            "# 17 Gradient out:  [0.24442702 0.2766471  0.31331088 0.24255213 0.28127747 0.29359425\n",
            " 0.31361266 0.27604422 0.27869317 0.28197834]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.32073681  0.40486886  0.11400039 -0.38693781  0.47440997  0.37751873\n",
            " -0.23511012  0.28387042 -0.48938734 -0.07929735]\n",
            "\n",
            "# 18 Gradient out:  [-0.48524574 -0.26829751 -1.18269037 -0.52806909 -0.87195487 -1.36747952\n",
            " -1.14542021 -1.45528388 -1.44297471 -0.87570222]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.2718514   0.46019828  0.17666256 -0.33842738  0.53066547  0.43623758\n",
            " -0.17238759  0.33907926 -0.4336487  -0.02290168]\n",
            "\n",
            "# 19 Gradient out:  [1.43196892 1.11783868 2.75986763 1.50207274 2.16574399 3.04114368\n",
            " 2.69638329 3.16051589 3.14405786 2.17350131]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.36890055  0.40653878 -0.05987551 -0.4440412   0.35627449  0.16274168\n",
            " -0.40147163  0.04802249 -0.72224364 -0.19804213]\n",
            "\n",
            "# 20 Gradient out:  [-0.16721405 -0.12700146 -0.31042415 -0.17547994 -0.2465065  -0.34519614\n",
            " -0.30311922 -0.36121187 -0.3589687  -0.24730523]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.08250677  0.63010652  0.49209801 -0.14362665  0.78942329  0.77097042\n",
            "  0.13780503  0.68012567 -0.09343207  0.23665814]\n",
            "\n",
            "# 21 Gradient out:  [-0.28469438 -0.21108619 -0.5477826  -0.29986116 -0.43035563 -0.6115099\n",
            " -0.53437343 -0.64076564 -0.63667362 -0.4318237 ]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.11594958  0.60470623  0.43001318 -0.17872264  0.74012199  0.70193119\n",
            "  0.07718119  0.60788329 -0.16522581  0.18719709]\n",
            "\n",
            "# 22 Gradient out:  [-0.61223388 -0.42990531 -1.26408493 -0.64986424 -0.97314297 -1.42212176\n",
            " -1.23082071 -1.49440703 -1.48431888 -0.97677641]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.17288845  0.56248899  0.32045666 -0.23869487  0.65405086  0.57962921\n",
            " -0.0296935   0.47973016 -0.29256054  0.10083235]\n",
            "\n",
            "# 23 Gradient out:  [0.91328683 0.7312782  1.8530494  0.95856251 1.43160614 2.02435603\n",
            " 1.81092315 2.08835326 2.07981904 1.43732623]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.29533523  0.47650793  0.06763968 -0.36866772  0.45942227  0.29520486\n",
            " -0.27585764  0.18084876 -0.58942431 -0.09452293]\n",
            "\n",
            "# 24 Gradient out:  [-0.28040288 -0.20757817 -0.54075209 -0.2954102  -0.42454727 -0.60380493\n",
            " -0.52748349 -0.63274658 -0.62869869 -0.42600013]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.11267786  0.62276357  0.43824956 -0.17695522  0.7457435   0.70007606\n",
            "  0.08632699  0.59851941 -0.1734605   0.19294231]\n",
            "\n",
            "# 25 Gradient out:  [-0.60313782 -0.42381764 -1.24430413 -0.64014743 -0.9581304  -1.39973118\n",
            " -1.21158792 -1.47082745 -1.46090459 -0.96170453]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.16875844  0.58124793  0.33009914 -0.23603726  0.66083405  0.57931508\n",
            " -0.01916971  0.47197009 -0.29920024  0.10774229]\n",
            "\n",
            "# 26 Gradient out:  [0.81769691 0.65990057 1.66567071 0.85784611 1.28523312 1.81577739\n",
            " 1.62811541 1.87029078 1.86307715 1.29043213]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.289386    0.4964844   0.08123831 -0.36406674  0.46920797  0.29936884\n",
            " -0.26148729  0.1778046  -0.59138116 -0.08459862]\n",
            "\n",
            "# 27 Gradient out:  [-0.35692568 -0.26027446 -0.70296913 -0.37686506 -0.5485128  -0.78670079\n",
            " -0.6853371  -0.82507144 -0.81970866 -0.55044411]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.12584662  0.62846452  0.41437246 -0.19249752  0.72625459  0.66252432\n",
            "  0.06413579  0.55186276 -0.21876573  0.17348781]\n",
            "\n",
            "# 28 Gradient out:  [-0.76057159 -0.51250913 -1.63422097 -0.81145591 -1.24437928 -1.84873541\n",
            " -1.58934127 -1.94733316 -1.93356979 -1.24922404]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.19723176  0.57640963  0.27377863 -0.26787053  0.61655203  0.50518416\n",
            " -0.07293163  0.38684847 -0.38270746  0.06339898]\n",
            "\n",
            "# 29 Gradient out:  [1.40432428 1.10323061 2.66036779 1.47100946 2.098483   2.92899175\n",
            " 2.60008262 3.04408093 3.02816372 2.10580171]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.34934607  0.4739078  -0.05306556 -0.43016171  0.36767618  0.13543708\n",
            " -0.39079988 -0.00261816 -0.76942142 -0.18644582]\n",
            "\n",
            "# 30 Gradient out:  [-0.20911311 -0.15525672 -0.40164628 -0.22020958 -0.31571041 -0.44827012\n",
            " -0.39183523 -0.46967944 -0.46668428 -0.31678496]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.06848122  0.69455392  0.47900799 -0.13595982  0.78737278  0.72123543\n",
            "  0.12921664  0.60619803 -0.16378868  0.23471452]\n",
            "\n",
            "# 31 Gradient out:  [-0.40379185 -0.29045584 -0.80998285 -0.42719172 -0.62867772 -0.90821068\n",
            " -0.78928862 -0.95317119 -0.94689073 -0.63094484]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.11030384  0.66350258  0.39867874 -0.18000174  0.72423069  0.63158141\n",
            "  0.0508496   0.51226214 -0.25712553  0.17135753]\n",
            "\n",
            "# 32 Gradient out:  [-0.75267591 -0.49284979 -1.63692112 -0.80515019 -1.24256746 -1.86015971\n",
            " -1.59086485 -1.96430879 -1.94972715 -1.24741869]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.19106221  0.60541141  0.23668217 -0.26544008  0.59849515  0.44993927\n",
            " -0.10700813  0.3216279  -0.44650368  0.04516856]\n",
            "\n",
            "# 33 Gradient out:  [1.21696664 0.97319105 2.20194097 1.26998693 1.7614913  2.41756555\n",
            " 2.15420823 2.51201968 2.49886303 1.76719399]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.34159739  0.50684145 -0.09070206 -0.42647012  0.34998166  0.07790733\n",
            " -0.4251811  -0.07123386 -0.83644911 -0.20431518]\n",
            "\n",
            "# 34 Gradient out:  [-0.55884336 -0.39106363 -1.15892032 -0.59347147 -0.89108424 -1.30433835\n",
            " -1.12830742 -1.37086964 -1.36158197 -0.89442991]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.09820406  0.70147966  0.34968614 -0.17247273  0.70227992  0.56142044\n",
            "  0.00566055  0.43117008 -0.3366765   0.14912362]\n",
            "\n",
            "# 35 Gradient out:  [0.32950669 0.28127663 0.7683905  0.34669141 0.57067704 0.82306224\n",
            " 0.75127517 0.83427277 0.83312439 0.57355857]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.20997274  0.62326694  0.11790208 -0.29116703  0.52406307  0.30055277\n",
            " -0.22000093  0.15699615 -0.6089929  -0.02976236]\n",
            "\n",
            "# 36 Gradient out:  [-0.78483573 -0.52842523 -1.67532276 -0.83707097 -1.27805239 -1.89638414\n",
            " -1.62934034 -1.99874096 -1.9844242  -1.28297112]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.1440714   0.67952226  0.27158018 -0.22182875  0.63819848  0.46516522\n",
            " -0.0697459   0.3238507  -0.44236802  0.08494935]\n",
            "\n",
            "# 37 Gradient out:  [1.3396888  1.06692674 2.44792006 1.3991884  1.95231783 2.68950557\n",
            " 2.39431366 2.79498304 2.78030381 1.95874222]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.30103854  0.57383722 -0.06348438 -0.38924294  0.382588    0.08588839\n",
            " -0.39561397 -0.07589749 -0.83925286 -0.17164487]\n",
            "\n",
            "# 38 Gradient out:  [-0.33335081 -0.23759953 -0.67725286 -0.35314144 -0.52374578 -0.76027948\n",
            " -0.65974538 -0.79823873 -0.79293777 -0.52566631]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.03310078  0.78722256  0.42609964 -0.10940526  0.77305157  0.6237895\n",
            "  0.08324876  0.48309912 -0.2831921   0.22010357]\n",
            "\n",
            "# 39 Gradient out:  [-0.76060425 -0.51708107 -1.61340604 -0.8103907  -1.23289623 -1.82365054\n",
            " -1.56952569 -1.92070174 -1.90713175 -1.23761982]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.09977095  0.73970266  0.29064906 -0.18003355  0.66830241  0.47173361\n",
            " -0.04870031  0.32345137 -0.44177965  0.11497031]\n",
            "\n",
            "# 40 Gradient out:  [1.45344627 1.14363248 2.73611757 1.52173533 2.16236985 3.01185465\n",
            " 2.67443861 3.13076682 3.11427909 2.16983485]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.2518918   0.63628644 -0.03203215 -0.34211169  0.42172316  0.1070035\n",
            " -0.36260545 -0.06068897 -0.823206   -0.13255365]\n",
            "\n",
            "# 41 Gradient out:  [-0.15283745 -0.1112015  -0.30229606 -0.16143597 -0.2355824  -0.33837999\n",
            " -0.29468953 -0.35490344 -0.35259395 -0.23641729]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [ 0.03879746  0.86501294  0.51519137 -0.03776462  0.85419713  0.70937443\n",
            "  0.17228227  0.56546439 -0.20035018  0.30141332]\n",
            "\n",
            "# 42 Gradient out:  [-0.2620438  -0.18704299 -0.53170793 -0.27755213 -0.41133618 -0.59675164\n",
            " -0.51798646 -0.62648016 -0.62232853 -0.41284269]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [ 0.00822997  0.84277264  0.45473216 -0.07005181  0.80708065  0.64169843\n",
            "  0.11334437  0.4944837  -0.27086897  0.25412986]\n",
            "\n",
            "# 43 Gradient out:  [-0.585722   -0.40433105 -1.23289202 -0.62312049 -0.94404783 -1.39004221\n",
            " -1.1998418  -1.46200717 -1.45195962 -0.94765312]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.04417879  0.80536404  0.34839057 -0.12556224  0.72481342  0.5223481\n",
            "  0.00974708  0.36918767 -0.39533468  0.17156132]\n",
            "\n",
            "# 44 Gradient out:  [0.59789189 0.44994739 1.44150169 0.63703028 1.06282326 1.5851293\n",
            " 1.4046389  1.63424228 1.62790427 1.06803465]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.16132319  0.72449783  0.10181217 -0.25018634  0.53600385  0.24433966\n",
            " -0.23022128  0.07678623 -0.6857266  -0.0179693 ]\n",
            "\n",
            "# 45 Gradient out:  [-0.47379725 -0.33069691 -0.98685887 -0.50336317 -0.75785192 -1.1109387\n",
            " -0.96071178 -1.1676556  -1.15973868 -0.76071466]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.04174481  0.81448731  0.39011251 -0.12278028  0.7485685   0.56136552\n",
            "  0.0507065   0.40363469 -0.36014575  0.19563763]\n",
            "\n",
            "# 46 Gradient out:  [-0.4486583  -0.28990962 -0.84190616 -0.47661967 -0.66757167 -0.97085886\n",
            " -0.81843883 -1.03920653 -1.02936458 -0.6694842 ]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.13650426  0.74834793  0.19274073 -0.22345292  0.59699812  0.33917778\n",
            " -0.14143586  0.17010357 -0.59209348  0.04349469]\n",
            "\n",
            "# 47 Gradient out:  [1.43587403 1.10668063 2.85575514 1.51011283 2.22031416 3.15189964\n",
            " 2.78833887 3.27614338 3.25906051 2.22864702]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [-0.22623592  0.690366    0.0243595  -0.31877685  0.46348379  0.14500601\n",
            " -0.30512362 -0.03773774 -0.7979664  -0.09040215]\n",
            "\n",
            "# 48 Gradient out:  [-0.08615994 -0.0637552  -0.16636654 -0.09077884 -0.13056606 -0.18576668\n",
            " -0.16228184 -0.19467108 -0.19342536 -0.1310139 ]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [ 0.06093888  0.91170213  0.59551053 -0.01675428  0.90754662  0.77538594\n",
            "  0.25254415  0.61749094 -0.1461543   0.35532726]\n",
            "\n",
            "# 49 Gradient out:  [-0.11785344 -0.08633249 -0.23088447 -0.12435854 -0.18043159 -0.25819258\n",
            " -0.22513054 -0.27070927 -0.26895913 -0.1810629 ]\n",
            "\n",
            "     Weights  out:  [-0.1968247  -0.3410781   0.17369651 -0.17246529  0.00912579  0.28710621\n",
            "  0.15303022  0.35335097  0.34325777  0.01106103] [ 0.0437069   0.89895109  0.56223722 -0.03491005  0.88143341  0.7382326\n",
            "  0.22008778  0.57855673 -0.18483937  0.32912448]\n",
            "\n",
            "Tanh error cuadrático medio (ECM): 1.102836486712915\n",
            "\n",
            "# 0 Gradient out:  [1.04037991 0.9458115  1.04589562 1.37465432 0.66187633 1.36446953\n",
            " 0.66887171 0.60494256 1.37169545 1.26650901]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.45210365  0.07121779  0.14673902  0.17651087  0.2990357   0.31365279\n",
            " -0.02112758 -0.37293148  0.01566331 -0.47974212]\n",
            "\n",
            "# 1 Gradient out:  [-0.93375776 -0.84270216 -0.93911051 -1.41713885 -0.48806051 -1.38849577\n",
            " -0.50221381 -0.3432134  -1.40883279 -1.1888287 ]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.24402767  0.26038009  0.35591814  0.45144173  0.43141097  0.5865467\n",
            "  0.11264677 -0.25194297  0.2900024  -0.22644032]\n",
            "\n",
            "# 2 Gradient out:  [0.78862094 0.7152179  0.79289384 1.01466944 0.5112686  1.01085983\n",
            " 0.51517544 0.48621974 1.01357021 0.95664798]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.43077922  0.09183966  0.16809604  0.16801396  0.33379887  0.30884754\n",
            "  0.012204   -0.32058565  0.00823584 -0.46420606]\n",
            "\n",
            "# 3 Gradient out:  [-1.18237595 -1.06086283 -1.18952089 -1.83317528 -0.5844601  -1.79441455\n",
            " -0.6036176  -0.38831892 -1.82194214 -1.52425435]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.27305503  0.23488324  0.32667481  0.37094785  0.43605259  0.51101951\n",
            "  0.11523909 -0.2233417   0.21094988 -0.27287646]\n",
            "\n",
            "# 4 Gradient out:  [2.36683376 2.13109272 2.38064502 3.43779689 1.30385959 3.38460137\n",
            " 1.3322048  1.0292561  3.4223586  2.98541493]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.50953022  0.02271067  0.08877063  0.00431279  0.31916057  0.1521366\n",
            " -0.00548443 -0.30100549 -0.15343855 -0.57772733]\n",
            "\n",
            "# 5 Gradient out:  [-0.14459402 -0.13301762 -0.1452745  -0.20625651 -0.08793056 -0.20253497\n",
            " -0.08973638 -0.06925296 -0.20517437 -0.17700397]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.03616347  0.44892922  0.56489963  0.69187217  0.57993248  0.82905687\n",
            "  0.26095653 -0.09515427  0.53103317  0.01935565]\n",
            "\n",
            "# 6 Gradient out:  [-0.19953019 -0.18305753 -0.20049847 -0.28714202 -0.11894728 -0.28187196\n",
            " -0.12151143 -0.09246997 -0.28561012 -0.24563008]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.06508227  0.42232569  0.53584473  0.65062087  0.56234637  0.78854988\n",
            "  0.24300925 -0.10900486  0.4899983  -0.01604514]\n",
            "\n",
            "# 7 Gradient out:  [-0.30822393 -0.28165759 -0.3097855  -0.44925244 -0.17835187 -0.44080889\n",
            " -0.18247625 -0.13586444 -0.44679931 -0.38253935]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.10498831  0.38571419  0.49574504  0.59319247  0.53855692  0.73217549\n",
            "  0.21870697 -0.12749885  0.43287627 -0.06517116]\n",
            "\n",
            "# 8 Gradient out:  [-0.5784857  -0.52511411 -0.5816229  -0.86132178 -0.31766054 -0.84450003\n",
            " -0.32592855 -0.23279837 -0.85643884 -0.72777318]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.1666331   0.32938267  0.43378794  0.50334198  0.50288654  0.64401371\n",
            "  0.18221172 -0.15467174  0.34351641 -0.14167903]\n",
            "\n",
            "# 9 Gradient out:  [-1.25023353 -1.11989772 -1.257899   -1.95493732 -0.60553551 -1.91259652\n",
            " -0.62638967 -0.39147513 -1.94266705 -1.61848901]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.28233024  0.22435985  0.31746336  0.33107762  0.43935443  0.4751137\n",
            "  0.11702601 -0.20123141  0.17222864 -0.28723366]\n",
            "\n",
            "# 10 Gradient out:  [2.2305603  2.01823923 2.24300519 3.22137009 1.26120691 3.16974054\n",
            " 1.28790327 0.99754044 3.20635227 2.79298823]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-5.32376943e-01  3.80302246e-04  6.58835562e-02 -5.99098428e-02\n",
            "  3.18247331e-01  9.25944013e-02 -8.25192611e-03 -2.79526441e-01\n",
            " -2.16304767e-01 -6.10931464e-01]\n",
            "\n",
            "# 11 Gradient out:  [-0.28299131 -0.25821888 -0.28444742 -0.41436656 -0.16194323 -0.40651408\n",
            " -0.16578342 -0.1224128  -0.41208542 -0.35226575]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.08626488  0.40402815  0.51448459  0.58436418  0.57048871  0.72654251\n",
            "  0.24932873 -0.08001835  0.42496569 -0.05233382]\n",
            "\n",
            "# 12 Gradient out:  [-0.51326584 -0.46573563 -0.51605964 -0.7649768  -0.28107683 -0.7500131\n",
            " -0.28843191 -0.20559044 -0.760633   -0.64617272]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.14286315  0.35238437  0.45759511  0.50149086  0.53810007  0.64523969\n",
            "  0.21617205 -0.10450091  0.3425486  -0.12278697]\n",
            "\n",
            "# 13 Gradient out:  [-1.16350904 -1.04531957 -1.17045855 -1.79700924 -0.58185789 -1.75916022\n",
            " -0.60050893 -0.39057036 -1.78603524 -1.49605165]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.24551632  0.25923725  0.35438318  0.3484955   0.4818847   0.49523707\n",
            "  0.15848566 -0.145619    0.190422   -0.25202151]\n",
            "\n",
            "# 14 Gradient out:  [2.32248352 2.08832818 2.33619995 3.37819977 1.27053898 3.32638748\n",
            " 1.29832885 1.00249707 3.36316696 2.93515095]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.47821812  0.05017333  0.12029147 -0.01090634  0.36551312  0.14340503\n",
            "  0.03838388 -0.22373307 -0.16678505 -0.55123184]\n",
            "\n",
            "# 15 Gradient out:  [-0.13685704 -0.12545605 -0.1375272  -0.19745113 -0.08110485 -0.19380931\n",
            " -0.08287756 -0.06280544 -0.19639254 -0.1687544 ]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.01372142  0.46783897  0.58753146  0.66473361  0.61962092  0.80868253\n",
            "  0.29804965 -0.02323366  0.50584835  0.03579835]\n",
            "\n",
            "# 16 Gradient out:  [-0.18665097 -0.17068833 -0.18758924 -0.27137933 -0.1086307  -0.26630187\n",
            " -0.11110811 -0.08309371 -0.26990388 -0.23129581]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.04109283  0.44274776  0.56002602  0.62524338  0.60339995  0.76992066\n",
            "  0.28147414 -0.03579475  0.46656984  0.00204747]\n",
            "\n",
            "# 17 Gradient out:  [-0.28287222 -0.25780216 -0.2843458  -0.41573623 -0.16040463 -0.40780519\n",
            " -0.16428711 -0.12046343 -0.41343253 -0.35296486]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.07842302  0.40861009  0.52250818  0.57096752  0.58167381  0.71666029\n",
            "  0.25925251 -0.05241349  0.41258906 -0.0442117 ]\n",
            "\n",
            "# 18 Gradient out:  [-0.51470048 -0.46659143 -0.51752828 -0.76937415 -0.27972189 -0.7542471\n",
            " -0.28716217 -0.20339206 -0.76498326 -0.64921105]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.13499747  0.35704966  0.46563901  0.48782027  0.54959288  0.63509925\n",
            "  0.22639509 -0.07650618  0.32990256 -0.11480467]\n",
            "\n",
            "# 19 Gradient out:  [-1.172607   -1.05350133 -1.17961057 -1.81189489 -0.58604415 -1.77362859\n",
            " -0.60487865 -0.39272999 -1.80079867 -1.50790684]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.23793756  0.26373137  0.36213336  0.33394544  0.4936485   0.48424983\n",
            "  0.16896266 -0.11718459  0.1769059  -0.24464688]\n",
            "\n",
            "# 20 Gradient out:  [2.32568446 2.09204395 2.3393717  3.38348241 1.27402974 3.33116637\n",
            " 1.30195459 1.00385236 3.36829797 2.93790275]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.47245896  0.05303111  0.12621124 -0.02843354  0.37643968  0.12952412\n",
            "  0.04798693 -0.19573059 -0.18325383 -0.54622824]\n",
            "\n",
            "# 21 Gradient out:  [-0.13916381 -0.12736413 -0.13985739 -0.2018151  -0.08148595 -0.19805684\n",
            " -0.08331801 -0.0625909  -0.20072285 -0.17216689]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.00732207  0.4714399   0.59408558  0.64826295  0.63124562  0.79575739\n",
            "  0.30837784  0.00503988  0.49040576  0.0413523 ]\n",
            "\n",
            "# 22 Gradient out:  [-0.19108918 -0.17446579 -0.19206628 -0.27924099 -0.10987163 -0.27396828\n",
            " -0.11244801 -0.08333795 -0.27770905 -0.23756902]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.03515483  0.44596707  0.56611411  0.60789993  0.61494843  0.75614602\n",
            "  0.29171424 -0.00747829  0.45026119  0.00691893]\n",
            "\n",
            "# 23 Gradient out:  [-0.29296534 -0.2665767  -0.29451641 -0.43269882 -0.16410091 -0.4243724\n",
            " -0.16818256 -0.12214617 -0.43028067 -0.36672694]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.07337267  0.41107391  0.52770085  0.55205173  0.59297411  0.70135237\n",
            "  0.26922464 -0.02414589  0.39471938 -0.04059488]\n",
            "\n",
            "# 24 Gradient out:  [-0.54427909 -0.49266093 -0.54731315 -0.81742885 -0.29218494 -0.80122367\n",
            " -0.30016401 -0.21037961 -0.81272569 -0.68859491]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.13196574  0.35775857  0.46879757  0.46551196  0.56015393  0.61647789\n",
            "  0.23558813 -0.04857512  0.30866325 -0.11394026]\n",
            "\n",
            "# 25 Gradient out:  [-1.23512585 -1.10915185 -1.24253449 -1.91605603 -0.61239167 -1.87499361\n",
            " -0.63252954 -0.40518553 -1.90414725 -1.59083144]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.24082155  0.25922639  0.35933494  0.30202619  0.50171694  0.45623315\n",
            "  0.17555533 -0.09065104  0.14611811 -0.25165925]\n",
            "\n",
            "# 26 Gradient out:  [2.31281486 2.09086375 2.32582301 3.34406687 1.30178719 3.2906017\n",
            " 1.32948646 1.02862394 3.32851332 2.89969603]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.48784672  0.03739602  0.11082804 -0.08118501  0.3792386   0.08123443\n",
            "  0.04904942 -0.17168815 -0.23471134 -0.56982554]\n",
            "\n",
            "# 27 Gradient out:  [-0.19229207 -0.1751633  -0.19329886 -0.28299463 -0.10865572 -0.27758432\n",
            " -0.11130489 -0.08140771 -0.28142308 -0.24016454]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.02528375  0.45556877  0.57599264  0.58762836  0.63959604  0.73935477\n",
            "  0.31494671  0.03403664  0.43099133  0.01011367]\n",
            "\n",
            "# 28 Gradient out:  [-0.29665965 -0.26936435 -0.29826398 -0.44101612 -0.16343612 -0.43243532\n",
            " -0.1676504  -0.12016826 -0.43852463 -0.37292802]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.06374217  0.42053611  0.53733287  0.53102944  0.6178649   0.68383791\n",
            "  0.29268573  0.0177551   0.37470671 -0.03791924]\n",
            "\n",
            "# 29 Gradient out:  [-0.55764582 -0.50388244 -0.56080596 -0.84198478 -0.29512735 -0.82514\n",
            " -0.30343128 -0.21005311 -0.83709671 -0.70794083]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.1230741   0.36666324  0.47768007  0.44282621  0.58517767  0.59735084\n",
            "  0.25915565 -0.00627855  0.28700178 -0.11250484]\n",
            "\n",
            "# 30 Gradient out:  [-1.2629511  -1.13455453 -1.27050327 -1.96154842 -0.6260805  -1.91908586\n",
            " -0.64681085 -0.4121426  -1.94922937 -1.62646828]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.23460326  0.26588675  0.36551888  0.27442925  0.5261522   0.43232284\n",
            "  0.1984694  -0.04828918  0.11958244 -0.25409301]\n",
            "\n",
            "# 31 Gradient out:  [2.24586364 2.03660663 2.25813042 3.23107959 1.28699254 3.17870688\n",
            " 1.31367573 1.02104888 3.21582135 2.80164114]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.48719348  0.03897584  0.11141823 -0.11788043  0.4009361   0.04850567\n",
            "  0.06910723 -0.13071769 -0.27026343 -0.57938666]\n",
            "\n",
            "# 32 Gradient out:  [-0.25542363 -0.23159926 -0.25682393 -0.38127329 -0.1392055  -0.37380684\n",
            " -0.14287728 -0.10153863 -0.37910563 -0.32196607]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.03802075  0.44629717  0.56304431  0.52833549  0.65833461  0.68424705\n",
            "  0.33184237  0.07349208  0.37290084 -0.01905844]\n",
            "\n",
            "# 33 Gradient out:  [-0.4487396  -0.40532007 -0.45129167 -0.67803452 -0.23689803 -0.66447012\n",
            " -0.24358872 -0.16838103 -0.67409831 -0.57004105]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.08910548  0.39997732  0.51167953  0.45208083  0.63049351  0.60948568\n",
            "  0.30326692  0.05318435  0.29707971 -0.08345165]\n",
            "\n",
            "# 34 Gradient out:  [-1.02203186 -0.91858862 -1.02811371 -1.57467683 -0.51400545 -1.54168235\n",
            " -0.530241   -0.34739392 -1.56510569 -1.31257884]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.1788534   0.3189133   0.42142119  0.31647392  0.58311391  0.47659165\n",
            "  0.25454917  0.01950815  0.16226005 -0.19745986]\n",
            "\n",
            "# 35 Gradient out:  [1.45818265 1.28405341 1.4683644  2.16242766 0.71374122 2.13484493\n",
            " 0.73078157 0.56344252 2.15450241 1.89688713]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.38325977  0.13519558  0.21579845  0.00153856  0.48031281  0.16825518\n",
            "  0.14850097 -0.04997064 -0.15076109 -0.45997563]\n",
            "\n",
            "# 36 Gradient out:  [-0.48509728 -0.43785438 -0.48787408 -0.73461672 -0.25457363 -0.71985978\n",
            " -0.26185534 -0.18001995 -0.73033475 -0.61709504]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.09162324  0.39200626  0.50947133  0.43402409  0.62306106  0.59522417\n",
            "  0.29465729  0.06271787  0.28013939 -0.0805982 ]\n",
            "\n",
            "# 37 Gradient out:  [-1.12348466 -1.00944838 -1.13019018 -1.7361764  -0.56173426 -1.69937932\n",
            " -0.57978964 -0.37608239 -1.72550112 -1.44456053]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.1886427   0.30443538  0.41189651  0.28710075  0.57214633  0.45125221\n",
            "  0.24228622  0.02671388  0.13407244 -0.20401721]\n",
            "\n",
            "# 38 Gradient out:  [2.09466976 1.87098084 2.10776879 3.08386313 1.09866615 3.03704999\n",
            " 1.12434978 0.85450782 3.07030246 2.67599336]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.41333963  0.10254571  0.18585848 -0.06013453  0.45979948  0.11137635\n",
            "  0.12632829 -0.0485026  -0.21102778 -0.49292932]\n",
            "\n",
            "# 39 Gradient out:  [-0.17746643 -0.16112512 -0.1784269  -0.26381536 -0.0977481  -0.25868531\n",
            " -0.10026757 -0.07188207 -0.26232572 -0.22310809]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [0.00559432 0.47674188 0.60741224 0.55663809 0.67953271 0.71878635\n",
            " 0.35119825 0.12239897 0.40303271 0.04226936]\n",
            "\n",
            "# 40 Gradient out:  [-0.26696378 -0.24172772 -0.26844704 -0.40018164 -0.14389178 -0.39228948\n",
            " -0.14777737 -0.10405943 -0.3978907  -0.33743643]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.02989896  0.44451685  0.57172686  0.50387502  0.65998309  0.66704928\n",
            "  0.33114473  0.10802255  0.35056757 -0.00235226]\n",
            "\n",
            "# 41 Gradient out:  [-0.48030231 -0.43324853 -0.48306799 -0.72873737 -0.25073524 -0.71405419\n",
            " -0.2579841  -0.17654037 -0.72447703 -0.61175795]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.08329172  0.39617131  0.51803745  0.42383869  0.63120473  0.58859139\n",
            "  0.30158926  0.08721067  0.27098943 -0.06983955]\n",
            "\n",
            "# 42 Gradient out:  [-1.11311761 -0.99999499 -1.11976938 -1.72084814 -0.55590632 -1.68434493\n",
            " -0.57381416 -0.37175346 -1.71025769 -1.43160178]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.17935218  0.3095216   0.42142385  0.27809122  0.58105769  0.44578055\n",
            "  0.24999244  0.05190259  0.12609402 -0.19219114]\n",
            "\n",
            "# 43 Gradient out:  [2.03310052 1.81243636 2.04602107 3.00270046 1.05340042 2.95740215\n",
            " 1.07846013 0.81641924 2.9895871  2.60531051]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.4019757   0.1095226   0.19746998 -0.06607841  0.46987642  0.10891156\n",
            "  0.13522961 -0.0224481  -0.21595751 -0.47851149]\n",
            "\n",
            "# 44 Gradient out:  [-0.1939562  -0.17585288 -0.19502022 -0.28954594 -0.10566772 -0.28387589\n",
            " -0.10845591 -0.07706489 -0.28789974 -0.24450921]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [0.0046444  0.47200988 0.60667419 0.53446168 0.68055651 0.70039199\n",
            " 0.35092163 0.14083575 0.38195991 0.04255061]\n",
            "\n",
            "# 45 Gradient out:  [-0.30252582 -0.27350658 -0.30423143 -0.45562705 -0.16103092 -0.44657083\n",
            " -0.16549545 -0.1152996  -0.45299865 -0.38355386]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.03414684  0.4368393   0.56767015  0.47655249  0.65942296  0.64361681\n",
            "  0.32923045  0.12542277  0.32437996 -0.00635123]\n",
            "\n",
            "# 46 Gradient out:  [-0.58030856 -0.52256479 -0.58370265 -0.88540902 -0.29844149 -0.86738062\n",
            " -0.30734833 -0.20731044 -0.8801789  -0.74170217]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.094652    0.38213798  0.50682386  0.38542708  0.62721678  0.55430265\n",
            "  0.29613136  0.10236285  0.23378023 -0.083062  ]\n",
            "\n",
            "# 47 Gradient out:  [-1.29645396 -1.166522   -1.30409911 -2.01506945 -0.64651521 -1.97051084\n",
            " -0.6680154  -0.4229286  -2.00213019 -1.66675678]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.21071372  0.27762503  0.39008333  0.20834528  0.56752848  0.38082652\n",
            "  0.23466169  0.06090076  0.05774445 -0.23140244]\n",
            "\n",
            "# 48 Gradient out:  [2.11086281 1.92477165 2.12177536 3.00660437 1.24977226 2.95694316\n",
            " 1.27435511 1.00025842 2.99209746 2.60870892]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.47000451  0.04432063  0.12926351 -0.19466861  0.43822544 -0.01327564\n",
            "  0.10105861 -0.02368496 -0.34268159 -0.5647538 ]\n",
            "\n",
            "# 49 Gradient out:  [-0.41685743 -0.37516886 -0.41930767 -0.63652077 -0.2136569  -0.62358044\n",
            " -0.22005965 -0.14821486 -0.63276692 -0.53324282]\n",
            "\n",
            "     Weights  out:  [ 0.02725732 -0.0265906   0.03043406  0.4083257  -0.26878777  0.37180701\n",
            " -0.25655293 -0.42941717  0.3972638   0.1905144 ] [-0.04783195  0.42927496  0.55361858  0.40665226  0.68817989  0.57811299\n",
            "  0.35592964  0.17636673  0.2557379  -0.04301201]\n",
            "\n",
            "Lineal error cuadrático medio (ECM): 1.5791508804109293\n",
            "\n",
            "# 0 Gradient out:  [3.52570571 3.4638575  3.4515844  1.04998466 1.33377726 0.96972953\n",
            " 3.5255327  0.98406836 1.12212992 1.53095685]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [-0.1533876  -0.03966069 -0.32016236 -0.46354224  0.28901216 -0.06332587\n",
            " -0.30769291  0.07611275 -0.11910732  0.26120614]\n",
            "\n",
            "# 1 Gradient out:  [-0.40520531 -0.39686283 -0.39518354 -0.11709585 -0.15515265 -0.10622659\n",
            " -0.40518238 -0.10813849 -0.12701192 -0.17925431]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.55175354  0.65311081  0.37015452 -0.2535453   0.55576761  0.13062004\n",
            "  0.39741363  0.27292642  0.10531866  0.56739751]\n",
            "\n",
            "# 2 Gradient out:  [-0.69215879 -0.67755478 -0.6746113  -0.18520896 -0.25210526 -0.16617461\n",
            " -0.69211869 -0.16951861 -0.20261245 -0.29454301]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.47071248  0.57373825  0.29111781 -0.27696447  0.52473708  0.10937472\n",
            "  0.31637715  0.25129873  0.07991628  0.53154665]\n",
            "\n",
            "# 3 Gradient out:  [-1.50110026 -1.46791654 -1.46121256 -0.3488477  -0.50167465 -0.30556797\n",
            " -1.50100937 -0.3131536  -0.38856301 -0.59845282]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.33228072  0.43822729  0.15619555 -0.31400626  0.47431603  0.0761398\n",
            "  0.17795341  0.21739501  0.03939379  0.47263804]\n",
            "\n",
            "# 4 Gradient out:  [0.42251217 0.42894123 0.43027102 0.18788065 0.17089447 0.19631961\n",
            " 0.42252872 0.19490291 0.18055472 0.18111152]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.03206067  0.14464398 -0.13604696 -0.3837758   0.3739811   0.0150262\n",
            " -0.12224846  0.15476429 -0.03831881  0.35294748]\n",
            "\n",
            "# 5 Gradient out:  [-1.51732209 -1.4745303  -1.46588073 -0.27828582 -0.46796693 -0.22246841\n",
            " -1.51720527 -0.23223188 -0.32917306 -0.57693199]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.1165631   0.23043223 -0.04999276 -0.34619967  0.40815999  0.05429013\n",
            " -0.03774271  0.19374487 -0.00220787  0.38916978]\n",
            "\n",
            "# 6 Gradient out:  [3.44106424 3.37891652 3.36662168 1.0354621  1.31618288 0.95488912\n",
            " 3.44088998 0.96932315 1.10742721 1.50826986]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [-0.18690131 -0.06447383 -0.3431689  -0.40185684  0.31456661  0.00979644\n",
            " -0.34118377  0.14729849 -0.06804248  0.27378339]\n",
            "\n",
            "# 7 Gradient out:  [-0.48733324 -0.47693793 -0.47484192 -0.12449669 -0.17222153 -0.11094629\n",
            " -0.4873047  -0.11332607 -0.13689682 -0.20257783]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.50131154  0.61130948  0.33015543 -0.19476442  0.57780318  0.20077427\n",
            "  0.34699423  0.34116312  0.15344296  0.57543736]\n",
            "\n",
            "# 8 Gradient out:  [-0.90928549 -0.88941837 -0.88540835 -0.21508385 -0.30653719 -0.18917901\n",
            " -0.90923101 -0.19372379 -0.23882936 -0.36469201]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.40384489  0.51592189  0.23518705 -0.21966376  0.54335888  0.17858501\n",
            "  0.24953329  0.31849791  0.1260636   0.53492179]\n",
            "\n",
            "# 9 Gradient out:  [-2.02480163 -1.97724191 -1.96764151 -0.4312965  -0.64817448 -0.3692821\n",
            " -2.02467132 -0.3801571  -0.48804705 -0.78301428]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.22198779  0.33803822  0.05810538 -0.26268053  0.48205144  0.14074921\n",
            "  0.06768708  0.27975315  0.07829773  0.46198339]\n",
            "\n",
            "# 10 Gradient out:  [3.39050036 3.32891926 3.31673165 0.97735833 1.25668927 0.89751067\n",
            " 3.39032771 0.91181095 1.04876535 1.44903572]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [-0.18297254 -0.05741017 -0.33542292 -0.34893983  0.35241654  0.06689279\n",
            " -0.33724718  0.20372173 -0.01931168  0.30538054]\n",
            "\n",
            "# 11 Gradient out:  [-0.4648462  -0.454809   -0.45278378 -0.11271214 -0.1589238  -0.09962589\n",
            " -0.46481867 -0.10192266 -0.12470329 -0.18838188]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.49512754  0.60837369  0.32792341 -0.15346816  0.6037544   0.24639492\n",
            "  0.34081836  0.38608392  0.19044139  0.59518768]\n",
            "\n",
            "# 12 Gradient out:  [-0.84854514 -0.82984565 -0.82606981 -0.19281979 -0.27905255 -0.16843462\n",
            " -0.84849388 -0.17271125 -0.21518987 -0.33397534]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.40215829  0.51741189  0.23736665 -0.17601059  0.57196964  0.22646974\n",
            "  0.24785463  0.36569939  0.16550073  0.55751131]\n",
            "\n",
            "# 13 Gradient out:  [-1.91234414 -1.86759656 -1.85856837 -0.40513943 -0.60922077 -0.34680026\n",
            " -1.91222145 -0.35703648 -0.45849865 -0.73651998]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.23244927  0.35144276  0.07215269 -0.21457455  0.51615913  0.19278282\n",
            "  0.07815585  0.33115714  0.12246275  0.49071624]\n",
            "\n",
            "# 14 Gradient out:  [3.08963187 3.03554082 3.02477136 0.78168399 1.03615122 0.71142711\n",
            " 3.08948088 0.72394726 0.8453846  1.21856992]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [-0.15001956 -0.02207656 -0.29956098 -0.29560243  0.39431497  0.12342277\n",
            " -0.30428844  0.25974984  0.03076302  0.34341224]\n",
            "\n",
            "# 15 Gradient out:  [-0.53548652 -0.52381037 -0.52145326 -0.12480765 -0.17866097 -0.10958235\n",
            " -0.5354545  -0.11225325 -0.13877149 -0.21302312]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.46790681  0.58503161  0.30539329 -0.13926563  0.60154522  0.26570819\n",
            "  0.31360774  0.40453929  0.19983994  0.58712623]\n",
            "\n",
            "# 16 Gradient out:  [-1.04534885 -1.02200533 -1.0172903  -0.22809331 -0.33578114 -0.19764938\n",
            " -1.04528488 -0.20298688 -0.25603311 -0.40429352]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.36080951  0.48026953  0.20110264 -0.16422716  0.56581302  0.24379172\n",
            "  0.20651684  0.38208864  0.17208565  0.5445216 ]\n",
            "\n",
            "# 17 Gradient out:  [-2.07318995 -2.02117008 -2.01071236 -0.44996758 -0.68131259 -0.38221846\n",
            " -2.07304697 -0.39414117 -0.51139691 -0.82022237]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.15173974  0.27586847 -0.00235542 -0.20984583  0.4986568   0.20426184\n",
            " -0.00254014  0.34149127  0.12087902  0.4636629 ]\n",
            "\n",
            "# 18 Gradient out:  [3.1189905  3.05886992 3.0470763  0.9905968  1.25092615 0.91283997\n",
            " 3.11882077 0.92687273 1.05883547 1.42191225]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [-0.26289825 -0.12836555 -0.4044979  -0.29983934  0.36239428  0.12781815\n",
            " -0.41714953  0.26266303  0.01859964  0.29961842]\n",
            "\n",
            "# 19 Gradient out:  [-0.93829    -0.91714891 -0.91287602 -0.19386861 -0.29167702 -0.16629193\n",
            " -0.9382321  -0.17112393 -0.21920888 -0.35406531]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.36089985  0.48340844  0.20491736 -0.10171998  0.61257951  0.31038614\n",
            "  0.20661462  0.44803758  0.23036674  0.58400087]\n",
            "\n",
            "# 20 Gradient out:  [-2.0242493  -1.97449678 -1.96449078 -0.42503162 -0.64797157 -0.36022743\n",
            " -2.02411254 -0.37163005 -0.48390073 -0.78394896]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.17324185  0.29997865  0.02234216 -0.14049371  0.55424411  0.27712776\n",
            "  0.0189682   0.41381279  0.18652496  0.51318781]\n",
            "\n",
            "# 21 Gradient out:  [3.10845161 3.04834406 3.03648997 0.84215606 1.1099209  0.76429768\n",
            " 3.10828262 0.77828448 0.91126857 1.29107754]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [-0.23160801 -0.0949207  -0.370556   -0.22550003  0.42464979  0.20508227\n",
            " -0.3858543   0.33948678  0.08974481  0.35639802]\n",
            "\n",
            "# 22 Gradient out:  [-0.733684   -0.71717914 -0.7138414  -0.1482041  -0.2247962  -0.1266714\n",
            " -0.73363882 -0.13044249 -0.16801445 -0.2738222 ]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.39008232  0.51474811  0.236742   -0.05706882  0.64663397  0.35794181\n",
            "  0.23580222  0.49514368  0.27199853  0.61461353]\n",
            "\n",
            "# 23 Gradient out:  [-1.60758089 -1.56976415 -1.56213286 -0.31831952 -0.49137751 -0.26901352\n",
            " -1.60747721 -0.27766417 -0.36345591 -0.60002008]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.24334552  0.37131228  0.09397372 -0.08670964  0.60167473  0.33260753\n",
            "  0.08907446  0.46905518  0.23839564  0.55984909]\n",
            "\n",
            "# 24 Gradient out:  [1.06123875 1.0552291  1.05381166 0.04152261 0.10473575 0.03329964\n",
            " 1.06122407 0.03455737 0.05214553 0.17880686]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [-0.07817066  0.05735945 -0.21845286 -0.15037354  0.50339923  0.27880482\n",
            " -0.23242098  0.41352235  0.16570446  0.43984507]\n",
            "\n",
            "# 25 Gradient out:  [-2.04397894 -1.991638   -1.98114128 -0.44723917 -0.67760089 -0.37911972\n",
            " -2.04383476 -0.39113466 -0.50871881 -0.81451431]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.13407709  0.26840527 -0.00769052 -0.14206902  0.52434638  0.28546475\n",
            " -0.02017617  0.42043382  0.17613356  0.47560644]\n",
            "\n",
            "# 26 Gradient out:  [3.05341846 2.99292623 2.98107199 0.92926134 1.19003702 0.85104682\n",
            " 3.05324753 0.86517526 0.99776324 1.36071138]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [-0.2747187  -0.12992233 -0.40391878 -0.23151686  0.3888262   0.20964081\n",
            " -0.42894312  0.34220689  0.0743898   0.31270358]\n",
            "\n",
            "# 27 Gradient out:  [-0.98031411 -0.9579615  -0.9534415  -0.19184245 -0.29542394 -0.16268123\n",
            " -0.98025292 -0.16778844 -0.21866204 -0.36153207]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.33596499  0.46866292  0.19229562 -0.04566459  0.62683361  0.37985017\n",
            "  0.18170638  0.51524194  0.27394245  0.58484586]\n",
            "\n",
            "# 28 Gradient out:  [-2.01522215 -1.96391202 -1.95362083 -0.42696813 -0.65358477 -0.36018782\n",
            " -2.01508079 -0.37196664 -0.48728649 -0.78932728]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.13990217  0.27707062  0.00160732 -0.08403308  0.56774882  0.34731393\n",
            " -0.0143442   0.48168425  0.23021004  0.51253944]\n",
            "\n",
            "# 29 Gradient out:  [2.97113068 2.91155619 2.89984302 0.80022544 1.06145891 0.72312476\n",
            " 2.97096278 0.73701205 0.86822487 1.23542357]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [-0.26314226 -0.11571179 -0.38911685 -0.1694267   0.43703187  0.27527636\n",
            " -0.41736036  0.40729092  0.13275274  0.35467399]\n",
            "\n",
            "# 30 Gradient out:  [-0.94820924 -0.9264933  -0.92210015 -0.1798564  -0.28066271 -0.15152224\n",
            " -0.94814982 -0.1564826  -0.20593652 -0.3450829 ]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.33108388  0.46659945  0.19085176 -0.00938162  0.64932365  0.41990131\n",
            "  0.1768322   0.55469334  0.30639772  0.6017587 ]\n",
            "\n",
            "# 31 Gradient out:  [-1.97418354 -1.9239484  -1.91387106 -0.40864534 -0.63094377 -0.34326077\n",
            " -1.97404515 -0.35479208 -0.46773605 -0.76457196]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.14144203  0.28130079  0.00643173 -0.0453529   0.59319111  0.38959687\n",
            " -0.01279777  0.52339682  0.26521041  0.53274212]\n",
            "\n",
            "# 32 Gradient out:  [2.84115476 2.78445444 2.77326092 0.68322101 0.9370055  0.60975474\n",
            " 2.84099548 0.6229406  0.74856834 1.10942051]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [-0.25339468 -0.10348889 -0.37634249 -0.12708197  0.46700235  0.32094471\n",
            " -0.4076068   0.4524384   0.1716632   0.37982773]\n",
            "\n",
            "# 33 Gradient out:  [-1.00506923 -0.98192093 -0.97723775 -0.18719897 -0.29463585 -0.15699545\n",
            " -1.00500589 -0.16228273 -0.21500063 -0.36323934]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [0.31483627 0.453402   0.1783097  0.00956224 0.65440345 0.44289566\n",
            " 0.1605923  0.57702652 0.32137687 0.60171183]\n",
            "\n",
            "# 34 Gradient out:  [-1.96458371 -1.9127877  -1.90242806 -0.42107468 -0.64652517 -0.35371642\n",
            " -1.96444069 -0.36562681 -0.48156235 -0.77912248]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.11382243  0.25701781 -0.01713785 -0.02787756  0.59547628  0.41149657\n",
            " -0.04040888  0.54456997  0.27837674  0.52906396]\n",
            "\n",
            "# 35 Gradient out:  [2.81852569 2.76061355 2.74923071 0.71694772 0.97043811 0.64200498\n",
            " 2.81836245 0.65550703 0.78299835 1.13891002]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [-0.27909431 -0.12553973 -0.39762346 -0.11209249  0.46617125  0.34075329\n",
            " -0.43329702  0.47144461  0.18206427  0.37323946]\n",
            "\n",
            "# 36 Gradient out:  [-1.13729935 -1.11082786 -1.10547367 -0.20771522 -0.3303394  -0.17317814\n",
            " -1.13722691 -0.17922523 -0.23948583 -0.40840358]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [0.28461082 0.42658298 0.15222268 0.03129705 0.66025887 0.46915428\n",
            " 0.13037547 0.60254602 0.33866394 0.60102147]\n",
            "\n",
            "# 37 Gradient out:  [-1.73152852 -1.68048113 -1.67036539 -0.42784188 -0.63849061 -0.36163414\n",
            " -1.73138652 -0.37343575 -0.48610958 -0.75321428]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.05715095  0.20441741 -0.06887206 -0.01024599  0.59419099  0.43451865\n",
            " -0.09706991  0.56670097  0.29076677  0.51934075]\n",
            "\n",
            "# 38 Gradient out:  [2.78005427 2.72229085 2.7109498  0.70927869 0.96068936 0.634552\n",
            " 2.7798913  0.64802804 0.77498561 1.12683274]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [-0.28915475 -0.13167882 -0.40294513 -0.09581437  0.46649287  0.36219183\n",
            " -0.44334721  0.49201382  0.19354486  0.36869789]\n",
            "\n",
            "# 39 Gradient out:  [-1.21492543 -1.18645529 -1.18069835 -0.21998399 -0.35164459 -0.18284213\n",
            " -1.2148475  -0.18934673 -0.25413012 -0.43526449]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [0.2668561  0.41277936 0.13924483 0.04604137 0.65863074 0.48910223\n",
            " 0.11263105 0.62161943 0.34854198 0.59406444]\n",
            "\n",
            "# 40 Gradient out:  [-1.44204476 -1.39472446 -1.38542312 -0.41040397 -0.59631724 -0.34917274\n",
            " -1.4419123  -0.36016357 -0.46333055 -0.6896978 ]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.02387102  0.1754883  -0.09689484  0.00204457  0.58830182  0.4525338\n",
            " -0.13033845  0.58375008  0.29771596  0.50701154]\n",
            "\n",
            "# 41 Gradient out:  [2.72581281 2.67083982 2.65997841 0.61940729 0.86634969 0.54816244\n",
            " 2.72565849 0.56094019 0.68288084 1.03460716]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [-0.26453793 -0.1034566  -0.37397947 -0.08003622  0.46903837  0.38269925\n",
            " -0.41872091  0.51171737  0.20504985  0.36907198]\n",
            "\n",
            "# 42 Gradient out:  [-1.14167716 -1.11507786 -1.10969776 -0.20767326 -0.33089101 -0.17296932\n",
            " -1.14160436 -0.17904555 -0.23959786 -0.40932934]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [0.28062463 0.43071137 0.15801621 0.04384523 0.64230831 0.49233174\n",
            " 0.12641078 0.62390541 0.34162602 0.57599342]\n",
            "\n",
            "# 43 Gradient out:  [-1.71834966 -1.66739948 -1.65730753 -0.42658799 -0.63631106 -0.36051484\n",
            " -1.71820789 -0.37229709 -0.48468143 -0.75011398]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.0522892   0.2076958  -0.06392334  0.00231058  0.57613011  0.45773788\n",
            " -0.10191009  0.5880963   0.29370644  0.49412755]\n",
            "\n",
            "# 44 Gradient out:  [2.77042043 2.71281859 2.70150582 0.69947636 0.9505421  0.62495224\n",
            " 2.77025796 0.63838813 0.76504547 1.1166738 ]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [-0.29138073 -0.1257841  -0.39538484 -0.08300702  0.4488679   0.38563491\n",
            " -0.44555167  0.51363688  0.19677016  0.34410475]\n",
            "\n",
            "# 45 Gradient out:  [-1.22356482 -1.19486518 -1.18906197 -0.22101345 -0.35371569 -0.18357244\n",
            " -1.22348626 -0.19012957 -0.25543273 -0.43798037]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [0.26270335 0.41677962 0.14491632 0.05688826 0.63897632 0.51062536\n",
            " 0.10849993 0.64131451 0.34977925 0.56743951]\n",
            "\n",
            "# 46 Gradient out:  [-1.40752944 -1.36070699 -1.35151233 -0.40724641 -0.5901161  -0.34667598\n",
            " -1.40739828 -0.35755711 -0.45948966 -0.68100916]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.01799039  0.17780659 -0.09289607  0.01268557  0.56823318  0.47391087\n",
            " -0.13619733  0.60328859  0.29869271  0.47984344]\n",
            "\n",
            "# 47 Gradient out:  [2.71264454 2.65820524 2.64743784 0.6039089  0.84974045 0.53333427\n",
            " 2.71249185 0.54598005 0.66692378 1.0180656 ]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [-0.2635155  -0.09433481 -0.36319854 -0.06876372  0.45020996  0.40457567\n",
            " -0.41767698  0.53177717  0.20679477  0.34364161]\n",
            "\n",
            "# 48 Gradient out:  [-1.14034233 -1.11377723 -1.10840404 -0.20734512 -0.3304098  -0.17268579\n",
            " -1.14026964 -0.17875421 -0.23922895 -0.40875909]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [0.27901341 0.43730623 0.16628903 0.05201806 0.62015805 0.51124252\n",
            " 0.12482139 0.64097318 0.34017953 0.54725472]\n",
            "\n",
            "# 49 Gradient out:  [-1.72879061 -1.67771581 -1.66759599 -0.42678007 -0.63739696 -0.36053933\n",
            " -1.72864852 -0.37234823 -0.48506059 -0.75199947]\n",
            "\n",
            "     Weights  out:  [ 0.47787269  0.42753074  0.41836463 -0.41283824 -0.25720245 -0.47662144\n",
            "  0.47772156 -0.46434097 -0.36456446 -0.18478548] [ 0.05094494  0.21455079 -0.05539178  0.01054904  0.55407609  0.47670537\n",
            " -0.10323254  0.60522234  0.29233374  0.46550291]\n",
            "\n",
            "Tanh error cuadrático medio (ECM): 0.9128616509592062\n",
            "\n",
            "# 0 Gradient out:  [-0.68111952 -0.20640712 -0.9840386  -1.05797301 -1.2380705  -0.31154183\n",
            " -0.40327749 -0.47535043 -1.26589629 -0.11523704]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [-0.07372945 -0.30176844  0.08498808 -0.18476651  0.45044345  0.20624566\n",
            "  0.24528926  0.29304745 -0.0548175  -0.11210964]\n",
            "\n",
            "# 1 Gradient out:  [2.26522186 1.17062223 3.02713375 3.16177655 3.4431515  1.34692179\n",
            " 1.52797031 1.69315109 3.48678898 1.03212958]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [-0.20995335 -0.34304987 -0.11181964 -0.39636111  0.20282935  0.1439373\n",
            "  0.16463376  0.19797736 -0.30799676 -0.13515705]\n",
            "\n",
            "# 2 Gradient out:  [-0.19648944 -0.10489207 -0.25755556 -0.2703209  -0.29972859 -0.12244988\n",
            " -0.13885908 -0.15270546 -0.30435734 -0.09014222]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [ 0.24309102 -0.10892542  0.49360711  0.2359942   0.89145965  0.41332165\n",
            "  0.47022782  0.53660758  0.38936104  0.07126886]\n",
            "\n",
            "# 3 Gradient out:  [-0.29742209 -0.15436943 -0.39281974 -0.41274655 -0.45856748 -0.18176207\n",
            " -0.20738518 -0.22901436 -0.46575857 -0.13139639]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [ 0.20379313 -0.12990384  0.44209599  0.18193002  0.83151394  0.38883168\n",
            "  0.44245601  0.50606648  0.32848957  0.05324042]\n",
            "\n",
            "# 4 Gradient out:  [-0.53691973 -0.26577735 -0.71775258 -0.75553102 -0.84219648 -0.31768129\n",
            " -0.36626756 -0.40727851 -0.85573241 -0.22234935]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [ 0.14430871 -0.16077772  0.36353205  0.09938071  0.73980044  0.35247926\n",
            "  0.40097897  0.46026361  0.23533785  0.02696114]\n",
            "\n",
            "# 5 Gradient out:  [-1.16366752 -0.51927797 -1.59161834 -1.68248856 -1.8917604  -0.64452156\n",
            " -0.76095872 -0.85850673 -1.92421029 -0.4143561 ]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [ 0.03692477 -0.21393319  0.21998153 -0.0517255   0.57136114  0.28894301\n",
            "  0.32772546  0.37880791  0.06419137 -0.01750873]\n",
            "\n",
            "# 6 Gradient out:  [2.23303148 1.14936349 2.98799041 3.12093117 3.39800343 1.32321882\n",
            " 1.5021645  1.66569652 3.44092958 1.01306572]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [-0.19580874 -0.31778878 -0.09834214 -0.38822321  0.19300906  0.16003869\n",
            "  0.17553371  0.20710656 -0.32065069 -0.10037995]\n",
            "\n",
            "# 7 Gradient out:  [-0.19835651 -0.10419251 -0.26115232 -0.27426695 -0.30444269 -0.12222301\n",
            " -0.13908631 -0.15332216 -0.30918532 -0.08906125]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [ 0.25079756 -0.08791609  0.49925594  0.23596302  0.87260975  0.42468246\n",
            "  0.47596662  0.54024587  0.36753523  0.10223319]\n",
            "\n",
            "# 8 Gradient out:  [-0.30217378 -0.15439372 -0.40074915 -0.42132326 -0.46858139 -0.18266547\n",
            " -0.20912789 -0.23147401 -0.47598807 -0.1307055 ]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [ 0.21112626 -0.10875459  0.44702548  0.18110963  0.81172121  0.40023786\n",
            "  0.44814935  0.50958144  0.30569816  0.08442094]\n",
            "\n",
            "# 9 Gradient out:  [-0.5518736  -0.26934131 -0.74032395 -0.77968159 -0.86991043 -0.32340364\n",
            " -0.37402724 -0.41676428 -0.8839896  -0.22413414]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [ 0.1506915  -0.13963333  0.36687565  0.09684498  0.71800493  0.36370476\n",
            "  0.40632378  0.46328664  0.21050055  0.05827985]\n",
            "\n",
            "# 10 Gradient out:  [-1.19546824 -0.53093985 -1.6362216  -1.73024095 -1.94739198 -0.66069404\n",
            " -0.78102393 -0.88161861 -1.98112281 -0.42200779]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [ 0.04031678 -0.19350159  0.21881086 -0.05909134  0.54402285  0.29902404\n",
            "  0.33151833  0.37993378  0.03370263  0.01345302]\n",
            "\n",
            "# 11 Gradient out:  [2.27488756 1.1790965  3.0353016  3.1713132  3.45872187 1.35801292\n",
            " 1.54023572 1.70555777 3.5036545  1.03729629]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [-0.19877687 -0.29968957 -0.10843346 -0.40513953  0.15454445  0.16688523\n",
            "  0.17531354  0.20361006 -0.36252193 -0.07094854]\n",
            "\n",
            "# 12 Gradient out:  [-0.20763213 -0.10670506 -0.27496429 -0.28900912 -0.32127204 -0.12600331\n",
            " -0.14406992 -0.15933042 -0.32633234 -0.09053276]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [ 0.25620064 -0.06387027  0.49862686  0.22912311  0.84628883  0.43848781\n",
            "  0.48336069  0.54472161  0.33820897  0.13651072]\n",
            "\n",
            "# 13 Gradient out:  [-0.32307501 -0.16143708 -0.430929   -0.45341747 -0.50499584 -0.19232381\n",
            " -0.22125828 -0.24570336 -0.51306378 -0.13559146]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [ 0.21467422 -0.08521128  0.443634    0.17132129  0.78203442  0.41328715\n",
            "  0.4545467   0.51285553  0.2729425   0.11840416]\n",
            "\n",
            "# 14 Gradient out:  [-0.61188374 -0.29200918 -0.82524145 -0.86980855 -0.97190542 -0.35321736\n",
            " -0.41054358 -0.45893565 -0.98781232 -0.24086449]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [ 0.15005922 -0.11749869  0.3574482   0.08063779  0.68103525  0.37482239\n",
            "  0.41029505  0.46371485  0.17032974  0.09128587]\n",
            "\n",
            "# 15 Gradient out:  [-1.25255063 -0.54916458 -1.7164959  -1.81742204 -2.05315931 -0.68919593\n",
            " -0.81772775 -0.92420616 -2.08996771 -0.43066091]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [ 0.02768247 -0.17590053  0.19239991 -0.09332392  0.48665417  0.30417892\n",
            "  0.32818633  0.37192772 -0.02723272  0.04311297]\n",
            "\n",
            "# 16 Gradient out:  [2.17683104 1.17359209 2.86704255 2.99465377 3.27291063 1.34362326\n",
            " 1.51288515 1.66410079 3.31749439 1.03539255]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [-0.22282766 -0.28573345 -0.15089927 -0.45680833  0.07602231  0.16633973\n",
            "  0.16464078  0.18708649 -0.44522626 -0.04301921]\n",
            "\n",
            "# 17 Gradient out:  [-0.37991594 -0.18286687 -0.51145538 -0.53884784 -0.60152969 -0.22046098\n",
            " -0.25572164 -0.28552934 -0.61130272 -0.1514728 ]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [ 0.21253855 -0.05101503  0.42250924  0.14212243  0.73060443  0.43506438\n",
            "  0.46721781  0.51990665  0.21827261  0.1640593 ]\n",
            "\n",
            "# 18 Gradient out:  [-0.78043236 -0.35881769 -1.06144298 -1.12031443 -1.25524084 -0.43971159\n",
            " -0.51538933 -0.57918672 -1.27622841 -0.29122489]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [ 0.13655536 -0.0875884   0.32021817  0.03435286  0.61029849  0.39097219\n",
            "  0.41607348  0.46280078  0.09601207  0.13376474]\n",
            "\n",
            "# 19 Gradient out:  [-0.77390444 -0.35193963 -1.03557904 -1.10515428 -1.28498757 -0.45329419\n",
            " -0.53782565 -0.60165788 -1.31443176 -0.25991287]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [-0.01953111 -0.15935194  0.10792957 -0.18971002  0.35925033  0.30302987\n",
            "  0.31299562  0.34696344 -0.15923361  0.07551976]\n",
            "\n",
            "# 20 Gradient out:  [2.23471473 1.15723405 2.98079316 3.11535813 3.40224063 1.33485856\n",
            " 1.51467563 1.6771843  3.44745846 1.01542168]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [-0.174312   -0.22973986 -0.09918624 -0.41074088  0.10225281  0.21237103\n",
            "  0.20543049  0.22663186 -0.42211997  0.02353719]\n",
            "\n",
            "# 21 Gradient out:  [-0.22805151 -0.11097822 -0.30623057 -0.32248865 -0.35968368 -0.13328574\n",
            " -0.15422018 -0.17192838 -0.36548798 -0.09234956]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [0.27263095 0.00170695 0.49697239 0.21233075 0.78270094 0.47934274\n",
            " 0.50836561 0.56206872 0.26737173 0.22662152]\n",
            "\n",
            "# 22 Gradient out:  [-0.37201413 -0.17619097 -0.50277095 -0.52997669 -0.59216276 -0.2135141\n",
            " -0.24854425 -0.27816929 -0.60184589 -0.1450524 ]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [ 0.22702065 -0.0204887   0.43572628  0.14783301  0.7107642   0.45268559\n",
            "  0.47752158  0.52768305  0.19427413  0.20815161]\n",
            "\n",
            "# 23 Gradient out:  [-0.76045322 -0.34612347 -1.03663841 -1.09447838 -1.22699327 -0.42558856\n",
            " -0.49994858 -0.56264569 -1.24759996 -0.27974371]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [ 0.15261782 -0.05572689  0.33517209  0.04183768  0.59233165  0.40998277\n",
            "  0.42781273  0.47204919  0.07390495  0.17914113]\n",
            "\n",
            "# 24 Gradient out:  [-0.88565782 -0.41672328 -1.17920298 -1.25497222 -1.44904529 -0.52650074\n",
            " -0.61912233 -0.69001572 -1.48088765 -0.31754692]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [ 0.00052718 -0.12495159  0.12784441 -0.177058    0.346933    0.32486506\n",
            "  0.32782301  0.35952005 -0.17561504  0.12319239]\n",
            "\n",
            "# 25 Gradient out:  [2.21845776 1.17358671 2.93867331 3.0708455  3.35749188 1.3492553\n",
            " 1.52494042 1.682439   3.40331809 1.0313755 ]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [-0.17660439 -0.20829624 -0.10799619 -0.42805245  0.05712394  0.21956492\n",
            "  0.20399855  0.22151691 -0.47179257  0.05968301]\n",
            "\n",
            "# 26 Gradient out:  [-0.27935181 -0.13157444 -0.37807329 -0.39857956 -0.44539771 -0.1596921\n",
            " -0.18610785 -0.20846498 -0.45268273 -0.10813642]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [0.26708716 0.0264211  0.47973847 0.18611665 0.72862231 0.48941598\n",
            " 0.50898663 0.55800471 0.20887105 0.26595811]\n",
            "\n",
            "# 27 Gradient out:  [-0.50133788 -0.22931044 -0.68295477 -0.72077058 -0.80713282 -0.28118296\n",
            " -0.32987132 -0.37103356 -0.82054962 -0.18607544]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [2.11216802e-01 1.06209408e-04 4.04123817e-01 1.06400742e-01\n",
            " 6.39542773e-01 4.57477555e-01 4.71765058e-01 5.16311713e-01\n",
            " 1.18334503e-01 2.44330822e-01]\n",
            "\n",
            "# 28 Gradient out:  [-1.11998672 -0.49802867 -1.53228711 -1.62035758 -1.82452722 -0.61969853\n",
            " -0.73235089 -0.82646644 -1.85646117 -0.39552781]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [ 0.11094923 -0.04575588  0.26753286 -0.03775337  0.47811621  0.40124096\n",
            "  0.40579079  0.442105   -0.04577542  0.20711573]\n",
            "\n",
            "# 29 Gradient out:  [1.8866071  0.89449399 2.58233685 2.70167939 2.94400146 1.0489184\n",
            " 1.21087424 1.36069033 2.98079725 0.77597918]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [-0.11304812 -0.14536161 -0.03892456 -0.36182489  0.11321076  0.27730126\n",
            "  0.25932062  0.27681171 -0.41706766  0.12801017]\n",
            "\n",
            "# 30 Gradient out:  [-0.30947161 -0.1440786  -0.41996741 -0.44291664 -0.49528562 -0.17554146\n",
            " -0.2051063  -0.2301302  -0.50342729 -0.11786469]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [0.2642733  0.03353718 0.47754281 0.17851099 0.70201106 0.48708494\n",
            " 0.50149546 0.54894978 0.17909179 0.28320601]\n",
            "\n",
            "# 31 Gradient out:  [-0.5837816  -0.2637425  -0.79737415 -0.84191082 -0.94366933 -0.3248527\n",
            " -0.38217533 -0.43060555 -0.95947283 -0.21279597]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [0.20237898 0.00472147 0.39354933 0.08992766 0.60295393 0.45197665\n",
            " 0.4604742  0.50292374 0.07840634 0.25963307]\n",
            "\n",
            "# 32 Gradient out:  [-1.24933131 -0.5601072  -1.70270961 -1.80218914 -2.03673742 -0.69859693\n",
            " -0.82496724 -0.92923489 -2.07379537 -0.4419797 ]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [ 0.08562266 -0.04802704  0.2340745  -0.0784545   0.41422007  0.38700611\n",
            "  0.38403914  0.41680263 -0.11348823  0.21707387]\n",
            "\n",
            "# 33 Gradient out:  [2.16200968 1.16077126 2.84962746 2.97754033 3.258976   1.33173142\n",
            " 1.50104019 1.65186636 3.30457112 1.02072075]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [-0.1642436  -0.16004847 -0.10646742 -0.43889233  0.00687258  0.24728672\n",
            "  0.21904569  0.23095565 -0.5282473   0.12867793]\n",
            "\n",
            "# 34 Gradient out:  [-0.34568023 -0.15599621 -0.47245028 -0.49875172 -0.55865566 -0.19203244\n",
            " -0.22592918 -0.25463414 -0.56794385 -0.12602295]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [0.26815834 0.07210578 0.46345807 0.15661574 0.65866778 0.513633\n",
            " 0.51925373 0.56132892 0.13266692 0.33282208]\n",
            "\n",
            "# 35 Gradient out:  [-0.68969652 -0.30363984 -0.9471698  -1.00099926 -1.12410117 -0.37754303\n",
            " -0.44678359 -0.50521124 -1.14321052 -0.24199865]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [0.19902229 0.04090654 0.36896801 0.05686539 0.54693665 0.47522651\n",
            " 0.47406789 0.5104021  0.01907815 0.30761749]\n",
            "\n",
            "# 36 Gradient out:  [-1.14108454 -0.54699813 -1.5210814  -1.6125673  -1.84068734 -0.67762327\n",
            " -0.79118478 -0.88093333 -1.87802805 -0.43093132]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [ 0.06108299 -0.01982143  0.17953405 -0.14333446  0.32211642  0.39971791\n",
            "  0.38471117  0.40935985 -0.20956395  0.25921776]\n",
            "\n",
            "# 37 Gradient out:  [2.06744225 1.14885089 2.69474058 2.81386363 3.08168363 1.30940693\n",
            " 1.46608009 1.60431316 3.12593367 1.01497977]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [-0.16713392 -0.12922106 -0.12468223 -0.46584792 -0.04602105  0.26419325\n",
            "  0.22647422  0.23317318 -0.58516956  0.1730315 ]\n",
            "\n",
            "# 38 Gradient out:  [-0.50913907 -0.22129433 -0.70141228 -0.74138964 -0.83244319 -0.27608376\n",
            " -0.32758339 -0.37115232 -0.84653649 -0.17573729]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [0.24635453 0.10054912 0.41426589 0.0969248  0.57031567 0.52607464\n",
            " 0.51969024 0.55403581 0.04001717 0.37602745]\n",
            "\n",
            "# 39 Gradient out:  [-1.13248191 -0.49772058 -1.55182358 -1.64246829 -1.85441552 -0.62340296\n",
            " -0.73898504 -0.83501687 -1.8877984  -0.39113953]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [ 0.14452671  0.05629025  0.27398343 -0.05135312  0.40382704  0.47085789\n",
            "  0.45417356  0.47980535 -0.12929013  0.34088   ]\n",
            "\n",
            "# 40 Gradient out:  [1.82136857 0.83101318 2.51327662 2.63380096 2.88178848 0.98786285\n",
            " 1.15067038 1.30020642 2.91974129 0.70937558]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [-0.08196967 -0.04325386 -0.03638128 -0.37984678  0.03294393  0.3461773\n",
            "  0.30637655  0.31280198 -0.50684981  0.26265209]\n",
            "\n",
            "# 41 Gradient out:  [-0.3728187  -0.16293863 -0.51313506 -0.54221765 -0.6083319  -0.20276115\n",
            " -0.24025646 -0.27202415 -0.61855601 -0.12987142]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [0.28230405 0.12294878 0.46627404 0.14691341 0.60930163 0.54374987\n",
            " 0.53651062 0.57284326 0.07709845 0.4045272 ]\n",
            "\n",
            "# 42 Gradient out:  [-0.7712269  -0.33210604 -1.0637914  -1.12518782 -1.26586596 -0.41647948\n",
            " -0.49538    -0.56184342 -1.28771736 -0.2616391 ]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [ 0.20774031  0.09036105  0.36364703  0.03846988  0.48763525  0.50319764\n",
            "  0.48845933  0.51843843 -0.04661275  0.37855292]\n",
            "\n",
            "# 43 Gradient out:  [-0.77273726 -0.44229554 -0.96552326 -1.02624902 -1.19799724 -0.53430463\n",
            " -0.60539458 -0.65507032 -1.22818424 -0.35308345]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [ 0.05349493  0.02393984  0.15088875 -0.18656768  0.23446206  0.41990174\n",
            "  0.38938333  0.40606975 -0.30415622  0.3262251 ]\n",
            "\n",
            "# 44 Gradient out:  [2.0280999  1.00204011 2.73811126 2.86647396 3.14103563 1.17166995\n",
            " 1.34306537 1.49779378 3.18448993 0.86621981]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [-0.10105253 -0.06451927 -0.0422159  -0.39181749 -0.00513739  0.31304081\n",
            "  0.26830442  0.27505568 -0.54979307  0.25560841]\n",
            "\n",
            "# 45 Gradient out:  [-0.31591859 -0.13858788 -0.4345045  -0.45905938 -0.51485563 -0.17220257\n",
            " -0.20386797 -0.2307083  -0.52348393 -0.11068349]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [0.30456745 0.13588875 0.50540635 0.1814773  0.62306973 0.5473748\n",
            " 0.53691749 0.57461444 0.08710491 0.42885237]\n",
            "\n",
            "# 46 Gradient out:  [-0.60667838 -0.2612839  -0.83721797 -0.88528446 -0.99494073 -0.32721048\n",
            " -0.38908676 -0.44136723 -1.01192615 -0.20640238]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [ 0.24138374  0.10817118  0.41850545  0.08966543  0.52009861  0.51293429\n",
            "  0.4961439   0.52847278 -0.01759187  0.40671568]\n",
            "\n",
            "# 47 Gradient out:  [-1.23474887 -0.56565317 -1.67057033 -1.76939809 -2.00784456 -0.70459609\n",
            " -0.82906802 -0.93020852 -2.04621187 -0.44504018]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [ 0.12004806  0.0559144   0.25106186 -0.08739147  0.32111046  0.44749219\n",
            "  0.41832655  0.44019933 -0.2199771   0.3654352 ]\n",
            "\n",
            "# 48 Gradient out:  [2.04893818 1.1106359  2.69011238 2.81156701 3.08417789 1.27420457\n",
            " 1.43405577 1.57525728 3.12919653 0.97441329]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [-0.12690171 -0.05721624 -0.08305221 -0.44127108 -0.08045845  0.30657297\n",
            "  0.25251294  0.25415763 -0.62921947  0.27642716]\n",
            "\n",
            "# 49 Gradient out:  [-0.46654048 -0.19779648 -0.64616122 -0.68343526 -0.76814748 -0.24883971\n",
            " -0.29688568 -0.33757003 -0.78122799 -0.15543139]\n",
            "\n",
            "     Weights  out:  [ 0.00972266 -0.32331137  0.21355346  0.26756238  0.43721346 -0.24051704\n",
            " -0.17619059 -0.12773167  0.47494742 -0.41313706] [ 0.28288592  0.16491094  0.45497027  0.12104232  0.53637713  0.56141389\n",
            "  0.53932409  0.56920908 -0.00338017  0.47130982]\n",
            "\n",
            "Lineal error cuadrático medio (ECM): 1.3710626394177992\n",
            "\n",
            "# 0 Gradient out:  [0.53118363 0.51065896 0.58603241 0.81845318 1.0329249  0.97822289\n",
            " 0.72388291 0.60841068 1.0410778  1.04245064]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.40722463 -0.17086019 -0.12748887 -0.39625112 -0.37857663  0.34317062\n",
            " -0.15161863 -0.13448024  0.08178122  0.36859677]\n",
            "\n",
            "# 1 Gradient out:  [-0.50622628 -0.3477676  -0.74541351 -1.21139364 -1.83835962 -1.55965476\n",
            " -1.04396478 -0.80632534 -1.90430919 -1.9137896 ]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.51346136 -0.0687284  -0.01028239 -0.23256048 -0.17199165  0.53881519\n",
            " -0.00684205 -0.0127981   0.28999678  0.5770869 ]\n",
            "\n",
            "# 2 Gradient out:  [1.1897514  0.97106033 1.55080465 2.41329527 3.44920902 3.04029565\n",
            " 2.08943308 1.65343456 3.53970826 3.55296107]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.4122161  -0.13828192 -0.15936509 -0.47483921 -0.53966357  0.22688424\n",
            " -0.21563501 -0.17406317 -0.09086506  0.19432898]\n",
            "\n",
            "# 3 Gradient out:  [-0.08676992 -0.07015399 -0.1113224  -0.15943552 -0.2240087  -0.19533204\n",
            " -0.14209642 -0.11757781 -0.2309432  -0.23195262]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [0.65016638 0.05593015 0.15079584 0.00781984 0.15017823 0.83494337\n",
            " 0.20225161 0.15662374 0.6170766  0.90492119]\n",
            "\n",
            "# 4 Gradient out:  [-0.11925244 -0.09516812 -0.15494909 -0.22501111 -0.31894703 -0.27727605\n",
            " -0.19975662 -0.16405367 -0.32899505 -0.33045606]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.6328124   0.04189935  0.12853136 -0.02406726  0.10537649  0.79587697\n",
            "  0.17383233  0.13310818  0.57088795  0.85853067]\n",
            "\n",
            "# 5 Gradient out:  [-0.18354948 -0.14339196 -0.24334424 -0.36093879 -0.51839808 -0.4486489\n",
            " -0.31854139 -0.2586174  -0.53514327 -0.53757369]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.60896191  0.02286573  0.09754154 -0.06906948  0.04158708  0.74042176\n",
            "  0.133881    0.10029744  0.50508894  0.79243946]\n",
            "\n",
            "# 6 Gradient out:  [-0.33837718 -0.25276636 -0.46683568 -0.71974866 -1.05808769 -0.90840792\n",
            " -0.62858343 -0.49969221 -1.09375368 -1.09891159]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.57225201 -0.00581266  0.04887269 -0.14125724 -0.06209253  0.65069198\n",
            "  0.07017272  0.04857397  0.39806029  0.68492472]\n",
            "\n",
            "# 7 Gradient out:  [-0.40027571 -0.22809048 -0.6548946  -1.12073844 -1.77110546 -1.4722787\n",
            " -0.95604479 -0.71772846 -1.84284571 -1.85310199]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.50457658 -0.05636594 -0.04449445 -0.28520697 -0.27371007  0.46901039\n",
            " -0.05554396 -0.05136448  0.17930956  0.4651424 ]\n",
            "\n",
            "# 8 Gradient out:  [1.08966755 0.89172233 1.40263433 2.11858419 2.99935318 2.64158915\n",
            " 1.85173126 1.48930066 3.08161115 3.09373778]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.42452143 -0.10198403 -0.17547337 -0.50935466 -0.62793116  0.17455465\n",
            " -0.24675292 -0.19491017 -0.18925959  0.094522  ]\n",
            "\n",
            "# 9 Gradient out:  [-0.24082981 -0.1815491  -0.32962414 -0.50470299 -0.73873852 -0.63526419\n",
            " -0.44156292 -0.3523477  -0.76344135 -0.7670187 ]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.64245494  0.07636044  0.1050535  -0.08563782 -0.02806053  0.70287248\n",
            "  0.12359333  0.10294996  0.42706264  0.71326956]\n",
            "\n",
            "# 10 Gradient out:  [-0.49164191 -0.34455165 -0.71266257 -1.14367497 -1.72336817 -1.46570378\n",
            " -0.98872794 -0.76894964 -1.78462173 -1.7934517 ]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.59428898  0.04005062  0.03912867 -0.18657842 -0.17580823  0.57581965\n",
            "  0.03528075  0.03248042  0.27437437  0.55986582]\n",
            "\n",
            "# 11 Gradient out:  [1.06034224 0.86836297 1.3870737  2.19726277 3.15109229 2.78372407\n",
            " 1.89105583 1.48202477 3.23031893 3.24190621]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.4959606  -0.02885971 -0.10340384 -0.41531342 -0.52048186  0.28267889\n",
            " -0.16246484 -0.12130951 -0.08254997  0.20117548]\n",
            "\n",
            "# 12 Gradient out:  [-0.08986355 -0.0706469  -0.11842776 -0.17462546 -0.24986234 -0.21653653\n",
            " -0.15435979 -0.12572394 -0.25787719 -0.25904169]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [0.70802905 0.14481288 0.1740109  0.02413914 0.10973659 0.8394237\n",
            " 0.21574632 0.17509545 0.56351381 0.84955672]\n",
            "\n",
            "# 13 Gradient out:  [-0.12814087 -0.09923921 -0.17122927 -0.25611952 -0.36966796 -0.31942186\n",
            " -0.22550186 -0.18224626 -0.38171823 -0.38346707]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.69005634  0.1306835   0.15032535 -0.01078595  0.05976412  0.7961164\n",
            "  0.18487437  0.14995066  0.51193837  0.79774838]\n",
            "\n",
            "# 14 Gradient out:  [-0.21054559 -0.15903399 -0.28767104 -0.43980245 -0.64312064 -0.55324235\n",
            " -0.38493098 -0.30741134 -0.66458729 -0.66769702]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.66442816  0.11083566  0.11607949 -0.06200986 -0.01416947  0.73223202\n",
            "  0.13977399  0.11350141  0.43559473  0.72105497]\n",
            "\n",
            "# 15 Gradient out:  [-0.42726236 -0.30541411 -0.6104551  -0.96982777 -1.45153424 -1.23807968\n",
            " -0.84043384 -0.65724292 -1.5022799  -1.50960487]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.62231904  0.07902886  0.05854529 -0.14997035 -0.14279359  0.62158355\n",
            "  0.0627878   0.05201914  0.30267727  0.58751557]\n",
            "\n",
            "# 16 Gradient out:  [0.40697722 0.37548175 0.4928735  0.81293245 1.12315399 1.03566691\n",
            " 0.68490326 0.52522596 1.13547043 1.13728812]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.53686657  0.01794604 -0.06354573 -0.3439359  -0.43310044  0.37396762\n",
            " -0.10529897 -0.07942944  0.00222129  0.28559459]\n",
            "\n",
            "# 17 Gradient out:  [-0.52078794 -0.35902345 -0.76292343 -1.2315287  -1.86460987 -1.58203155\n",
            " -1.06337337 -0.8243424  -1.93199384 -1.94170781]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.61826202  0.09304239  0.03502897 -0.18134941 -0.20846965  0.581101\n",
            "  0.03168168  0.02561575  0.22931537  0.51305222]\n",
            "\n",
            "# 18 Gradient out:  [1.17523472 0.95489574 1.53382064 2.38079698 3.40450297 2.99724813\n",
            " 2.06332733 1.63503068 3.49582048 3.50923699]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.51410443  0.02123769 -0.11755572 -0.42765515 -0.58139162  0.26469469\n",
            " -0.18099299 -0.13925273 -0.15708339  0.12471065]\n",
            "\n",
            "# 19 Gradient out:  [-0.0830618  -0.0643802  -0.11090496 -0.16578842 -0.23917937 -0.20671107\n",
            " -0.14599039 -0.11802557 -0.24696886 -0.2480997 ]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [0.74915137 0.21221684 0.18920841 0.04850424 0.09950897 0.86414431\n",
            " 0.23167247 0.18775341 0.5420807  0.82655805]\n",
            "\n",
            "# 20 Gradient out:  [-0.11710991 -0.0894999  -0.15836691 -0.23978707 -0.34858019 -0.30049066\n",
            " -0.21041252 -0.16892692 -0.36008916 -0.36175832]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [0.73253901 0.1993408  0.16702742 0.01534656 0.0516731  0.8228021\n",
            " 0.20247439 0.16414829 0.49268693 0.77693811]\n",
            "\n",
            "# 21 Gradient out:  [-0.18899539 -0.14124335 -0.26059875 -0.40203028 -0.59089251 -0.50747493\n",
            " -0.35100527 -0.27894079 -0.61078938 -0.6136707 ]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.70911703  0.18144082  0.13535403 -0.03261086 -0.01804294  0.76270397\n",
            "  0.16039189  0.13036291  0.4206691   0.70458645]\n",
            "\n",
            "# 22 Gradient out:  [-0.38045154 -0.27206248 -0.54340575 -0.86374243 -1.29261956 -1.10277757\n",
            " -0.74834088 -0.58506645 -1.3377622  -1.34428251]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.67131795  0.15319215  0.08323428 -0.11301691 -0.13622144  0.66120898\n",
            "  0.09019084  0.07457475  0.29851122  0.58185231]\n",
            "\n",
            "# 23 Gradient out:  [-0.08630234 -0.00451996 -0.17747691 -0.24115285 -0.41703167 -0.30085377\n",
            " -0.22784126 -0.19278519 -0.45178377 -0.45682379]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.59522764  0.09877966 -0.02544687 -0.2857654  -0.39474535  0.44065347\n",
            " -0.05947734 -0.04243854  0.03095878  0.31299581]\n",
            "\n",
            "# 24 Gradient out:  [0.57181928 0.48283161 0.75098301 1.27450948 1.84123047 1.64702181\n",
            " 1.07156837 0.80861072 1.87732683 1.88254945]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.57796718  0.09787566 -0.06094225 -0.33399597 -0.47815169  0.38048272\n",
            " -0.10504559 -0.08099558 -0.05939797  0.22163105]\n",
            "\n",
            "# 25 Gradient out:  [-0.3230601  -0.23289262 -0.45865348 -0.72589648 -1.08316251 -0.92523176\n",
            " -0.62955694 -0.49336277 -1.1207173  -1.12614475]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.69233103  0.19444198  0.08925435 -0.07909407 -0.10990559  0.70988708\n",
            "  0.10926808  0.08072657  0.3160674   0.59814094]\n",
            "\n",
            "# 26 Gradient out:  [-0.47033833 -0.29707768 -0.71594147 -1.1431736  -1.75871302 -1.46786181\n",
            " -0.99391723 -0.77489758 -1.83119191 -1.84166326]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.62771901  0.14786346 -0.00247634 -0.22427337 -0.32653809  0.52484073\n",
            " -0.0166433  -0.01794599  0.09192393  0.37291199]\n",
            "\n",
            "# 27 Gradient out:  [1.10737628 0.91273723 1.40548185 2.07159332 2.90223036 2.55937199\n",
            " 1.82422714 1.48681052 2.98337797 2.99543775]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.53365135  0.08844792 -0.14566464 -0.45290809 -0.6782807   0.23126836\n",
            " -0.21542675 -0.1729255  -0.27431445  0.00457934]\n",
            "\n",
            "# 28 Gradient out:  [-0.2585553  -0.18541936 -0.36869211 -0.58636181 -0.87688738 -0.74865831\n",
            " -0.50784406 -0.39692684 -0.90734519 -0.91174733]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.7551266   0.27099537  0.13543174 -0.03858943 -0.09783463  0.74314276\n",
            "  0.14941868  0.1244366   0.32236115  0.60366689]\n",
            "\n",
            "# 29 Gradient out:  [-0.5542751  -0.37462956 -0.81878297 -1.31874175 -2.0038055  -1.69392688\n",
            " -1.14030391 -0.88502352 -2.078747   -2.08957834]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.70341554  0.2339115   0.06169331 -0.15586179 -0.2732121   0.5934111\n",
            "  0.04784986  0.04505123  0.14089211  0.42131742]\n",
            "\n",
            "# 30 Gradient out:  [1.15380412 0.94474705 1.47520171 2.19710185 3.09469981 2.7254005\n",
            " 1.92875648 1.56314904 3.18183106 3.19477786]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.59256052  0.15898559 -0.10206328 -0.41961014 -0.6739732   0.25462572\n",
            " -0.18021092 -0.13195347 -0.27485729  0.00340175]\n",
            "\n",
            "# 31 Gradient out:  [-0.16640128 -0.11950529 -0.23713902 -0.3774384  -0.56431199 -0.48199414\n",
            " -0.32678794 -0.25530738 -0.58383975 -0.58666257]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.82332135  0.347935    0.19297706  0.01981023 -0.05503324  0.79970582\n",
            "  0.20554038  0.18067633  0.36150892  0.64235733]\n",
            "\n",
            "# 32 Gradient out:  [-0.33928941 -0.23593918 -0.49486777 -0.80104848 -1.21069335 -1.02949471\n",
            " -0.69072746 -0.53467178 -1.25373141 -1.25994652]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.79004109  0.32403394  0.14554926 -0.05567745 -0.16789564  0.703307\n",
            "  0.14018279  0.12961486  0.24474097  0.52502481]\n",
            "\n",
            "# 33 Gradient out:  [-0.36321452 -0.23220236 -0.52368154 -0.72832258 -1.0898029  -0.89240813\n",
            " -0.66356691 -0.55687648 -1.14523496 -1.15338944]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.72218321  0.2768461   0.04657571 -0.21588714 -0.41003431  0.49740805\n",
            "  0.0020373   0.0226805  -0.00600531  0.27303551]\n",
            "\n",
            "# 34 Gradient out:  [1.08712    0.86993572 1.43717604 2.25840754 3.25481712 2.85653276\n",
            " 1.95090641 1.53555138 3.34491913 3.35819048]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.64954031  0.23040563 -0.0581606  -0.36155166 -0.62799489  0.31892643\n",
            " -0.13067608 -0.08869479 -0.2350523   0.04235762]\n",
            "\n",
            "# 35 Gradient out:  [-0.090059   -0.06576831 -0.12664585 -0.19926714 -0.29595934 -0.25337724\n",
            " -0.1730416  -0.13604474 -0.30607615 -0.30753993]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [0.8669643  0.40439277 0.2292746  0.09012985 0.02296854 0.89023298\n",
            " 0.2595052  0.21841548 0.43393152 0.71399572]\n",
            "\n",
            "# 36 Gradient out:  [-0.13783281 -0.09898279 -0.19645905 -0.31284753 -0.46778716 -0.39957227\n",
            " -0.27081995 -0.21152422 -0.48396406 -0.4863026 ]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.8489525   0.39123911  0.20394543  0.05027642 -0.03622333  0.83955753\n",
            "  0.22489688  0.19120653  0.37271629  0.65248773]\n",
            "\n",
            "# 37 Gradient out:  [-0.25804672 -0.18052183 -0.37505206 -0.60649739 -0.91523248 -0.77905701\n",
            " -0.52300534 -0.40506814 -0.9475098  -0.95217112]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.82138594  0.37144255  0.16465362 -0.01229309 -0.12978076  0.75964308\n",
            "  0.17073289  0.14890169  0.27592348  0.55522721]\n",
            "\n",
            "# 38 Gradient out:  [-0.56402285 -0.37862807 -0.83271364 -1.32995756 -2.02010888 -1.70420113\n",
            " -1.15334853 -0.8992301  -2.09755939 -2.10878677]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.7697766   0.33533819  0.08964321 -0.13359257 -0.31282726  0.60383168\n",
            "  0.06613182  0.06788806  0.08642152  0.36479299]\n",
            "\n",
            "# 39 Gradient out:  [1.12671942 0.9259646  1.4272434  2.08785403 2.91956165 2.57241134\n",
            " 1.84315015 1.5083772  3.00345217 3.01599425]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.65697203  0.25961257 -0.07689952 -0.39958408 -0.71684904  0.26299145\n",
            " -0.16453788 -0.11195796 -0.33309036 -0.05696437]\n",
            "\n",
            "# 40 Gradient out:  [-0.22204767 -0.1531844  -0.32625572 -0.53292003 -0.80817059 -0.68695575\n",
            " -0.45833054 -0.35302986 -0.83683401 -0.84097096]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.88231591  0.44480549  0.20854916  0.01798673 -0.13293671  0.77747372\n",
            "  0.20409215  0.18971748  0.26760008  0.54623448]\n",
            "\n",
            "# 41 Gradient out:  [-0.51397554 -0.34449587 -0.76317791 -1.23604846 -1.8825774  -1.59066815\n",
            " -1.06708807 -0.82569417 -1.9532954  -1.96353555]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.83790638  0.41416861  0.14329802 -0.08859728 -0.29457083  0.64008257\n",
            "  0.11242604  0.11911151  0.10023328  0.37804029]\n",
            "\n",
            "# 42 Gradient out:  [1.03289447 0.81778834 1.37351109 2.16066836 3.1238323  2.73490152\n",
            " 1.86664565 1.46834534 3.2132313  3.2264474 ]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.73511127  0.34526944 -0.00933756 -0.33580697 -0.67108631  0.32194894\n",
            " -0.10099158 -0.04602732 -0.2904258  -0.01466682]\n",
            "\n",
            "# 43 Gradient out:  [-0.10969302 -0.07669478 -0.15973479 -0.25946206 -0.39191184 -0.33374056\n",
            " -0.22342675 -0.17262469 -0.40564494 -0.40762743]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.94169016  0.50882711  0.26536466  0.0963267  -0.04631985  0.86892925\n",
            "  0.27233755  0.24764175  0.35222046  0.63062266]\n",
            "\n",
            "# 44 Gradient out:  [-0.19044039 -0.13056337 -0.28122778 -0.46167648 -0.70169359 -0.59613474\n",
            " -0.39651923 -0.30458351 -0.72661187 -0.73020692]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.91975156  0.49348815  0.2334177   0.04443429 -0.12470221  0.80218113\n",
            "  0.2276522   0.21311681  0.27109147  0.54909718]\n",
            "\n",
            "# 45 Gradient out:  [-0.43324438 -0.28957354 -0.64727567 -1.06134072 -1.62095598 -1.37102912\n",
            " -0.91273839 -0.70153607 -1.6808364  -1.68949247]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.88166348  0.46737547  0.17717214 -0.047901   -0.26504093  0.68295419\n",
            "  0.14834836  0.15220011  0.12576909  0.40305579]\n",
            "\n",
            "# 46 Gradient out:  [0.4915564  0.36494731 0.73738129 1.4074919  2.15769976 1.88805912\n",
            " 1.15072437 0.8132893  2.20917331 2.21649386]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.79501461  0.40946077  0.04771701 -0.26016915 -0.58923213  0.40874836\n",
            " -0.03419932  0.01189289 -0.21039819  0.0651573 ]\n",
            "\n",
            "# 47 Gradient out:  [-0.24949306 -0.17031134 -0.36926739 -0.60643821 -0.92259763 -0.78325337\n",
            " -0.52087154 -0.40001754 -0.95555632 -0.96031233]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.89332589  0.48245023  0.19519327  0.02132923 -0.15769218  0.78636018\n",
            "  0.19594555  0.17455075  0.23143647  0.50845607]\n",
            "\n",
            "# 48 Gradient out:  [-0.56190797 -0.3752185  -0.82922491 -1.31672403 -1.99949051 -1.68437275\n",
            " -1.14415459 -0.89486782 -2.07756918 -2.08891864]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.84342728  0.44838796  0.12133979 -0.09995841 -0.3422117   0.62970951\n",
            "  0.09177124  0.09454724  0.04032521  0.31639361]\n",
            "\n",
            "# 49 Gradient out:  [1.105338   0.90342004 1.40375222 2.05333728 2.87587316 2.53029354\n",
            " 1.81309145 1.48381882 2.96035618 2.97302681]\n",
            "\n",
            "     Weights  out:  [-0.3265561  -0.47790261 -0.18064072  0.03085034  0.37908949  0.19373024\n",
            " -0.04158434 -0.1500573   0.44461009  0.45543694] [ 0.73104568  0.37334426 -0.04450519 -0.36330322 -0.74210981  0.29283496\n",
            " -0.13705967 -0.08442632 -0.37518862 -0.10139012]\n",
            "\n",
            "Tanh error cuadrático medio (ECM): 1.039175360963628\n",
            "\n",
            "# 0 Gradient out:  [0.39978287 0.34305841 0.43222188 0.27677154 0.36097717 0.330232\n",
            " 0.3627716  0.33728213 0.33714175 0.3953313 ]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.37440463  0.44705809 -0.26706551 -0.08857553  0.31072695 -0.21827884\n",
            " -0.03957596 -0.39149078  0.4648707  -0.02946665]\n",
            "\n",
            "# 1 Gradient out:  [-0.32332897 -1.33616448 -0.17856157 -1.65870237 -0.74534808 -1.40382922\n",
            " -0.60526465 -1.36807021 -1.36881232 -0.34539462]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.29444806  0.51566977 -0.18062113 -0.03322122  0.38292238 -0.15223244\n",
            "  0.03297835 -0.32403436  0.53229905  0.04959961]\n",
            "\n",
            "# 2 Gradient out:  [1.24218431 2.97633064 1.0498695  3.41511714 1.93144603 3.07213899\n",
            " 1.67826881 3.02213737 3.02318895 1.27280036]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.35911385  0.24843687 -0.21633345 -0.36496169  0.23385276 -0.43299828\n",
            " -0.08807457 -0.5976484   0.25853659 -0.01947931]\n",
            "\n",
            "# 3 Gradient out:  [-0.15560109 -0.33730341 -0.13062636 -0.39398721 -0.23038442 -0.34893655\n",
            " -0.20489385 -0.3427976  -0.34292518 -0.1593867 ]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.11067699  0.843703   -0.00635955  0.31806173  0.62014197  0.18142951\n",
            "  0.24757919  0.00677907  0.86317438  0.23508076]\n",
            "\n",
            "# 4 Gradient out:  [-0.25651908 -0.58947513 -0.21103427 -0.69253713 -0.39347736 -0.61073153\n",
            " -0.34673397 -0.59951818 -0.59975129 -0.26343217]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.14179721  0.77624232 -0.03248482  0.23926429  0.57406508  0.1116422\n",
            "  0.20660042 -0.06178045  0.79458934  0.20320342]\n",
            "\n",
            "# 5 Gradient out:  [-0.50529074 -1.32242122 -0.39448854 -1.57245405 -0.84138234 -1.37449795\n",
            " -0.72663924 -1.34703894 -1.3476101  -0.52221327]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.19310102  0.6583473  -0.07469167  0.10075687  0.49536961 -0.0105041\n",
            "  0.13725362 -0.18168408  0.67463908  0.15051699]\n",
            "\n",
            "# 6 Gradient out:  [0.73733656 1.60189318 0.66812255 1.76253229 1.06630129 1.64063225\n",
            " 0.9341695  1.62078587 1.62121164 0.74934312]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.29415917  0.39386305 -0.15358938 -0.21373394  0.32709315 -0.28540369\n",
            " -0.00807423 -0.45109187  0.40511706  0.04607433]\n",
            "\n",
            "# 7 Gradient out:  [-0.38223796 -0.94588078 -0.30567527 -1.11900879 -0.61400173 -0.98178518\n",
            " -0.53483212 -0.96285095 -0.96324473 -0.39390815]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.14669186  0.71424169 -0.01996487  0.13877251  0.5403534   0.04272276\n",
            "  0.17875967 -0.1269347   0.72935939  0.19594296]\n",
            "\n",
            "# 8 Gradient out:  [-0.45691326 -1.51511773 -0.30379225 -1.8581165  -0.89815267 -1.58612655\n",
            " -0.75194639 -1.5485734  -1.54935209 -0.48009823]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.22313945  0.52506553 -0.08109992 -0.08502925  0.41755306 -0.15363428\n",
            "  0.07179325 -0.31950489  0.53671044  0.11716133]\n",
            "\n",
            "# 9 Gradient out:  [1.17757915 2.70756376 1.00197106 3.1096156  1.78822702 2.79377333\n",
            " 1.56590266 2.74869559 2.74964162 1.2052157 ]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.3145221   0.22204198 -0.14185837 -0.45665254  0.23792252 -0.47085959\n",
            " -0.07859603 -0.62921957  0.22684003  0.02114168]\n",
            "\n",
            "# 10 Gradient out:  [-0.26300976 -0.63469408 -0.21246347 -0.74912711 -0.4158233  -0.65836742\n",
            " -0.3636104  -0.64588221 -0.64614184 -0.2707056 ]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.07900627  0.76355474  0.05853584  0.16527058  0.59556793  0.08789508\n",
            "  0.23458451 -0.07948045  0.77676835  0.26218482]\n",
            "\n",
            "# 11 Gradient out:  [-0.5464655  -1.47245295 -0.42037187 -1.75693276 -0.92764838 -1.53165653\n",
            " -0.79774549 -1.50043358 -1.5010829  -0.56571   ]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.13160823  0.63661592  0.01604314  0.01544515  0.51240327 -0.04377841\n",
            "  0.16186242 -0.20865689  0.64753998  0.2080437 ]\n",
            "\n",
            "# 12 Gradient out:  [1.08389305 2.68500318 0.92401645 3.04977242 1.7112381  2.76778139\n",
            " 1.47381548 2.72482934 2.72573834 1.1100933 ]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.24090133  0.34212533 -0.06803123 -0.3359414   0.32687359 -0.35010971\n",
            "  0.00231333 -0.50874361  0.3473234   0.0949017 ]\n",
            "\n",
            "# 13 Gradient out:  [-0.11194211 -0.2505368  -0.09295779 -0.2936076  -0.168958   -0.25939239\n",
            " -0.14950411 -0.25472006 -0.25481717 -0.11482297]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.02412272  0.87912597  0.11677206  0.27401309  0.66912121  0.20344657\n",
            "  0.29707642  0.03622226  0.89247107  0.31692036]\n",
            "\n",
            "# 14 Gradient out:  [-0.16712823 -0.38747106 -0.13705753 -0.45563077 -0.25774203 -0.40152516\n",
            " -0.22679947 -0.39411157 -0.39426569 -0.17169863]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.04651114  0.82901861  0.0981805   0.21529157  0.63532961  0.15156809\n",
            "  0.2671756  -0.01472175  0.84150764  0.29395577]\n",
            "\n",
            "# 15 Gradient out:  [-0.29668655 -0.72958314 -0.23788823 -0.86263571 -0.47465447 -0.75714282\n",
            " -0.41383666 -0.74260905 -0.7429113  -0.30564463]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.07993678  0.75152439  0.070769    0.12416541  0.58378121  0.07126306\n",
            "  0.2218157  -0.09354406  0.7626545   0.25961604]\n",
            "\n",
            "# 16 Gradient out:  [-0.60657822 -1.69234689 -0.45731886 -2.02872336 -1.0544146  -1.76228901\n",
            " -0.902447   -1.72538651 -1.7261536  -0.62932937]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.13927409  0.60560777  0.02319135 -0.04836173  0.48885031 -0.08016551\n",
            "  0.13904837 -0.24206587  0.61407224  0.19848712]\n",
            "\n",
            "# 17 Gradient out:  [1.29286825 3.04719106 1.0962176  3.49700571 1.99081678 3.14460491\n",
            " 1.73497915 3.09373424 3.09480336 1.32402985]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.26058974  0.26713839 -0.06827242 -0.4541064   0.27796739 -0.43262331\n",
            " -0.04144103 -0.58714318  0.26884152  0.07262124]\n",
            "\n",
            "# 18 Gradient out:  [-0.11209948 -0.25603232 -0.09242864 -0.30064277 -0.1712959  -0.26521783\n",
            " -0.15108611 -0.26037203 -0.26047276 -0.11508704]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.00201609  0.8765766   0.1509711   0.24529474  0.67613075  0.19629767\n",
            "  0.3055548   0.03160367  0.88780219  0.33742721]\n",
            "\n",
            "# 19 Gradient out:  [-0.1691055  -0.3998902  -0.13767513 -0.47110474 -0.26399122 -0.41459419\n",
            " -0.23157281 -0.40683867 -0.40699993 -0.17388632]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.02443598  0.82537014  0.13248537  0.18516619  0.64187157  0.14325411\n",
            "  0.27533758 -0.02047073  0.83570764  0.3144098 ]\n",
            "\n",
            "# 20 Gradient out:  [-0.30611859 -0.76663385 -0.24365023 -0.90794548 -0.49541903 -0.79593423\n",
            " -0.43071129 -0.78048365 -0.780805   -0.31564126]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.05825708  0.7453921   0.10495034  0.09094524  0.58907332  0.06033527\n",
            "  0.22902302 -0.10183847  0.75430765  0.27963254]\n",
            "\n",
            "# 21 Gradient out:  [-0.62374869 -1.75224541 -0.46709382 -2.10531243 -1.09000336 -1.82543528\n",
            " -0.93237672 -1.78680077 -1.78760344 -0.64757495]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.1194808   0.59206533  0.0562203  -0.09064386  0.48998952 -0.09885158\n",
            "  0.14288076 -0.2579352   0.59814665  0.21650429]\n",
            "\n",
            "# 22 Gradient out:  [1.25015688 2.85056022 1.06532564 3.27443955 1.88923484 2.94098731\n",
            " 1.65681882 2.89368744 2.89467971 1.27916312]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.24423054  0.24161625 -0.03719847 -0.51170634  0.27198885 -0.46393863\n",
            " -0.04359458 -0.61529535  0.24062596  0.0869893 ]\n",
            "\n",
            "# 23 Gradient out:  [-0.17922261 -0.43704566 -0.14422186 -0.51630025 -0.28518825 -0.45344529\n",
            " -0.24895592 -0.44479695 -0.44497681 -0.18455313]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [ 0.00580084  0.81172829  0.17586666  0.14318157  0.64983582  0.12425883\n",
            "  0.28776918 -0.03655786  0.8195619   0.34282192]\n",
            "\n",
            "# 24 Gradient out:  [-0.34038029 -0.87872304 -0.26745906 -1.04358162 -0.5616618  -0.91296006\n",
            " -0.48601204 -0.89490793 -0.89528343 -0.35150563]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.03004369  0.72431916  0.14702229  0.03992152  0.59279817  0.03356977\n",
            "  0.237978   -0.12551725  0.73056654  0.3059113 ]\n",
            "\n",
            "# 25 Gradient out:  [-0.61606072 -1.74149736 -0.45247303 -2.11028742 -1.08487097 -1.8168765\n",
            " -0.92921855 -1.77699732 -1.77782384 -0.64068967]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.09811974  0.54857455  0.09353048 -0.16879481  0.4804658  -0.14902224\n",
            "  0.14077559 -0.30449884  0.55150986  0.23561017]\n",
            "\n",
            "# 26 Gradient out:  [1.13656709 2.44105416 0.97913822 2.80379679 1.66028759 2.51664318\n",
            " 1.47200959 2.47700877 2.47783799 1.1609123 ]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.22133189  0.20027508  0.00303587 -0.59085229  0.26349161 -0.51239754\n",
            " -0.04506812 -0.6598983   0.19594509  0.10747224]\n",
            "\n",
            "# 27 Gradient out:  [-0.40499629 -1.08513875 -0.31278811 -1.2934578  -0.68466939 -1.12844742\n",
            " -0.58913335 -1.10561163 -1.10608663 -0.41906978]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [ 0.00598153  0.68848591  0.19886351 -0.03009293  0.59554913 -0.0090689\n",
            "  0.24933379 -0.16449655  0.69151268  0.3396547 ]\n",
            "\n",
            "# 28 Gradient out:  [-0.31630747 -0.77294549 -0.21765359 -0.9963765  -0.5229897  -0.81388083\n",
            " -0.4665166  -0.79184321 -0.79229137 -0.33006812]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.07501773  0.47145816  0.13630589 -0.28878449  0.45861525 -0.23475839\n",
            "  0.13150713 -0.38561888  0.47029536  0.25584074]\n",
            "\n",
            "# 29 Gradient out:  [1.14583046 2.90309264 0.95976467 3.327737   1.83976069 2.99733776\n",
            " 1.58137363 2.94827638 2.94931102 1.17582128]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.13827922  0.31686906  0.09277517 -0.48805979  0.35401731 -0.39753455\n",
            "  0.0382038  -0.54398752  0.31183709  0.18982712]\n",
            "\n",
            "# 30 Gradient out:  [-0.08822798 -0.21241571 -0.07136002 -0.25063256 -0.13926579 -0.2203143\n",
            " -0.12181235 -0.21614882 -0.21623544 -0.09079552]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [0.09088687 0.89748759 0.28472811 0.17748761 0.72196945 0.201933\n",
            " 0.35447853 0.04566776 0.90169929 0.42499137]\n",
            "\n",
            "# 31 Gradient out:  [-0.12566973 -0.31015687 -0.10067187 -0.36675856 -0.2014719  -0.32187729\n",
            " -0.17553643 -0.31569714 -0.31582568 -0.12947871]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [0.07324127 0.85500445 0.2704561  0.1273611  0.69411629 0.15787014\n",
            " 0.33011606 0.00243799 0.8584522  0.40683227]\n",
            "\n",
            "# 32 Gradient out:  [-0.20653985 -0.52827013 -0.16305218 -0.62664748 -0.33871426 -0.54869121\n",
            " -0.29347596 -0.53792479 -0.53814876 -0.21317474]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [ 0.04810733  0.79297307  0.25032173  0.05400939  0.65382191  0.09349468\n",
            "  0.29500878 -0.06070143  0.79528707  0.38093653]\n",
            "\n",
            "# 33 Gradient out:  [-0.4322796  -1.16752891 -0.33245877 -1.39301515 -0.73470003 -1.21439862\n",
            " -0.63145824 -1.18968354 -1.19019759 -0.44751189]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [ 0.00679936  0.68731905  0.21771129 -0.07132011  0.58607906 -0.01624356\n",
            "  0.23631358 -0.16828639  0.68765731  0.33830158]\n",
            "\n",
            "# 34 Gradient out:  [-0.08422505 -0.07740127 -0.0377493  -0.18323936 -0.10575    -0.09223558\n",
            " -0.11657686 -0.08382851 -0.08399015 -0.08963763]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.07965656  0.45381327  0.15121954 -0.34992314  0.43913905 -0.25912329\n",
            "  0.11002194 -0.4062231   0.4496178   0.2487992 ]\n",
            "\n",
            "# 35 Gradient out:  [0.15742087 0.57969009 0.15404767 0.58683555 0.3032386  0.58914923\n",
            " 0.23264726 0.5848258  0.58493073 0.1598232 ]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.09650157  0.43833301  0.14366968 -0.38657101  0.41798905 -0.2775704\n",
            "  0.08670656 -0.4229888   0.43281976  0.23087168]\n",
            "\n",
            "# 36 Gradient out:  [-0.60369734 -1.66101385 -0.44395115 -2.02171414 -1.04709019 -1.73371355\n",
            " -0.90206431 -1.6951795  -1.6959765  -0.62752449]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.0650174   0.55427103  0.17447921 -0.2692039   0.47863677 -0.15974056\n",
            "  0.13323602 -0.30602364  0.54980591  0.26283631]\n",
            "\n",
            "# 37 Gradient out:  [1.1548496  2.45101654 0.99671546 2.81596277 1.67587851 2.52657134\n",
            " 1.48907295 2.48693096 2.48775975 1.1792085 ]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.18575686  0.22206826  0.08568898 -0.67354673  0.26921873 -0.50648327\n",
            " -0.04717685 -0.64505954  0.21061061  0.13733142]\n",
            "\n",
            "# 38 Gradient out:  [-0.38983326 -1.06083854 -0.29892735 -1.26620114 -0.66572678 -1.10354897\n",
            " -0.57146444 -1.08102952 -1.08149795 -0.40371142]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [ 0.04521305  0.71227157  0.28503208 -0.11035418  0.60439444 -0.001169\n",
            "  0.25063774 -0.14767335  0.70816256  0.37317312]\n",
            "\n",
            "# 39 Gradient out:  [-0.40835584 -0.9565003  -0.29727505 -1.2088636  -0.65236247 -1.00312827\n",
            " -0.58292472 -0.97808673 -0.97859729 -0.42396947]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.0327536   0.50010386  0.22524661 -0.3635944   0.47124908 -0.22187879\n",
            "  0.13634486 -0.36387925  0.49186297  0.29243083]\n",
            "\n",
            "# 40 Gradient out:  [1.22263192 2.97465189 1.02719671 3.42218965 1.91901033 3.07155432\n",
            " 1.66324812 3.02096358 3.02202709 1.25361736]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.11442477  0.3088038   0.16579159 -0.60536712  0.34077658 -0.42250445\n",
            "  0.01975991 -0.5594966   0.29614351  0.20763694]\n",
            "\n",
            "# 41 Gradient out:  [-0.09319132 -0.23381345 -0.07417495 -0.27686312 -0.1509545  -0.24273654\n",
            " -0.13117908 -0.23803191 -0.23812977 -0.0960907 ]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [0.13010162 0.90373418 0.37123094 0.07907081 0.72457865 0.19180642\n",
            " 0.35240954 0.04469612 0.90054893 0.45836041]\n",
            "\n",
            "# 42 Gradient out:  [-0.13763529 -0.35404848 -0.10843184 -0.42011926 -0.22651566 -0.36776802\n",
            " -0.19607491 -0.36053539 -0.36068586 -0.14209224]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [ 0.11146335  0.85697149  0.35639595  0.02369818  0.69438775  0.14325911\n",
            "  0.32617372 -0.00291026  0.85292298  0.43914227]\n",
            "\n",
            "# 43 Gradient out:  [-0.24146937 -0.64341895 -0.18728175 -0.76590628 -0.40656693 -0.66890323\n",
            " -0.35003387 -0.65546948 -0.65574899 -0.24974711]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [ 0.0839363   0.78616179  0.33470958 -0.06032567  0.64908462  0.0697055\n",
            "  0.28695874 -0.07501734  0.7807858   0.41072382]\n",
            "\n",
            "# 44 Gradient out:  [-0.54692975 -1.51704715 -0.41332201 -1.81881653 -0.94697508 -1.57951909\n",
            " -0.8111647  -1.54655371 -1.54723884 -0.56725583]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [ 0.03564242  0.657478    0.29725323 -0.21350693  0.56777123 -0.06407514\n",
            "  0.21695196 -0.20611123  0.64963601  0.3607744 ]\n",
            "\n",
            "# 45 Gradient out:  [0.98230378 2.65644789 0.81113879 3.04616039 1.64064545 2.74443272\n",
            " 1.39334381 2.69872018 2.69968627 1.01021068]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.07374353  0.35406857  0.21458883 -0.57727023  0.37837622 -0.37997896\n",
            "  0.05471902 -0.51542198  0.34018824  0.24732323]\n",
            "\n",
            "# 46 Gradient out:  [-0.11455782 -0.29210329 -0.0905821  -0.34636031 -0.18747859 -0.30336193\n",
            " -0.16250657 -0.29742637 -0.29754985 -0.11821558]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [0.12271723 0.88535815 0.37681658 0.03196185 0.70650531 0.16890758\n",
            " 0.33338778 0.02432206 0.88012549 0.44936537]\n",
            "\n",
            "# 47 Gradient out:  [-0.18459321 -0.48501768 -0.14409865 -0.57658818 -0.30797212 -0.50405662\n",
            " -0.26571162 -0.49402042 -0.49422924 -0.19077746]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [ 0.09980566  0.82693749  0.35870016 -0.03731022  0.66900959  0.1082352\n",
            "  0.30088647 -0.03516322  0.82061552  0.42572225]\n",
            "\n",
            "# 48 Gradient out:  [-0.37696905 -1.03245297 -0.28822863 -1.23291886 -0.64645174 -1.0741565\n",
            " -0.55435785 -1.05216876 -1.05262615 -0.3905192 ]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [ 0.06288702  0.72993396  0.32988043 -0.15262785  0.60741517  0.00742387\n",
            "  0.24774415 -0.1339673   0.72176968  0.38756676]\n",
            "\n",
            "# 49 Gradient out:  [-0.4782128  -1.1435743  -0.35375401 -1.42636857 -0.76904023 -1.19681645\n",
            " -0.68258156 -1.16831787 -1.16890103 -0.49594514]\n",
            "\n",
            "     Weights  out:  [-0.27262965  0.23003023 -0.37886635  0.4959198  -0.05497603  0.27040312\n",
            " -0.12083829  0.24859314  0.24903432 -0.2589605 ] [-0.01250679  0.52344336  0.27223471 -0.39921162  0.47812482 -0.20740743\n",
            "  0.13687258 -0.34440105  0.51124444  0.30946292]\n",
            "\n",
            "Lineal error cuadrático medio (ECM): 1.1991858715054264\n",
            "\n",
            "# 0 Gradient out:  [-0.31572759 -0.3526122  -0.27646857 -0.12281079 -0.60706862 -0.1938784\n",
            " -1.20258644 -0.73736495 -1.20002998 -0.84701386]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.44007327 -0.39306392 -0.09327238  0.47009822 -0.21951946 -0.4124992\n",
            "  0.39744556  0.38142212 -0.12926899  0.05572976]\n",
            "\n",
            "# 1 Gradient out:  [1.35289098 1.42282936 1.28351983 1.05057665 2.03287934 1.15216731\n",
            " 3.21260749 2.3781964  3.20896533 2.63465514]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.37692775 -0.46358636 -0.14856609  0.44553606 -0.34093318 -0.45127488\n",
            "  0.15692827  0.23394913 -0.36927498 -0.11367301]\n",
            "\n",
            "# 2 Gradient out:  [-0.22054534 -0.23315291 -0.20748501 -0.15885095 -0.3295049  -0.18099177\n",
            " -0.53793608 -0.38129578 -0.53711567 -0.42233051]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.64750595 -0.17902048  0.10813787  0.65565139  0.06564269 -0.22084142\n",
            "  0.79944977  0.70958841  0.27251808  0.41325801]\n",
            "\n",
            "# 3 Gradient out:  [-0.39494621 -0.41880827 -0.3702219  -0.27817257 -0.60095023 -0.32006458\n",
            " -0.99506939 -0.69879511 -0.9935231  -0.77637965]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 6.03396877e-01 -2.25651067e-01  6.66408722e-02  6.23881202e-01\n",
            " -2.58292019e-04 -2.57039774e-01  6.91862552e-01  6.33329254e-01\n",
            "  1.65094950e-01  3.28791910e-01]\n",
            "\n",
            "# 4 Gradient out:  [-0.75413116 -0.80641271 -0.69971742 -0.49547482 -1.19903042 -0.58866146\n",
            " -2.05887349 -1.40840457 -2.0554578  -1.5759482 ]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.52440764 -0.30941272 -0.00740351  0.56824669 -0.12044834 -0.32105269\n",
            "  0.49284867  0.49357023 -0.03360967  0.17351598]\n",
            "\n",
            "# 5 Gradient out:  [1.47518587 1.55323804 1.39724012 1.1308855  2.22123885 1.24796166\n",
            " 3.53425216 2.59677942 3.53001976 2.87809509]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.3735814  -0.47069526 -0.14734699  0.46915172 -0.36025442 -0.43878498\n",
            "  0.08107398  0.21188932 -0.44470123 -0.14167366]\n",
            "\n",
            "# 6 Gradient out:  [-0.19888852 -0.21049528 -0.18686808 -0.14214161 -0.29926128 -0.1624958\n",
            " -0.49112119 -0.34698751 -0.49036795 -0.3847893 ]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.66861858 -0.16004765  0.13210103  0.69532882  0.08399335 -0.18919265\n",
            "  0.78792441  0.7312452   0.26130272  0.43394536]\n",
            "\n",
            "# 7 Gradient out:  [-0.3444249  -0.36541715 -0.3226797  -0.24176991 -0.52578537 -0.27858356\n",
            " -0.8725362  -0.61196335 -0.87117762 -0.68026764]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.62884088 -0.20214671  0.09472742  0.6669005   0.02414109 -0.22169181\n",
            "  0.68970017  0.6618477   0.16322913  0.3569875 ]\n",
            "\n",
            "# 8 Gradient out:  [-0.70325334 -0.75009182 -0.65459385 -0.47255389 -1.10419663 -0.55552635\n",
            " -1.87587549 -1.2936034  -1.87282472 -1.44459893]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.5599559  -0.27523014  0.03019148  0.61854652 -0.08101598 -0.27740852\n",
            "  0.51519293  0.53945503 -0.01100639  0.22093397]\n",
            "\n",
            "# 9 Gradient out:  [1.12701312 1.18630831 1.06869249 0.87731992 1.71533656 0.95987618\n",
            " 2.7181763  2.0171476  2.71526189 2.23909775]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.41930523 -0.42524851 -0.10072729  0.52403574 -0.30185531 -0.38851379\n",
            "  0.14001783  0.28073435 -0.38557134 -0.06798582]\n",
            "\n",
            "# 10 Gradient out:  [-0.31400941 -0.33333152 -0.29399815 -0.21957763 -0.48102745 -0.25343125\n",
            " -0.80019181 -0.56041462 -0.79894304 -0.62331806]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.64470785 -0.18798684  0.11301121  0.69949973  0.041212   -0.19653856\n",
            "  0.68365309  0.68416387  0.15748104  0.37983373]\n",
            "\n",
            "# 11 Gradient out:  [-0.64494974 -0.68741198 -0.6008725  -0.43623046 -1.00936456 -0.51123508\n",
            " -1.7094259  -1.18179558 -1.70666536 -1.31903717]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.58190597 -0.25465315  0.05421157  0.6555842  -0.05499349 -0.24722481\n",
            "  0.52361473  0.57208095 -0.00230757  0.25517012]\n",
            "\n",
            "# 12 Gradient out:  [0.58613959 0.61509621 0.5589881  0.48177021 0.90562392 0.5126557\n",
            " 1.40376673 1.0776803  1.4027803  1.19836202]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.45291602 -0.39213554 -0.06596293  0.56833811 -0.2568664  -0.34947182\n",
            "  0.18172955  0.33572183 -0.34364064 -0.00863731]\n",
            "\n",
            "# 13 Gradient out:  [-0.72797025 -0.77690529 -0.67707539 -0.48615125 -1.14551278 -0.5732731\n",
            " -1.95155527 -1.34236797 -1.94834377 -1.4996062 ]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.57014394 -0.2691163   0.04583469  0.66469215 -0.07574162 -0.24694068\n",
            "  0.46248289  0.55125789 -0.06308458  0.23103509]\n",
            "\n",
            "# 14 Gradient out:  [1.26499956 1.33413893 1.19649672 0.96734013 1.93875763 1.06707422\n",
            " 3.10443094 2.28127923 3.10088005 2.5354075 ]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.42454989 -0.42449736 -0.08958038  0.5674619  -0.30484417 -0.36159531\n",
            "  0.07217184  0.2827843  -0.45275334 -0.06888615]\n",
            "\n",
            "# 15 Gradient out:  [-0.23738101 -0.25214696 -0.222095   -0.16530762 -0.36516827 -0.19112849\n",
            " -0.60909293 -0.42595168 -0.6081412  -0.47408092]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.6775498  -0.15766957  0.14971896  0.76092993  0.08290735 -0.14818046\n",
            "  0.69305802  0.73904014  0.16742268  0.43819535]\n",
            "\n",
            "# 16 Gradient out:  [-0.45192368 -0.48120223 -0.42158444 -0.30867089 -0.70452107 -0.36004135\n",
            " -1.18774711 -0.82443667 -1.18585622 -0.91957238]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.6300736  -0.20809897  0.10529996  0.7278684   0.0098737  -0.18640616\n",
            "  0.57123944  0.65384981  0.04579444  0.34337917]\n",
            "\n",
            "# 17 Gradient out:  [-0.73689348 -0.78781943 -0.68327126 -0.47646788 -1.15563726 -0.57186473\n",
            " -1.99078125 -1.34840991 -1.98721097 -1.50601049]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.53968886 -0.30433941  0.02098307  0.66613423 -0.13103051 -0.25841443\n",
            "  0.33369002  0.48896247 -0.19137681  0.15946469]\n",
            "\n",
            "# 18 Gradient out:  [1.46939882 1.54425544 1.39410917 1.13148492 2.1728133  1.24807314\n",
            " 3.43202746 2.52378911 3.42770778 2.78893479]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.39231017 -0.4619033  -0.11567118  0.57084065 -0.36215797 -0.37278738\n",
            " -0.06446623  0.21928049 -0.588819   -0.14173741]\n",
            "\n",
            "# 19 Gradient out:  [-0.2883647  -0.30707389 -0.26899824 -0.19709764 -0.45026921 -0.22977725\n",
            " -0.75917706 -0.52727355 -0.7579755  -0.58825449]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.68618993 -0.15305221  0.16315065  0.79713764  0.07240469 -0.12317275\n",
            "  0.62193926  0.72403831  0.09672255  0.41604955]\n",
            "\n",
            "# 20 Gradient out:  [-0.59656106 -0.63658873 -0.55501436 -0.39982662 -0.94018463 -0.4705287\n",
            " -1.6002629  -1.10280914 -1.59765725 -1.23222068]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.62851699 -0.21446699  0.10935101  0.75771811 -0.01764915 -0.1691282\n",
            "  0.47010385  0.6185836  -0.05487255  0.29839865]\n",
            "\n",
            "# 21 Gradient out:  [0.10400597 0.11166892 0.09883734 0.10371117 0.23644191 0.09704106\n",
            " 0.37749247 0.31859616 0.37798192 0.36886328]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.50920478 -0.34178473 -0.00165187  0.67775278 -0.20568607 -0.26323394\n",
            "  0.15005127  0.39802177 -0.374404    0.05195452]\n",
            "\n",
            "# 22 Gradient out:  [-0.48764317 -0.51958079 -0.45278114 -0.30756107 -0.72101669 -0.37650384\n",
            " -1.23936133 -0.81955873 -1.23665679 -0.90720319]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.53000597 -0.31945095  0.0181156   0.69849502 -0.15839769 -0.24382573\n",
            "  0.22554976  0.46174101 -0.29880761  0.12572717]\n",
            "\n",
            "# 23 Gradient out:  [1.36396524 1.43929668 1.28885384 1.03319501 2.08685808 1.14537618\n",
            " 3.35494994 2.45148882 3.35089923 2.72408595]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.43247734 -0.42336711 -0.07244063  0.6369828  -0.30260103 -0.31912649\n",
            " -0.0223225   0.29782926 -0.54613897 -0.05571347]\n",
            "\n",
            "# 24 Gradient out:  [-0.20916148 -0.22270467 -0.19514833 -0.14317129 -0.32650227 -0.16678672\n",
            " -0.55015463 -0.38235268 -0.54928666 -0.42654953]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.70527039 -0.13550777  0.18533014  0.84362181  0.11477059 -0.09005126\n",
            "  0.64866748  0.78812702  0.12404088  0.48910373]\n",
            "\n",
            "# 25 Gradient out:  [-0.38324208 -0.40873119 -0.35684416 -0.25874236 -0.60346632 -0.30334535\n",
            " -1.02413792 -0.70810321 -1.02249865 -0.79104938]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.66343809 -0.18004871  0.14630047  0.81498755  0.04947013 -0.1234086\n",
            "  0.53863656  0.71165649  0.01418354  0.40379382]\n",
            "\n",
            "# 26 Gradient out:  [-0.78280672 -0.83560774 -0.72761414 -0.51801475 -1.22689797 -0.61415137\n",
            " -2.0959564  -1.43439424 -2.09237142 -1.60158551]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.58678968 -0.26179494  0.07493164  0.76323908 -0.07122313 -0.18407767\n",
            "  0.33380897  0.57003585 -0.19031619  0.24558394]\n",
            "\n",
            "# 27 Gradient out:  [1.44437709 1.52121266 1.36731979 1.10062661 2.17155895 1.21859523\n",
            " 3.46466374 2.53575606 3.4603225  2.80989561]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.43022833 -0.42891649 -0.07059119  0.65963613 -0.31660272 -0.30690795\n",
            " -0.08538231  0.283157   -0.60879047 -0.07473316]\n",
            "\n",
            "# 28 Gradient out:  [-0.22175115 -0.23651623 -0.20647678 -0.14986583 -0.34972543 -0.17557584\n",
            " -0.59348024 -0.4106478  -0.59253712 -0.45885118]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.71910375 -0.12467396  0.20287277  0.87976145  0.11770907 -0.0631889\n",
            "  0.60755044  0.79030821  0.08327403  0.48724596]\n",
            "\n",
            "# 29 Gradient out:  [-0.42063885 -0.44925408 -0.39099502 -0.2807776  -0.66764027 -0.33089601\n",
            " -1.13975654 -0.78492904 -1.13791542 -0.87796074]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.67475352 -0.1719772   0.16157742  0.84978828  0.04776398 -0.09830407\n",
            "  0.48885439  0.70817865 -0.03523339  0.39547573]\n",
            "\n",
            "# 30 Gradient out:  [-0.78666073 -0.83837724 -0.73217231 -0.52131671 -1.21165802 -0.61877688\n",
            " -2.06179801 -1.40728787 -2.0581038  -1.56721936]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.59062575 -0.26182802  0.08337841  0.79363276 -0.08576407 -0.16448327\n",
            "  0.26090308  0.55119284 -0.26281648  0.21988358]\n",
            "\n",
            "# 31 Gradient out:  [1.45326876 1.52683744 1.37912315 1.11873486 2.14149861 1.23473706\n",
            " 3.38036    2.48412825 3.37600726 2.74351274]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.4332936  -0.42950347 -0.06305605  0.68936942 -0.32809568 -0.28823864\n",
            " -0.15145652  0.26973527 -0.67443724 -0.09356029]\n",
            "\n",
            "# 32 Gradient out:  [-0.29009493 -0.31011174 -0.26938389 -0.19261743 -0.46345357 -0.22747808\n",
            " -0.79374275 -0.54593787 -0.79246603 -0.61123695]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 7.23947352e-01 -1.24135980e-01  2.12768582e-01  9.13116393e-01\n",
            "  1.00204045e-01 -4.12912319e-02  5.24615481e-01  7.66560919e-01\n",
            "  7.64216903e-04  4.55142255e-01]\n",
            "\n",
            "# 33 Gradient out:  [-0.613772   -0.65624946 -0.56962746 -0.40424054 -0.97711058 -0.47968391\n",
            " -1.67737918 -1.14868033 -1.67459092 -1.28550937]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.66592837 -0.18615833  0.1588918   0.87459291  0.00751333 -0.08678685\n",
            "  0.36586693  0.65737334 -0.15772899  0.33289486]\n",
            "\n",
            "# 34 Gradient out:  [0.23618669 0.26112335 0.2136857  0.15969062 0.53022999 0.17865202\n",
            " 0.95565102 0.69266419 0.95531717 0.80390966]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.54317397 -0.31740822  0.04496631  0.7937448  -0.18790878 -0.18272363\n",
            "  0.03039109  0.42763728 -0.49264717  0.07579299]\n",
            "\n",
            "# 35 Gradient out:  [-0.77900801 -0.8293917  -0.72574451 -0.51795585 -1.18895056 -0.61431734\n",
            " -2.0169716  -1.37641707 -2.01329034 -1.53065082]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.5904113  -0.26518355  0.08770345  0.82568292 -0.08186279 -0.14699323\n",
            "  0.2215213   0.56617012 -0.30158374  0.23657492]\n",
            "\n",
            "# 36 Gradient out:  [1.44473824 1.51772229 1.37113238 1.11209405 2.1264573  1.22761708\n",
            " 3.35576339 2.46558055 3.35141381 2.72249997]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.4346097  -0.43106189 -0.05744545  0.72209175 -0.3196529  -0.26985669\n",
            " -0.18187302  0.2908867  -0.70424181 -0.06955524]\n",
            "\n",
            "# 37 Gradient out:  [-0.29977859 -0.32073569 -0.27809459 -0.19773086 -0.48126394 -0.23422197\n",
            " -0.82701707 -0.56760847 -0.82568146 -0.63596919]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.72355735 -0.12751743  0.21678103  0.94451056  0.10563856 -0.02433328\n",
            "  0.48927966  0.78400281 -0.03395905  0.47494475]\n",
            "\n",
            "# 38 Gradient out:  [-0.64096468 -0.68548381 -0.59465392 -0.42074113 -1.02073497 -0.50015307\n",
            " -1.75455886 -1.19976387 -1.75161723 -1.34277376]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.66360163 -0.19166457  0.16116211  0.90496439  0.00938577 -0.07117767\n",
            "  0.32387625  0.67048112 -0.19909534  0.34775092]\n",
            "\n",
            "# 39 Gradient out:  [0.46007623 0.4998597  0.42234358 0.31279967 0.88612229 0.35685358\n",
            " 1.55838989 1.11238391 1.55712564 1.27335903]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.5354087  -0.32876133  0.04223133  0.82081616 -0.19476122 -0.17120828\n",
            " -0.02703553  0.43052834 -0.54941878  0.07919616]\n",
            "\n",
            "# 40 Gradient out:  [-0.72837715 -0.77817098 -0.6764339  -0.48003046 -1.14977299 -0.56996914\n",
            " -1.97018637 -1.34744487 -1.96683466 -1.50610532]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.62742394 -0.22878939  0.12670004  0.8833761  -0.01753676 -0.09983757\n",
            "  0.28464245  0.65300513 -0.23799366  0.33386797]\n",
            "\n",
            "# 41 Gradient out:  [1.12651306 1.19647933 1.05711725 0.82464604 1.80606507 0.9258368\n",
            " 2.98348624 2.15089954 2.97990957 2.40722129]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.48174851 -0.38442359 -0.00858674  0.78737001 -0.24749136 -0.2138314\n",
            " -0.10939482  0.38351615 -0.63136059  0.03264691]\n",
            "\n",
            "# 42 Gradient out:  [-0.28619395 -0.3060883  -0.26561083 -0.18933214 -0.45851621 -0.22396828\n",
            " -0.78677451 -0.54051395 -0.78550641 -0.60542298]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.70705112 -0.14512772  0.20283671  0.95229921  0.11372165 -0.02866404\n",
            "  0.48730243  0.81369606 -0.03537867  0.51409116]\n",
            "\n",
            "# 43 Gradient out:  [-0.60507407 -0.64718781 -0.56131483 -0.39743835 -0.96547169 -0.47217993\n",
            " -1.65976499 -1.1357021  -1.65700361 -1.2714248 ]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.64981233 -0.20634538  0.14971455  0.91443279  0.02201841 -0.07345769\n",
            "  0.32994752  0.70559327 -0.19247996  0.39300657]\n",
            "\n",
            "# 44 Gradient out:  [0.16117719 0.18237088 0.14253072 0.10281782 0.42215357 0.11527012\n",
            " 0.78490619 0.56864529 0.78482476 0.66743989]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.52879752 -0.33578294  0.03745158  0.83494511 -0.17107593 -0.16789368\n",
            " -0.00200547  0.47845285 -0.52388068  0.13872161]\n",
            "\n",
            "# 45 Gradient out:  [-0.73084998 -0.77647416 -0.68217745 -0.48834039 -1.09180912 -0.57895989\n",
            " -1.84037278 -1.25374211 -1.836856   -1.38947167]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.56103296 -0.29930877  0.06595772  0.85550868 -0.08664521 -0.14483965\n",
            "  0.15497576  0.59218191 -0.36691573  0.27220959]\n",
            "\n",
            "# 46 Gradient out:  [1.44145199 1.51521497 1.36710611 1.10594181 2.13143766 1.22230902\n",
            " 3.37372045 2.47492922 3.36935028 2.7349734 ]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.41486296 -0.4546036  -0.07047777  0.7578406  -0.30500704 -0.26063163\n",
            " -0.21309879  0.34143348 -0.73428693 -0.00568475]\n",
            "\n",
            "# 47 Gradient out:  [-0.2867041  -0.30679857 -0.26591485 -0.18888605 -0.46077331 -0.22385939\n",
            " -0.7923087  -0.54360533 -0.79102884 -0.60917283]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.70315336 -0.1515606   0.20294345  0.97902896  0.1212805  -0.01616983\n",
            "  0.4616453   0.83641933 -0.06041687  0.54130993]\n",
            "\n",
            "# 48 Gradient out:  [-0.60789988 -0.65039748 -0.56373364 -0.39825866 -0.97139101 -0.47374361\n",
            " -1.67198917 -1.1430267  -1.66919909 -1.2799132 ]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.64581254 -0.21292032  0.14976048  0.94125175  0.02912583 -0.06094171\n",
            "  0.30318356  0.72769826 -0.21862264  0.41947536]\n",
            "\n",
            "# 49 Gradient out:  [0.18300672 0.20667293 0.1618612  0.11346803 0.46672022 0.12974363\n",
            " 0.87023158 0.62440446 0.8700221  0.7317748 ]\n",
            "\n",
            "     Weights  out:  [-0.20206575 -0.176888   -0.22972654 -0.35532124 -0.01065013 -0.29255809\n",
            "  0.44383667  0.07384336  0.44041848  0.14534194] [ 0.52423256 -0.34299981  0.03701375  0.86160002 -0.16515237 -0.15569043\n",
            " -0.03121427  0.49909292 -0.55246245  0.16349272]\n",
            "\n",
            "Tanh error cuadrático medio (ECM): 0.595390589580377\n",
            "\n",
            "# 0 Gradient out:  [0.96706219 1.85806933 3.16836898 2.97600993 3.07250747 3.09189966\n",
            " 1.31819747 3.32690911 3.19326969 2.23344759]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.13001134  0.44551845  0.26600572 -0.07306572 -0.04299636 -0.1625181\n",
            "  0.10779584 -0.42696479 -0.46686666 -0.454004  ]\n",
            "\n",
            "# 1 Gradient out:  [-0.03767835 -0.066431   -0.10559069 -0.09889328 -0.10220112 -0.10287975\n",
            " -0.05001211 -0.11122772 -0.10648162 -0.0768008 ]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.32342378  0.81713232  0.89967952  0.52213627  0.57150513  0.45586184\n",
            "  0.37143533  0.23841703  0.17178727 -0.00731448]\n",
            "\n",
            "# 2 Gradient out:  [-0.04521237 -0.08155232 -0.13110337 -0.12264482 -0.12682425 -0.1276813\n",
            " -0.06077645 -0.13820844 -0.13222739 -0.09468474]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.31588811  0.80384612  0.87856138  0.50235762  0.55106491  0.43528589\n",
            "  0.36143291  0.21617149  0.15049095 -0.02267464]\n",
            "\n",
            "# 3 Gradient out:  [-0.05657757 -0.1050864  -0.17132595 -0.16004511 -0.16562201 -0.16676496\n",
            " -0.07731307 -0.18077781 -0.17282301 -0.12265963]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.30684564  0.78753566  0.85234071  0.47782865  0.52570006  0.40974963\n",
            "  0.34927762  0.1885298   0.12404547 -0.04161159]\n",
            "\n",
            "# 4 Gradient out:  [-0.0755085  -0.14596698 -0.24235882 -0.22599238 -0.23408906 -0.23574717\n",
            " -0.1055502  -0.2560258  -0.24452695 -0.17157257]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.29553012  0.76651838  0.81807552  0.44581963  0.49257565  0.37639663\n",
            "  0.33381501  0.15237424  0.08948087 -0.06614351]\n",
            "\n",
            "# 5 Gradient out:  [-0.11223958 -0.23034058 -0.39231675 -0.36492488 -0.37848916 -0.38126405\n",
            " -0.16241928 -0.41508059 -0.39593641 -0.27343948]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.28042842  0.73732498  0.76960375  0.40062116  0.44575784  0.3292472\n",
            "  0.31270497  0.10116908  0.04057548 -0.10045803]\n",
            "\n",
            "# 6 Gradient out:  [-0.20270821 -0.46167758 -0.81792875 -0.75795439 -0.78769424 -0.79376942\n",
            " -0.31223721 -0.86739634 -0.82582466 -0.55661638]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.25798051  0.69125686  0.6911404   0.32763618  0.37006001  0.25299439\n",
            "  0.28022111  0.01815296 -0.0386118  -0.15514592]\n",
            "\n",
            "# 7 Gradient out:  [-0.36987052 -1.05812653 -1.98067171 -1.81746752 -1.89804052 -1.91459728\n",
            " -0.66857975 -2.11599385 -2.00231794 -1.29677866]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.21743887  0.59892135  0.52755465  0.1760453   0.21252116  0.09424051\n",
            "  0.21777367 -0.15532631 -0.20377673 -0.2664692 ]\n",
            "\n",
            "# 8 Gradient out:  [0.67607276 1.08189352 1.64103019 1.54883273 1.59410682 1.60343057\n",
            " 0.85045852 1.72371718 1.65358014 1.23442637]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.14346476  0.38729604  0.13142031 -0.1874482  -0.16708694 -0.28867895\n",
            "  0.08405772 -0.57852508 -0.60424032 -0.52582493]\n",
            "\n",
            "# 9 Gradient out:  [-0.25043303 -0.73767067 -1.32618659 -1.20148274 -1.26180948 -1.27451663\n",
            " -0.48423595 -1.43568654 -1.34341804 -0.87236578]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.27867931  0.60367475  0.45962635  0.12231835  0.15173442  0.03200716\n",
            "  0.25414943 -0.23378164 -0.27352429 -0.27893966]\n",
            "\n",
            "# 10 Gradient out:  [0.91030042 1.60009248 2.57769953 2.42425056 2.50028786 2.51578633\n",
            " 1.19616993 2.71050986 2.5981516  1.87258542]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.22859271  0.45614061  0.19438903 -0.1179782  -0.10062747 -0.22289616\n",
            "  0.15730224 -0.52091895 -0.5422079  -0.45341281]\n",
            "\n",
            "# 11 Gradient out:  [-0.13535296 -0.31038542 -0.55135286 -0.51085229 -0.5309371  -0.53503942\n",
            " -0.20933127 -0.58477342 -0.5566849  -0.3746659 ]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.41065279  0.77615911  0.70992894  0.36687191  0.3994301   0.28026111\n",
            "  0.39653622  0.02118302 -0.02257758 -0.07889573]\n",
            "\n",
            "# 12 Gradient out:  [-0.29302835 -0.76088599 -1.40353739 -1.29495635 -1.34881436 -1.35981485\n",
            " -0.49101123 -1.4927489  -1.41781365 -0.93167207]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.3835822   0.71408202  0.59965836  0.26470145  0.29324268  0.17325322\n",
            "  0.35466997 -0.09577166 -0.13391456 -0.15382891]\n",
            "\n",
            "# 13 Gradient out:  [0.58410616 1.35042688 2.56570899 2.4120202  2.49114189 2.50655804\n",
            " 0.85400459 2.68067726 2.58440982 1.71849993]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.32497653  0.56190483  0.31895089  0.00571018  0.02347981 -0.09870975\n",
            "  0.25646772 -0.39432144 -0.41747729 -0.34016332]\n",
            "\n",
            "# 14 Gradient out:  [-0.04992515 -0.09876779 -0.1656424  -0.15430396 -0.15991464 -0.16106331\n",
            " -0.07072916 -0.17510139 -0.16714356 -0.11654467]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [0.44179776 0.8319902  0.83209268 0.48811422 0.52170818 0.40260186\n",
            " 0.42726864 0.14181401 0.09940467 0.00353666]\n",
            "\n",
            "# 15 Gradient out:  [-0.06638651 -0.13642171 -0.23247094 -0.21622948 -0.22427132 -0.22591661\n",
            " -0.09615006 -0.24597991 -0.23461789 -0.1619829 ]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.43181273  0.81223664  0.7989642   0.45725343  0.48972526  0.3703892\n",
            "  0.41312281  0.10679373  0.06597596 -0.01977227]\n",
            "\n",
            "# 16 Gradient out:  [-0.09818929 -0.21314258 -0.37112732 -0.34450291 -0.35769669 -0.36039361\n",
            " -0.14689762 -0.39318137 -0.37463928 -0.25524436]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.41853543  0.7849523   0.75247002  0.41400754  0.44487099  0.32520588\n",
            "  0.3938928   0.05759775  0.01905238 -0.05216885]\n",
            "\n",
            "# 17 Gradient out:  [-0.17683931 -0.41960688 -0.7539659  -0.69779385 -0.72565901 -0.73134872\n",
            " -0.27935859 -0.80022516 -0.76135441 -0.50879743]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.39889757  0.74232379  0.67824455  0.34510695  0.37333166  0.25312715\n",
            "  0.36451327 -0.02103853 -0.05587547 -0.10321772]\n",
            "\n",
            "# 18 Gradient out:  [-0.38594388 -1.06213972 -1.9737907  -1.8143492  -1.89312362 -1.90929272\n",
            " -0.67787114 -2.10611253 -1.99491993 -1.29970689]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.36352971  0.65840241  0.52745137  0.20554818  0.22819985  0.10685741\n",
            "  0.30864156 -0.18108356 -0.20814636 -0.20497721]\n",
            "\n",
            "# 19 Gradient out:  [0.7886657  1.27642933 1.94709293 1.83613614 1.89058142 1.90180306\n",
            " 0.9988345  2.04693574 1.96222395 1.45913681]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.28634094  0.44597447  0.13269323 -0.15732166 -0.15042487 -0.27500114\n",
            "  0.17306733 -0.60230607 -0.60713034 -0.46491859]\n",
            "\n",
            "# 20 Gradient out:  [-0.37989882 -1.04360453 -1.93889991 -1.78252741 -1.8597809  -1.87563785\n",
            " -0.66635789 -2.06884209 -1.95963027 -1.27714258]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.44407408  0.70126033  0.52211182  0.20990557  0.22769141  0.10535948\n",
            "  0.37283423 -0.19291892 -0.21468555 -0.17309123]\n",
            "\n",
            "# 21 Gradient out:  [0.84473587 1.38844639 2.13609675 2.01243178 2.07311108 2.08561782\n",
            " 1.0790086  2.24741099 2.15296278 1.59216293]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.36809431  0.49253943  0.13433183 -0.14659991 -0.14426477 -0.26976809\n",
            "  0.23956265 -0.60668734 -0.60661161 -0.42851974]\n",
            "\n",
            "# 22 Gradient out:  [-0.29914936 -0.81632568 -1.52457734 -1.40424711 -1.4638951  -1.47608777\n",
            " -0.51871702 -1.62361993 -1.54041897 -1.00395929]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.53704149  0.77022871  0.56155118  0.25588645  0.27035745  0.14735547\n",
            "  0.45536437 -0.15720514 -0.17601905 -0.11008716]\n",
            "\n",
            "# 23 Gradient out:  [0.69291698 1.56368809 2.88267911 2.69970347 2.79240617 2.81081951\n",
            " 1.02189058 3.02795273 2.90581711 1.95000239]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.47721161  0.60696357  0.25663572 -0.02496298 -0.02242157 -0.14786209\n",
            "  0.35162097 -0.48192912 -0.48410285 -0.31087902]\n",
            "\n",
            "# 24 Gradient out:  [-0.03334554 -0.06973305 -0.11967071 -0.11123703 -0.11541369 -0.116268\n",
            " -0.04879688 -0.12668118 -0.12078509 -0.0830312 ]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [0.61579501 0.91970119 0.83317154 0.51497772 0.53605966 0.41430182\n",
            " 0.55599908 0.12366142 0.09706058 0.07912146]\n",
            "\n",
            "# 25 Gradient out:  [-0.04125071 -0.08857009 -0.15358351 -0.14262398 -0.14805377 -0.14916391\n",
            " -0.06131331 -0.16267558 -0.15503012 -0.1058965 ]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [0.6091259  0.90575458 0.80923739 0.49273031 0.51297693 0.39104822\n",
            " 0.54623971 0.09832519 0.07290356 0.06251522]\n",
            "\n",
            "# 26 Gradient out:  [-0.05411045 -0.12019958 -0.21112527 -0.19583168 -0.20341264 -0.20496172\n",
            " -0.08207838 -0.22378138 -0.21314132 -0.14445445]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [0.60087576 0.88804056 0.77852069 0.46420552 0.48336617 0.36121543\n",
            " 0.53397704 0.06579007 0.04189753 0.04133592]\n",
            "\n",
            "# 27 Gradient out:  [-0.07819914 -0.18199411 -0.32502982 -0.3010346  -0.31293665 -0.31536699\n",
            " -0.1220216  -0.34482256 -0.32818764 -0.22018998]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 5.90053669e-01  8.64000643e-01  7.36295639e-01  4.25039182e-01\n",
            "  4.42683646e-01  3.20223090e-01  5.17561369e-01  2.10337922e-02\n",
            " -7.30732138e-04  1.24450344e-02]\n",
            "\n",
            "# 28 Gradient out:  [-0.13512869 -0.33704511 -0.61569385 -0.56904464 -0.59220021 -0.59692491\n",
            " -0.2201816  -0.654016   -0.6218208  -0.41149842]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.57441384  0.82760182  0.67128967  0.36483226  0.38009632  0.25714969\n",
            "  0.49315705 -0.04793072 -0.06636826 -0.03159296]\n",
            "\n",
            "# 29 Gradient out:  [-0.31858389 -0.87557127 -1.63624809 -1.50635895 -1.57070481 -1.58386791\n",
            " -0.55577589 -1.74335841 -1.65337076 -1.07653702]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.5473881   0.7601928   0.54815091  0.25102334  0.26165628  0.13776471\n",
            "  0.44912073 -0.17873392 -0.19073242 -0.11389265]\n",
            "\n",
            "# 30 Gradient out:  [0.82786791 1.69391046 2.96170686 2.77410973 2.86804982 2.88696566\n",
            " 1.17151006 3.11764354 2.98610331 2.05607512]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.48367133  0.58507855  0.22090129 -0.05024845 -0.05248469 -0.17900887\n",
            "  0.33796555 -0.5274056  -0.52140657 -0.32920005]\n",
            "\n",
            "# 31 Gradient out:  [-0.03663757 -0.0792503  -0.13781407 -0.12794667 -0.13283584 -0.13383534\n",
            " -0.05469788 -0.14599679 -0.13911623 -0.09486144]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [0.64924491 0.92386064 0.81324266 0.50457349 0.52112528 0.39838426\n",
            " 0.57226756 0.09612311 0.07581409 0.08201497]\n",
            "\n",
            "# 32 Gradient out:  [-0.04682507 -0.10439623 -0.18361505 -0.1702943  -0.1768976  -0.17824684\n",
            " -0.07118391 -0.19463714 -0.18537088 -0.1255313 ]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [0.6419174  0.90801058 0.78567984 0.47898416 0.49455811 0.37161719\n",
            " 0.56132799 0.06692375 0.04799084 0.06304269]\n",
            "\n",
            "# 33 Gradient out:  [-0.0647457  -0.15026094 -0.26810551 -0.2483372  -0.25814228 -0.26014449\n",
            " -0.10085286 -0.28441639 -0.27070737 -0.18173203]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [0.63255238 0.88713133 0.74895683 0.4449253  0.45917859 0.33596782\n",
            " 0.54709121 0.02799632 0.01091667 0.03793643]\n",
            "\n",
            "# 34 Gradient out:  [-0.10287411 -0.2527975  -0.45972427 -0.42509678 -0.44228385 -0.4457909\n",
            " -0.16602771 -0.48819183 -0.46427353 -0.30810699]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.61960324  0.85707915  0.69533573  0.39525786  0.40755013  0.28393893\n",
            "  0.52692063 -0.02888696 -0.04322481  0.00159002]\n",
            "\n",
            "# 35 Gradient out:  [-0.21373448 -0.57212344 -1.06600205 -0.98306358 -1.02423255 -1.03263363\n",
            " -0.36484874 -1.13402196 -1.07689083 -0.70380644]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.59902842  0.80651964  0.60339088  0.3102385   0.31909336  0.19478075\n",
            "  0.49371509 -0.12652532 -0.13607951 -0.06003138]\n",
            "\n",
            "# 36 Gradient out:  [-0.22467759 -0.46199569 -0.64488221 -0.56999279 -0.60419913 -0.6119092\n",
            " -0.37557499 -0.72216673 -0.65641747 -0.47376361]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.55628152  0.69209496  0.39019047  0.11362579  0.11424685 -0.01174598\n",
            "  0.42074534 -0.35332971 -0.35145768 -0.20079267]\n",
            "\n",
            "# 37 Gradient out:  [0.64526408 1.50158444 2.81041227 2.63199003 2.72267382 2.74061877\n",
            " 0.96443733 2.95029641 2.83280049 1.88740408]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 5.11346007e-01  5.99695818e-01  2.61214026e-01 -3.72771916e-04\n",
            " -6.59297328e-03 -1.34127819e-01  3.45630347e-01 -4.97763061e-01\n",
            " -4.82741173e-01 -2.95545387e-01]\n",
            "\n",
            "# 38 Gradient out:  [-0.03560838 -0.07539725 -0.13002325 -0.12080337 -0.12537001 -0.12630396\n",
            " -0.0524954  -0.13768206 -0.13124108 -0.08994761]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [0.64039882 0.90001271 0.82329648 0.52602523 0.53794179 0.41399593\n",
            " 0.53851781 0.09229622 0.08381892 0.08193543]\n",
            "\n",
            "# 39 Gradient out:  [-0.04485986 -0.09774793 -0.17044503 -0.15819917 -0.1642673  -0.16550772\n",
            " -0.06726954 -0.1805958  -0.17206073 -0.11712801]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [0.63327715 0.88493326 0.79729183 0.50186456 0.51286779 0.38873514\n",
            " 0.52801873 0.06475981 0.05757071 0.06394591]\n",
            "\n",
            "# 40 Gradient out:  [-0.06058043 -0.13706593 -0.24235267 -0.22465918 -0.23343164 -0.23522377\n",
            " -0.09292298 -0.25697921 -0.2446838  -0.16516177]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [0.62430518 0.86538367 0.76320282 0.47022473 0.48001433 0.3556336\n",
            " 0.51456482 0.02864065 0.02315856 0.04052031]\n",
            "\n",
            "# 41 Gradient out:  [-0.09217138 -0.21988325 -0.39598449 -0.36646998 -0.38111356 -0.38410287\n",
            " -0.14604292 -0.42029596 -0.39986594 -0.2669249 ]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.61218909  0.83797048  0.71473229  0.42529289  0.433328    0.30858884\n",
            "  0.49598023 -0.02275519 -0.0257782   0.00748795]\n",
            "\n",
            "# 42 Gradient out:  [-0.17608059 -0.45531374 -0.84053916 -0.7759934  -0.80803573 -0.81457326\n",
            " -0.2937058  -0.89349977 -0.84901302 -0.5581734 ]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.59375481  0.79399383  0.63553539  0.35199889  0.35710529  0.23176827\n",
            "  0.46677164 -0.10681439 -0.10575139 -0.04589703]\n",
            "\n",
            "# 43 Gradient out:  [-0.39123616 -1.06184044 -1.93520537 -1.77293167 -1.85245675 -1.86893808\n",
            " -0.69175905 -2.07362552 -1.95709228 -1.28154641]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.5585387   0.70293108  0.46742756  0.19680022  0.19549814  0.06885362\n",
            "  0.40803048 -0.28551434 -0.27555399 -0.15753171]\n",
            "\n",
            "# 44 Gradient out:  [0.76378118 1.18154649 1.74137168 1.64464985 1.69172654 1.70151842\n",
            " 0.94955027 1.8312281  1.75481003 1.33106215]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.48029146  0.490563    0.08038648 -0.15778612 -0.17499321 -0.304934\n",
            "  0.26967867 -0.70023944 -0.66697245 -0.41384099]\n",
            "\n",
            "# 45 Gradient out:  [-0.37216553 -0.95337475 -1.66792227 -1.52152836 -1.59240197 -1.60730439\n",
            " -0.64779434 -1.79775738 -1.68817784 -1.12184629]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.6330477   0.7268723   0.42866082  0.17114385  0.1633521   0.03536969\n",
            "  0.45958873 -0.33399382 -0.31601044 -0.14762856]\n",
            "\n",
            "# 46 Gradient out:  [0.83405226 1.34134666 2.02596064 1.90907299 1.96608729 1.97791746\n",
            " 1.05774337 2.13366003 2.04212187 1.52521695]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.55861459  0.53619735  0.09507636 -0.13316182 -0.15512829 -0.28609119\n",
            "  0.33002986 -0.6935453  -0.65364601 -0.37199782]\n",
            "\n",
            "# 47 Gradient out:  [-0.33576989 -0.95428275 -1.79011521 -1.64467634 -1.71654175 -1.73128798\n",
            " -0.60230449 -1.91108936 -1.80939506 -1.17283448]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.72542505  0.80446668  0.50026849  0.24865278  0.23808917  0.1094923\n",
            "  0.54157853 -0.26681329 -0.24522163 -0.06695443]\n",
            "\n",
            "# 48 Gradient out:  [0.85118798 1.56734007 2.56646105 2.40531495 2.48473967 2.50102655\n",
            " 1.15424354 2.70906734 2.58821539 1.84268027]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.65827107  0.61361013  0.14224545 -0.08028249 -0.10521918 -0.2367653\n",
            "  0.42111764 -0.64903116 -0.60710065 -0.30152133]\n",
            "\n",
            "# 49 Gradient out:  [-0.09680265 -0.26177759 -0.49018702 -0.45216154 -0.47105712 -0.47490787\n",
            " -0.16599784 -0.52127684 -0.49516802 -0.3229623 ]\n",
            "\n",
            "     Weights  out:  [-0.4646638  -0.07380256  0.35525544  0.25518733  0.30119532  0.31137587\n",
            " -0.25183404  0.47098708  0.37100222  0.02293154] [ 0.82850866  0.92707814  0.65553766  0.4007805   0.39172875  0.26344002\n",
            "  0.65196634 -0.10721769 -0.08945757  0.06701473]\n",
            "\n",
            "Lineal error cuadrático medio (ECM): 1.948368957614507\n",
            "\n",
            "# 0 Gradient out:  [-1.32910975 -0.90807561 -1.40521933 -1.00412785 -0.20104671 -1.33299991\n",
            " -0.96415453 -0.31897381 -1.64453254 -1.52597895]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.07807725 -0.18509618 -0.04101315  0.3159141  -0.35800199  0.27801178\n",
            "  0.37047534  0.05581827  0.23510674 -0.02147801]\n",
            "\n",
            "# 1 Gradient out:  [2.68503518 1.95335496 2.80467934 2.12296846 0.94203102 2.691301\n",
            " 2.05198192 1.08813262 3.13938553 2.98121758]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [-0.1877447  -0.36671131 -0.32205702  0.11508853 -0.39821133  0.0114118\n",
            "  0.17764443 -0.0079765  -0.09379977 -0.3266738 ]\n",
            "\n",
            "# 2 Gradient out:  [-0.40471702 -0.303111   -0.42264477 -0.32638691 -0.13801967 -0.40563837\n",
            " -0.31668579 -0.16571471 -0.4778173  -0.4506751 ]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.34926233  0.02395969  0.23887885  0.53968223 -0.20980513  0.549672\n",
            "  0.58804081  0.20965003  0.53407734  0.26956972]\n",
            "\n",
            "# 3 Gradient out:  [-0.76674578 -0.56481688 -0.80236137 -0.61107651 -0.23791354 -0.76857643\n",
            " -0.59179594 -0.29228464 -0.91180586 -0.85800955]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.26831893 -0.03666251  0.1543499   0.47440484 -0.23740906  0.46854432\n",
            "  0.52470366  0.17650708  0.43851388  0.1794347 ]\n",
            "\n",
            "# 4 Gradient out:  [-1.50667732 -1.06119446 -1.58622417 -1.16303654 -0.32762603 -1.51075463\n",
            " -1.12062186 -0.44934819 -1.83340064 -1.71145793]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.11496978 -0.14962589 -0.00612238  0.35218954 -0.28499177  0.31482904\n",
            "  0.40634447  0.11805016  0.25615271  0.00783279]\n",
            "\n",
            "# 5 Gradient out:  [2.69217002 1.9633694  2.81145071 2.13229363 0.95306189 2.69841528\n",
            " 2.0615986  1.09980566 3.14565784 2.98760212]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [-0.18636569 -0.36186478 -0.32336721  0.11958223 -0.35051698  0.01267811\n",
            "  0.1822201   0.02818052 -0.11052742 -0.3344588 ]\n",
            "\n",
            "# 6 Gradient out:  [-0.39478864 -0.29439229 -0.41249712 -0.31739225 -0.13143689 -0.39569881\n",
            " -0.30780598 -0.1587318  -0.46696628 -0.44017655]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.35206832  0.0308091   0.23892293  0.54604096 -0.1599046   0.55236117\n",
            "  0.59453982  0.24814165  0.51860415  0.26306163]\n",
            "\n",
            "# 7 Gradient out:  [-0.7420834  -0.54532704 -0.77678049 -0.59040296 -0.22693157 -0.74386692\n",
            " -0.57161556 -0.27986618 -0.88337702 -0.83098589]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.27311059 -0.02806936  0.15642351  0.48256251 -0.18619198  0.47322141\n",
            "  0.53297862  0.21639529  0.42521089  0.17502632]\n",
            "\n",
            "# 8 Gradient out:  [-1.52021856 -1.07829636 -1.59904318 -1.17934389 -0.35112129 -1.5242598\n",
            " -1.13725712 -0.47208313 -1.84379832 -1.72306895]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.12469391 -0.13713477  0.00106741  0.36448192 -0.23157829  0.32444802\n",
            "  0.41865551  0.16042205  0.24853549  0.00882914]\n",
            "\n",
            "# 9 Gradient out:  [2.72432484 1.98893009 2.84463028 2.15939481 0.96996944 2.73062443\n",
            " 2.08805326 1.11807847 3.1815613  3.02224123]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [-0.1793498  -0.35279404 -0.31874123  0.12861314 -0.30180255  0.01959606\n",
            "  0.19120408  0.06600543 -0.12022418 -0.33578465]\n",
            "\n",
            "# 10 Gradient out:  [-0.35206417 -0.2618691  -0.36796956 -0.2825328  -0.1155545  -0.35288172\n",
            " -0.27392017 -0.14004748 -0.41687748 -0.3928261 ]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.36551517  0.04499198  0.25018483  0.5604921  -0.10780867  0.56572095\n",
            "  0.60881474  0.28962112  0.51608809  0.2686636 ]\n",
            "\n",
            "# 11 Gradient out:  [-0.6297346  -0.46299591 -0.65912969 -0.50119686 -0.1932149  -0.63124568\n",
            " -0.48527461 -0.23810343 -0.74942089 -0.70504517]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.29510233 -0.00738184  0.17659092  0.50398554 -0.13091956  0.4951446\n",
            "  0.5540307   0.26161163  0.43271259  0.19009838]\n",
            "\n",
            "# 12 Gradient out:  [-1.37928339 -0.9900625  -1.44825236 -1.07915788 -0.35651321 -1.38282475\n",
            " -1.04203455 -0.46151961 -1.66100262 -1.55630699]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.16915541 -0.09998102  0.04476498  0.40374617 -0.16956255  0.36889547\n",
            "  0.45697578  0.21399094  0.28282841  0.04908934]\n",
            "\n",
            "# 13 Gradient out:  [2.4216159  1.74613722 2.52922354 1.90332271 0.86793797 2.42728952\n",
            " 1.83745064 0.98544081 2.81916583 2.68454303]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [-0.10670127 -0.29799352 -0.24488549  0.18791459 -0.24086519  0.09233052\n",
            "  0.24856887  0.12168702 -0.04937211 -0.26217206]\n",
            "\n",
            "# 14 Gradient out:  [-0.3224616  -0.23942191 -0.33710285 -0.25844678 -0.10476685 -0.32321419\n",
            " -0.25051714 -0.12729866 -0.3821142  -0.359981  ]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.37762191  0.05123392  0.26095921  0.56857913 -0.06727759  0.57778842\n",
            "  0.616059    0.31877518  0.51446105  0.27473655]\n",
            "\n",
            "# 15 Gradient out:  [-0.55517524 -0.40815469 -0.58108918 -0.44183919 -0.17031218 -0.55650742\n",
            " -0.42779924 -0.20990177 -0.66067663 -0.62156283]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.31312959  0.00334954  0.19353864  0.51688978 -0.08823096  0.51314558\n",
            "  0.56595557  0.29331545  0.43803821  0.20274035]\n",
            "\n",
            "# 16 Gradient out:  [-1.19985497 -0.86578004 -1.25890559 -0.94228393 -0.32406984 -1.20288878\n",
            " -0.91040232 -0.41379937 -1.44062375 -1.35127415]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.20209455 -0.0782814   0.07732081  0.42852194 -0.1222934   0.4018441\n",
            "  0.48039572  0.25133509  0.30590289  0.07842778]\n",
            "\n",
            "# 17 Gradient out:  [0.99423552 0.71048364 1.03436813 0.77758655 0.43694527 0.99642093\n",
            " 0.74931037 0.45750608 1.12262587 1.08604932]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [-0.03787645 -0.25143741 -0.17446031  0.24006515 -0.18710737  0.16126634\n",
            "  0.29831526  0.16857522  0.01777814 -0.19182705]\n",
            "\n",
            "# 18 Gradient out:  [-1.44830588 -1.03770612 -1.52124124 -1.13165755 -0.36595932 -1.45204871\n",
            " -1.0925164  -0.47778584 -1.74685553 -1.63570716]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.16097066 -0.10934068  0.03241331  0.39558247 -0.09971831  0.36055053\n",
            "  0.44817733  0.26007643  0.24230331  0.02538282]\n",
            "\n",
            "# 19 Gradient out:  [2.67021536 1.93064275 2.78965391 2.10240149 0.93728538 2.67649045\n",
            " 2.03047141 1.07601401 3.11797821 2.96407489]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [-0.12869052 -0.3168819  -0.27183493  0.16925096 -0.17291018  0.07014079\n",
            "  0.22967405  0.16451927 -0.10706779 -0.30175862]\n",
            "\n",
            "# 20 Gradient out:  [-0.25924076 -0.19182904 -0.27112285 -0.20727422 -0.08259767 -0.25985157\n",
            " -0.2008365  -0.10086089 -0.30763685 -0.28968509]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [0.40535255 0.06924665 0.28609585 0.58973125 0.0145469  0.60543888\n",
            " 0.63576834 0.37972207 0.51652785 0.29105636]\n",
            "\n",
            "# 21 Gradient out:  [-0.40773774 -0.29961516 -0.42678876 -0.32438908 -0.12475531 -0.40871719\n",
            " -0.3140629  -0.15387809 -0.48528292 -0.45653762]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.3535044   0.03088084  0.23187128  0.54827641 -0.00197264  0.55346856\n",
            "  0.59560104  0.35954989  0.45500048  0.23311934]\n",
            "\n",
            "# 22 Gradient out:  [-0.78371638 -0.56940328 -0.82149737 -0.61850348 -0.22315106 -0.78565861\n",
            " -0.59803854 -0.28054309 -0.93748113 -0.88049818]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.27195685 -0.02904219  0.14651353  0.48339859 -0.0269237   0.47172512\n",
            "  0.53278846  0.32877427  0.35794389  0.14181182]\n",
            "\n",
            "# 23 Gradient out:  [-1.54939606 -1.10689298 -1.62907334 -1.20791635 -0.36310278 -1.55347171\n",
            " -1.16586257 -0.4895015  -1.87927705 -1.75529844]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.11521358 -0.14292285 -0.01778595  0.3596979  -0.07155391  0.3145934\n",
            "  0.41318075  0.27266566  0.17044767 -0.03428782]\n",
            "\n",
            "# 24 Gradient out:  [2.5907714  1.91643619 2.70204058 2.07255098 0.95921264 2.59658465\n",
            " 2.00724292 1.10360813 3.01786909 2.86756276]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [-0.19466563 -0.36430145 -0.34360061  0.11811463 -0.14417447  0.00389906\n",
            "  0.18000823  0.17476536 -0.20540774 -0.38534751]\n",
            "\n",
            "# 25 Gradient out:  [-0.51910055 -0.37802181 -0.54394888 -0.41034858 -0.15031554 -0.52037821\n",
            " -0.39687404 -0.18809179 -0.62017475 -0.58273301]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [0.32348865 0.01898579 0.1968075  0.53262482 0.04766806 0.52321599\n",
            " 0.58145682 0.39548698 0.39816607 0.18816505]\n",
            "\n",
            "# 26 Gradient out:  [-1.10750489 -0.79707881 -1.16234829 -0.86817296 -0.29398717 -1.11032288\n",
            " -0.83854487 -0.37737298 -1.33104589 -1.24810965]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.21966854 -0.05661857  0.08801773  0.45055511  0.01760495  0.41914035\n",
            "  0.50208201  0.35786862  0.27413112  0.07161844]\n",
            "\n",
            "# 27 Gradient out:  [0.07448641 0.02005891 0.07545072 0.03435167 0.09747706 0.07464309\n",
            " 0.02812704 0.06111637 0.04745756 0.06727642]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [-0.00183244 -0.21603433 -0.14445193  0.27692052 -0.04119248  0.19707577\n",
            "  0.33437303  0.28239403  0.00792195 -0.17800349]\n",
            "\n",
            "# 28 Gradient out:  [-0.22873273 -0.19606905 -0.24235492 -0.20189129  0.00747692 -0.22933542\n",
            " -0.19970824 -0.04776142 -0.3123844  -0.27244932]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.01306484 -0.21202255 -0.12936179  0.28379085 -0.02169707  0.21200439\n",
            "  0.33999844  0.2946173   0.01741346 -0.1645482 ]\n",
            "\n",
            "# 29 Gradient out:  [1.01909506 0.68760538 1.06678594 0.76582076 0.35831119 1.02168017\n",
            " 0.73288784 0.38345562 1.17458361 1.12919479]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [-0.03268171 -0.25123636 -0.17783277  0.24341259 -0.02020168  0.1661373\n",
            "  0.30005679  0.28506502 -0.04506342 -0.21903807]\n",
            "\n",
            "# 30 Gradient out:  [-1.45781188 -1.044828   -1.53130423 -1.13929733 -0.36597292 -1.4615816\n",
            " -1.09994441 -0.4796664  -1.75918502 -1.64680558]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.17113731 -0.11371528  0.03552441  0.39657674  0.05146055  0.37047334\n",
            "  0.44663436  0.36175614  0.1898533   0.00680089]\n",
            "\n",
            "# 31 Gradient out:  [2.63296662 1.89707813 2.75202952 2.06793519 0.90410697 2.63921898\n",
            " 1.99638936 1.04368329 3.08021207 2.92617611]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [-0.12042507 -0.32268089 -0.27073643  0.16871728 -0.02173403  0.07815702\n",
            "  0.22664548  0.26582286 -0.1619837  -0.32256022]\n",
            "\n",
            "# 32 Gradient out:  [-0.27850176 -0.2033137  -0.29174015 -0.22054339 -0.08193261 -0.2791825\n",
            " -0.21336148 -0.10210905 -0.33234824 -0.31240066]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [0.40616825 0.05673474 0.27966947 0.58230432 0.15908736 0.60600081\n",
            " 0.62592335 0.47455952 0.45405871 0.262675  ]\n",
            "\n",
            "# 33 Gradient out:  [-0.45220833 -0.32808571 -0.4740604  -0.35652918 -0.12796777 -0.45333205\n",
            " -0.344673   -0.1611262  -0.54105504 -0.50815594]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [0.3504679  0.016072   0.22132144 0.53819564 0.14270084 0.55016432\n",
            " 0.58325106 0.45413771 0.38758906 0.20019487]\n",
            "\n",
            "# 34 Gradient out:  [-0.91497029 -0.6579739  -0.96030037 -0.71684731 -0.24270584 -0.91730035\n",
            " -0.69230981 -0.31142099 -1.09949135 -1.03110655]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.26002623 -0.04954514  0.12650936  0.4668898   0.11710729  0.45949791\n",
            "  0.51431646  0.42191247  0.27937805  0.09856368]\n",
            "\n",
            "# 35 Gradient out:  [-1.26230763 -0.92491405 -1.32617004 -1.00128608 -0.2958908  -1.26553629\n",
            " -0.96959021 -0.41211496 -1.53791009 -1.43080985]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.07703218 -0.18113992 -0.06555071  0.32352034  0.06856612  0.27603783\n",
            "  0.37585449  0.35962827  0.05947978 -0.10765763]\n",
            "\n",
            "# 36 Gradient out:  [2.62424969 1.94446821 2.73652682 2.1018226  0.97568185 2.63011398\n",
            " 2.03599884 1.12300764 3.05583161 2.90371696]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [-0.17542935 -0.36612273 -0.33078472  0.12326313  0.00938796  0.02293058\n",
            "  0.18193645  0.27720528 -0.24810223 -0.3938196 ]\n",
            "\n",
            "# 37 Gradient out:  [-0.45598548 -0.32913372 -0.47830944 -0.35820425 -0.1248907  -0.45713359\n",
            " -0.34608647 -0.15865954 -0.54670561 -0.51312876]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [0.34942059 0.02277091 0.21652065 0.54362765 0.20452433 0.54895337\n",
            " 0.58913622 0.50180681 0.36306409 0.18692379]\n",
            "\n",
            "# 38 Gradient out:  [-0.92713642 -0.66439116 -0.97348532 -0.72458035 -0.23984752 -0.92951881\n",
            " -0.69949465 -0.31006582 -1.11580662 -1.04588517]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.25822349 -0.04305584  0.12085876  0.47198679  0.17954619  0.45752666\n",
            "  0.51991892  0.4700749   0.25372297  0.08429804]\n",
            "\n",
            "# 39 Gradient out:  [-1.20935038 -0.89871712 -1.26908869 -0.96883495 -0.29965071 -1.21235948\n",
            " -0.93976366 -0.41343111 -1.47051891 -1.36799653]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.07279621 -0.17593407 -0.0738383   0.32707073  0.13157669  0.27162289\n",
            "  0.38001999  0.40806174  0.03056164 -0.124879  ]\n",
            "\n",
            "# 40 Gradient out:  [2.63354134 1.94865772 2.74662734 2.10720063 0.97289831 2.6394483\n",
            " 2.04087856 1.12135826 3.06814178 2.91498875]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [-0.16907387 -0.35567749 -0.32765604  0.13330374  0.07164654  0.029151\n",
            "  0.19206726  0.32537551 -0.26354214 -0.3984783 ]\n",
            "\n",
            "# 41 Gradient out:  [-0.42735082 -0.3072672  -0.44847492 -0.33478843 -0.11415973 -0.42843733\n",
            " -0.32331621 -0.14603196 -0.5131543  -0.48141113]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [0.3576344  0.03405405 0.22166943 0.55474386 0.26622621 0.55704066\n",
            " 0.60024298 0.54964717 0.35008622 0.18451945]\n",
            "\n",
            "# 42 Gradient out:  [-0.84460172 -0.60369499 -0.88706789 -0.65888779 -0.21505559 -0.84678491\n",
            " -0.63588357 -0.27923837 -1.01735198 -0.9533674 ]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.27216424 -0.02739939  0.13197444  0.48778617  0.24339426  0.47135319\n",
            "  0.53557973  0.52044077  0.24745535  0.08823722]\n",
            "\n",
            "# 43 Gradient out:  [-1.47974955 -1.08244371 -1.55325494 -1.17273758 -0.37269794 -1.4834852\n",
            " -1.13521022 -0.50053579 -1.79147301 -1.67195548]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.10324389 -0.14813839 -0.04543914  0.35600862  0.20038314  0.30199621\n",
            "  0.40840302  0.4645931   0.04398496 -0.10243626]\n",
            "\n",
            "# 44 Gradient out:  [2.48639707 1.86644745 2.58959729 2.00978729 0.96259061 2.49177613\n",
            " 1.94984931 1.10484581 2.88672834 2.74434244]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [-0.19270602 -0.36462713 -0.35609012  0.1214611   0.12584355  0.00529917\n",
            "  0.18136097  0.36448594 -0.31430964 -0.43682735]\n",
            "\n",
            "# 45 Gradient out:  [-0.65441012 -0.4665595  -0.68747376 -0.50960744 -0.1644875  -0.65611055\n",
            " -0.49166362 -0.21422985 -0.78872928 -0.7390371 ]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [0.3045734  0.00866236 0.16182933 0.52341856 0.31836168 0.50365439\n",
            " 0.57133084 0.5854551  0.26303602 0.11204114]\n",
            "\n",
            "# 46 Gradient out:  [-1.44914781 -1.03728719 -1.52270879 -1.1314437  -0.35413599 -1.45291767\n",
            " -1.0922292  -0.46976857 -1.75185908 -1.63863523]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [ 0.17369137 -0.08464954  0.02433458  0.42149707  0.28546418  0.37243228\n",
            "  0.47299811  0.54260913  0.10529017 -0.03576628]\n",
            "\n",
            "# 47 Gradient out:  [2.46106636 1.74768235 2.57646944 1.91331742 0.78603066 2.46712687\n",
            " 1.84395796 0.92087236 2.8944077  2.74522311]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [-0.11613819 -0.29210698 -0.28020718  0.19520833  0.21463698  0.08184875\n",
            "  0.25455227  0.44865542 -0.24508165 -0.36349333]\n",
            "\n",
            "# 48 Gradient out:  [-0.36698024 -0.26222796 -0.3853933  -0.28623834 -0.09414747 -0.3679275\n",
            " -0.27622922 -0.12180432 -0.44170774 -0.41408399]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [0.37607508 0.05742949 0.23508671 0.57787181 0.37184311 0.57527412\n",
            " 0.62334386 0.63282989 0.33379989 0.18555129]\n",
            "\n",
            "# 49 Gradient out:  [-0.67603684 -0.48095471 -0.71037477 -0.52565941 -0.16729824 -0.67780279\n",
            " -0.50702507 -0.21892021 -0.81552831 -0.76392508]\n",
            "\n",
            "     Weights  out:  [ 0.12363414 -0.05463389  0.15822649 -0.01439416 -0.46865126  0.12536714\n",
            " -0.03108566 -0.35977365  0.28304562  0.21718293] [0.30267903 0.0049839  0.15800805 0.52062415 0.35301362 0.50168862\n",
            " 0.56809802 0.60846903 0.24545835 0.10273449]\n",
            "\n",
            "Tanh error cuadrático medio (ECM): 0.7833249381852975\n",
            "\n",
            "# 0 Gradient out:  [0.7864102  1.26924277 0.69839068 0.70264155 1.62121312 0.86167075\n",
            " 0.867591   1.68425358 1.27013423 1.71528526]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [-0.0428968   0.4653252  -0.43083475 -0.10172603 -0.00512033 -0.29888473\n",
            "  0.09801028  0.148542    0.18092845 -0.48369192]\n",
            "\n",
            "# 1 Gradient out:  [-0.47815115 -0.99933597 -0.31915334 -0.32605858 -1.3863556  -0.59221738\n",
            " -0.60008475 -1.49710275 -1.00013616 -1.55467357]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.11438524  0.71917375 -0.29115661  0.03880229  0.3191223  -0.12655058\n",
            "  0.27152849  0.48539272  0.43495529 -0.14063487]\n",
            "\n",
            "# 2 Gradient out:  [0.27143257 0.25595464 0.32063712 0.31883512 0.2394827  0.24510477\n",
            " 0.24383763 0.20641233 0.25604427 0.18797986]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.01875501  0.51930656 -0.35498728 -0.02640943  0.04185118 -0.24499406\n",
            "  0.15151153  0.18597217  0.23492806 -0.45156958]\n",
            "\n",
            "# 3 Gradient out:  [-0.20999899 -0.64546192 -0.0468154  -0.05372244 -0.97210108 -0.32060043\n",
            " -0.32785994 -1.08463363 -0.64605512 -1.1441759 ]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.07304153  0.57049749 -0.29085986  0.03735759  0.08974772 -0.1959731\n",
            "  0.20027906  0.22725464  0.28613691 -0.41397361]\n",
            "\n",
            "# 4 Gradient out:  [1.09785786 2.13150389 0.86441504 0.87475941 2.89111946 1.28509135\n",
            " 1.29897132 3.05870361 2.13328081 3.14174854]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.03104173  0.4414051  -0.30022294  0.0266131  -0.1046725  -0.26009319\n",
            "  0.13470707  0.01032791  0.15692589 -0.64280879]\n",
            "\n",
            "# 5 Gradient out:  [-0.19380805 -0.38921751 -0.13415319 -0.13676931 -0.53425842 -0.23640276\n",
            " -0.23934288 -0.57564016 -0.38951853 -0.59726119]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.2506133   0.86770588 -0.12733993  0.20156499  0.4735514  -0.00307492\n",
            "  0.39450134  0.62206863  0.58358205 -0.01445908]\n",
            "\n",
            "# 6 Gradient out:  [-0.35456581 -0.73918045 -0.23724428 -0.2423656  -1.02472012 -0.43854865\n",
            " -0.44434414 -1.10627236 -0.73977204 -1.14877171]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.21185169  0.78986238 -0.15417057  0.17421113  0.36669971 -0.05035547\n",
            "  0.34663276  0.5069406   0.50567835 -0.13391132]\n",
            "\n",
            "# 7 Gradient out:  [-0.56266769 -1.27404267 -0.33081372 -0.34086221 -1.80372815 -0.72535661\n",
            " -0.73640461 -1.96424004 -1.27510071 -2.04846306]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.14093853  0.64202629 -0.20161942  0.12573801  0.16175569 -0.1380652\n",
            "  0.25776393  0.28568613  0.35772394 -0.36366566]\n",
            "\n",
            "# 8 Gradient out:  [1.24101722 2.34449932 0.96261602 0.97515021 3.15746163 1.45256054\n",
            " 1.46787049 3.35297179 2.34634136 3.4529571 ]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.02840499  0.38721776 -0.26778217  0.05756556 -0.19898994 -0.28313652\n",
            "  0.11048301 -0.10716188  0.1027038  -0.77335828]\n",
            "\n",
            "# 9 Gradient out:  [-0.22690591 -0.47381836 -0.15186863 -0.15514843 -0.65709167 -0.28066249\n",
            " -0.28437582 -0.70924578 -0.47419893 -0.73642529]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.27660843  0.85611762 -0.07525896  0.25259561  0.43250238  0.00737559\n",
            "  0.40405711  0.56343248  0.57197207 -0.08276685]\n",
            "\n",
            "# 10 Gradient out:  [-0.45108672 -0.97485224 -0.29048267 -0.29747956 -1.36382326 -0.56595709\n",
            " -0.573873   -1.47549673 -0.97565529 -1.53367809]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.23122725  0.76135395 -0.10563269  0.22156592  0.30108405 -0.04875691\n",
            "  0.34718195  0.42158332  0.47713229 -0.23005191]\n",
            "\n",
            "# 11 Gradient out:  [-0.05099962 -0.09166104  0.02763101  0.02402609 -0.12732448 -0.08876221\n",
            " -0.09062441 -0.17573014 -0.09158505 -0.20567688]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.14100991  0.5663835  -0.16372922  0.16207001  0.0283194  -0.16194833\n",
            "  0.23240735  0.12648398  0.28200123 -0.53678753]\n",
            "\n",
            "# 12 Gradient out:  [0.17906538 0.41256774 0.18545415 0.18498273 0.57948802 0.19614446\n",
            " 0.1981958  0.58231826 0.41308955 0.57829443]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.13080998  0.54805129 -0.15820302  0.16687523  0.0028545  -0.17970077\n",
            "  0.21428247  0.09133795  0.26368422 -0.57792291]\n",
            "\n",
            "# 13 Gradient out:  [-0.49244184 -1.0666239  -0.2825133  -0.29176436 -1.49580661 -0.63304458\n",
            " -0.64235646 -1.6384859  -1.06743392 -1.71529254]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.16662306  0.63056484 -0.12111219  0.20387177  0.1187521  -0.14047188\n",
            "  0.25392163  0.2078016   0.34630213 -0.46226402]\n",
            "\n",
            "# 14 Gradient out:  [1.23050562 2.34180303 0.94993858 0.96260505 3.16044815 1.44337542\n",
            " 1.45878358 3.35723449 2.34365916 3.4580292 ]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.06813469  0.41724006 -0.17761485  0.1455189  -0.18040922 -0.26708079\n",
            "  0.12545033 -0.11989558  0.13281534 -0.80532253]\n",
            "\n",
            "# 15 Gradient out:  [-0.20089582 -0.43111625 -0.13121703 -0.13425706 -0.60199281 -0.25093518\n",
            " -0.25439445 -0.65048373 -0.43147145 -0.67571139]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.31423582  0.88560066  0.01237286  0.33803991  0.45168041  0.02159429\n",
            "  0.41720705  0.55155132  0.60154718 -0.11371669]\n",
            "\n",
            "# 16 Gradient out:  [-0.39368276 -0.86371709 -0.2500558  -0.25631407 -1.21274255 -0.4965404\n",
            " -0.5036344  -1.31264705 -0.86443885 -1.36466776]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.27405665  0.79937741 -0.01387054  0.3111885   0.33128185 -0.02859274\n",
            "  0.36632816  0.42145457  0.51525289 -0.24885897]\n",
            "\n",
            "# 17 Gradient out:  [-0.43362553 -0.86364703 -0.25103256 -0.25926495 -1.18680831 -0.54899605\n",
            " -0.55639411 -1.30804268 -0.86420632 -1.37542147]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.1953201   0.626634   -0.0638817   0.25992569  0.08873334 -0.12790082\n",
            "  0.26560128  0.15892516  0.34236512 -0.52179252]\n",
            "\n",
            "# 18 Gradient out:  [1.13711742 2.25277629 0.86589786 0.87803461 3.07404538 1.34700885\n",
            " 1.36232124 3.26596775 2.25465728 3.36306367]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.108595    0.45390459 -0.11408821  0.20807269 -0.14862832 -0.23770003\n",
            "  0.15432246 -0.10268337  0.16952385 -0.79687681]\n",
            "\n",
            "# 19 Gradient out:  [-0.18278848 -0.39756385 -0.11794279 -0.12076912 -0.55697176 -0.22942232\n",
            " -0.23264769 -0.60213139 -0.39789542 -0.62560337]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.33601848  0.90445985  0.05909136  0.38367962  0.46618075  0.03170173\n",
            "  0.42678671  0.55051018  0.62045531 -0.12426408]\n",
            "\n",
            "# 20 Gradient out:  [-0.34900199 -0.77275947 -0.21999158 -0.22561032 -1.0873888  -0.44153923\n",
            " -0.44792664 -1.17718217 -0.77341108 -1.22389668]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.29946078  0.82494708  0.0355028   0.35952579  0.3547864  -0.01418273\n",
            "  0.38025717  0.4300839   0.54087622 -0.24938475]\n",
            "\n",
            "# 21 Gradient out:  [-0.58207784 -1.21441433 -0.35381686 -0.3639927  -1.6864851  -0.73470961\n",
            " -0.74485838 -1.84104295 -1.21531786 -1.92460068]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.22966039  0.67039518 -0.00849551  0.31440373  0.13730864 -0.10249057\n",
            "  0.29067184  0.19464746  0.38619401 -0.49416409]\n",
            "\n",
            "# 22 Gradient out:  [1.20600398 2.26471955 0.92883875 0.94151171 3.0450337  1.41197335\n",
            " 1.42677671 3.23745509 2.26647371 3.3373946 ]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.11324482  0.42751232 -0.07925889  0.24160519 -0.19998838 -0.2494325\n",
            "  0.14170016 -0.17356113  0.14313044 -0.87908423]\n",
            "\n",
            "# 23 Gradient out:  [-0.24189198 -0.54304606 -0.15103481 -0.15498566 -0.76659033 -0.30732865\n",
            " -0.31185432 -0.82993515 -0.54351067 -0.86281232]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.35444562  0.88045623  0.10650886  0.42990753  0.40901836  0.03296217\n",
            "  0.42705551  0.47392989  0.59642518 -0.21160531]\n",
            "\n",
            "# 24 Gradient out:  [-0.51532261 -1.15189267 -0.31536654 -0.32411554 -1.62498535 -0.65685376\n",
            " -0.66655648 -1.76342287 -1.15285954 -1.83597993]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.30606722  0.77184702  0.0763019   0.3989104   0.25570029 -0.02850356\n",
            "  0.36468464  0.30794286  0.48772305 -0.38416777]\n",
            "\n",
            "# 25 Gradient out:  [0.50891572 1.30713517 0.36511548 0.3710197  1.89186675 0.64067939\n",
            " 0.65087969 2.00202282 1.30856588 2.05180862]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.2030027   0.54146848  0.01322859  0.33408729 -0.06929678 -0.15987431\n",
            "  0.23137335 -0.04474171  0.25715114 -0.75136376]\n",
            "\n",
            "# 26 Gradient out:  [-0.44073756 -0.98990403 -0.27142412 -0.27880801 -1.39781822 -0.56156636\n",
            " -0.56988324 -1.51543905 -0.99074412 -1.57679602]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.30478584  0.80289552  0.08625169  0.40829123  0.30907657 -0.03173843\n",
            "  0.36154928  0.35566285  0.51886431 -0.34100203]\n",
            "\n",
            "# 27 Gradient out:  [-0.11358096  0.00341593 -0.05880765 -0.06178827  0.08380489 -0.12475211\n",
            " -0.1245455   0.05662895  0.00376936  0.03449966]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.21663833  0.60491471  0.03196686  0.35252963  0.02951293 -0.14405171\n",
            "  0.24757264  0.05257504  0.32071549 -0.65636124]\n",
            "\n",
            "# 28 Gradient out:  [-0.10447301 -0.01304619 -0.04616953 -0.04922982  0.04853116 -0.11985566\n",
            " -0.11998076  0.01807595 -0.0127382  -0.00518587]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.19392214  0.6055979   0.02020533  0.34017197  0.04627391 -0.16900213\n",
            "  0.22266354  0.06390083  0.32146936 -0.6494613 ]\n",
            "\n",
            "# 29 Gradient out:  [-0.06008189  0.05540506 -0.0108945  -0.0134969   0.13483607 -0.06986036\n",
            " -0.06961266  0.11018271  0.05574878  0.0903072 ]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.17302754  0.60298866  0.01097143  0.33032601  0.05598014 -0.19297326\n",
            "  0.19866738  0.06751602  0.31892172 -0.65049848]\n",
            "\n",
            "# 30 Gradient out:  [-0.14641136 -0.16669481 -0.0638453  -0.06784341 -0.18751768 -0.18265278\n",
            " -0.18431716 -0.23640552 -0.16657485 -0.2681603 ]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.16101116  0.61406967  0.00879253  0.32762663  0.08294735 -0.20694533\n",
            "  0.18474485  0.08955256  0.33007148 -0.63243704]\n",
            "\n",
            "# 31 Gradient out:  [0.22538711 0.62670504 0.19232882 0.19342603 0.91759746 0.27494445\n",
            " 0.27935567 0.9497779  0.62750401 0.95968273]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.13172889  0.58073071 -0.00397653  0.31405795  0.04544381 -0.24347589\n",
            "  0.14788142  0.04227146  0.29675651 -0.6860691 ]\n",
            "\n",
            "# 32 Gradient out:  [-0.60490522 -1.30965493 -0.3672243  -0.37768728 -1.83469064 -0.7685176\n",
            " -0.77955644 -1.9975946  -1.31069237 -2.08421174]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.17680631  0.70607172  0.03448923  0.35274316  0.22896331 -0.188487\n",
            "  0.20375255  0.23222704  0.42225731 -0.49413255]\n",
            "\n",
            "# 33 Gradient out:  [1.21947057 2.2885022  0.94128175 0.953961   3.0763873  1.42701282\n",
            " 1.44194494 3.26993612 2.29027526 3.37017372]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.05582526  0.44414073 -0.03895563  0.2772057  -0.13797482 -0.34219052\n",
            "  0.04784127 -0.16729188  0.16011884 -0.9109749 ]\n",
            "\n",
            "# 34 Gradient out:  [-0.24166021 -0.536644   -0.15248544 -0.15636829 -0.75560613 -0.30579335\n",
            " -0.31022732 -0.81772728 -0.53709897 -0.85000427]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.29971938  0.90184117  0.14930072  0.4679979   0.47730264 -0.05678795\n",
            "  0.33623025  0.48669534  0.61817389 -0.23694016]\n",
            "\n",
            "# 35 Gradient out:  [-0.51149435 -1.14205668 -0.31476132 -0.32335599 -1.61059462 -0.65117328\n",
            " -0.66076265 -1.7469843  -1.14301686 -1.81833666]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.25138734  0.79451237  0.11880364  0.43672424  0.32618141 -0.11794662\n",
            "  0.27418479  0.32314989  0.5107541  -0.40694101]\n",
            "\n",
            "# 36 Gradient out:  [0.49115394 1.24062939 0.36036408 0.36573118 1.78924412 0.61287196\n",
            " 0.62236091 1.89000231 1.24198249 1.93513924]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.14908847  0.56610103  0.05585137  0.37205304  0.00406249 -0.24818128\n",
            "  0.14203226 -0.02624697  0.28215072 -0.77060834]\n",
            "\n",
            "# 37 Gradient out:  [-0.46796956 -1.04601358 -0.28941024 -0.29719924 -1.4753975  -0.595286\n",
            " -0.60404568 -1.59939885 -1.04689724 -1.66411594]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.24731925  0.81422691  0.12792419  0.44519928  0.36191131 -0.12560689\n",
            "  0.26650444  0.35175349  0.53054722 -0.38358049]\n",
            "\n",
            "# 38 Gradient out:  [0.10908243 0.45028259 0.0978494  0.09786487 0.69659257 0.14491183\n",
            " 0.14840185 0.71472678 0.45099109 0.71655146]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.15372534  0.60502419  0.07004214  0.38575943  0.06683181 -0.24466409\n",
            "  0.14569531  0.03187372  0.32116777 -0.71640368]\n",
            "\n",
            "# 39 Gradient out:  [-0.55194203 -1.14159864 -0.3325957  -0.34239464 -1.58231298 -0.69702508\n",
            " -0.70660694 -1.73027296 -1.14242807 -1.81069437]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.17554183  0.69508071  0.08961202  0.40533241  0.20615032 -0.21568172\n",
            "  0.17537568  0.17481907  0.41136599 -0.57309339]\n",
            "\n",
            "# 40 Gradient out:  [1.20054652 2.28117685 0.920567   0.93331825 3.07753445 1.40987364\n",
            " 1.4249484  3.27250454 2.28297132 3.37335065]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.06515342  0.46676098  0.02309288  0.33685348 -0.11031227 -0.35508674\n",
            "  0.03405429 -0.17123552  0.18288038 -0.93523226]\n",
            "\n",
            "# 41 Gradient out:  [-0.2281593  -0.51183914 -0.14253913 -0.14626488 -0.72240572 -0.28979143\n",
            " -0.29405383 -0.78207754 -0.51227686 -0.81306303]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.30526273  0.92299635  0.20720628  0.52351713  0.50519462 -0.07311201\n",
            "  0.31904397  0.48326539  0.63947464 -0.26056213]\n",
            "\n",
            "# 42 Gradient out:  [-0.48121171 -1.08330435 -0.29427665 -0.30243874 -1.53062022 -0.61420429\n",
            " -0.62334454 -1.66031777 -1.08422297 -1.72809452]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.25963087  0.82062852  0.17869845  0.49426415  0.36071347 -0.1310703\n",
            "  0.2602332   0.32684988  0.53701927 -0.42317474]\n",
            "\n",
            "# 43 Gradient out:  [0.22604763 0.74894419 0.16655307 0.16862913 1.12964353 0.29865526\n",
            " 0.30476081 1.18219168 0.74994581 1.20131591]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.16338852  0.60396766  0.11984312  0.4337764   0.05458943 -0.25391116\n",
            "  0.13556429 -0.00521367  0.32017468 -0.76879364]\n",
            "\n",
            "# 44 Gradient out:  [-0.6132323  -1.3350825  -0.37387691 -0.38443464 -1.87244096 -0.7788071\n",
            " -0.79002454 -2.03664319 -1.33615493 -2.12381208]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.20859805  0.75375649  0.15315374  0.46750223  0.28051814 -0.1941801\n",
            "  0.19651645  0.23122467  0.47016384 -0.52853046]\n",
            "\n",
            "# 45 Gradient out:  [1.16295952 2.24972759 0.88315427 0.89588033 3.05050908 1.37283051\n",
            " 1.38796448 3.24563341 2.25153522 3.346361  ]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.08595159  0.48673999  0.07837836  0.3906153  -0.09397006 -0.34994152\n",
            "  0.03851154 -0.17610397  0.20293285 -0.95329288]\n",
            "\n",
            "# 46 Gradient out:  [-0.22173137 -0.50348174 -0.13683812 -0.1405289  -0.71261423 -0.28290635\n",
            " -0.28713846 -0.77181409 -0.50391664 -0.80253049]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.31854349  0.93668551  0.25500921  0.56979137  0.51613176 -0.07537542\n",
            "  0.31610444  0.47302271  0.6532399  -0.28402068]\n",
            "\n",
            "# 47 Gradient out:  [-0.46816197 -1.06206972 -0.28383907 -0.29188754 -1.5033005  -0.59931578\n",
            " -0.60833054 -1.63119058 -1.062976   -1.69801845]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.27419722  0.83598916  0.22764159  0.54168559  0.37360892 -0.13195669\n",
            "  0.25867675  0.31865989  0.55245657 -0.44452678]\n",
            "\n",
            "# 48 Gradient out:  [0.11823087 0.56390715 0.08447574 0.08532381 0.88737368 0.17377969\n",
            " 0.17872185 0.92289022 0.56479023 0.93256261]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.18056483  0.62357522  0.17087377  0.48330808  0.07294881 -0.25181985\n",
            "  0.13701064 -0.00757822  0.33986137 -0.78413047]\n",
            "\n",
            "# 49 Gradient out:  [-0.60166463 -1.25961207 -0.36657143 -0.37707466 -1.75052838 -0.75922175\n",
            " -0.76972485 -1.90971958 -1.26055841 -1.99575558]\n",
            "\n",
            "     Weights  out:  [-0.29839049  0.02607142 -0.48162939 -0.47073439  0.26699727 -0.2103273\n",
            " -0.2049056   0.36918613  0.02650501  0.43941451] [ 0.204211    0.73635665  0.18776892  0.50037284  0.25042355 -0.21706391\n",
            "  0.17275501  0.17699982  0.45281942 -0.59761795]\n",
            "\n",
            "Lineal error cuadrático medio (ECM): 1.1630094737541492\n",
            "\n",
            "# 0 Gradient out:  [1.09657319 0.99069494 0.94119128 1.88322053 0.98035558 0.90296216\n",
            " 2.6028124  2.60289872 2.34138965 2.30853644]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.34173015  0.30910639 -0.4699337  -0.10338777 -0.32207225 -0.14358269\n",
            "  0.39325807 -0.17395066 -0.10880911 -0.36390257]\n",
            "\n",
            "# 1 Gradient out:  [-0.2734523  -0.23834101 -0.22032833 -0.46467086 -0.2346599  -0.20586451\n",
            " -0.67361365 -0.67364611 -0.58125495 -0.57141406]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.56104479  0.50724538 -0.28169545  0.27325633 -0.12600114  0.03700974\n",
            "  0.91382055  0.34662908  0.35946882  0.09780472]\n",
            "\n",
            "# 2 Gradient out:  [-0.51779991 -0.43989976 -0.40003267 -0.94179445 -0.43174459 -0.36811367\n",
            " -1.40463114 -1.40470213 -1.20044486 -1.17859169]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.50635433  0.45957718 -0.32576111  0.18032216 -0.17293312 -0.00416316\n",
            "  0.77909782  0.21189986  0.24321783 -0.0164781 ]\n",
            "\n",
            "# 3 Gradient out:  [ 0.02294422  0.07618705  0.10577957 -0.15259712  0.08214038  0.13005375\n",
            " -0.41858422 -0.41863627 -0.27170907 -0.25843862]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.40279435  0.37159723 -0.40576765 -0.00803673 -0.25928203 -0.0777859\n",
            "  0.49817159 -0.06904056  0.00312885 -0.25219643]\n",
            "\n",
            "# 4 Gradient out:  [0.49466945 0.46828044 0.45903589 0.82251468 0.46619005 0.45301844\n",
            " 1.05754975 1.05756317 1.00367551 0.99347769]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.40738319  0.38683464 -0.38461173 -0.03855615 -0.24285396 -0.05177515\n",
            "  0.41445475 -0.15276782 -0.05121296 -0.30388416]\n",
            "\n",
            "# 5 Gradient out:  [-0.68288659 -0.56414364 -0.50306631 -1.31326238 -0.55166236 -0.45409802\n",
            " -2.01167171 -2.01178029 -1.69951825 -1.66643426]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.50631708  0.48049072 -0.29280456  0.12594678 -0.14961595  0.03882854\n",
            "  0.6259647   0.05874482  0.14952214 -0.10518862]\n",
            "\n",
            "# 6 Gradient out:  [1.38794616 1.22789336 1.14993129 2.44555156 1.21177311 1.08855998\n",
            " 3.47806389 3.47820299 3.07127341 3.02362354]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.36973976  0.367662   -0.39341782 -0.13670569 -0.25994842 -0.05199106\n",
            "  0.22363035 -0.34361124 -0.19038151 -0.43847547]\n",
            "\n",
            "# 7 Gradient out:  [-0.16388395 -0.14164084 -0.13024612 -0.28550819 -0.13931128 -0.12110428\n",
            " -0.41805432 -0.41807481 -0.35961878 -0.35337585]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.647329    0.61324067 -0.16343156  0.35240462 -0.0175938   0.16572094\n",
            "  0.91924313  0.35202936  0.42387317  0.16624924]\n",
            "\n",
            "# 8 Gradient out:  [-0.270492   -0.2315799  -0.2116644  -0.48332341 -0.22750693 -0.19570247\n",
            " -0.71512394 -0.71515962 -0.61302405 -0.60209782]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.61455221  0.5849125  -0.18948078  0.29530298 -0.04545605  0.14150008\n",
            "  0.83563227  0.26841439  0.35194942  0.09557407]\n",
            "\n",
            "# 9 Gradient out:  [-0.54660516 -0.45925403 -0.41450572 -1.02009509 -0.45010256 -0.37866122\n",
            " -1.53828659 -1.53836636 -1.30914637 -1.28467039]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.56045381  0.53859652 -0.23181366  0.1986383  -0.09095744  0.10235959\n",
            "  0.69260748  0.12538247  0.22934461 -0.0248455 ]\n",
            "\n",
            "# 10 Gradient out:  [0.23470435 0.22889033 0.23062565 0.45567319 0.22901405 0.23375028\n",
            " 0.56856319 0.56855409 0.57148726 0.56690952]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.45113278  0.44674572 -0.31471481 -0.00538072 -0.18097795  0.02662734\n",
            "  0.38495016 -0.1822908  -0.03248466 -0.28177958]\n",
            "\n",
            "# 11 Gradient out:  [-0.61100267 -0.49580699 -0.43508238 -1.16664902 -0.48347232 -0.38580696\n",
            " -1.82159576 -1.82170625 -1.51278734 -1.481579  ]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.49807365  0.49252378 -0.26858968  0.08575392 -0.13517514  0.0733774\n",
            "  0.4986628  -0.06857998  0.08181279 -0.16839767]\n",
            "\n",
            "# 12 Gradient out:  [1.37285277 1.21990979 1.14419218 2.34588649 1.20432481 1.08395859\n",
            " 3.31875576 3.31889454 2.92433425 2.87944921]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.37587311  0.39336238 -0.35560615 -0.14757588 -0.23186961 -0.00378399\n",
            "  0.13434365 -0.43292123 -0.22074468 -0.46471347]\n",
            "\n",
            "# 13 Gradient out:  [-0.24763317 -0.20997534 -0.19072745 -0.45415657 -0.20603732 -0.17531613\n",
            " -0.67864677 -0.67868115 -0.57997324 -0.56938772]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.65044367  0.63734434 -0.12676772  0.32160141  0.00899536  0.21300772\n",
            "  0.7980948   0.23085767  0.36412217  0.11117637]\n",
            "\n",
            "# 14 Gradient out:  [-0.50334552 -0.42118389 -0.37909942 -0.94910937 -0.41257715 -0.34538647\n",
            " -1.43672639 -1.43680147 -1.22119238 -1.19816484]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.60091703  0.59534927 -0.16491321  0.2307701  -0.03221211  0.1779445\n",
            "  0.66236545  0.09512144  0.24812752 -0.00270117]\n",
            "\n",
            "# 15 Gradient out:  [-0.16807156 -0.12942679 -0.10495283 -0.20277446 -0.12466101 -0.08343801\n",
            " -0.36176045 -0.3618125  -0.24119431 -0.23315931]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.50024793  0.51111249 -0.24073309  0.04094823 -0.11472754  0.1088672\n",
            "  0.37502017 -0.19223885  0.00388905 -0.24233414]\n",
            "\n",
            "# 16 Gradient out:  [0.41249595 0.36518577 0.34677258 0.89476525 0.36112844 0.33428019\n",
            " 1.26762675 1.26765068 1.16666985 1.14985217]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 4.66633616e-01  4.85227136e-01 -2.61723658e-01  3.93335845e-04\n",
            " -1.39659739e-01  9.21796022e-02  3.02668078e-01 -2.64601351e-01\n",
            " -4.43498135e-02 -2.88966001e-01]\n",
            "\n",
            "# 17 Gradient out:  [-0.68250804 -0.56654635 -0.50673337 -1.29529806 -0.5543346  -0.45865968\n",
            " -1.97680882 -1.97691613 -1.67096772 -1.6387232 ]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.54913281  0.55826429 -0.19236914  0.17934639 -0.06743405  0.15903564\n",
            "  0.55619343 -0.01107122  0.18898416 -0.05899557]\n",
            "\n",
            "# 18 Gradient out:  [1.28946104 1.13475142 1.05970164 2.32349129 1.11921703 1.00074866\n",
            " 3.32630359 3.32643701 2.93433094 2.88808449]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.4126312   0.44495502 -0.29371582 -0.07971323 -0.17830097  0.06730371\n",
            "  0.16083166 -0.40645444 -0.14520939 -0.38674021]\n",
            "\n",
            "# 19 Gradient out:  [-0.16426292 -0.13952864 -0.12688973 -0.30014921 -0.13694269 -0.11676991\n",
            " -0.44771197 -0.44773456 -0.38290623 -0.37595035]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.67052341  0.67190531 -0.08177549  0.38498503  0.04554243  0.26745344\n",
            "  0.82609238  0.25883296  0.4416568   0.19087669]\n",
            "\n",
            "# 20 Gradient out:  [-0.28158078 -0.23720181 -0.21452765 -0.52496657 -0.23256209 -0.19638103\n",
            " -0.78947275 -0.78951317 -0.67325126 -0.66077426]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.63767082  0.64399958 -0.10715343  0.32495519  0.0181539   0.24409946\n",
            "  0.73654999  0.16928605  0.36507555  0.11568662]\n",
            "\n",
            "# 21 Gradient out:  [-0.60019732 -0.49919326 -0.44729233 -1.14180411 -0.48858727 -0.40565011\n",
            " -1.7386562  -1.73874906 -1.47302578 -1.44481766]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.58135466  0.59655921 -0.15005896  0.21996188 -0.02835852  0.20482325\n",
            "  0.57865544  0.01138341  0.2304253  -0.01646823]\n",
            "\n",
            "# 22 Gradient out:  [0.69887687 0.60540298 0.56358874 1.44511505 0.59655073 0.53238589\n",
            " 2.09813158 2.09819765 1.87668279 1.8467363 ]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.4613152   0.49672056 -0.23951743 -0.00839894 -0.12607598  0.12369323\n",
            "  0.2309242  -0.3363664  -0.06417985 -0.30543176]\n",
            "\n",
            "# 23 Gradient out:  [-0.42329913 -0.35420645 -0.31886112 -0.79999933 -0.34697575 -0.29056275\n",
            " -1.21082206 -1.21088506 -1.02974172 -1.01034851]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.60109058  0.61780116 -0.12679968  0.28062407 -0.00676583  0.23017041\n",
            "  0.65055051  0.08327313  0.3111567   0.06391549]\n",
            "\n",
            "# 24 Gradient out:  [-0.62933355 -0.52024153 -0.46172128 -1.1252564  -0.50841086 -0.41372169\n",
            " -1.73460468 -1.73471438 -1.43732948 -1.40830366]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.51643075  0.54695987 -0.19057191  0.1206242  -0.07616098  0.17205786\n",
            "  0.4083861  -0.15890388  0.10520836 -0.13815421]\n",
            "\n",
            "# 25 Gradient out:  [1.36438466 1.21208422 1.1363632  2.32556285 1.19651868 1.07593201\n",
            " 3.29194186 3.29208202 2.89747946 2.85293222]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.39056404  0.44291156 -0.28291616 -0.10442708 -0.17784315  0.08931352\n",
            "  0.06146517 -0.50584676 -0.18225754 -0.41981494]\n",
            "\n",
            "# 26 Gradient out:  [-0.23876071 -0.20004448 -0.18028437 -0.45164409 -0.19599983 -0.16448123\n",
            " -0.68258864 -0.68262379 -0.58129889 -0.57040363]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.66344097  0.68532841 -0.05564352  0.36068549  0.06146058  0.30449992\n",
            "  0.71985354  0.15256964  0.39723836  0.1507715 ]\n",
            "\n",
            "# 27 Gradient out:  [-0.49374092 -0.4099199  -0.36696946 -0.94771826 -0.4011368  -0.33255721\n",
            " -1.44485132 -1.44492796 -1.22490233 -1.20142067]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.61568883  0.64531951 -0.0917004   0.27035667  0.02226062  0.27160367\n",
            "  0.58333581  0.01604489  0.28097858  0.03669078]\n",
            "\n",
            "# 28 Gradient out:  [-0.23354268 -0.19968646 -0.17677264 -0.21960162 -0.19529348 -0.15599139\n",
            " -0.34283172 -0.34288457 -0.23023872 -0.22397233]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.51694065  0.56333553 -0.16509429  0.08081302 -0.05796674  0.20509223\n",
            "  0.29436555 -0.27294071  0.03599811 -0.20359336]\n",
            "\n",
            "# 29 Gradient out:  [0.35566203 0.30300097 0.28239372 0.88015574 0.29846154 0.26846865\n",
            " 1.28888651 1.28891206 1.17675565 1.15818356]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.47023211  0.52339824 -0.20044882  0.0368927  -0.09702544  0.17389395\n",
            "  0.2257992  -0.34151762 -0.01004963 -0.24838782]\n",
            "\n",
            "# 30 Gradient out:  [-0.68908026 -0.571177   -0.51020896 -1.30750015 -0.55873813 -0.46112744\n",
            " -1.99875784 -1.99886773 -1.68705941 -1.65435528]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.54136451  0.58399843 -0.14397007  0.21292384 -0.03733313  0.22758768\n",
            "  0.48357651 -0.08373521  0.2253015  -0.01675111]\n",
            "\n",
            "# 31 Gradient out:  [1.27091204 1.11597792 1.04044835 2.2945751  1.10036565 0.98093218\n",
            " 3.29440989 3.29454521 2.90016835 2.85405618]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.40354846  0.46976303 -0.24601187 -0.04857619 -0.14908076  0.13536219\n",
            "  0.08382494 -0.48350876 -0.11211038 -0.34762217]\n",
            "\n",
            "# 32 Gradient out:  [-0.17636545 -0.14834499 -0.13404375 -0.33060791 -0.14541783 -0.12260407\n",
            " -0.49784673 -0.4978722  -0.42452563 -0.41663868]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.65773087  0.69295861 -0.0379222   0.41033883  0.07099237  0.33154863\n",
            "  0.74270692  0.17540029  0.46792329  0.22318907]\n",
            "\n",
            "# 33 Gradient out:  [-0.31825313 -0.26557791 -0.23867542 -0.60702463 -0.26007208 -0.21715533\n",
            " -0.92085695 -0.92090482 -0.78298908 -0.76817818]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.62245778  0.66328962 -0.06473095  0.34421725  0.04190881  0.30702782\n",
            "  0.64313757  0.07582585  0.38301816  0.13986133]\n",
            "\n",
            "# 34 Gradient out:  [-0.68870432 -0.5703966  -0.50910611 -1.30586851 -0.55789837 -0.45970586\n",
            " -1.99829325 -1.9984041  -1.68497802 -1.6522205 ]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.55880716  0.61017403 -0.11246603  0.22281233 -0.01010561  0.26359675\n",
            "  0.45896618 -0.10835512  0.22642035 -0.0137743 ]\n",
            "\n",
            "# 35 Gradient out:  [1.23644522 1.08303565 1.0081482  2.24697506 1.06756208 0.94908447\n",
            " 3.23586757 3.23600207 2.84502314 2.7994177 ]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.42106629  0.49609471 -0.21428725 -0.03836138 -0.12168528  0.17165558\n",
            "  0.05930753 -0.50803594 -0.11057526 -0.3442184 ]\n",
            "\n",
            "# 36 Gradient out:  [-0.18919136 -0.15811725 -0.14226993 -0.36044733 -0.15487281 -0.12960197\n",
            " -0.54595388 -0.54598205 -0.46471346 -0.45596207]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.66835534  0.71270184 -0.01265761  0.41103364  0.09182713  0.36147247\n",
            "  0.70648104  0.13916448  0.45842937  0.21566514]\n",
            "\n",
            "# 37 Gradient out:  [-0.35701884 -0.29617511 -0.26509389 -0.68997022 -0.28981419 -0.24023242\n",
            " -1.05217816 -1.05223343 -0.89292677 -0.87582641]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.63051706  0.68107839 -0.0411116   0.33894417  0.06085257  0.33555208\n",
            "  0.59729027  0.02996807  0.36548668  0.12447273]\n",
            "\n",
            "# 38 Gradient out:  [-0.72692224 -0.60355747 -0.53866217 -1.33754357 -0.59037697 -0.4859025\n",
            " -2.04698756 -2.04710741 -1.71589164 -1.68228304]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.5591133   0.62184337 -0.09413037  0.20095013  0.00288973  0.28750559\n",
            "  0.38685463 -0.18047862  0.18690133 -0.05069256]\n",
            "\n",
            "# 39 Gradient out:  [1.32023948 1.17187514 1.0975775  2.24260547 1.15663461 1.03797667\n",
            " 3.17939699 3.17953655 2.79241281 2.74927559]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.41372885  0.50113188 -0.20186281 -0.06655859 -0.11518566  0.19032509\n",
            " -0.02254288 -0.5899001  -0.156277   -0.38714917]\n",
            "\n",
            "# 40 Gradient out:  [-0.27030476 -0.22321049 -0.19920091 -0.52947504 -0.21829413 -0.18001977\n",
            " -0.81036782 -0.81041037 -0.68732563 -0.67406415]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [0.67777675 0.73550691 0.01765269 0.38196251 0.11614126 0.39792043\n",
            " 0.61333652 0.04600721 0.40220556 0.16270595]\n",
            "\n",
            "# 41 Gradient out:  [-0.5943291  -0.48953645 -0.43548174 -1.14945423 -0.47850176 -0.39200985\n",
            " -1.76615564 -1.76625297 -1.48960191 -1.46044885]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.62371579  0.69086481 -0.02218749  0.2760675   0.07248243  0.36191647\n",
            "  0.45126296 -0.11607487  0.26474043  0.02789312]\n",
            "\n",
            "# 42 Gradient out:  [0.57486964 0.47464745 0.42989478 1.36651398 0.46515992 0.39669631\n",
            " 2.06139266 2.06146116 1.82525976 1.7932168 ]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.50484997  0.59295752 -0.10928384  0.04617665 -0.02321792  0.2835145\n",
            "  0.09803183 -0.46932546 -0.03317995 -0.26419665]\n",
            "\n",
            "# 43 Gradient out:  [-0.46484427 -0.38331783 -0.34155796 -0.90666658 -0.37477728 -0.30810832\n",
            " -1.39026632 -1.39034079 -1.17641393 -1.15356866]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.6198239   0.68788701 -0.02330488  0.31947945  0.06981407  0.36285377\n",
            "  0.51031036 -0.05703323  0.331872    0.09444671]\n",
            "\n",
            "# 44 Gradient out:  [-0.4072306  -0.35336638 -0.32007744 -0.50556181 -0.34686448 -0.29081186\n",
            " -0.7504493  -0.75052246 -0.58410757 -0.57222448]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.52685505  0.61122344 -0.09161647  0.13814613 -0.00514139  0.3012321\n",
            "  0.2322571  -0.33510139  0.09658922 -0.13626702]\n",
            "\n",
            "# 45 Gradient out:  [0.78848599 0.67008276 0.61537683 1.66661082 0.6586013  0.573777\n",
            " 2.46645147 2.46654103 2.17898071 2.14210752]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.44540893  0.54055017 -0.15563196  0.03703377 -0.07451429  0.24306973\n",
            "  0.08216724 -0.48520588 -0.0202323  -0.25071192]\n",
            "\n",
            "# 46 Gradient out:  [-0.33113795 -0.27488432 -0.24615828 -0.63943163 -0.26900491 -0.22318416\n",
            " -0.97450913 -0.9745602  -0.82730987 -0.81149272]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.60310613  0.67456672 -0.03255659  0.37035593  0.05720597  0.35782513\n",
            "  0.57545753  0.00810233  0.41556384  0.17770959]\n",
            "\n",
            "# 47 Gradient out:  [-0.71108009 -0.58871121 -0.52495378 -1.33751856 -0.57572958 -0.47339429\n",
            " -2.04920716 -2.04932343 -1.72349705 -1.6898151 ]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.53687854  0.61958985 -0.08178825  0.24246961  0.00340499  0.3131883\n",
            "  0.3805557  -0.18680971  0.25010187  0.01541105]\n",
            "\n",
            "# 48 Gradient out:  [1.28136502 1.12812602 1.05226325 2.2591049  1.11251329 0.99187271\n",
            " 3.23547849 3.23561808 2.84004025 2.79503904]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [ 0.39466252  0.50184761 -0.186779   -0.0250341  -0.11174092  0.21850944\n",
            " -0.02928573 -0.5966744  -0.09459754 -0.32255198]\n",
            "\n",
            "# 49 Gradient out:  [-0.21870123 -0.181206   -0.16209654 -0.42544928 -0.1772928  -0.14683071\n",
            " -0.64927498 -0.64930886 -0.55132634 -0.54076256]\n",
            "\n",
            "     Weights  out:  [-0.23296386 -0.30337602 -0.34577882  0.04738963 -0.31161795 -0.3843562\n",
            "  0.44784625  0.4479602   0.22462401  0.20730123] [0.65093552 0.72747282 0.02367364 0.42678688 0.11076173 0.41688398\n",
            " 0.61780997 0.05044922 0.47341051 0.23645583]\n",
            "\n",
            "Tanh error cuadrático medio (ECM): 0.9569400908228407\n",
            "\n",
            "# 0 Gradient out:  [2.28399085 2.86744123 3.28535916 1.85082728 1.31135433 1.69162095\n",
            " 2.63923478 2.74621377 3.08756066 3.08808312]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.14047258  0.14491641 -0.34692934 -0.2415005   0.45294485 -0.33678179\n",
            " -0.45476708  0.1984783  -0.06288936 -0.428015  ]\n",
            "\n",
            "# 1 Gradient out:  [-0.13807626 -0.17131998 -0.19948803 -0.1144992  -0.08178623 -0.10545035\n",
            " -0.15774477 -0.16397901 -0.18559939 -0.18563488]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [0.59727075 0.71840465 0.31014249 0.12866495 0.71521571 0.0015424\n",
            " 0.07307988 0.74772106 0.55462277 0.18960162]\n",
            "\n",
            "# 2 Gradient out:  [-0.19457941 -0.24274559 -0.28345049 -0.16040432 -0.11304118 -0.1472929\n",
            " -0.22308488 -0.23211586 -0.26340173 -0.26345304]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.5696555   0.68414066  0.27024488  0.10576511  0.69885847 -0.01954767\n",
            "  0.04153093  0.71492525  0.5175029   0.15247465]\n",
            "\n",
            "# 3 Gradient out:  [-0.31251354 -0.39290884 -0.46061365 -0.25544179 -0.17645821 -0.23355559\n",
            " -0.36010911 -0.37517964 -0.42731616 -0.42740152]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.53073962  0.63559154  0.21355479  0.07368425  0.67625023 -0.04900625\n",
            " -0.00308605  0.66850208  0.46482255  0.09978404]\n",
            "\n",
            "# 4 Gradient out:  [-0.63507857 -0.80852045 -0.95405919 -0.51193354 -0.34164348 -0.46471285\n",
            " -0.73777465 -0.77028618 -0.88262831 -0.88281189]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.46823691  0.55700977  0.12143206  0.02259589  0.64095859 -0.09571737\n",
            " -0.07510787  0.59346615  0.37935932  0.01430374]\n",
            "\n",
            "# 5 Gradient out:  [-1.26012836 -1.63772194 -1.97448928 -0.99736088 -0.61728508 -0.89465569\n",
            " -1.48095383 -1.55240754 -1.80720656 -1.80763267]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.34122119  0.39530568 -0.06937978 -0.07979082  0.57262989 -0.18865994\n",
            " -0.2226628   0.43940892  0.20283365 -0.16225864]\n",
            "\n",
            "# 6 Gradient out:  [1.61379456 1.97625673 2.25371273 1.34813842 1.00620355 1.24933625\n",
            " 1.83266124 1.89954018 2.11923757 2.11958423]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.08919552  0.06776129 -0.46427764 -0.27926299  0.44917288 -0.36759108\n",
            " -0.51885357  0.12892741 -0.15860766 -0.52378518]\n",
            "\n",
            "# 7 Gradient out:  [-1.17237846 -1.51291594 -1.8017321  -0.93157764 -0.59560137 -0.83887663\n",
            " -1.37351167 -1.43747169 -1.65979917 -1.66016386]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.41195443  0.46301264 -0.01353509 -0.00963531  0.65041358 -0.11772383\n",
            " -0.15232132  0.50883545  0.26523986 -0.09986833]\n",
            "\n",
            "# 8 Gradient out:  [2.31583119 2.91946049 3.34673945 1.86657231 1.31053972 1.70183164\n",
            " 2.68394586 2.79448688 3.14530446 3.14583851]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.17747874  0.16042945 -0.37388151 -0.19595084  0.53129331 -0.28549915\n",
            " -0.42702365  0.22134111 -0.06671998 -0.4319011 ]\n",
            "\n",
            "# 9 Gradient out:  [-0.10425124 -0.12949266 -0.15086785 -0.08634707 -0.06151353 -0.07947635\n",
            " -0.11918654 -0.1239198  -0.14033032 -0.14035725]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [0.64064498 0.74432155 0.29546638 0.17736362 0.79340126 0.05486717\n",
            " 0.10976552 0.78023848 0.56234091 0.1972666 ]\n",
            "\n",
            "# 10 Gradient out:  [-0.13570485 -0.16922109 -0.19754874 -0.11192337 -0.07896649 -0.10279988\n",
            " -0.15554066 -0.16182469 -0.18359449 -0.18363019]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [0.61979473 0.71842302 0.26529281 0.16009421 0.78109855 0.03897191\n",
            " 0.08592821 0.75545452 0.53427485 0.16919515]\n",
            "\n",
            "# 11 Gradient out:  [-0.19080167 -0.23913648 -0.27988857 -0.15649198 -0.10899554 -0.14333404\n",
            " -0.21941507 -0.22847591 -0.25983405 -0.25988541]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [0.59265376 0.6845788  0.22578306 0.13770954 0.76530525 0.01841193\n",
            " 0.05482008 0.72308959 0.49755595 0.13246911]\n",
            "\n",
            "# 12 Gradient out:  [-0.30528439 -0.38534895 -0.45264211 -0.24842645 -0.16981339 -0.22662942\n",
            " -0.35269556 -0.36770163 -0.41957142 -0.41965626]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.55449343  0.6367515   0.16980535  0.10641114  0.74350615 -0.01025488\n",
            "  0.01093706  0.6773944   0.44558914  0.08049203]\n",
            "\n",
            "# 13 Gradient out:  [-0.61684778 -0.78727867 -0.93014616 -0.49581698 -0.32853415 -0.44941508\n",
            " -0.71777387 -0.74971822 -0.86005178 -0.86023199]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.49343655  0.55968171  0.07927692  0.05672585  0.70954347 -0.05558076\n",
            " -0.05960205  0.60385408  0.36167486 -0.00343922]\n",
            "\n",
            "# 14 Gradient out:  [-1.29677665 -1.67842497 -2.01834902 -1.03092618 -0.64715106 -0.9271173\n",
            " -1.52010366 -1.59228999 -1.8494282  -1.8498581 ]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.37006699  0.40222598 -0.10675231 -0.04243755  0.64383664 -0.14546378\n",
            " -0.20315682  0.45391043  0.1896645  -0.17548562]\n",
            "\n",
            "# 15 Gradient out:  [1.61585531 1.97056653 2.24509807 1.35640032 1.02070369 1.25972898\n",
            " 1.82976297 1.89527416 2.11149248 2.11183538]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.11071166  0.06654098 -0.51042211 -0.24862279  0.51440642 -0.33088724\n",
            " -0.50717755  0.13545243 -0.18022114 -0.54545724]\n",
            "\n",
            "# 16 Gradient out:  [-1.18254771 -1.52674677 -1.81958216 -0.93935808 -0.59939468 -0.84566512\n",
            " -1.38573877 -1.45041139 -1.67554576 -1.67591552]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.43388273  0.46065429 -0.0614025   0.02265728  0.71854716 -0.07894144\n",
            " -0.14122496  0.51450727  0.24207736 -0.12309017]\n",
            "\n",
            "# 17 Gradient out:  [2.28326306 2.87249104 3.29389675 1.8455585  1.30114472 1.684773\n",
            " 2.6421524  2.75015808 3.09445743 3.09498408]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.19737318  0.15530493 -0.42531893 -0.16521434  0.59866823 -0.24807446\n",
            " -0.41837271  0.22442499 -0.09303179 -0.45827327]\n",
            "\n",
            "# 18 Gradient out:  [-0.11722877 -0.14669569 -0.17155445 -0.09631288 -0.06735397 -0.08829135\n",
            " -0.13467221 -0.14019612 -0.15931723 -0.15934856]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [0.6540258  0.72980314 0.23346042 0.20389736 0.85889717 0.08888014\n",
            " 0.11005776 0.7744566  0.52585969 0.16072355]\n",
            "\n",
            "# 19 Gradient out:  [-0.15804952 -0.19859997 -0.23273894 -0.12925669 -0.08942774 -0.11821753\n",
            " -0.18205941 -0.18965995 -0.21594722 -0.21599025]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [0.63058004 0.70046401 0.19914953 0.18463479 0.84542638 0.07122187\n",
            " 0.08312332 0.74641738 0.49399625 0.12885384]\n",
            "\n",
            "# 20 Gradient out:  [-0.2353552  -0.29737623 -0.34945826 -0.19130023 -0.13042339 -0.17441516\n",
            " -0.27208728 -0.28371022 -0.32386856 -0.32393422]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [0.59897014 0.66074401 0.15260174 0.15878345 0.82754083 0.04757836\n",
            " 0.04671144 0.70848539 0.4508068  0.08565578]\n",
            "\n",
            "# 21 Gradient out:  [-0.41746499 -0.53167729 -0.62732565 -0.33631665 -0.2242767  -0.30522068\n",
            " -0.48512002 -0.50652178 -0.58039444 -0.58051506]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.5518991   0.60126877  0.08271009  0.1205234   0.80145615  0.01269533\n",
            " -0.00770601  0.65174335  0.38603309  0.02086894]\n",
            "\n",
            "# 22 Gradient out:  [-0.9897297  -1.27535363 -1.51609038 -0.78733741 -0.50627018 -0.70957767\n",
            " -1.15864643 -1.21223897 -1.39791776 -1.39822161]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.4684061   0.49493331 -0.04275504  0.05326007  0.75660081 -0.04834881\n",
            " -0.10473002  0.55043899  0.2699542  -0.09523407]\n",
            "\n",
            "# 23 Gradient out:  [1.58011612 2.06159682 2.35048777 1.21035293 0.78828248 1.07866423\n",
            " 1.87972413 1.96648234 2.22245822 2.22281815]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.27046016  0.23986258 -0.34597312 -0.10420741  0.65534677 -0.19026434\n",
            " -0.3364593   0.3079912  -0.00962935 -0.37487839]\n",
            "\n",
            "# 24 Gradient out:  [-0.2766105  -0.3500856  -0.41175232 -0.22441676 -0.15230558 -0.2044131\n",
            " -0.32012788 -0.3338971  -0.38146169 -0.38153944]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [0.58648338 0.65218195 0.12412444 0.13786318 0.81300327 0.0254685\n",
            " 0.03948552 0.70128766 0.4348623  0.06968524]\n",
            "\n",
            "# 25 Gradient out:  [-0.53311334 -0.68096844 -0.80477237 -0.42807884 -0.2830189  -0.38782273\n",
            " -0.62068905 -0.64839746 -0.74404547 -0.74420163]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.53116128  0.58216483  0.04177397  0.09297983  0.78254215 -0.01541412\n",
            " -0.02454005  0.63450824  0.35856996 -0.00662265]\n",
            "\n",
            "# 26 Gradient out:  [-1.28710777 -1.66321568 -1.98758771 -1.02244953 -0.64902657 -0.92009339\n",
            " -1.50857645 -1.57937953 -1.8275264  -1.82793615]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.42453861  0.44597114 -0.1191805   0.00736406  0.72593838 -0.09297866\n",
            " -0.14867787  0.50482875  0.20976086 -0.15546298]\n",
            "\n",
            "# 27 Gradient out:  [2.00016543 2.46675085 2.81923173 1.65723075 1.21892668 1.53001952\n",
            " 2.28241368 2.36838621 2.64911813 2.64955849]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.16711706  0.113328   -0.51669804 -0.19712585  0.59613306 -0.27699734\n",
            " -0.45039316  0.18895285 -0.15574441 -0.52105021]\n",
            "\n",
            "# 28 Gradient out:  [-0.41490515 -0.52944019 -0.62527295 -0.33351447 -0.22118682 -0.30233006\n",
            " -0.48275849 -0.50421921 -0.57826737 -0.57838824]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [0.56715015 0.60667817 0.0471483  0.1343203  0.8399184  0.02900656\n",
            " 0.00608958 0.66263009 0.37407921 0.00886149]\n",
            "\n",
            "# 29 Gradient out:  [-0.98427286 -1.26931898 -1.50963512 -0.7823064  -0.50177905 -0.70470423\n",
            " -1.15283946 -1.20632566 -1.39166031 -1.39196362]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.48416912  0.50079014 -0.07790628  0.06761741  0.79568103 -0.03145945\n",
            " -0.09046212  0.56178625  0.25842574 -0.10681616]\n",
            "\n",
            "# 30 Gradient out:  [1.51888938 1.99172723 2.27216462 1.1551     0.74189139 1.02575655\n",
            " 1.81346964 1.89858911 2.14853057 2.14887994]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.28731454  0.24692634 -0.37983331 -0.08884387  0.69532522 -0.1724003\n",
            " -0.32103001  0.32052111 -0.01990633 -0.38520888]\n",
            "\n",
            "# 31 Gradient out:  [-0.31055847 -0.3945283  -0.464887   -0.2508944  -0.16851952 -0.22803275\n",
            " -0.36030012 -0.37603432 -0.43035058 -0.43043929]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [0.59109242 0.64527178 0.07459962 0.14217612 0.8437035  0.03275102\n",
            " 0.04166392 0.70023893 0.40979979 0.04456711]\n",
            "\n",
            "# 32 Gradient out:  [-0.63891455 -0.81941775 -0.97053189 -0.51071242 -0.33359692 -0.46156667\n",
            " -0.74581627 -0.77964662 -0.89643653 -0.89662716]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.52898073  0.56636612 -0.01837778  0.09199724  0.8099996  -0.01285553\n",
            " -0.03039611  0.62503207  0.32372967 -0.04152075]\n",
            "\n",
            "# 33 Gradient out:  [-1.25485707 -1.61370604 -1.94475372 -1.00744314 -0.64182713 -0.90989751\n",
            " -1.46350566 -1.53169683 -1.77876804 -1.77918684]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.40119782  0.40248258 -0.21248416 -0.01014524  0.74328022 -0.10516887\n",
            " -0.17955936  0.46910275  0.14444237 -0.22084618]\n",
            "\n",
            "# 34 Gradient out:  [1.64155564 1.99242642 2.26778807 1.38556052 1.05214951 1.2899587\n",
            " 1.85279833 1.91767816 2.13308828 2.13343207]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.1502264   0.07974137 -0.60143491 -0.21163387  0.61491479 -0.28714837\n",
            " -0.47226049  0.16276338 -0.21131124 -0.57668355]\n",
            "\n",
            "# 35 Gradient out:  [-1.15018766 -1.48595896 -1.7719046  -0.9129886  -0.58126646 -0.82159133\n",
            " -1.34838387 -1.41147713 -1.63119524 -1.63155626]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.47853753  0.47822665 -0.14787729  0.06547824  0.82534469 -0.02915663\n",
            " -0.10170083  0.54629901  0.21530642 -0.14999714]\n",
            "\n",
            "# 36 Gradient out:  [2.23279821 2.82735802 3.2471568  1.7899853  1.24283372 1.62771445\n",
            " 2.59553887 2.70438041 3.04935307 3.04987764]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.2485      0.18103486 -0.50225821 -0.11711948  0.7090914  -0.1934749\n",
            " -0.3713776   0.26400359 -0.11093263 -0.47630839]\n",
            "\n",
            "# 37 Gradient out:  [-0.11061359 -0.13929269 -0.16340911 -0.09024467 -0.06208655 -0.0824371\n",
            " -0.12759732 -0.13297211 -0.15155157 -0.15158197]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [0.69505964 0.74650647 0.14717315 0.24087758 0.95765814 0.13206799\n",
            " 0.14773017 0.80487967 0.49893798 0.13366714]\n",
            "\n",
            "# 38 Gradient out:  [-0.14722042 -0.18606665 -0.21867301 -0.11962214 -0.08150068 -0.10904629\n",
            " -0.17022968 -0.17750896 -0.20265299 -0.2026941 ]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [0.67293692 0.71864793 0.11449133 0.22282864 0.94524083 0.11558057\n",
            " 0.12221071 0.77828525 0.46862767 0.10335075]\n",
            "\n",
            "# 39 Gradient out:  [-0.21458849 -0.27249305 -0.3209901  -0.17343675 -0.11664502 -0.15767156\n",
            " -0.24889385 -0.25974289 -0.29718489 -0.29724603]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [0.64349284 0.6814346  0.07075673 0.19890421 0.9289407  0.09377131\n",
            " 0.08816477 0.74278346 0.42809707 0.06281193]\n",
            "\n",
            "# 40 Gradient out:  [-0.36615364 -0.46798726 -0.55309003 -0.29376819 -0.19393755 -0.26604138\n",
            " -0.42649328 -0.44557158 -0.51136284 -0.51147017]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [0.60057514 0.62693599 0.0065587  0.16421686 0.90561169 0.062237\n",
            " 0.038386   0.69083488 0.36866009 0.00336272]\n",
            "\n",
            "# 41 Gradient out:  [-0.82543097 -1.06441027 -1.26498316 -0.65587177 -0.4210954  -0.59080644\n",
            " -0.96687587 -1.01168873 -1.16661609 -1.16686919]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.52734441  0.53333854 -0.1040593   0.10546322  0.86682419  0.00902873\n",
            " -0.04691265  0.60172056  0.26638753 -0.09893131]\n",
            "\n",
            "# 42 Gradient out:  [-0.01939668  0.03403114 -0.01897873 -0.080256   -0.09061909 -0.09532166\n",
            "  0.02419486  0.03134909  0.01938835  0.01931871]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.36225822  0.32045648 -0.35705593 -0.02571113  0.78260511 -0.10913256\n",
            " -0.24028783  0.39938282  0.03306431 -0.33230515]\n",
            "\n",
            "# 43 Gradient out:  [ 0.00686672  0.06361577  0.01443106 -0.05618832 -0.07016264 -0.07215176\n",
            "  0.05233683  0.06013277  0.05072454  0.05065965]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.35837888  0.32726271 -0.36085168 -0.04176233  0.76448129 -0.12819689\n",
            " -0.23544885  0.40565263  0.03694198 -0.32844141]\n",
            "\n",
            "# 44 Gradient out:  [-0.1097586  -0.09328146 -0.17078793 -0.14300594 -0.11971548 -0.14797506\n",
            " -0.08877007 -0.08837251 -0.12133686 -0.12143739]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.35975222  0.33998586 -0.35796547 -0.05299999  0.75044876 -0.14262724\n",
            " -0.22498149  0.41767919  0.04708689 -0.31830948]\n",
            "\n",
            "# 45 Gradient out:  [0.5076835  0.70588807 0.76543032 0.34164416 0.1933352  0.28711745\n",
            " 0.63823233 0.67222303 0.74943983 0.74951152]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.3378005   0.32132957 -0.39212305 -0.08160118  0.72650566 -0.17222226\n",
            " -0.2427355   0.40000468  0.02281951 -0.34259696]\n",
            "\n",
            "# 46 Gradient out:  [-1.32670503 -1.713158   -2.05254279 -1.0562031  -0.66987994 -0.95106367\n",
            " -1.55351702 -1.62644693 -1.88432578 -1.88475466]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.4393372   0.46250718 -0.23903699 -0.01327235  0.7651727  -0.11479877\n",
            " -0.11508904  0.53444929  0.17270748 -0.19269465]\n",
            "\n",
            "# 47 Gradient out:  [1.75096396 2.13433245 2.43227954 1.47072566 1.10750959 1.36625199\n",
            " 1.98205596 2.05288055 2.28702669 2.28739875]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.1739962   0.11987559 -0.64954555 -0.22451297  0.63119671 -0.3050115\n",
            " -0.42579244  0.20915991 -0.20415767 -0.56964558]\n",
            "\n",
            "# 48 Gradient out:  [-0.9079269  -1.17137964 -1.39296794 -0.72112535 -0.46208891 -0.6493992\n",
            " -1.06379377 -1.11321118 -1.28424271 -1.28452236]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.52418899  0.54674207 -0.16308964  0.06963216  0.85269863 -0.0317611\n",
            " -0.02938125  0.61973602  0.25324766 -0.11216583]\n",
            "\n",
            "# 49 Gradient out:  [0.804776   1.09699743 1.22753165 0.57016084 0.33291432 0.48999466\n",
            " 0.99194546 1.04333257 1.17771152 1.17787255]\n",
            "\n",
            "     Weights  out:  [ 0.02401211  0.18680564  0.38372482 -0.08416954 -0.26180588 -0.1281048\n",
            "  0.1162847   0.14763482  0.27388734  0.27412871] [ 0.34260361  0.31246615 -0.44168323 -0.07459291  0.76028085 -0.16164094\n",
            " -0.24214     0.39709378 -0.00360088 -0.36907031]\n",
            "\n",
            "Lineal error cuadrático medio (ECM): 1.3744512516514913\n",
            "\n",
            "# 0 Gradient out:  [2.4760022  3.43651007 1.09272769 1.47506763 3.12645301 3.04876472\n",
            " 1.42542943 3.40770342 1.01272925 1.1260014 ]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [-0.25465792 -0.41329462  0.11260342  0.38953679  0.46476817 -0.29630706\n",
            " -0.43572137 -0.29871959 -0.46267743 -0.27759379]\n",
            "\n",
            "# 1 Gradient out:  [-0.35597073 -0.49338041 -0.17748121 -0.23445681 -0.44270884 -0.43102482\n",
            " -0.22765319 -0.48856644 -0.1642166  -0.18288317]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.24054252  0.27400739  0.33114895  0.68455032  1.09005877  0.31344588\n",
            " -0.15063548  0.3828211  -0.26013158 -0.05239351]\n",
            "\n",
            "# 2 Gradient out:  [-0.65529955 -0.92812631 -0.29955144 -0.41275773 -0.82816018 -0.80494101\n",
            " -0.39920108 -0.91871297 -0.27337672 -0.31023946]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.16934837  0.17533131  0.29565271  0.63765896  1.001517    0.22724092\n",
            " -0.19616612  0.28510781 -0.2929749  -0.08897014]\n",
            "\n",
            "# 3 Gradient out:  [-1.31477833 -1.97710923 -0.448902   -0.72533636 -1.73671419 -1.67994192\n",
            " -0.69217883 -1.95508518 -0.38584039 -0.47483154]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.03828846 -0.01029395  0.23574243  0.55510741  0.83588497  0.06625272\n",
            " -0.27600634  0.10136522 -0.34765024 -0.15101804]\n",
            "\n",
            "# 4 Gradient out:  [2.57213245 3.55969792 1.14539012 1.5377291  3.24216999 3.16248645\n",
            " 1.48665098 3.5301433  1.06352552 1.17944474]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [-0.22466721 -0.4057158   0.14596203  0.41004014  0.48854213 -0.26973567\n",
            " -0.4144421  -0.28965182 -0.42481832 -0.24598434]\n",
            "\n",
            "# 5 Gradient out:  [-0.24839957 -0.3427969  -0.12588721 -0.16501927 -0.30793492 -0.2999105\n",
            " -0.16034932 -0.33947745 -0.11676192 -0.12960101]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.28975928  0.30622379  0.37504005  0.71758596  1.13697613  0.36276162\n",
            " -0.11711191  0.41637684 -0.21211322 -0.0100954 ]\n",
            "\n",
            "# 6 Gradient out:  [-0.394324   -0.55094912 -0.19058984 -0.25553599 -0.49331557 -0.47999683\n",
            " -0.24777233 -0.54548662 -0.17550273 -0.19673876]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.24007937  0.23766441  0.34986261  0.68458211  1.07538914  0.30277952\n",
            " -0.14918177  0.34848135 -0.2354656  -0.0360156 ]\n",
            "\n",
            "# 7 Gradient out:  [-0.76464162 -1.0934625  -0.33532842 -0.4718121  -0.97325211 -0.94525655\n",
            " -0.45545204 -1.08217994 -0.30385037 -0.34819463]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.16121457  0.12747458  0.31174464  0.63347491  0.97672603  0.20678016\n",
            " -0.19873624  0.23938403 -0.27056614 -0.07536335]\n",
            "\n",
            "# 8 Gradient out:  [-1.24082749 -1.92403914 -0.35903224 -0.64631823 -1.67304354 -1.61394591\n",
            " -0.61219718 -1.90123301 -0.29303811 -0.38617765]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.00828624 -0.09121792  0.24467896  0.53911249  0.78207561  0.01772885\n",
            " -0.28982664  0.02294804 -0.33133622 -0.14500228]\n",
            "\n",
            "# 9 Gradient out:  [2.40702881 3.32893503 1.09319532 1.46094498 3.02615134 2.95139158\n",
            " 1.41360671 3.30044846 1.01500277 1.12555955]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [-0.23987925 -0.47602575  0.17287251  0.40984885  0.4474669  -0.30506033\n",
            " -0.41226608 -0.35729856 -0.38994384 -0.22223781]\n",
            "\n",
            "# 10 Gradient out:  [-0.43733131 -0.61843958 -0.20125042 -0.27635111 -0.55201282 -0.53661145\n",
            " -0.26735896 -0.61216523 -0.18386175 -0.20834547]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.24152651  0.18976126  0.39151157  0.70203784  1.05269717  0.28521798\n",
            " -0.12954474  0.30279113 -0.18694329  0.0028741 ]\n",
            "\n",
            "# 11 Gradient out:  [-0.89891665 -1.30035714 -0.37436005 -0.54106911 -1.15385707 -1.11965769\n",
            " -0.52107325 -1.28665098 -0.33599318 -0.39005645]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.15406025  0.06607334  0.35126149  0.64676762  0.9422946   0.17789569\n",
            " -0.18301653  0.18035808 -0.22371564 -0.03879499]\n",
            "\n",
            "# 12 Gradient out:  [-0.62747865 -1.06747739 -0.10666935 -0.29793894 -0.89115098 -0.85152553\n",
            " -0.27659929 -1.05139428 -0.05987471 -0.12572476]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [-0.02572308 -0.19399808  0.27638948  0.5385538   0.71152319 -0.04603584\n",
            " -0.28723118 -0.07697211 -0.29091427 -0.11680628]\n",
            "\n",
            "# 13 Gradient out:  [2.42268728 3.33813462 1.07850828 1.43937215 3.05059537 2.97743766\n",
            " 1.39172479 3.31139721 1.0046087  1.10935218]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [-0.15121881 -0.40749356  0.25505561  0.47896601  0.53329299 -0.21634095\n",
            " -0.34255104 -0.28725097 -0.30288921 -0.14195124]\n",
            "\n",
            "# 14 Gradient out:  [-0.21434073 -0.30100513 -0.10148514 -0.13740536 -0.26915612 -0.26179054\n",
            " -0.13310758 -0.29798634 -0.09314931 -0.10488307]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.33331864  0.26013336  0.47075726  0.76684044  1.14341207  0.37914658\n",
            " -0.06420608  0.37502847 -0.10196747  0.0799192 ]\n",
            "\n",
            "# 15 Gradient out:  [-0.32531747 -0.46068694 -0.14878497 -0.20490328 -0.41105548 -0.39954765\n",
            " -0.19818161 -0.45599686 -0.13579424 -0.15408533]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.2904505   0.19993234  0.45046024  0.73935937  1.08958084  0.32678847\n",
            " -0.0908276   0.31543121 -0.12059734  0.05894259]\n",
            "\n",
            "# 16 Gradient out:  [-0.59080201 -0.84798361 -0.25482477 -0.36150822 -0.7539994  -0.73211932\n",
            " -0.34871329 -0.83914884 -0.23022038 -0.26487899]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.225387    0.10779495  0.42070324  0.69837871  1.00736975  0.24687894\n",
            " -0.13046392  0.22423183 -0.14775618  0.02812552]\n",
            "\n",
            "# 17 Gradient out:  [-1.30983218 -1.93578488 -0.49564917 -0.75649336 -1.70653586 -1.65298397\n",
            " -0.72531737 -1.91446256 -0.43554876 -0.52025915]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.1072266  -0.06180177  0.36973829  0.62607707  0.85656987  0.10045508\n",
            " -0.20020658  0.05640207 -0.19380026 -0.02485028]\n",
            "\n",
            "# 18 Gradient out:  [2.5297807  3.49658169 1.12652024 1.50934706 3.18745352 3.10976158\n",
            " 1.45929714 3.46768088 1.0469237  1.15962553]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [-0.15473983 -0.44895875  0.27060845  0.4747784   0.51526269 -0.23014171\n",
            " -0.34527005 -0.32649045 -0.28091001 -0.12890211]\n",
            "\n",
            "# 19 Gradient out:  [-0.19987607 -0.28162794 -0.09334661 -0.12722907 -0.2516133  -0.24466563\n",
            " -0.12317301 -0.27878546 -0.08549108 -0.09654973]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.35121631  0.25035759  0.4959125   0.77664781  1.1527534   0.3918106\n",
            " -0.05341062  0.36704573 -0.07152527  0.103023  ]\n",
            "\n",
            "# 20 Gradient out:  [-0.29628739 -0.42055889 -0.13414713 -0.18566063 -0.37502751 -0.36446413\n",
            " -0.17948811 -0.41625829 -0.12222996 -0.13901037]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.31124109  0.194032    0.47724318  0.751202    1.10243074  0.34287748\n",
            " -0.07804523  0.31128864 -0.08862349  0.08371305]\n",
            "\n",
            "# 21 Gradient out:  [-0.51698805 -0.74219066 -0.2227177  -0.31611582 -0.65990677 -0.64075232\n",
            " -0.30491199 -0.73445217 -0.20117801 -0.23151893]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.25198361  0.10992022  0.45041375  0.71406987  1.02742523  0.26998465\n",
            " -0.11394285  0.22803698 -0.11306948  0.05591098]\n",
            "\n",
            "# 22 Gradient out:  [-1.14322682 -1.67749423 -0.44645526 -0.66866839 -1.48225203 -1.4366504\n",
            " -0.64205401 -1.65927776 -0.3953012  -0.4673931 ]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.148586   -0.03851791  0.40587021  0.65084671  0.89544388  0.14183419\n",
            " -0.17492525  0.08114655 -0.15330508  0.00960719]\n",
            "\n",
            "# 23 Gradient out:  [1.55513103 2.10855542 0.68245537 0.89381364 1.95444705 1.91192155\n",
            " 0.86406435 2.09464326 0.64343198 0.69912917]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [-0.08005936 -0.37401676  0.31657916  0.51711303  0.59899347 -0.14549589\n",
            " -0.30333605 -0.250709   -0.23236532 -0.08387143]\n",
            "\n",
            "# 24 Gradient out:  [-0.68331083 -0.98921915 -0.2833427  -0.4102744  -0.87760349 -0.8515689\n",
            " -0.39504117 -0.97875209 -0.25412065 -0.29529245]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.23096684  0.04769433  0.45307023  0.69587576  0.98988288  0.23688842\n",
            " -0.13052318  0.16821965 -0.10367893  0.05595441]\n",
            "\n",
            "# 25 Gradient out:  [-1.42323508 -2.12603037 -0.52069935 -0.8149684  -1.86491943 -1.804442\n",
            " -0.78013559 -2.10169087 -0.4521488  -0.54871209]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.09430468 -0.1501495   0.39640169  0.61382088  0.81436219  0.06657464\n",
            " -0.20953141 -0.02753077 -0.15450306 -0.00310408]\n",
            "\n",
            "# 26 Gradient out:  [2.36725945 3.25419377 1.12337533 1.47797449 2.95509419 2.88297107\n",
            " 1.43291152 3.2254408  1.04605667 1.15512265]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [-0.19034234 -0.57535558  0.29226182  0.4508272   0.4413783  -0.29431376\n",
            " -0.36555853 -0.44786895 -0.24493281 -0.1128465 ]\n",
            "\n",
            "# 27 Gradient out:  [-0.48109414 -0.69625279 -0.19949559 -0.28871678 -0.61782416 -0.59952676\n",
            " -0.27800052 -0.68889198 -0.1789666  -0.20789006]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.28310955  0.07548318  0.51693689  0.74642209  1.03239714  0.28228045\n",
            " -0.07897623  0.19721921 -0.03572148  0.11817803]\n",
            "\n",
            "# 28 Gradient out:  [-1.05469133 -1.54993662 -0.40870816 -0.61459257 -1.3689252  -1.32667886\n",
            " -0.58992908 -1.53301888 -0.36129164 -0.42810926]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.18689072 -0.06376738  0.47703777  0.68867874  0.90883231  0.1623751\n",
            " -0.13457633  0.05944082 -0.0715148   0.07660002]\n",
            "\n",
            "# 29 Gradient out:  [0.67740416 0.88671144 0.25943829 0.32998962 0.85775916 0.84402402\n",
            " 0.31729215 0.8849719  0.25303239 0.26287489]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [-0.02404754 -0.3737547   0.39529614  0.56576022  0.63504727 -0.10296067\n",
            " -0.25256215 -0.24716296 -0.14377313 -0.00902183]\n",
            "\n",
            "# 30 Gradient out:  [-1.43241587 -2.13888077 -0.53287292 -0.82920855 -1.87360556 -1.81267979\n",
            " -0.79435198 -2.11398729 -0.46319615 -0.56127242]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.11143329 -0.19641241  0.4471838   0.63175815  0.8065991   0.06584413\n",
            " -0.18910372 -0.07016858 -0.09316665  0.04355314]\n",
            "\n",
            "# 31 Gradient out:  [2.2975122  3.1485879  1.11516529 1.45591753 2.8572493  2.7879201\n",
            " 1.41294031 3.12026117 1.03980705 1.14597246]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [-0.17504988 -0.62418857  0.34060921  0.46591644  0.43187798 -0.29669183\n",
            " -0.34797411 -0.49296604 -0.18580588 -0.06870134]\n",
            "\n",
            "# 32 Gradient out:  [-0.57951335 -0.8473625  -0.22853728 -0.33964131 -0.74993621 -0.72714945\n",
            " -0.32628439 -0.83824644 -0.20303408 -0.23897546]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.28445256  0.00552901  0.56364227  0.75709995  1.00332785  0.26089219\n",
            " -0.06538605  0.1310862   0.02215553  0.16049315]\n",
            "\n",
            "# 33 Gradient out:  [-1.31625993 -1.95201701 -0.4950583  -0.76023762 -1.71699237 -1.66253915\n",
            " -0.72870474 -1.92998322 -0.43343307 -0.52022517]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.16854989 -0.16394349  0.51793482  0.68917168  0.8533406   0.1154623\n",
            " -0.13064293 -0.03656309 -0.01845129  0.11269806]\n",
            "\n",
            "# 34 Gradient out:  [2.38293372 3.32798214 1.01800024 1.39270182 3.02338562 2.94731952\n",
            " 1.34391236 3.29936636 0.93952956 1.05057048]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [-0.0947021  -0.55434689  0.41892315  0.53712416  0.50994213 -0.21704553\n",
            " -0.27638388 -0.42255974 -0.1051379   0.00865302]\n",
            "\n",
            "# 35 Gradient out:  [-0.25239366 -0.36611786 -0.10328375 -0.1504134  -0.32475398 -0.31508996\n",
            " -0.1447447  -0.3622377  -0.09245892 -0.10771177]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.38188464  0.11124954  0.6225232   0.81566452  1.11461925  0.37241838\n",
            " -0.00760141  0.23731354  0.08276801  0.21876712]\n",
            "\n",
            "# 36 Gradient out:  [-0.41593122 -0.60726995 -0.16495862 -0.24428534 -0.53774579 -0.52147821\n",
            " -0.23474121 -0.60076242 -0.1467623  -0.17240652]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.33140591  0.03802597  0.60186645  0.78558184  1.04966846  0.30940038\n",
            " -0.03655035  0.164866    0.06427623  0.19722477]\n",
            "\n",
            "# 37 Gradient out:  [-0.86733235 -1.27871405 -0.32951325 -0.50037762 -1.12875007 -1.09369659\n",
            " -0.47987228 -1.26469939 -0.2902424  -0.34558706]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.24821967 -0.08342802  0.56887473  0.73672477  0.9421193   0.20510474\n",
            " -0.08349859  0.04471351  0.03492377  0.16274346]\n",
            "\n",
            "# 38 Gradient out:  [-0.88693647 -1.34509036 -0.38432673 -0.58417205 -1.14533901 -1.10390997\n",
            " -0.5630006  -1.32532766 -0.33133939 -0.40534761]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.0747532  -0.33917083  0.50297208  0.63664925  0.71636928 -0.01363458\n",
            " -0.17947304 -0.20822636 -0.02312471  0.09362605]\n",
            "\n",
            "# 39 Gradient out:  [2.43985547 3.39047305 1.09321715 1.47199853 3.074522   2.99754002\n",
            " 1.4234599  3.36025636 1.01165053 1.12680866]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [-0.1026341  -0.60818891  0.42610673  0.51981484  0.48730148 -0.23441657\n",
            " -0.29207317 -0.4732919  -0.08939259  0.01255653]\n",
            "\n",
            "# 40 Gradient out:  [-0.28422013 -0.41452223 -0.11319093 -0.16719318 -0.36720911 -0.35613571\n",
            " -0.16069249 -0.41009244 -0.10080924 -0.11825895]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.385337    0.0699057   0.64475016  0.81421455  1.10220588  0.36509144\n",
            " -0.00738119  0.19875937  0.11293752  0.23791826]\n",
            "\n",
            "# 41 Gradient out:  [-0.49518274 -0.7270011  -0.19096989 -0.28710202 -0.64285105 -0.62313606\n",
            " -0.27553169 -0.7191378  -0.16894434 -0.19998955]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.32849297 -0.01299874  0.62211198  0.78077591  1.02876406  0.29386429\n",
            " -0.03951968  0.11674089  0.09277567  0.21426647]\n",
            "\n",
            "# 42 Gradient out:  [-1.10488356 -1.63802659 -0.4115397  -0.63338798 -1.44247985 -1.39694817\n",
            " -0.6068703  -1.61972478 -0.36030417 -0.43248994]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.22945642 -0.15839896  0.583918    0.7233555   0.90019385  0.16923708\n",
            " -0.09462602 -0.02708668  0.0589868   0.17426856]\n",
            "\n",
            "# 43 Gradient out:  [1.06876563 1.51331629 0.31370684 0.48000956 1.40947141 1.37617949\n",
            " 0.45496373 1.50522602 0.28782755 0.32540638]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.00847971 -0.48600428  0.50161006  0.59667791  0.61169788 -0.11015255\n",
            " -0.21600008 -0.35103163 -0.01307403  0.08777057]\n",
            "\n",
            "# 44 Gradient out:  [-1.20695897 -1.78983861 -0.45106672 -0.69383786 -1.57533494 -1.52549893\n",
            " -0.66488182 -1.76974374 -0.39484777 -0.47404129]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.22223284 -0.18334102  0.56435143  0.69267982  0.89359216  0.16508335\n",
            " -0.12500734 -0.04998643  0.04449148  0.15285185]\n",
            "\n",
            "# 45 Gradient out:  [1.85207967 2.6175945  0.68840061 0.9872128  2.39145897 2.33101973\n",
            " 0.94656984 2.59733781 0.63056253 0.71293604]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [-0.01915896 -0.54130874  0.47413808  0.55391225  0.57852517 -0.14001644\n",
            " -0.2579837  -0.40393518 -0.03447808  0.05804359]\n",
            "\n",
            "# 46 Gradient out:  [-0.47195509 -0.69101777 -0.18462766 -0.27546368 -0.61142908 -0.59280056\n",
            " -0.26453514 -0.68357259 -0.16379617 -0.19315538]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.35125698 -0.01778984  0.61181821  0.75135481  1.05681697  0.32618751\n",
            " -0.06866973  0.11553239  0.09163443  0.2006308 ]\n",
            "\n",
            "# 47 Gradient out:  [-1.03725656 -1.53443788 -0.38920785 -0.59593593 -1.35256868 -1.31014732\n",
            " -0.57118321 -1.51743042 -0.34156619 -0.40869766]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.25686596 -0.1559934   0.57489267  0.69626207  0.93453115  0.20762739\n",
            " -0.12157676 -0.02118213  0.0588752   0.16199972]\n",
            "\n",
            "# 48 Gradient out:  [0.46890828 0.63622316 0.09068678 0.14375292 0.62893613 0.61878888\n",
            " 0.13272217 0.63715193 0.08995281 0.09203742]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.04941465 -0.46288097  0.4970511   0.57707489  0.66401741 -0.05440207\n",
            " -0.2358134  -0.32466822 -0.00943804  0.08026019]\n",
            "\n",
            "# 49 Gradient out:  [-1.27449948 -1.91293419 -0.49994053 -0.77123023 -1.65992053 -1.60398874\n",
            " -0.74042731 -1.8886574  -0.43324976 -0.52683598]\n",
            "\n",
            "     Weights  out:  [ 0.07036619  0.47052796 -0.34078593 -0.17926976  0.27412694  0.24120182\n",
            " -0.19558069  0.44564245 -0.39168355 -0.32211916] [ 0.1431963  -0.33563634  0.51518846  0.60582547  0.78980464  0.06935571\n",
            " -0.20926897 -0.19723783  0.00855252  0.09866767]\n",
            "\n",
            "Tanh error cuadrático medio (ECM): 1.1624124788744625\n",
            "\n",
            "# 0 Gradient out:  [-0.72832131 -2.08155576 -2.06553252 -0.43094383 -2.11486835 -1.63494025\n",
            " -1.78186983 -0.31142151 -2.11929178 -0.4817339 ]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [-0.08231293  0.18072119  0.04259057  0.08834867  0.37331259  0.21654617\n",
            "  0.47998328  0.47549966 -0.44291015 -0.10506518]\n",
            "\n",
            "# 1 Gradient out:  [0.98431442 1.98603646 1.97453864 0.783093   2.01071666 1.67935966\n",
            " 1.78247834 0.69626074 2.01409104 0.81749951]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [-0.2279772  -0.23558996 -0.37051594  0.0021599  -0.04966108 -0.11044188\n",
            "  0.12360931  0.41321536 -0.8667685  -0.20141196]\n",
            "\n",
            "# 2 Gradient out:  [-0.75721173 -2.10139793 -2.0850566  -0.45822237 -2.13545604 -1.65244904\n",
            " -1.79888419 -0.33625353 -2.13998784 -0.50967839]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [-0.03111431  0.16161733  0.02439179  0.1587785   0.35248226  0.22543005\n",
            "  0.48010498  0.55246751 -0.46395029 -0.03791206]\n",
            "\n",
            "# 3 Gradient out:  [0.99185779 1.93600115 1.92468991 0.79874027 1.9603711  1.6416979\n",
            " 1.73924604 0.71324191 1.96371266 0.83221085]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [-0.18255666 -0.25866226 -0.39261953  0.06713403 -0.07460895 -0.10505976\n",
            "  0.12032814  0.4852168  -0.89194786 -0.13984774]\n",
            "\n",
            "# 4 Gradient out:  [-0.74686253 -2.00856635 -1.9923209  -0.45706998 -2.04251933 -1.57402143\n",
            " -1.7129928  -0.33577138 -2.04704662 -0.5077314 ]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.0158149   0.12853797 -0.00768154  0.22688208  0.31746527  0.22327982\n",
            "  0.46817735  0.62786519 -0.49920533  0.02659443]\n",
            "\n",
            "# 5 Gradient out:  [1.0356661  1.98784112 1.97606043 0.83820975 2.01329204 1.68693466\n",
            " 1.78558375 0.74910428 2.01678919 0.8727807 ]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [-0.13355761 -0.2731753  -0.40614573  0.13546809 -0.0910386  -0.09152447\n",
            "  0.12557879  0.56071091 -0.90861466 -0.07495185]\n",
            "\n",
            "# 6 Gradient out:  [-0.78226188 -2.08414776 -2.06740417 -0.48473782 -2.11921036 -1.63763715\n",
            " -1.78057426 -0.35962656 -2.12389413 -0.53676981]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.07357561  0.12439293 -0.01093364  0.30311004  0.31161981  0.24586247\n",
            "  0.48269554  0.71053177 -0.50525682  0.09960429]\n",
            "\n",
            "# 7 Gradient out:  [1.05330975 1.98666921 1.97468784 0.85661427 2.01263128 1.68693555\n",
            " 1.78395333 0.76592584 2.01620688 0.89145082]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [-0.08287676 -0.29243663 -0.42441447  0.20616247 -0.11222226 -0.08166496\n",
            "  0.12658069  0.63860646 -0.93003564 -0.00774967]\n",
            "\n",
            "# 8 Gradient out:  [-0.77976527 -2.04353646 -2.02672459 -0.48591126 -2.07882659 -1.60273067\n",
            " -1.74222417 -0.36022427 -2.08354987 -0.53778755]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.12778519  0.10489721 -0.02947691  0.37748533  0.29030399  0.25572215\n",
            "  0.48337136  0.79179162 -0.52679427  0.17054049]\n",
            "\n",
            "# 9 Gradient out:  [1.08739192 2.05585865 2.04311809 0.8810693  2.08351916 1.74146212\n",
            " 1.84235252 0.7845898  2.0873343  0.9178907 ]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [-0.02816787 -0.30381008 -0.43482182  0.28030308 -0.12546133 -0.06482399\n",
            "  0.13492652  0.71974677 -0.94350424  0.06298298]\n",
            "\n",
            "# 10 Gradient out:  [-0.77619764 -2.07615732 -2.05928393 -0.47884161 -2.11157709 -1.62963991\n",
            " -1.77220713 -0.35265866 -2.11631877 -0.53100742]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.18931052  0.10736165 -0.0261982   0.45651693  0.29124251  0.28346844\n",
            "  0.50339703  0.87666473 -0.52603738  0.24656112]\n",
            "\n",
            "# 11 Gradient out:  [1.11685749 2.1676627  2.15368868 0.89189849 2.19802534 1.82487475\n",
            " 1.93445314 0.78605935 2.20221568 0.93218101]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.03407099 -0.30786981 -0.43805499  0.36074861 -0.13107291 -0.04245955\n",
            "  0.1489556   0.806133   -0.94930114  0.14035964]\n",
            "\n",
            "# 12 Gradient out:  [-0.71141577 -1.97911713 -1.96344591 -0.42952719 -2.011956   -1.5552569\n",
            " -1.69292171 -0.31234344 -2.01634701 -0.47832641]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.25744249  0.12566273 -0.00731725  0.53912831  0.30853215  0.3225154\n",
            "  0.53584623  0.96334487 -0.508858    0.32679584]\n",
            "\n",
            "# 13 Gradient out:  [1.13441064 2.5159909  2.49894187 0.84841678 2.55282204 2.08010507\n",
            " 2.22313978 0.71946455 2.55788275 0.89845681]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.11515933 -0.2701607  -0.40000644  0.45322287 -0.09385905  0.01146402\n",
            "  0.19726188  0.90087618 -0.9121274   0.23113056]\n",
            "\n",
            "# 14 Gradient out:  [-0.35361399 -1.03377836 -1.02606152 -0.20929966 -1.04988324 -0.81632473\n",
            " -0.88904585 -0.15162188 -1.05203031 -0.23368631]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.34204146  0.23303748  0.09978194  0.62290623  0.41670536  0.42748504\n",
            "  0.64188984  1.04476909 -0.40055085  0.41082192]\n",
            "\n",
            "# 15 Gradient out:  [-0.68393723 -1.55534317 -1.54009631 -0.44612991 -1.58775871 -1.20049622\n",
            " -1.3022335  -0.33189841 -1.59213932 -0.49118222]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.27131866  0.02628181 -0.10543037  0.5810463   0.20672871  0.26422009\n",
            "  0.46408067  1.01444471 -0.61095692  0.36408466]\n",
            "\n",
            "# 16 Gradient out:  [1.10065444 2.44592149 2.42905994 0.82019518 2.48238855 2.01850817\n",
            " 2.15800352 0.69263004 2.48740347 0.86950503]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.13453122 -0.28478682 -0.41344963  0.49182032 -0.11082303  0.02412085\n",
            "  0.20363397  0.94806503 -0.92938478  0.26584821]\n",
            "\n",
            "# 17 Gradient out:  [-0.39969035 -1.17771204 -1.16884116 -0.23409112 -1.19622629 -0.92823882\n",
            " -1.01152528 -0.1677902  -1.19869458 -0.26211131]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.3546621   0.20439747  0.07236236  0.65585935  0.38565468  0.42782248\n",
            "  0.63523467  1.08659104 -0.43190409  0.43974922]\n",
            "\n",
            "# 18 Gradient out:  [-0.44157337 -0.58428129 -0.57452821 -0.33089483 -0.60553124 -0.42282814\n",
            " -0.45111076 -0.25759753 -0.60845272 -0.35698475]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.27472403 -0.03114493 -0.16140587  0.60904113  0.14640943  0.24217472\n",
            "  0.43292962  1.053033   -0.671643    0.38732696]\n",
            "\n",
            "# 19 Gradient out:  [0.56837389 2.14589697 2.13451351 0.30840235 2.16948235 1.74699262\n",
            " 1.90178435 0.22292024 2.17262299 0.34665129]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.18640936 -0.14800119 -0.27631151  0.54286216  0.02530318  0.15760909\n",
            "  0.34270746  1.0015135  -0.79333355  0.31593001]\n",
            "\n",
            "# 20 Gradient out:  [-0.23745186 -0.68344798 -0.67841671 -0.14322192 -0.6939502  -0.54141172\n",
            " -0.58900891 -0.10561189 -0.69535065 -0.15912265]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.30008414  0.2811782   0.15059119  0.60454263  0.45919965  0.50700761\n",
            "  0.72306433  1.04609754 -0.35880895  0.38526027]\n",
            "\n",
            "# 21 Gradient out:  [-0.61012678 -1.74610923 -1.73263351 -0.3631861  -1.77429244 -1.37443091\n",
            " -1.49686534 -0.26244214 -1.77805555 -0.40544503]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.25259377  0.14448861  0.01490785  0.57589825  0.32040961  0.39872527\n",
            "  0.60526255  1.02497517 -0.49787908  0.35343574]\n",
            "\n",
            "# 22 Gradient out:  [0.93817717 2.67032231 2.65331666 0.61394466 2.70642423 2.17520896\n",
            " 2.35046826 0.48577855 2.71131965 0.66671968]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.13056841 -0.20473324 -0.33161885  0.50326102 -0.03444888  0.12383909\n",
            "  0.30588948  0.97248674 -0.85349019  0.27234673]\n",
            "\n",
            "# 23 Gradient out:  [-0.15216999 -0.43294935 -0.42978581 -0.0929339  -0.43955474 -0.34364478\n",
            " -0.37358665 -0.06928298 -0.44043579 -0.10292745]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.31820384  0.32933122  0.19904448  0.62604996  0.50683597  0.55888088\n",
            "  0.77598314  1.06964245 -0.31122626  0.40569067]\n",
            "\n",
            "# 24 Gradient out:  [-0.31030291 -0.90127238 -0.89458499 -0.18515806 -0.91523008 -0.71267264\n",
            " -0.77580323 -0.13517171 -0.91709108 -0.20629191]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.28776984  0.24274135  0.11308732  0.60746318  0.41892502  0.49015193\n",
            "  0.70126581  1.05578585 -0.39931341  0.38510518]\n",
            "\n",
            "# 25 Gradient out:  [-0.75836371 -1.99995155 -1.98303468 -0.46683832 -2.0355642  -1.56255925\n",
            " -1.69988375 -0.34026189 -2.04034233 -0.51866652]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.22570926  0.06248688 -0.06582968  0.57043157  0.235879    0.3476174\n",
            "  0.54610516  1.02875151 -0.58273163  0.3438468 ]\n",
            "\n",
            "# 26 Gradient out:  [1.08135149 2.18061253 2.16572674 0.84402943 2.21299655 1.81901077\n",
            " 1.93385148 0.73125406 2.21747    0.88676397]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.07403652 -0.33750343 -0.46243662  0.4770639  -0.17123384  0.03510555\n",
            "  0.20612841  0.96069913 -0.9908001   0.24011349]\n",
            "\n",
            "# 27 Gradient out:  [-0.67133729 -1.89975435 -1.88458176 -0.39834836 -1.93155085 -1.48925524\n",
            " -1.62262844 -0.2848874  -1.93580286 -0.44559416]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.29030682  0.09861907 -0.02929127  0.64586979  0.27136547  0.3989077\n",
            "  0.59289871  1.10694994 -0.5473061   0.41746629]\n",
            "\n",
            "# 28 Gradient out:  [1.01350567 2.484749   2.46742301 0.71514756 2.52203818 2.02993685\n",
            " 2.1815815  0.58421572 2.52714705 0.76659368]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.15603936 -0.2813318  -0.40620762  0.56620012 -0.1149447   0.10105665\n",
            "  0.26837302  1.04997246 -0.93446667  0.32834745]\n",
            "\n",
            "# 29 Gradient out:  [-0.30998955 -0.92433665 -0.9174163  -0.18004594 -0.93876995 -0.72852764\n",
            " -0.79416322 -0.12832838 -0.94069317 -0.20195619]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.35874049  0.215618    0.08727698  0.70922963  0.38946294  0.50704403\n",
            "  0.70468932  1.16681561 -0.42903726  0.48166619]\n",
            "\n",
            "# 30 Gradient out:  [-0.7330229  -1.87901811 -1.86230793 -0.45353252 -1.91432066 -1.46021009\n",
            " -1.58858454 -0.32842402 -1.91907007 -0.50413145]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.29674258  0.03075067 -0.09620628  0.67322044  0.20170895  0.3613385\n",
            "  0.54585668  1.14114993 -0.61717589  0.44127495]\n",
            "\n",
            "# 31 Gradient out:  [1.02222434 2.19277972 2.17701969 0.77005861 2.22704229 1.80859393\n",
            " 1.93084683 0.65068575 2.23177259 0.81538429]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.150138   -0.34505295 -0.46866786  0.58251394 -0.18115519  0.06929648\n",
            "  0.22813977  1.07546513 -1.00098991  0.34044866]\n",
            "\n",
            "# 32 Gradient out:  [-0.6156787  -1.77792538 -1.76374795 -0.35905264 -1.80761483 -1.39194599\n",
            " -1.51789001 -0.25304502 -1.8115829  -0.40330727]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.35458287  0.093503   -0.03326392  0.73652566  0.26425327  0.43101527\n",
            "  0.61430913  1.20560228 -0.55463539  0.50352552]\n",
            "\n",
            "# 33 Gradient out:  [0.82833741 2.37218729 2.35619279 0.53219365 2.40626231 1.92034306\n",
            " 2.07751643 0.41158475 2.41089471 0.58122845]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.23144713 -0.26208208 -0.38601351  0.66471513 -0.09726969  0.15262607\n",
            "  0.31073113  1.15499327 -0.91695197  0.42286407]\n",
            "\n",
            "# 34 Gradient out:  [-0.27742467 -0.83821453 -0.83193518 -0.15911442 -0.85130371 -0.65992917\n",
            " -0.71980681 -0.11219276 -0.85304704 -0.17902658]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.39711461  0.21235538  0.08522504  0.77115386  0.38398277  0.53669468\n",
            "  0.72623442  1.23731022 -0.43477303  0.53910975]\n",
            "\n",
            "# 35 Gradient out:  [-0.70543421 -1.92235346 -1.90604795 -0.42263577 -1.95666851 -1.4978283\n",
            " -1.63192563 -0.30062339 -1.96127194 -0.47268872]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.34162968  0.04471247 -0.08116199  0.73933098  0.21372203  0.40470885\n",
            "  0.58227306  1.21487167 -0.60538244  0.50330444]\n",
            "\n",
            "# 36 Gradient out:  [0.96395759 2.22169616 2.20538137 0.6974527  2.25705804 1.81566088\n",
            " 1.94657483 0.57397181 2.26192876 0.74480768]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.20054284 -0.33975822 -0.46237158  0.65480382 -0.17761167  0.10514319\n",
            "  0.25588793  1.15474699 -0.99763682  0.40876669]\n",
            "\n",
            "# 37 Gradient out:  [-0.53784963 -1.59102919 -1.57853343 -0.30863152 -1.61715385 -1.2460925\n",
            " -1.3597066  -0.2152231  -1.62064108 -0.34784799]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.39333436  0.10458101 -0.02129531  0.79429436  0.27379993  0.46827536\n",
            "  0.6452029   1.26954135 -0.54525107  0.55772823]\n",
            "\n",
            "# 38 Gradient out:  [0.49475732 1.96294595 1.952302   0.2509672  1.98493488 1.58933065\n",
            " 1.73392768 0.17113073 1.9878548  0.28688839]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.28576443 -0.21362483 -0.33700199  0.73256806 -0.04963084  0.21905686\n",
            "  0.37326158  1.22649673 -0.86937929  0.48815863]\n",
            "\n",
            "# 39 Gradient out:  [-0.33630216 -1.01793452 -1.01024833 -0.19192088 -1.03396033 -0.80040935\n",
            " -0.87329282 -0.1344863  -1.03609517 -0.21626847]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.38471589  0.17896436  0.05345841  0.7827615   0.34735614  0.53692299\n",
            "  0.72004711  1.26072288 -0.47180833  0.54553631]\n",
            "\n",
            "# 40 Gradient out:  [-0.66681145 -1.49695289 -1.48158458 -0.43296178 -1.52974257 -1.14816229\n",
            " -1.24609454 -0.31771899 -1.53418636 -0.47790233]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.31745546 -0.02462254 -0.14859126  0.74437732  0.14056407  0.37684112\n",
            "  0.54538855  1.23382562 -0.67902736  0.50228262]\n",
            "\n",
            "# 41 Gradient out:  [0.94526421 2.30762661 2.29093587 0.66392931 2.34364743 1.87889963\n",
            " 2.01991065 0.5377282  2.34859264 0.71304137]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.18409317 -0.32401312 -0.44490818  0.65778497 -0.16538444  0.14720866\n",
            "  0.29616964  1.17028182 -0.98586463  0.40670215]\n",
            "\n",
            "# 42 Gradient out:  [-0.43084931 -1.29719932 -1.28725818 -0.24560834 -1.31794496 -1.01823519\n",
            " -1.11115871 -0.17131593 -1.32071034 -0.27700144]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.37314601  0.1375122   0.013279    0.79057083  0.30334505  0.52298859\n",
            "  0.70015177  1.27782746 -0.51614611  0.54931042]\n",
            "\n",
            "# 43 Gradient out:  [-0.17019288  0.38001189  0.38369337 -0.18938394  0.37121139  0.34475306\n",
            "  0.38788486 -0.16134898  0.36992718 -0.19517111]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.28697615 -0.12192766 -0.24417264  0.74144916  0.03975605  0.31934155\n",
            "  0.47792003  1.24356428 -0.78028817  0.49391014]\n",
            "\n",
            "# 44 Gradient out:  [-0.60487446 -1.20780417 -1.19403012 -0.40945715 -1.23737022 -0.91758486\n",
            " -0.99281011 -0.30608936 -1.24139433 -0.44879774]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.25293757 -0.04592528 -0.16743396  0.70357237  0.11399833  0.38829216\n",
            "  0.555497    1.21129448 -0.70630274  0.45487592]\n",
            "\n",
            "# 45 Gradient out:  [0.91992695 2.46817997 2.45122611 0.61576533 2.50445863 2.00431208\n",
            " 2.16277936 0.48780639 2.50940722 0.66702347]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.13196268 -0.28748612 -0.40623999  0.62168094 -0.13347571  0.20477519\n",
            "  0.35693498  1.15007661 -0.9545816   0.36511637]\n",
            "\n",
            "# 46 Gradient out:  [-0.26874394 -0.80668999 -0.80065981 -0.15524951 -0.81926323 -0.63564945\n",
            " -0.69307587 -0.11018623 -0.82093824 -0.17435928]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.31594807  0.20614988  0.08400523  0.74483401  0.36741601  0.60563761\n",
            "  0.78949085  1.24763789 -0.45270016  0.49852106]\n",
            "\n",
            "# 47 Gradient out:  [-0.69769806 -1.94480336 -1.92876279 -0.41436792 -1.97849048 -1.51911876\n",
            " -1.65550939 -0.29437717 -1.98300256 -0.46395774]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.26219929  0.04481188 -0.07612673  0.71378411  0.20356337  0.47850772\n",
            "  0.65087568  1.22560064 -0.61688781  0.46364921]\n",
            "\n",
            "# 48 Gradient out:  [0.98190138 2.29501564 2.27840051 0.70682167 2.33096436 1.87586469\n",
            " 2.01219516 0.58111741 2.33590928 0.75532672]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.12265967 -0.34414879 -0.46187929  0.63091052 -0.19213473  0.17468397\n",
            "  0.3197738   1.16672521 -1.01348832  0.37085766]\n",
            "\n",
            "# 49 Gradient out:  [-0.47882367 -1.43082694 -1.41979044 -0.27420826 -1.45387326 -1.12274432\n",
            " -1.22501662 -0.19172134 -1.45694683 -0.30898801]\n",
            "\n",
            "     Weights  out:  [-0.20643456  0.43580045  0.42122149 -0.38152059  0.46891848  0.16725625\n",
            "  0.23690567 -0.49345469  0.47364968 -0.34470237] [ 0.31903995  0.11485434 -0.00619919  0.77227486  0.27405815  0.5498569\n",
            "  0.72221283  1.28294869 -0.54630646  0.521923  ]\n",
            "\n",
            "Lineal error cuadrático medio (ECM): 0.6410252009894142\n",
            "\n",
            "# 0 Gradient out:  [-1.50932195 -0.29682343 -0.9296294  -0.44716946 -0.16130171 -1.55257388\n",
            " -1.50087316 -1.20954824 -1.6025676  -0.27005915]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [-0.07798663  0.25891496  0.40001644 -0.24692207 -0.070324    0.21690893\n",
            "  0.03917102 -0.31437812  0.356351    0.1134612 ]\n",
            "\n",
            "# 1 Gradient out:  [2.99908057 1.10870835 2.12263715 1.30474168 0.93813895 3.05338802\n",
            " 2.98858979 2.5998153  3.11926381 1.07544906]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [-0.37985102  0.19955027  0.21409056 -0.33635596 -0.10258434 -0.09360585\n",
            " -0.26100361 -0.55628776  0.03583748  0.05944937]\n",
            "\n",
            "# 2 Gradient out:  [-0.48948712 -0.17219795 -0.33986453 -0.20862383 -0.13970509 -0.49985221\n",
            " -0.4874737  -0.41620549 -0.51210229 -0.16582724]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [ 0.2199651   0.42129194  0.63861799 -0.07540762  0.08504345  0.51707176\n",
            "  0.33671435 -0.0363247   0.65969024  0.27453918]\n",
            "\n",
            "# 3 Gradient out:  [-1.02712549 -0.32330425 -0.69532873 -0.40400191 -0.25178615 -1.04992228\n",
            " -1.02268868 -0.86480786 -1.07674033 -0.30923135]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [ 0.12206768  0.38685235  0.57064509 -0.11713239  0.05710243  0.41710131\n",
            "  0.23921961 -0.1195658   0.55726978  0.24137373]\n",
            "\n",
            "# 4 Gradient out:  [-1.70533653 -0.41218513 -1.08723174 -0.57218234 -0.2664521  -1.7519041\n",
            " -1.69627345 -1.38604827 -1.80625942 -0.38359484]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [-0.08335742  0.3221915   0.43157934 -0.19793277  0.0067452   0.20711686\n",
            "  0.03468187 -0.29252737  0.34192171  0.17952746]\n",
            "\n",
            "# 5 Gradient out:  [2.65490371 1.04296594 1.90464374 1.2139138  0.89024756 2.7036661\n",
            " 2.64553406 2.30731891 2.76340456 1.01351394]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [-0.42442473  0.23975448  0.21413299 -0.31236924 -0.04654522 -0.14326396\n",
            " -0.30457282 -0.56973703 -0.01933017  0.1028085 ]\n",
            "\n",
            "# 6 Gradient out:  [-1.01536964 -0.3078786  -0.6818905  -0.3889349  -0.23612517 -1.0382384\n",
            " -1.01091772 -0.85232397 -1.06512826 -0.29375227]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [ 0.10655601  0.44834766  0.59506174 -0.06958648  0.13150429  0.39746926\n",
            "  0.224534   -0.10827325  0.53335074  0.30551128]\n",
            "\n",
            "# 7 Gradient out:  [-1.77464527 -0.47489138 -1.15214471 -0.63728153 -0.32494025 -1.82263114\n",
            " -1.76533764 -1.4507053  -1.87907762 -0.44566625]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [-0.09651792  0.38677194  0.45868364 -0.14737346  0.08427925  0.18982158\n",
            "  0.02235045 -0.27873804  0.32032509  0.24676083]\n",
            "\n",
            "# 8 Gradient out:  [2.52793101 1.03360597 1.83049147 1.1945635  0.88703035 2.57482711\n",
            " 2.51895564 2.20100726 2.63271492 1.00556925]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [-0.45144697  0.29179367  0.2282547  -0.27482976  0.0192912  -0.17470465\n",
            " -0.33071708 -0.5688791  -0.05549043  0.15762758]\n",
            "\n",
            "# 9 Gradient out:  [-1.28321971 -0.36520068 -0.85034373 -0.47061193 -0.27194402 -1.31293883\n",
            " -1.27743169 -1.07124985 -1.34783974 -0.3468277 ]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [ 0.05413923  0.49851486  0.59435299 -0.03591706  0.19669727  0.34026077\n",
            "  0.17307405 -0.12867765  0.47105255  0.35874143]\n",
            "\n",
            "# 10 Gradient out:  [ 0.14072439 -0.03347235  0.08576658 -0.05036349  0.00192175  0.12877971\n",
            "  0.14288771  0.16771469  0.11363532 -0.02771977]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [-0.20250471  0.42547473  0.42428424 -0.13003945  0.14230847  0.07767301\n",
            " -0.08241229 -0.34292762  0.2014846   0.28937589]\n",
            "\n",
            "# 11 Gradient out:  [-0.56791707 -0.20772202 -0.37556755 -0.27962615 -0.12718361 -0.59413352\n",
            " -0.56294624 -0.42910114 -0.625849   -0.19286534]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [-0.17435983  0.41878026  0.44143756 -0.14011215  0.14269282  0.10342895\n",
            " -0.05383474 -0.30938468  0.22421167  0.28383194]\n",
            "\n",
            "# 12 Gradient out:  [2.57207304 0.74355955 1.74002652 0.91216843 0.61257381 2.61324733\n",
            " 2.56396808 2.22461221 2.66183194 0.71694781]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [-0.28794325  0.37723585  0.36632405 -0.19603738  0.1172561  -0.01539775\n",
            " -0.16642399 -0.39520491  0.09904187  0.24525887]\n",
            "\n",
            "# 13 Gradient out:  [-0.35915173 -0.11849088 -0.24572485 -0.14604033 -0.09399951 -0.36696144\n",
            " -0.35763361 -0.30371727 -0.37617855 -0.113682  ]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [ 0.22647136  0.52594776  0.71432935 -0.01360369  0.23977086  0.50725171\n",
            "  0.34636963  0.04971753  0.63140825  0.38864843]\n",
            "\n",
            "# 14 Gradient out:  [-0.64655951 -0.20018968 -0.43622343 -0.25123789 -0.15496783 -0.66097378\n",
            " -0.64375473 -0.54384779 -0.67794545 -0.1912935 ]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [ 0.15464102  0.50224959  0.66518438 -0.04281176  0.22097096  0.43385942\n",
            "  0.2748429  -0.01102592  0.55617254  0.36591203]\n",
            "\n",
            "# 15 Gradient out:  [-1.55648623 -0.43752212 -1.02843684 -0.56658748 -0.32312009 -1.59295057\n",
            " -1.549385   -1.29707321 -1.63575849 -0.41499021]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [ 0.02532911  0.46221165  0.5779397  -0.09305933  0.18997739  0.30166467\n",
            "  0.14609196 -0.11979548  0.42058345  0.32765333]\n",
            "\n",
            "# 16 Gradient out:  [2.53412928 0.72894497 1.71323465 0.8946809  0.60073632 2.57441029\n",
            " 2.52619483 2.19242484 2.62189987 0.70285876]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [-0.28596813  0.37470722  0.37225233 -0.20637683  0.12535338 -0.01692544\n",
            " -0.16378504 -0.37921012  0.09343176  0.24465529]\n",
            "\n",
            "# 17 Gradient out:  [-0.37667803 -0.12370245 -0.25744811 -0.1526605  -0.09796349 -0.38488539\n",
            " -0.37508252 -0.31840948 -0.39457057 -0.11864809]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [ 0.22085773  0.52049622  0.71489926 -0.02744065  0.24550064  0.49795661\n",
            "  0.34145392  0.05927485  0.61781173  0.38522704]\n",
            "\n",
            "# 18 Gradient out:  [-0.69466647 -0.21348584 -0.46792411 -0.26852033 -0.16474515 -0.71020186\n",
            " -0.69164324 -0.58393699 -0.72848914 -0.2038958 ]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [ 0.14552212  0.49575573  0.66340964 -0.05797275  0.22590794  0.42097954\n",
            "  0.26643742 -0.00440705  0.53889762  0.36149742]\n",
            "\n",
            "# 19 Gradient out:  [-1.70389407 -0.47427994 -1.12323091 -0.61665205 -0.34784718 -1.74420037\n",
            " -1.69604577 -1.41784544 -1.79151621 -0.449389  ]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [ 0.00658883  0.45305856  0.56982482 -0.11167682  0.19295891  0.27893916\n",
            "  0.12810877 -0.12119445  0.39319979  0.32071826]\n",
            "\n",
            "# 20 Gradient out:  [3.15637118 1.0129418  2.17040348 1.2248105  0.83666752 3.21222153\n",
            " 3.14550195 2.72288104 3.27921335 0.97800698]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [-0.33418999  0.35820257  0.34517864 -0.23500723  0.12338948 -0.06990091\n",
            " -0.21110038 -0.40476354  0.03489655  0.23084046]\n",
            "\n",
            "# 21 Gradient out:  [-0.18816109 -0.06540776 -0.1302863  -0.07948367 -0.05285003 -0.19216705\n",
            " -0.1873831  -0.15983861 -0.19690476 -0.06294642]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [0.29708425 0.56079093 0.77925933 0.00995487 0.29072298 0.5725434\n",
            " 0.41800001 0.13981267 0.69073922 0.42644186]\n",
            "\n",
            "# 22 Gradient out:  [-0.2607545  -0.08766357 -0.17916571 -0.10748816 -0.07001565 -0.26638287\n",
            " -0.25966082 -0.22086357 -0.27303124 -0.08420085]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [ 0.25945203  0.54770938  0.75320207 -0.00594186  0.28015298  0.53410999\n",
            "  0.38052339  0.10784495  0.65135826  0.41385257]\n",
            "\n",
            "# 23 Gradient out:  [-0.40604249 -0.13038543 -0.27614119 -0.16191639 -0.10239618 -0.41496609\n",
            " -0.40430719 -0.34259518 -0.42548899 -0.12488573]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [ 0.20730113  0.53017667  0.71736893 -0.02743949  0.26614985  0.48083341\n",
            "  0.32859122  0.06367223  0.59675202  0.3970124 ]\n",
            "\n",
            "# 24 Gradient out:  [-0.77916292 -0.23369284 -0.52213715 -0.29606921 -0.17850737 -0.79675033\n",
            " -0.77573932 -0.65366554 -0.81743814 -0.22282852]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [ 0.12609263  0.50409958  0.66214069 -0.05982277  0.24567061  0.39784019\n",
            "  0.24772979 -0.0048468   0.51165422  0.37203526]\n",
            "\n",
            "# 25 Gradient out:  [-1.91375493 -0.52579469 -1.25700654 -0.68827894 -0.38055499 -1.9600872\n",
            " -1.90474057 -1.58763399 -2.01452509 -0.49725639]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [-0.02973995  0.45736101  0.55771326 -0.11903661  0.20996914  0.23849013\n",
            "  0.09258192 -0.13557991  0.34816659  0.32746955]\n",
            "\n",
            "# 26 Gradient out:  [3.04445323 1.1370604  2.15778403 1.33784254 0.95857399 3.10141504\n",
            " 3.03350213 2.63589721 3.17117265 1.10259125]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [-0.41249094  0.35220207  0.30631195 -0.2566924   0.13385814 -0.15352731\n",
            " -0.28836619 -0.45310671 -0.05473843  0.22801828]\n",
            "\n",
            "# 27 Gradient out:  [-0.39417266 -0.12121555 -0.26558919 -0.15237915 -0.0936277  -0.40296559\n",
            " -0.39246169 -0.33145847 -0.41332064 -0.11578793]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [0.19639971 0.57961415 0.73786876 0.01087611 0.32557294 0.46675569\n",
            " 0.31833423 0.07407273 0.5794961  0.44853653]\n",
            "\n",
            "# 28 Gradient out:  [-0.74598654 -0.21630754 -0.49646333 -0.27679795 -0.16288831 -0.76300755\n",
            " -0.74267185 -0.62427444 -0.78301239 -0.20578234]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [ 0.11756518  0.55537104  0.68475092 -0.01959972  0.3068474   0.38616258\n",
            "  0.2398419   0.00778104  0.49683197  0.42537894]\n",
            "\n",
            "# 29 Gradient out:  [-1.83864494 -0.50212682 -1.20640332 -0.65834784 -0.36245254 -1.88320354\n",
            " -1.82997811 -1.52502884 -1.93560571 -0.47469433]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [-0.03163213  0.51210954  0.58545825 -0.07495931  0.27426973  0.23356107\n",
            "  0.09130753 -0.11707385  0.34022949  0.38422247]\n",
            "\n",
            "# 30 Gradient out:  [3.10818258 1.08297229 2.16918403 1.29294216 0.89921239 3.16672987\n",
            " 3.09689448 2.68038491 3.23808032 1.04726784]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [-0.39936112  0.41168417  0.34417759 -0.20662888  0.20177923 -0.14307964\n",
            " -0.27468809 -0.42207962 -0.04689165  0.28928361]\n",
            "\n",
            "# 31 Gradient out:  [-0.28749625 -0.08780779 -0.19344349 -0.11058515 -0.0676575  -0.29391819\n",
            " -0.28624651 -0.24165485 -0.30148005 -0.08384256]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [0.22227539 0.62827863 0.7780144  0.05195955 0.3816217  0.49026633\n",
            " 0.3446908  0.11399737 0.60072442 0.49873717]\n",
            "\n",
            "# 32 Gradient out:  [-0.46758261 -0.13683929 -0.31182522 -0.17454046 -0.10356176 -0.47818543\n",
            " -0.46551795 -0.39170832 -0.49065178 -0.13028294]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [0.16477615 0.61071707 0.7393257  0.02984253 0.3680902  0.4314827\n",
            " 0.2874415  0.0656664  0.54042841 0.48196866]\n",
            "\n",
            "# 33 Gradient out:  [-0.96943203 -0.26791664 -0.63890333 -0.34811606 -0.1971658  -0.9919723\n",
            " -0.96504057 -0.80809384 -1.018433   -0.25396573]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [ 0.07125962  0.58334922  0.67696065 -0.00506557  0.34737785  0.33584561\n",
            "  0.19433791 -0.01267527  0.44229805  0.45591207]\n",
            "\n",
            "# 34 Gradient out:  [-1.89213424 -0.55408314 -1.25015166 -0.72262014 -0.39567314 -1.94292382\n",
            " -1.88233036 -1.55590825 -2.00336373 -0.52349367]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [-0.12262678  0.52976589  0.54917999 -0.07468878  0.30794469  0.13745115\n",
            "  0.00132979 -0.17429404  0.23861145  0.40511893]\n",
            "\n",
            "# 35 Gradient out:  [2.4267299  1.04219304 1.77708781 1.19575901 0.89726304 2.47327048\n",
            " 2.41788765 2.1154073  2.53152494 1.01489062]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [-0.50105363  0.41894926  0.29914965 -0.21921281  0.22881006 -0.25113361\n",
            " -0.37513628 -0.48547569 -0.1620613   0.30042019]\n",
            "\n",
            "# 36 Gradient out:  [-1.50129594 -0.39541969 -0.97914714 -0.52334081 -0.28180363 -1.53751681\n",
            " -1.49424479 -1.24424485 -1.5800729  -0.37306001]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [-0.01570765  0.62738787  0.65456722  0.01993899  0.40826267  0.24352048\n",
            "  0.10844125 -0.06239422  0.34424369  0.50339832]\n",
            "\n",
            "# 37 Gradient out:  [1.85822662 0.34609855 1.17865671 0.47430735 0.2577426  1.88556839\n",
            " 1.85270399 1.59180497 1.91635886 0.32720494]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [-0.31596684  0.54830393  0.45873779 -0.08472917  0.35190194 -0.06398288\n",
            " -0.1904077  -0.31124319  0.02822911  0.42878632]\n",
            "\n",
            "# 38 Gradient out:  [-1.001882   -0.26962211 -0.65687143 -0.35333482 -0.19582794 -1.02538965\n",
            " -0.99730102 -0.83348203 -1.05297132 -0.2550649 ]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [0.05567849 0.61752364 0.69446913 0.0101323  0.40345046 0.3131308\n",
            " 0.18013309 0.0071178  0.41150088 0.4942273 ]\n",
            "\n",
            "# 39 Gradient out:  [-1.77891409 -0.54440916 -1.18281647 -0.70497993 -0.39010156 -1.82849589\n",
            " -1.76937847 -1.45935347 -1.88787686 -0.5148491 ]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [-0.14469791  0.56359922  0.56309484 -0.06053467  0.36428488  0.10805287\n",
            " -0.01932711 -0.15957861  0.20090662  0.44321432]\n",
            "\n",
            "# 40 Gradient out:  [2.50943642 1.05437752 1.82676788 1.2156782  0.90217815 2.5583106\n",
            " 2.50015085 2.18241373 2.61948958 1.02570521]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [-0.50048073  0.45471738  0.32653155 -0.20153065  0.28626457 -0.25764631\n",
            " -0.3732028  -0.4514493  -0.17666875  0.3402445 ]\n",
            "\n",
            "# 41 Gradient out:  [-1.287207   -0.33329293 -0.83730029 -0.44297491 -0.23632174 -1.3181066\n",
            " -1.28118725 -1.06669228 -1.35436686 -0.31417789]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [ 0.00140655  0.66559289  0.69188513  0.04160499  0.4667002   0.25401581\n",
            "  0.12682736 -0.01496655  0.34722916  0.54538555]\n",
            "\n",
            "# 42 Gradient out:  [ 0.11951889 -0.18846865  0.00777489 -0.19815568 -0.15032557  0.10637834\n",
            "  0.121786    0.13104571  0.08816572 -0.18298668]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [-0.25603485  0.5989343   0.52442507 -0.04698999  0.41943585 -0.00960551\n",
            " -0.12941009 -0.22830501  0.07635579  0.48254997]\n",
            "\n",
            "# 43 Gradient out:  [-0.24613685 -0.25234623 -0.21874103 -0.29246019 -0.19038997 -0.26676117\n",
            " -0.24237832 -0.1727185  -0.29340542 -0.24194388]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [-0.23213107  0.56124057  0.52598005 -0.08662113  0.38937073  0.01167016\n",
            " -0.10505289 -0.20209587  0.09398894  0.44595263]\n",
            "\n",
            "# 44 Gradient out:  [1.30759999 0.18584585 0.81274614 0.26847236 0.13949861 1.32149359\n",
            " 1.30466724 1.13285407 1.33606943 0.17505308]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [-0.28135844  0.51077133  0.48223184 -0.14511317  0.35129274 -0.04168207\n",
            " -0.15352855 -0.23663957  0.03530785  0.39756386]\n",
            "\n",
            "# 45 Gradient out:  [-1.66584704 -0.44796542 -1.09045943 -0.58932286 -0.32210965 -1.70598024\n",
            " -1.65803701 -1.38188268 -1.75315462 -0.42321672]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [-0.01983844  0.5479405   0.64478107 -0.09141869  0.37919246  0.22261664\n",
            "  0.1074049  -0.01006875  0.30252174  0.43257447]\n",
            "\n",
            "# 46 Gradient out:  [2.82006777 0.79472272 1.89113748 0.99133667 0.63460155 2.87067546\n",
            " 2.81017738 2.41714317 2.93093006 0.76271184]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [-0.35300785  0.45834741  0.42668918 -0.20928327  0.31477053 -0.11857941\n",
            " -0.2242025  -0.28644529 -0.04810919  0.34793113]\n",
            "\n",
            "# 47 Gradient out:  [-0.30835945 -0.0926659  -0.20677128 -0.11726545 -0.07091252 -0.31529196\n",
            " -0.3070102  -0.25885092 -0.32345283 -0.08838427]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [ 0.21100571  0.61729196  0.80491668 -0.01101593  0.44169084  0.45555569\n",
            "  0.33783297  0.19698334  0.53807683  0.5004735 ]\n",
            "\n",
            "# 48 Gradient out:  [-0.51772217 -0.14887681 -0.3440214  -0.19092235 -0.11177918 -0.52954159\n",
            " -0.51542031 -0.43310682 -0.54343393 -0.1415661 ]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [ 0.14933382  0.59875878  0.76356242 -0.03446902  0.42750834  0.39249729\n",
            "  0.27643093  0.14521316  0.47338626  0.48279664]\n",
            "\n",
            "# 49 Gradient out:  [-1.13303102 -0.30788218 -0.74411004 -0.40240873 -0.22441271 -1.1596257\n",
            " -1.12784998 -0.94291068 -1.19084414 -0.29142662]\n",
            "\n",
            "     Weights  out:  [ 0.3816174  -0.33074029  0.02960086 -0.22949198 -0.45780204  0.42344085\n",
            "  0.37411371  0.17834464  0.48186826 -0.35191327] [ 0.04578938  0.56898342  0.69475814 -0.07265349  0.4051525   0.28658897\n",
            "  0.17334687  0.0585918   0.36469947  0.45448342]\n",
            "\n",
            "Tanh error cuadrático medio (ECM): 0.515526670793126\n",
            "Promedio MSE salida lineal: 1.3992546531446195 ± 0.4690064460527766\n",
            "Promedio MSE salida tanh: 0.8434145350587672 ± 0.22090628428428055\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "errors_linear = []\n",
        "errors_tanh = []\n",
        "\n",
        "for _ in range(10):\n",
        "    train(X, t)\n",
        "    _, mse_lin = recall(X, t)\n",
        "    errors_linear.append(mse_lin)\n",
        "\n",
        "    train_tanh(X, t)\n",
        "    _, mse_tanh = recall_tanh(X, t)\n",
        "    errors_tanh.append(mse_tanh)\n",
        "\n",
        "print(\"Promedio MSE salida lineal:\", np.mean(errors_linear), \"±\", np.std(errors_linear))\n",
        "print(\"Promedio MSE salida tanh:\", np.mean(errors_tanh), \"±\", np.std(errors_tanh))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se observa que el Error Cuadrático Medio (MSE) obtenido con activación lineal en la capa de salida es consistentemente más alto, con un promedio cercano a 1.422. En contraste, al emplear la función tangente hiperbólica (tanh) como activación de salida, el modelo logra un MSE promedio de aproximadamente 0.794.\n",
        "\n",
        "Este resultado sugiere que la red con activación tanh en la salida ofrece un mejor desempeño predictivo, al adaptarse más eficazmente a la distribución del conjunto de datos.\n",
        "La función tanh, al ser no lineal y acotada en [-1, 1], proporciona una salida más adecuada para problemas donde las variables objetivo también están dentro de ese rango, favoreciendo una mejor aproximación a la función real y facilitando la convergencia del modelo.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
