{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GnUElm5_e8m"
   },
   "source": [
    "# Práctica de Laboratorio 8 - Inteligencia Artificial 2025-1 Sección 1 EPISW-FISI\n",
    "## Implementación de una red PMC-BP con Python y Numpy\n",
    "### Prof. Rolando A. Maguiña Pérez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ky22d26K_e8n"
   },
   "source": [
    "## Introducción\n",
    "La Práctica Guiada de Laboratorio (PGL) 8 a realizarse el Jueves 05 de Junio del presente año, tratará sobre la red Perceptrón Multicapa con su algoritmo de aprendizaje llamado Backpropagation. Esta red se aplicará para resolver problemas genéricos de clasificación y de regresión.\n",
    "\n",
    "Se desea abordar el problema de la aproximación de una función mediante una Perceptrón Multicapa-Backpropagation (PMC-BP). Inicialmente se presenta la implementación del algoritmo de entrenamiento de esta red (presentado en las sesiones de teoría), con el lenguaje `Python` y sus bibliotecas `Numpy` y `Matplotlib`. Posteriormente, **se propondrán algunos ejercicios cuyas soluciones se podrán obtener en grupos de hasta 4 alumnos**, y deberán enviarse para su respectiva revisión (ver sección 'Instrucciones para el envío' en este mismo cuaderno).  \n",
    "\n",
    "Requiere: numpy, matplotlib\n",
    "\n",
    "Nomenclatura:\n",
    "- Z: número de instancias (muestras) en el conjunto de datos\n",
    "- N: número de atributos o variables de entrada\n",
    "- M: número de atributos o variables de salida\n",
    "- t: vector de salidas esperadas o targets\n",
    "- y: vector de salidas estimadas por la red.\n",
    "\n",
    "### Paso previo\n",
    "Importamos las bibliotecas de Python requeridas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "5r_BRXlK_e8n"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKy9zmzb_e8p"
   },
   "source": [
    "## Dataset\n",
    "El primer paso consiste en obtener el arreglo conteniendo los pares entrada-salida (instancias) a usar en el entrenamiento/validación de la red PMC-BP a implementar; dicho arreglo se denominará 'Dataset'. El tamaño de dicho arreglo es de $Z \\times d$, donde $Z$ es el número de instancias (muestras) y $d$ es el número de características o atributos considerados para el problema abordado (incluye los atributos de entrada y los de salida)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "lHAeppdW_e8q",
    "outputId": "be4a459f-13d9-425f-bd6d-6e0cbbe7d8cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.  ],\n",
       "       [ 1.  ,  0.84],\n",
       "       [ 2.  ,  0.91],\n",
       "       [ 3.  ,  0.14],\n",
       "       [ 4.  , -0.77],\n",
       "       [ 5.  , -0.96],\n",
       "       [ 6.  , -0.28],\n",
       "       [ 7.  ,  0.66],\n",
       "       [ 8.  ,  0.99]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset = np.array([[0.00000, 0.00000], [1.00000, 0.84000], [2.00000, 0.91000], [3.00000, 0.14000],\n",
    "[4.00000, -0.77000], [5.00000, -0.96000],[6.00000, -0.28000], [7.00000, 0.66000], [8.00000, 0.99000]])\n",
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "PQUmblTn_e8q",
    "outputId": "339662ed-f65c-4cb2-d5ba-a944a8775d4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 2)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xJFV52G_e8q"
   },
   "source": [
    "## Data para el entrenamiento/validación de la red\n",
    "Como sabemos, a partir del dataset obtenido, se deben determinar los conjuntos de datos a emplear en el entrenamiento y en la validación de la red PMC-BP. Enseguida, se deben obtener dos arreglos: uno con los vectores de entrada a usar en el entrenamiento, y el segundo, con los respectivos vectores de salida. Análogamente, se deben determinar los arreglos con los vectores de entrada y de salida, a usar en la validación del entrenamiento. **Sin embargo, para el problema planteado, el dataset se usará tanto para el entrenamiento como para la validación**.\n",
    "\n",
    "Separando los valores de entrada de los de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "Hr48ISV7_e8q",
    "outputId": "649fd8d4-c634-4166-8853-9208bad639a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2., 3., 4., 5., 6., 7., 8.]),\n",
       " array([ 0.  ,  0.84,  0.91,  0.14, -0.77, -0.96, -0.28,  0.66,  0.99]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Dataset[:,0]\n",
    "t = Dataset[:,1]\n",
    "X, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "L0tmqcxX_e8r",
    "outputId": "c5dd6b48-055e-4a0e-a4b4-5ba76e3800f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9,), (9,))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "sxiXCKVT_e8r",
    "outputId": "dc3bdc08-c4cd-47c4-a353-61323d72eba7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f412efc440>]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot(X,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQJsVNIL_e8r"
   },
   "source": [
    "## Normalización de los datos\n",
    "Antes de iniciar algún cálculo, sabemos que debemos tener en cuenta las diferencias que existen en las unidades de nuestros datos. Se requiere que los datos de nuestras variables estén en el mismo orden de magnitud, y en un buen número de casos es necesario normalizarlos; de esta manera nuestro modelo trabajará con unidades normalizadas. A pesar de lo indicado, incluso sabedores que hay varios procedimientos de normalización, en este caso, **no vamos a normalizar inicialmente nuestros datos**.\n",
    "\n",
    "## Diseño de la red\n",
    "Inicialmente se considera una topología de la red como la mostrada en la figura, vale decir, con 10 neuronas ocultas. Como función de activación de las neuronas ocultas se usará la logística sigmoidea y en las neuronas de salida, dado que se trata de un problema de aproximación de funciones, se usará una función lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WGsNXQEa_e8r",
    "outputId": "855b611b-4ff4-4ed2-bdaa-cf13deb780df"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "i = Image(filename='D:\\\\Cursos\\\\Redes Neuronales\\\\2021-2\\\\arquit-red_aprox-fc_2021-2.png')\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkStZNAt_e8s"
   },
   "source": [
    "## Inicialización de los pesos y biases de la red\n",
    "Según el algoritmo, los parámetros libres de la red se inicializan a valores aleatorios pequeños, los cuales pueden estar en el rangos: [-0.5,0.5] o [-1,1] o en torno de cero. A continuación se presenta el código para inicializarlos, aplicado al **problema planteado**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "lVovH8l6_e8s"
   },
   "outputs": [],
   "source": [
    "# Implementación básica sin funciones\n",
    "intervalo = 0.5\n",
    "capa_entrada = 1\n",
    "capa_oculta = 10\n",
    "capa_salida = 1\n",
    "\n",
    "w1 = np.random.uniform(-intervalo, intervalo, capa_oculta)\n",
    "\n",
    "w2 = np.random.uniform(-intervalo, intervalo, capa_oculta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "CZ0RMbRe_e8s",
    "outputId": "f683c42b-d53b-4b2e-ea4a-14907601f2eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.39200561,  0.38383045, -0.2399938 ,  0.21144574, -0.02639301,\n",
       "         0.45291044, -0.28963087,  0.10128324,  0.3868592 ,  0.22146414]),\n",
       " array([ 0.44353722, -0.42064916, -0.24896485, -0.09773909,  0.13186035,\n",
       "         0.24705392,  0.34147077, -0.21340051,  0.1061367 ,  0.4959227 ]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1, w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmCcNM_d_e8s",
    "outputId": "9d457a8a-6bf1-4af0-b0c6-588ff5716fa7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBsY50rR_e8t"
   },
   "source": [
    "### Definición de la función logística sigmoidea\n",
    "Sabemos que la expresión matemática de la función logística sigmoidea `f(n)` es:\n",
    "\n",
    "                         f(u) =  1/1 + exp(-u)\n",
    "\n",
    "donde `u` es el vector de entradas netas. A partir de dicho parámetro, es posible calcular la función logistica sigmoidea; en la sgte celda se presenta el respectivo código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "epFEjYWl_e8t"
   },
   "outputs": [],
   "source": [
    "# Funcion de activacion Logistica Sigmoidea para la unidad de salida\n",
    "def logistica(u):\n",
    "    return 1/(1 + np.exp(-u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Th5dgmub_e8t"
   },
   "source": [
    "Supongamos que se desea aplicar esta función al arreglo 'a'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "TAEvUwwY_e8t",
    "outputId": "8437d4cb-1c63-4f29-c846-8e595401d360"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0.6, -0.8]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[0, 0.6, -0.8]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "9iHeZAXi_e8t",
    "outputId": "c8eae3ea-8366-4e37-df4a-31a00e9f57e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.64565631, 0.31002552]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistica(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4M6Vnr-_e8t"
   },
   "source": [
    "A continuación se presenta la implementación de la derivada de la función logística sigmoidea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "3XH0afOY_e8u"
   },
   "outputs": [],
   "source": [
    "def deriv_logistica(x):\n",
    "    return x * (1.0 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "CQBQqCLR_e8u",
    "outputId": "7b7de73a-c865-432a-c424-840452937c46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.8576"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deriv_logistica(-1.76)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPor0YoF_e8u"
   },
   "source": [
    "## Implementación\n",
    "Luego de haber determinado la topología de la red neuronal, la implementaremos en el lenguaje de programación `Python` con la ayuda de su biblioteca `Numpy`. Enseguida, se efectuarán las sgtes actividades:\n",
    "\n",
    "- Construiremos el algoritmo de aprendizaje de nuestra red PMC, Backpropagation, mediante la función `train()`. Dentro de ella se instancian constantes y variables importantes como globales, de modo que estos valores sean accesibles para toda la función.\n",
    "- Aplicaremos dicho algoritmo de aprendizaje para resolver el problema de aproximación de una función planteado; para tal efecto, se usará el conjunto de datos disponible.\n",
    "\n",
    "En las sgtes celdas se presentan las líneas de código correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6M-xeAvc_e8u"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "NETtXa7d_e8u"
   },
   "outputs": [],
   "source": [
    "Dataset = np.array([[0.00000, 0.00000], [1.00000, 0.84000], [2.00000, 0.91000], [3.00000, 0.14000],\n",
    "[4.00000, -0.77000], [5.00000, -0.96000],[6.00000, -0.28000], [7.00000, 0.66000], [8.00000, 0.99000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "0YVIEN_G_e8v",
    "outputId": "09e186ca-8f01-4101-f9fc-2c82d36c0d54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2., 3., 4., 5., 6., 7., 8.]),\n",
       " array([ 0.  ,  0.84,  0.91,  0.14, -0.77, -0.96, -0.28,  0.66,  0.99]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Dataset[:,0]\n",
    "t = Dataset[:,1]\n",
    "X, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "2nIZHvFq_e8v"
   },
   "outputs": [],
   "source": [
    "def train(X, t, learning_rate=0.2, epochs=50):\n",
    "    global input_num\n",
    "    global hidden_num\n",
    "    global w1\n",
    "    global w2\n",
    "\n",
    "    input_num = 1\n",
    "    hidden_num = 10\n",
    "    output_num = 1\n",
    "    intervalo = 0.5\n",
    "\n",
    "    # inicializando los pesos\n",
    "    w1 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
    "\n",
    "    w2 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        gradient_out = 0.0                 # gradientes para la capa de salida y la capa oculta\n",
    "        gradient_hidden = []\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "        # propagacion hacia adelante\n",
    "            x = X[i]\n",
    "\n",
    "            u1 = x * w1\n",
    "            o = logistica(u1)\n",
    "            u2 = o.dot(w2)\n",
    "            y = u2\n",
    "\n",
    "        # backpropagation\n",
    "            delta_hidden_s = []           # inicializamos los delta_j a lista vacía\n",
    "            gradient_hidden_s = []       # inicializamos los gradientes de neurs ocultas a lista vacía\n",
    "\n",
    "            delta_out_s = t[i] - y     # cálculo del único delta_k (f'(u) = 1 pq fc de activ es lineal)\n",
    "            gradient_out_s = delta_out_s * o     # error por la salida de la capa anterior\n",
    "\n",
    "            for j in range(hidden_num):\n",
    "\n",
    "                delta_hidden_s.append(deriv_logistica(u1[j]) * w2[j] * delta_out_s)\n",
    "                gradient_hidden_s.append(delta_hidden_s[j] * x)\n",
    "\n",
    "\n",
    "            gradient_out = gradient_out + gradient_out_s\n",
    "            gradient_hidden = gradient_hidden + gradient_hidden_s\n",
    "\n",
    "\n",
    "        print(\"\\n#\", epoch, \"Gradient out: \",gradient_out),\n",
    "        print(\"\\n     Weights  out: \", w1, w2)\n",
    "\n",
    "        # Ahora actualizando pesos\n",
    "        w2 = w2 + learning_rate * gradient_out\n",
    "\n",
    "        for j in range(hidden_num):\n",
    "            w1[j] = w1[j] + learning_rate * gradient_hidden[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "oJgS7qCi_e8v",
    "outputId": "dc1f053a-dec7-40d4-fa7f-6db8b843e96a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 0 Gradient out:  [1.3996968  2.55724446 1.02124993 2.32963589 0.78678809 1.13467017\n",
      " 1.75206405 0.71479298 1.50880204 2.48015012]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [-0.26711408 -0.34853556  0.21629445 -0.47900125 -0.13975495  0.0075435\n",
      "  0.1058368   0.35290739  0.09299243  0.41667388]\n",
      "\n",
      "# 1 Gradient out:  [-5.49689363 -9.96871684 -4.09709487 -8.81755575 -3.00367812 -4.54662555\n",
      " -6.67739427 -2.60355617 -5.86612574 -9.54320141]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [ 0.01282528  0.16291334  0.42054443 -0.01307407  0.01760267  0.23447754\n",
      "  0.45624961  0.49586599  0.39475283  0.9127039 ]\n",
      "\n",
      "# 2 Gradient out:  [21.13854844 38.40032122 15.67317338 34.22772583 11.6395817  17.39705714\n",
      " 25.8756686  10.21663446 22.61594006 36.88503237]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [-1.08655345 -1.83083003 -0.39887454 -1.77658522 -0.58313296 -0.67484757\n",
      " -0.87922925 -0.02484525 -0.77847231 -0.99593638]\n",
      "\n",
      "# 3 Gradient out:  [ -81.71979149 -148.39303497  -60.67174265 -132.00590111  -44.90521012\n",
      "  -67.34157054  -99.83683712  -39.28777392  -87.37415237 -142.41325731]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [3.14115624 5.84923421 2.73576013 5.06895994 1.74478338 2.80456385\n",
      " 4.29590447 2.01848165 3.7447157  6.38107009]\n",
      "\n",
      "# 4 Gradient out:  [315.49802409 572.95963361 234.15838024 509.95000826 173.46175368\n",
      " 259.90285084 385.63741738 151.89082637 337.38451573 549.99517374]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [-13.20280206 -23.82937278  -9.3985884  -21.33222028  -7.23625864\n",
      " -10.66375025 -15.67146295  -5.83907314 -13.73011478 -22.10158137]\n",
      "\n",
      "# 5 Gradient out:  [-1218.46860447 -2212.74751022  -904.40842132 -1969.14404121\n",
      "  -669.82071597 -1003.84114021 -1489.157263    -586.39614573\n",
      " -1302.93916473 -2123.93566436]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [49.89680276 90.76255394 37.43308765 80.65778137 27.4560921  41.31681992\n",
      " 61.45602052 24.53909214 53.74678837 87.89745338]\n",
      "\n",
      "# 6 Gradient out:  [4705.37423442 8545.03958044 3492.48809526 7604.5708628  2586.75294663\n",
      " 3876.46192226 5750.88766887 2264.70798043 5031.6309461  8202.19590589]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [-193.79691813 -351.78694811 -143.44859661 -313.17102687 -106.5080511\n",
      " -159.45140813 -236.37543208  -92.74013701 -206.84104458 -336.88967949]\n",
      "\n",
      "# 7 Gradient out:  [-18171.2034666  -32999.1698526  -13487.35794251 -29367.01205223\n",
      "  -9989.41674386 -14970.19409349 -22208.57386295  -8745.62754683\n",
      " -19431.08539944 -31675.05484737]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [ 747.27792875 1357.22096798  555.04902244 1207.74314569  410.84253823\n",
      "  615.84097633  913.80210169  360.20145908  799.48514464 1303.54950168]\n",
      "\n",
      "# 8 Gradient out:  [ 70173.11022806 127435.43146245  52085.07520958 113409.11108965\n",
      "  38576.98677007  57811.44857331  85764.71894116  33773.86867131\n",
      "  75038.54679061 122322.11852653]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [-2886.96276457 -5242.61300254 -2142.42256606 -4665.65926476\n",
      " -1587.04081054 -2378.19784237 -3527.9126709  -1388.92405029\n",
      " -3086.73193524 -5031.46146779]\n",
      "\n",
      "# 9 Gradient out:  [-270993.20373316 -492127.72343395 -201141.24265818 -437960.88384726\n",
      " -148975.78380406 -223255.25141205 -331204.39689205 -130427.07557256\n",
      " -289782.40053917 -472381.10517301]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [11147.65928104 20244.47328995  8274.59247586 18016.16295318\n",
      "  6128.35654347  9184.09187229 13625.03111734  5365.84968397\n",
      " 11920.97742288 19432.96223752]\n",
      "\n",
      "# 10 Gradient out:  [1046516.08625333 1900488.95191681  776763.11888244 1691308.80184411\n",
      "  575311.77829687  862162.54428356 1279038.64609613  503680.8677202\n",
      " 1119075.88224349 1824231.98197404]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [-43050.98146559 -78181.07139684 -31953.65605578 -69576.01381628\n",
      " -23666.80021734 -35466.95841012 -52615.84826107 -20719.56543054\n",
      " -46035.50268496 -75043.25879709]\n",
      "\n",
      "# 11 Gradient out:  [-4041415.09991032 -7339270.56476951 -2999688.50497166 -6531462.54511208\n",
      " -2221727.53089286 -3329482.32250584 -4939365.92882264 -1945104.58223583\n",
      " -4321625.02857857 -7044782.78623689]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [166252.23578507 301916.71898653 123398.96772071 268685.74655255\n",
      "  91395.55544203 136965.55044659 203191.88095815  80016.6081135\n",
      " 177779.67376374 289803.13759772]\n",
      "\n",
      "# 12 Gradient out:  [15607056.41693422 28342649.06798539 11584137.30808488 25223072.38939383\n",
      "  8579823.27417632 12857728.50282433 19074745.24875757  7511566.39176454\n",
      " 16689165.59847107 27205402.14644941]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [ -642030.78419699 -1165937.39396738  -476538.73327362 -1037606.76246987\n",
      "  -352949.95073654  -528930.91405458  -784681.30480638  -309004.30833366\n",
      "  -686545.33195197 -1119153.41964966]\n",
      "\n",
      "# 13 Gradient out:  [-6.02710203e+07 -1.09453079e+08 -4.47353913e+07 -9.74059594e+07\n",
      " -3.31333909e+07 -4.96537205e+07 -7.36624719e+07 -2.90080176e+07\n",
      " -6.44498880e+07 -1.05061281e+08]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [2479380.49918986 4502592.4196297  1840288.72834335 4007007.7154089\n",
      " 1363014.70409873 2042614.78651029 3030267.74494514 1193308.97001924\n",
      " 2651287.78774224 4321927.00964023]\n",
      "\n",
      "# 14 Gradient out:  [2.32753428e+08 4.22683724e+08 1.72758245e+08 3.76160398e+08\n",
      " 1.27953870e+08 1.91751751e+08 2.84468270e+08 1.12022586e+08\n",
      " 2.48891296e+08 4.05723567e+08]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [ -9574823.56342315 -17388023.35690741  -7106789.53528207\n",
      " -15474184.16509587  -5263663.47800823  -7888129.31181941\n",
      " -11702226.64364029  -4608294.54898535 -10238689.81048748\n",
      " -16690329.23030033]\n",
      "\n",
      "# 15 Gradient out:  [-8.98842562e+08 -1.63231160e+09 -6.67154356e+08 -1.45264875e+09\n",
      " -4.94129713e+08 -7.40503099e+08 -1.09855391e+09 -4.32606595e+08\n",
      " -9.61163461e+08 -1.56681521e+09]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [36975862.05540764 67148721.484171   27444859.42632994 59757895.42370258\n",
      " 20327110.61210652 30462220.81403909 45191427.35075257 17796222.63240118\n",
      " 39539569.4444048  64454384.23794325]\n",
      "\n",
      "# 16 Gradient out:  [3.47113234e+09 6.30362851e+09 2.57640343e+09 5.60981006e+09\n",
      " 1.90822030e+09 2.85966015e+09 4.24237365e+09 1.67063155e+09\n",
      " 3.71180195e+09 6.05069582e+09]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [-1.42792650e+08 -2.59313599e+08 -1.05986012e+08 -2.30771854e+08\n",
      " -7.84988321e+07 -1.17638399e+08 -1.74519355e+08 -6.87250964e+07\n",
      " -1.52693123e+08 -2.48908657e+08]\n",
      "\n",
      "# 17 Gradient out:  [-1.34047499e+10 -2.43432273e+10 -9.94950355e+09 -2.16638530e+10\n",
      " -7.36912724e+09 -1.10433787e+10 -1.63831142e+10 -6.45161171e+09\n",
      " -1.43341630e+10 -2.33664569e+10]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [5.51433817e+08 1.00141210e+09 4.09294674e+08 8.91190157e+08\n",
      " 3.03145229e+08 4.54293631e+08 6.73955376e+08 2.65401214e+08\n",
      " 5.89667266e+08 9.61230507e+08]\n",
      "\n",
      "# 18 Gradient out:  [5.17661966e+10 9.40081911e+10 3.84227950e+10 8.36610367e+10\n",
      " 2.84579491e+10 4.26471004e+10 6.32679849e+10 2.49147059e+10\n",
      " 5.53553856e+10 9.02361186e+10]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [-2.12951616e+09 -3.86723335e+09 -1.58060604e+09 -3.44158044e+09\n",
      " -1.17068022e+09 -1.75438211e+09 -2.60266747e+09 -1.02492113e+09\n",
      " -2.27716533e+09 -3.71206086e+09]\n",
      "\n",
      "# 19 Gradient out:  [-1.99909669e+11 -3.63038964e+11 -1.48380386e+11 -3.23080529e+11\n",
      " -1.09898342e+11 -1.64693725e+11 -2.44327047e+11 -9.62151159e+10\n",
      " -2.13770328e+11 -3.48472049e+11]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [8.22372316e+09 1.49344049e+10 6.10395297e+09 1.32906269e+10\n",
      " 4.52090960e+09 6.77503797e+09 1.00509295e+10 3.95802004e+09\n",
      " 8.79391180e+09 1.43351629e+10]\n",
      "\n",
      "# 20 Gradient out:  [7.72007186e+11 1.40197665e+12 5.73012425e+11 1.24766596e+12\n",
      " 4.24403233e+11 6.36010952e+11 9.43537332e+11 3.71561622e+11\n",
      " 8.25534003e+11 1.34572243e+12]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [-3.17582106e+10 -5.76733879e+10 -2.35721242e+10 -5.13254788e+10\n",
      " -1.74587588e+10 -2.61637070e+10 -3.88144798e+10 -1.52850031e+10\n",
      " -3.39601538e+10 -5.53592470e+10]\n",
      "\n",
      "# 21 Gradient out:  [-2.98132200e+12 -5.41412557e+12 -2.21284799e+12 -4.81821162e+12\n",
      " -1.63895197e+12 -2.45613445e+12 -3.64373371e+12 -1.43488929e+12\n",
      " -3.18803080e+12 -5.19688414e+12]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [1.22643226e+11 2.22721943e+11 9.10303608e+10 1.98207714e+11\n",
      " 6.74218878e+10 1.01038483e+11 1.49892987e+11 5.90273212e+10\n",
      " 1.31146647e+11 2.13785239e+11]\n",
      "\n",
      "# 22 Gradient out:  [1.15132100e+13 2.09081625e+13 8.54553240e+12 1.86068738e+13\n",
      " 6.32927214e+12 9.48505120e+12 1.40712984e+13 5.54122692e+12\n",
      " 1.23114740e+13 2.00692239e+13]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [-4.73621174e+11 -8.60103172e+11 -3.51539238e+11 -7.65434609e+11\n",
      " -2.60368506e+11 -3.90188407e+11 -5.78853756e+11 -2.27950536e+11\n",
      " -5.06459514e+11 -8.25591588e+11]\n",
      "\n",
      "# 23 Gradient out:  [-4.44614857e+13 -8.07427264e+13 -3.30009671e+13 -7.18556555e+13\n",
      " -2.44422573e+13 -3.66291822e+13 -5.43402605e+13 -2.13990000e+13\n",
      " -4.75442055e+13 -7.75029298e+13]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [1.82902084e+12 3.32152933e+12 1.35756724e+12 2.95594016e+12\n",
      " 1.00548592e+12 1.50682183e+12 2.23540593e+12 8.80294848e+11\n",
      " 1.95583528e+12 3.18825318e+12]\n",
      "\n",
      "# 24 Gradient out:  [1.71700482e+14 3.11810656e+14 1.27442479e+14 2.77490742e+14\n",
      " 9.43906235e+13 1.41453848e+14 2.09850138e+14 8.26382327e+13\n",
      " 1.83605268e+14 2.99299274e+14]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [-7.06327631e+12 -1.28270159e+13 -5.24262619e+12 -1.14151909e+13\n",
      " -3.88296554e+12 -5.81901460e+12 -8.63264618e+12 -3.39950515e+12\n",
      " -7.55300581e+12 -1.23123328e+13]\n",
      "\n",
      "# 25 Gradient out:  [-6.63069507e+14 -1.20414419e+15 -4.92154832e+14 -1.07160823e+15\n",
      " -3.64515833e+14 -5.46263657e+14 -8.10395091e+14 -3.19130684e+14\n",
      " -7.09043173e+14 -1.15582799e+15]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [2.72768200e+13 4.95351152e+13 2.02458696e+13 4.40829575e+13\n",
      " 1.49951591e+13 2.24717549e+13 3.33373814e+13 1.31281414e+13\n",
      " 2.91680477e+13 4.75475219e+13]\n",
      "\n",
      "# 26 Gradient out:  [2.56062864e+15 4.65014011e+15 1.90059375e+15 4.13831537e+15\n",
      " 1.40768000e+15 2.10955013e+15 3.12956765e+15 1.23241253e+15\n",
      " 2.73816883e+15 4.46355354e+15]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [-1.05337081e+14 -1.91293723e+14 -7.81850968e+13 -1.70238689e+14\n",
      " -5.79080075e+13 -8.67809765e+13 -1.28741637e+14 -5.06979955e+13\n",
      " -1.12640587e+14 -1.83618075e+14]\n",
      "\n",
      "# 27 Gradient out:  [-9.88858479e+15 -1.79578186e+16 -7.33967515e+15 -1.59812640e+16\n",
      " -5.43615064e+15 -8.14661876e+15 -1.20857022e+16 -4.75930622e+15\n",
      " -1.05742060e+16 -1.72372623e+16]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [4.06788647e+14 7.38734298e+14 3.01933653e+14 6.57424385e+14\n",
      " 2.23627992e+14 3.35129050e+14 4.97171894e+14 1.95784511e+14\n",
      " 4.34993179e+14 7.09092632e+14]\n",
      "\n",
      "# 28 Gradient out:  [3.81875402e+16 6.93491470e+16 2.83442116e+16 6.17161278e+16\n",
      " 2.09932185e+16 3.14604504e+16 4.66723243e+16 1.83793942e+16\n",
      " 4.08352584e+16 6.65665170e+16]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [-1.57092831e+15 -2.85282943e+15 -1.16600138e+15 -2.53882842e+15\n",
      " -8.63602136e+14 -1.29419470e+15 -1.91996854e+15 -7.56076733e+14\n",
      " -1.67984801e+15 -2.73835983e+15]\n",
      "\n",
      "# 29 Gradient out:  [-1.47471884e+17 -2.67811157e+17 -1.09459113e+17 -2.38334115e+17\n",
      " -8.10711938e+16 -1.21493342e+17 -1.80238254e+17 -7.09771790e+16\n",
      " -1.57696789e+17 -2.57065252e+17]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [6.06657972e+15 1.10170000e+16 4.50284094e+15 9.80439713e+15\n",
      " 3.33504156e+15 4.99789538e+15 7.41449633e+15 2.91980210e+15\n",
      " 6.48720366e+15 1.05749436e+16]\n",
      "\n",
      "# 30 Gradient out:  [5.69503988e+17 1.03422780e+18 4.22707026e+17 9.20393949e+17\n",
      " 3.13079125e+17 4.69180573e+17 6.96040508e+17 2.74098259e+17\n",
      " 6.08990325e+17 9.92729481e+17]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [-2.34277970e+16 -4.25452315e+16 -1.73889816e+16 -3.78624260e+16\n",
      " -1.28791972e+16 -1.93007730e+16 -2.86331545e+16 -1.12756337e+16\n",
      " -2.50521542e+16 -4.08381069e+16]\n",
      "\n",
      "# 31 Gradient out:  [-2.19929918e+18 -3.99396037e+18 -1.63240159e+18 -3.55435906e+18\n",
      " -1.20904274e+18 -1.81187221e+18 -2.68795540e+18 -1.05850721e+18\n",
      " -2.35178673e+18 -3.83370298e+18]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [9.04730007e+16 1.64300329e+17 6.71524236e+16 1.46216364e+17\n",
      " 4.97366277e+16 7.45353416e+16 1.10574947e+17 4.35440181e+16\n",
      " 9.67459109e+16 1.57707789e+17]\n",
      "\n",
      "# 32 Gradient out:  [8.49320986e+18 1.54237968e+19 6.30397602e+18 1.37261532e+19\n",
      " 4.66905722e+18 6.99705209e+18 1.03802927e+19 4.08772210e+18\n",
      " 9.08208326e+18 1.48049179e+19]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [-3.49386836e+17 -6.34491746e+17 -2.59327895e+17 -5.64655448e+17\n",
      " -1.92071920e+17 -2.87839101e+17 -4.27016133e+17 -1.68157424e+17\n",
      " -3.73611436e+17 -6.09032806e+17]\n",
      "\n",
      "# 33 Gradient out:  [-3.27989090e+19 -5.95633118e+19 -2.43445693e+19 -5.30073854e+19\n",
      " -1.80308724e+19 -2.70210767e+19 -4.00864081e+19 -1.57858839e+19\n",
      " -3.50730086e+19 -5.71733378e+19]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [1.34925514e+18 2.45026761e+18 1.00146731e+18 2.18057518e+18\n",
      " 7.41739524e+17 1.11157132e+18 1.64904241e+18 6.49386996e+17\n",
      " 1.44280522e+18 2.35195078e+18]\n",
      "\n",
      "# 34 Gradient out:  [1.26662175e+20 2.30020414e+20 9.40133737e+19 2.04702867e+20\n",
      " 6.96312645e+19 1.04349457e+20 1.54804894e+20 6.09616128e+19\n",
      " 1.35444247e+20 2.20790859e+20]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [-5.21052667e+18 -9.46239475e+18 -3.86744655e+18 -8.42090190e+18\n",
      " -2.86443495e+18 -4.29264402e+18 -6.36823921e+18 -2.50778979e+18\n",
      " -5.57179650e+18 -9.08271678e+18]\n",
      "\n",
      "# 35 Gradient out:  [-4.89141469e+20 -8.88288261e+20 -3.63058978e+20 -7.90517464e+20\n",
      " -2.68900633e+20 -4.02974658e+20 -5.97822462e+20 -2.35420345e+20\n",
      " -5.23055902e+20 -8.52645752e+20]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [2.01219083e+19 3.65416880e+19 1.49352282e+19 3.25196716e+19\n",
      " 1.10618179e+19 1.65772473e+19 2.45927396e+19 9.68453277e+18\n",
      " 2.15170530e+19 3.50754551e+19]\n",
      "\n",
      "# 36 Gradient out:  [1.88895680e+21 3.43037395e+21 1.40205394e+21 3.05280463e+21\n",
      " 1.03843512e+21 1.55619952e+21 2.30865890e+21 9.09141607e+20\n",
      " 2.01992689e+21 3.29273042e+21]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [-7.77063855e+19 -1.41115964e+20 -5.76765674e+19 -1.25583821e+20\n",
      " -4.27183087e+19 -6.40176842e+19 -9.49717529e+19 -3.73995361e+19\n",
      " -8.30941275e+19 -1.35453695e+20]\n",
      "\n",
      "# 37 Gradient out:  [-7.29473583e+21 -1.32473499e+22 -5.41442405e+21 -1.17892602e+22\n",
      " -4.01020810e+21 -6.00970038e+21 -8.91553305e+21 -3.51090498e+21\n",
      " -7.80051350e+21 -1.27158009e+22]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [3.00084975e+20 5.44958825e+20 2.22734221e+20 4.84977104e+20\n",
      " 1.64968715e+20 2.47222220e+20 3.66760027e+20 1.44428785e+20\n",
      " 3.20891250e+20 5.23092388e+20]\n",
      "\n",
      "# 38 Gradient out:  [2.81706658e+22 5.11583526e+22 2.09093152e+22 4.55275308e+22\n",
      " 1.54865419e+22 2.32081415e+22 3.44298283e+22 1.35583431e+22\n",
      " 3.01238680e+22 4.91056270e+22]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [-1.15886219e+21 -2.10451116e+21 -8.60150588e+20 -1.87287494e+21\n",
      " -6.37072905e+20 -9.54717856e+20 -1.41634658e+21 -5.57752212e+20\n",
      " -1.23921145e+21 -2.02006779e+21]\n",
      "\n",
      "# 39 Gradient out:  [-1.08788917e+23 -1.97562309e+23 -8.07471777e+22 -1.75817313e+23\n",
      " -5.98056198e+22 -8.96247394e+22 -1.32960427e+23 -5.23593398e+22\n",
      " -1.16331754e+23 -1.89635134e+23]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [4.47527097e+21 8.12715936e+21 3.32171244e+21 7.23263122e+21\n",
      " 2.46023548e+21 3.68691044e+21 5.46961908e+21 2.15391640e+21\n",
      " 4.78556214e+21 7.80105762e+21]\n",
      "\n",
      "# 40 Gradient out:  [4.20118878e+23 7.62942198e+23 3.11827846e+23 6.78967806e+23\n",
      " 2.30956154e+23 3.46111037e+23 5.13463933e+23 2.02200258e+23\n",
      " 4.49247657e+23 7.32329192e+23]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [-1.72825125e+22 -3.13853025e+22 -1.28277231e+22 -2.79308315e+22\n",
      " -9.50088848e+21 -1.42380374e+22 -2.11224662e+22 -8.31795155e+21\n",
      " -1.84807888e+22 -3.01259693e+22]\n",
      "\n",
      "# 41 Gradient out:  [-1.62240673e+24 -2.94631502e+24 -1.20421058e+24 -2.62202438e+24\n",
      " -8.91901884e+23 -1.33660472e+24 -1.98288481e+24 -7.80852936e+23\n",
      " -1.73489567e+24 -2.82809432e+24]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [6.67412632e+22 1.21203137e+23 4.95378460e+22 1.07862730e+23\n",
      " 3.66903423e+22 5.49841700e+22 8.15703203e+22 3.21221000e+22\n",
      " 7.13687426e+22 1.16339869e+23]\n",
      "\n",
      "# 42 Gradient out:  [6.26537807e+24 1.13780208e+25 4.65039646e+24 1.01256816e+25\n",
      " 3.44432896e+24 5.16167355e+24 7.65746514e+24 3.01548234e+24\n",
      " 6.69978562e+24 1.09214784e+25]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [-2.57740083e+23 -4.68059866e+23 -1.91304269e+23 -4.16542146e+23\n",
      " -1.41690034e+23 -2.12336775e+23 -3.15006641e+23 -1.24048487e+23\n",
      " -2.75610392e+23 -4.49278994e+23]\n",
      "\n",
      "# 43 Gradient out:  [-2.41955125e+25 -4.39394144e+25 -1.79588086e+25 -3.91031560e+25\n",
      " -1.33012411e+25 -1.99332483e+25 -2.95714466e+25 -1.16451298e+25\n",
      " -2.58730989e+25 -4.21763483e+25]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [9.95335531e+23 1.80754429e+24 7.38775024e+23 1.60859418e+24\n",
      " 5.47175759e+23 8.19997936e+23 1.21648639e+24 4.79047982e+23\n",
      " 1.06434673e+24 1.73501669e+24]\n",
      "\n",
      "# 44 Gradient out:  [9.34377492e+25 1.69684357e+26 6.93529702e+25 1.51007791e+26\n",
      " 5.13664686e+25 7.69778221e+25 1.14198425e+26 4.49709307e+25\n",
      " 9.99162191e+25 1.62875783e+26]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [-3.84376697e+24 -6.98033859e+24 -2.85298670e+24 -6.21203702e+24\n",
      " -2.11307247e+24 -3.16665173e+24 -4.69780294e+24 -1.84997797e+24\n",
      " -4.11027305e+24 -6.70025296e+24]\n",
      "\n",
      "# 45 Gradient out:  [-3.60836042e+26 -6.55283677e+26 -2.67825922e+26 -5.83158884e+26\n",
      " -1.98366007e+26 -2.97271423e+26 -4.41009207e+26 -1.73667846e+26\n",
      " -3.85854469e+26 -6.28990462e+26]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [1.48437829e+25 2.69565328e+25 1.10176073e+25 2.39895211e+25\n",
      " 8.16022125e+24 1.22289127e+25 1.81418820e+25 7.14420816e+24\n",
      " 1.58729708e+25 2.58749037e+25]\n",
      "\n",
      "# 46 Gradient out:  [1.39346946e+27 2.53056148e+27 1.03428482e+27 2.25203139e+27\n",
      " 7.66045904e+26 1.14799687e+27 1.70308059e+27 6.70667036e+26\n",
      " 1.49008512e+27 2.42902286e+27]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [-5.73234256e+25 -1.04100203e+26 -4.25475770e+25 -9.26422557e+25\n",
      " -3.15129802e+25 -4.72253720e+25 -7.00599594e+25 -2.75893611e+25\n",
      " -6.12979230e+25 -9.99231888e+25]\n",
      "\n",
      "# 47 Gradient out:  [-5.38127265e+27 -9.77247202e+27 -3.99418056e+27 -8.69685004e+27\n",
      " -2.95830084e+27 -4.43331151e+27 -6.57692276e+27 -2.58996863e+27\n",
      " -5.75438109e+27 -9.38035221e+27]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [2.21370466e+26 4.02012093e+26 1.64309387e+26 3.57764021e+26\n",
      " 1.21696201e+26 1.82374003e+26 2.70556158e+26 1.06544046e+26\n",
      " 2.36719101e+26 3.85881384e+26]\n",
      "\n",
      "# 48 Gradient out:  [2.07812917e+28 3.77391382e+28 1.54246471e+28 3.35853226e+28\n",
      " 1.14243074e+28 1.71204742e+28 2.53986296e+28 1.00018894e+28\n",
      " 2.22221545e+28 3.62248577e+28]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [-8.54884064e+26 -1.55248231e+27 -6.34526725e+26 -1.38160599e+27\n",
      " -4.69963968e+26 -7.04288298e+26 -1.04482839e+27 -4.11449680e+26\n",
      " -9.14157117e+26 -1.49018906e+27]\n",
      "\n",
      "# 49 Gradient out:  [-8.02527793e+28 -1.45740254e+29 -5.95665955e+28 -1.29699131e+29\n",
      " -4.41181632e+28 -6.61155071e+28 -9.80839229e+28 -3.86250975e+28\n",
      " -8.58170745e+28 -1.39892435e+29]\n",
      "\n",
      "     Weights  out:  [-0.06380257  0.38100446 -0.18855889  0.22240988 -0.31967213 -0.14535517\n",
      "  0.03015144 -0.38475415 -0.03409506  0.31297369] [3.30137428e+27 5.99534533e+27 2.45040269e+27 5.33545853e+27\n",
      " 1.81489751e+27 2.71980655e+27 4.03489752e+27 1.58892819e+27\n",
      " 3.53027378e+27 5.75478249e+27]\n"
     ]
    }
   ],
   "source": [
    "train(X, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6KIURxgz_e8v"
   },
   "source": [
    "## Ejercicios\n",
    "### Ejercicio A  (3 puntos)\n",
    "1. Obtenga, a partir del código presentado para el entrenamiento de la PMC-BP, el algoritmo de recuerdo de la red.\n",
    "2. Aplique ahora dicho algoritmo de recuerdo en la etapa denominada *Validación* para el mismo problema de regresión. Determine el error cuadrático de la red en cada época y grafique sus resultados.\n",
    "\n",
    "### Ejercicio B  (5 puntos)\n",
    "1. Use la función tangente hiperbólica en lugar de la lineal en la capa de salida para abordar el mismo problema. Con ese objetivo defina la(s) función(nes) que se requieran e insértelas en el código de modo que la red funcione correctamente. Mantenga inalterada la arquitectura de la red.\n",
    "2. A partir de las modificaciones pedidas, entrene nuevamente la red al mismo problema de regresión. Enseguida aplique el algoritmo de recuerdo.\n",
    "3. Compare los resultados que obtenga con los obtenidos con la red PMC-BP que usaba una función lineal en la salida.\n",
    "\n",
    "### Ejercicio C (4 puntos)\n",
    "1. Modifique la arquitectura de la red PMC usando ahora 4, 6, 8 y 12 neuronas en la capa oculta. Aplique las etapas de entrenamiento/validación de la red.\n",
    "2. Determine el mejor modelo, indicando específicamente con cuántas neuronas ocultas obtuvo la mejor respuesta de la red.\n",
    "\n",
    "### Ejercicio D (8 puntos)\n",
    "1. Modifique la arquitectura de la red PMC usando ahora **dos capas ocultas**, inicialmente con 10 neuronas en la primera capa oculta y 8 neuronas en la segunda capa oculta. Use diferentes números de neuronas en las capas ocultas. Aplique las etapas de entrenamiento/validación de la red para cada combinación.\n",
    "2. Determine con qué combinación de neuronas en las capas ocultas obtuvo el mejor modelo, el que produjo la mejor respuesta de la red.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIjpy3jH_e8v"
   },
   "source": [
    "## Instrucciones para el envío de la solución\n",
    "La solución de la \"Práctica de Laboratorio 8 IA 2025-1 EPISW\" deberá enviarse al correo electrónico rmaguinacursos@gmail.com, hasta las 23:59 h del Domingo 08 de Junio del 2025 en un cuaderno computacional interactivo (archivo con extensión .ipynb).\n",
    "\n",
    "El documento deberá tener las sgtes características:\n",
    "- Nombre del archivo: solPGL8_IA_2025-1_EPISW_nombre-apellidos_integrantes.ipynb.\n",
    "- Todas las preguntas de la Práctica deben responderse en el mismo cci (**Sugerencia**: obtener una copia de este documento y desarrollar en ellas las respectivas soluciones); la solución a cada pregunta debe registrarse en una celda debajo del planteamiento de la misma, mencionando explícitamente como subtítulo: \\\"Solución del ejercicio n\\\", donde \\\"n\\\" corresponde al número del ejercicio.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución del ejercicio A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Obtenga, a partir del código presentado para el entrenamiento de la PMC-BP, el algoritmo de recuerdo de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función auxiliar necesaria\n",
    "def logistica(u):\n",
    "    return 1/(1 + np.exp(-u))\n",
    "\n",
    "# Extraído de la fase de propagación hacia adelante del código de entrenamiento.\n",
    "def recall(x, w1, w2):\n",
    "    # Capa oculta\n",
    "    u1 = x * w1        # Entrada neta de las neuronas ocultas\n",
    "    o = logistica(u1)  # (función sigmoidea)\n",
    "    \n",
    "    # Capa de salida\n",
    "    u2 = o.dot(w2)     # Entrada neta de la neurona de salida\n",
    "    y = u2             # Salida final (función lineal)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Aplique ahora dicho algoritmo de recuerdo en la etapa denominada Validación para el mismo problema de regresión. Determine el error cuadrático de la red en cada época y grafique sus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIÓN DE ENTRENAMIENTO MODIFICADA PARA INCLUIR VALIDACIÓN\n",
    "\n",
    "def train_with_validation(X, t, learning_rate=0.2, epochs=50):\n",
    "    # Variables globales\n",
    "    input_num = 1\n",
    "    hidden_num = 10\n",
    "    output_num = 1\n",
    "    intervalo = 0.5\n",
    "\n",
    "    # Inicializando los pesos\n",
    "    w1 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
    "    w2 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
    "    \n",
    "    validation_errors = []\n",
    "\n",
    "    print(\"APLICACIÓN DEL ALGORITMO DE RECUERDO EN VALIDACIÓN\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Época\\t\\tError Cuadrático de Validación\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # FASE DE ENTRENAMIENTO\n",
    "        gradient_out = 0.0\n",
    "        gradient_hidden = np.zeros(hidden_num)\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            # Propagación hacia adelante\n",
    "            x = X[i]\n",
    "            u1 = x * w1\n",
    "            o = logistica(u1)\n",
    "            u2 = o.dot(w2)\n",
    "            y = u2\n",
    "\n",
    "            # Backpropagation\n",
    "            delta_hidden_s = []\n",
    "            gradient_hidden_s = []\n",
    "\n",
    "            delta_out_s = t[i] - y\n",
    "            gradient_out_s = delta_out_s * o\n",
    "\n",
    "            for j in range(hidden_num):\n",
    "                delta_hidden_s.append(deriv_logistica(o[j]) * w2[j] * delta_out_s)\n",
    "                gradient_hidden_s.append(delta_hidden_s[j] * x)\n",
    "\n",
    "            gradient_out = gradient_out + gradient_out_s\n",
    "            gradient_hidden = gradient_hidden + np.array(gradient_hidden_s)\n",
    "\n",
    "        # Actualizar pesos\n",
    "        w2 = w2 + learning_rate * gradient_out\n",
    "        for j in range(hidden_num):\n",
    "            w1[j] = w1[j] + learning_rate * gradient_hidden[j]\n",
    "\n",
    "        # FASE DE VALIDACIÓN - APLICACIÓN DEL ALGORITMO DE RECUERDO\n",
    "        \n",
    "        total_squared_error = 0.0\n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            # Aplicar algoritmo de recuerdo para obtener predicción\n",
    "            y_pred = recall(X[i], w1, w2)\n",
    "            \n",
    "            # Calcular error cuadrático para esta muestra\n",
    "            squared_error = (t[i] - y_pred)**2\n",
    "            total_squared_error += squared_error\n",
    "        \n",
    "        # Error cuadrático medio de la época\n",
    "        mse_validation = total_squared_error / X.shape[0]\n",
    "        validation_errors.append(mse_validation)\n",
    "        \n",
    "        # Mostrar progreso\n",
    "        print(f\"{epoch}\\t\\t{mse_validation:.8f}\")\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Error final: {validation_errors[-1]:.8f}\")\n",
    "    \n",
    "    return validation_errors, w1, w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EJECUTAMOS ENTRENAMIENTO CON VALIDACIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APLICACIÓN DEL ALGORITMO DE RECUERDO EN VALIDACIÓN\n",
      "============================================================\n",
      "Época\t\tError Cuadrático de Validación\n",
      "----------------------------------------\n",
      "0\t\t5.54722614\n",
      "1\t\t10.23585532\n",
      "2\t\t0.70177878\n",
      "3\t\t0.45483170\n",
      "4\t\t0.40520703\n",
      "5\t\t0.39395510\n",
      "6\t\t0.39033068\n",
      "7\t\t0.38838757\n",
      "8\t\t0.38695564\n",
      "9\t\t0.38577897\n",
      "10\t\t0.38477913\n",
      "11\t\t0.38391603\n",
      "12\t\t0.38316157\n",
      "13\t\t0.38249415\n",
      "14\t\t0.38189703\n",
      "15\t\t0.38135727\n",
      "16\t\t0.38086494\n",
      "17\t\t0.38041239\n",
      "18\t\t0.37999374\n",
      "19\t\t0.37960441\n",
      "20\t\t0.37924077\n",
      "21\t\t0.37889996\n",
      "22\t\t0.37857963\n",
      "23\t\t0.37827786\n",
      "24\t\t0.37799303\n",
      "25\t\t0.37772375\n",
      "26\t\t0.37746883\n",
      "27\t\t0.37722721\n",
      "28\t\t0.37699796\n",
      "29\t\t0.37678021\n",
      "30\t\t0.37657321\n",
      "31\t\t0.37637624\n",
      "32\t\t0.37618864\n",
      "33\t\t0.37600982\n",
      "34\t\t0.37583920\n",
      "35\t\t0.37567625\n",
      "36\t\t0.37552049\n",
      "37\t\t0.37537145\n",
      "38\t\t0.37522871\n",
      "39\t\t0.37509186\n",
      "40\t\t0.37496052\n",
      "41\t\t0.37483435\n",
      "42\t\t0.37471302\n",
      "43\t\t0.37459623\n",
      "44\t\t0.37448369\n",
      "45\t\t0.37437514\n",
      "46\t\t0.37427034\n",
      "47\t\t0.37416907\n",
      "48\t\t0.37407111\n",
      "49\t\t0.37397627\n",
      "----------------------------------------\n",
      "Error final: 0.37397627\n"
     ]
    }
   ],
   "source": [
    "validation_errors, final_w1, final_w2 = train_with_validation(X, t, learning_rate=0.2, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRAFICAMOS LOS RESULTADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x500 with 0 Axes>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gráfico 1: Evolución del error cuadrático en validación\n",
    "plt.subplot(1, 2, 1)\n",
    "epochs_range = range(len(validation_errors))\n",
    "plt.plot(epochs_range, validation_errors, 'r-', linewidth=2, marker='o', markersize=4)\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Error Cuadrático de Validación')\n",
    "plt.title('Error Cuadrático de Validación por Época\\n(usando Algoritmo de Recuerdo)')\n",
    "plt.grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error cuadrático final de validación: 0.37397627\n"
     ]
    }
   ],
   "source": [
    "# Gráfico 2: Predicciones finales vs valores reales\n",
    "plt.subplot(1, 2, 2)\n",
    "y_predictions = []\n",
    "for i in range(X.shape[0]):\n",
    "    y_pred = recall(X[i], final_w1, final_w2)\n",
    "    y_predictions.append(y_pred)\n",
    "\n",
    "plt.plot(X, t, 'bo-', label='Valores Reales', markersize=8, linewidth=2)\n",
    "plt.plot(X, y_predictions, 'r^-', label='Predicciones (Algoritmo de Recuerdo)', markersize=8, linewidth=2)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Comparación Final: Valores Reales vs Predicciones')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nError cuadrático final de validación: {validation_errors[-1]:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución del ejercicio B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritmo de entramiento con tanh como función de activación de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv_tanh(u):\n",
    "    return 1 - np.tanh(u) ** 2\n",
    "\n",
    "def train_tanh(X, t, learning_rate=0.2, epochs=50):\n",
    "    global input_num\n",
    "    global hidden_num\n",
    "    global w1\n",
    "    global w2\n",
    "\n",
    "    input_num = 1\n",
    "    hidden_num = 10\n",
    "    output_num = 1\n",
    "    intervalo = 0.5\n",
    "\n",
    "    # inicializando los pesos\n",
    "    w1 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
    "\n",
    "    w2 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        gradient_out = 0.0                 \n",
    "        gradient_hidden = []\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "        # propagacion hacia adelante\n",
    "            x = X[i]\n",
    "\n",
    "            u1 = x * w1\n",
    "            o = logistica(u1)\n",
    "            u2 = o.dot(w2)\n",
    "            y = np.tanh(u2)  #Función de activación tanh para la salida\n",
    "\n",
    "        # backpropagation\n",
    "            delta_hidden_s = []           \n",
    "            gradient_hidden_s = []       \n",
    "\n",
    "            delta_out_s = (t[i] - y)* deriv_tanh(u2)     \n",
    "            gradient_out_s = delta_out_s * o     \n",
    "\n",
    "            for j in range(hidden_num):\n",
    "\n",
    "                delta_hidden_s.append(deriv_logistica(u1[j]) * w2[j] * delta_out_s)\n",
    "                gradient_hidden_s.append(delta_hidden_s[j] * x)\n",
    "\n",
    "\n",
    "            gradient_out = gradient_out + gradient_out_s\n",
    "            gradient_hidden = gradient_hidden + gradient_hidden_s\n",
    "\n",
    "\n",
    "        print(\"\\n#\", epoch, \"Gradient out: \",gradient_out),\n",
    "        print(\"\\n     Weights  out: \", w1, w2)\n",
    "\n",
    "        # Ahora actualizando pesos\n",
    "        w2 = w2 + learning_rate * gradient_out\n",
    "\n",
    "        for j in range(hidden_num):\n",
    "            w1[j] = w1[j] + learning_rate * gradient_hidden[j]\n",
    "\n",
    "def recall_tanh(X, t):\n",
    "    predictions = []\n",
    "    for i in range(X.shape[0]):\n",
    "        x = X[i]\n",
    "        u1 = x * w1\n",
    "        o = logistica(u1)\n",
    "        u2 = o.dot(w2)\n",
    "        y = np.tanh(u2)  # Activación en salida\n",
    "        predictions.append(y)\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "    mse = np.mean((predictions - t)**2)\n",
    "    print(\"\\nTanh error cuadrático medio (ECM):\", mse)\n",
    "\n",
    "    return predictions, mse\n",
    "\n",
    "def recall(X, t):\n",
    "    predictions = []\n",
    "    for i in range(X.shape[0]):\n",
    "        x = X[i]\n",
    "        u1 = x * w1\n",
    "        o = logistica(u1)\n",
    "        u2 = o.dot(w2)\n",
    "        y = u2  # salida lineal\n",
    "        predictions.append(y)\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "    mse = np.mean((predictions - t)**2)\n",
    "    print(\"\\nLineal error cuadrático medio (ECM):\", mse)\n",
    "\n",
    "    return predictions, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hallando por cada algoritmo el promedio de sus MSE de 10 entrenamientos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 0 Gradient out:  [-5.60318485 -6.71306187 -2.18988799 -5.68605429 -5.6859973  -2.06858119\n",
      " -4.92115463 -6.58155064 -2.0620782  -5.31493186]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [ 0.27032809 -0.10567065  0.14777945  0.40380732  0.16156904 -0.25173847\n",
      "  0.23200716  0.45736501 -0.06913792  0.08558164]\n",
      "\n",
      "# 1 Gradient out:  [34.60474058 40.5737469  14.84222234 35.05940565 35.05909385 14.17097542\n",
      " 30.76455577 39.8600666  14.1351512  33.00273388]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [-0.85030888 -1.44828302 -0.29019815 -0.73340354 -0.97563042 -0.66545471\n",
      " -0.75222377 -0.85894512 -0.48155356 -0.97740474]\n",
      "\n",
      "# 2 Gradient out:  [-213.79669918 -251.53416467  -90.58784487 -216.65925372 -216.6572896\n",
      "  -86.36846084 -189.73492533 -247.0260108   -86.1430859  -203.73481758]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [6.07063924 6.66646636 2.67824632 6.27847759 6.03618835 2.16874037\n",
      " 5.40068738 7.1130682  2.34547668 5.62314204]\n",
      "\n",
      "# 3 Gradient out:  [1321.01641429 1553.35367524  560.66136342 1338.65329424 1338.64119388\n",
      "  534.65779251 1172.64772465 1525.59757877  533.2690259  1258.99786758]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [-36.6887006  -43.64036658 -15.43932265 -37.05337315 -37.29526957\n",
      " -15.1049518  -32.54629768 -42.29213396 -14.8831405  -35.12382148]\n",
      "\n",
      "# 4 Gradient out:  [-8162.04825858 -9598.38680393 -3463.32898417 -8271.06739995\n",
      " -8270.99260267 -3302.59989583 -7245.0570301  -9426.79343034\n",
      " -3294.01567485 -7778.71784234]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [227.51458226 267.03036847  96.69295003 230.67728569 230.43296921\n",
      "  91.8266067  201.98324725 262.82738179  91.77066468 216.67575204]\n",
      "\n",
      "# 5 Gradient out:  [50430.59066833 59304.45112074 21399.41050876 51104.1384355\n",
      " 51103.67632015 20406.37820306 44765.06152648 58244.33182773\n",
      " 20353.34252847 48062.25200551]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [-1404.89506946 -1652.64699232  -595.9728468  -1423.5361943\n",
      " -1423.76555133  -568.69337246 -1247.02815877 -1622.53130427\n",
      "  -567.03247029 -1339.06781643]\n",
      "\n",
      "# 6 Gradient out:  [-311593.31311597 -366422.63565215 -132219.0780336  -315754.97698276\n",
      " -315752.12169963 -126083.41589988 -276587.71686851 -359872.42305642\n",
      " -125755.72344908 -296960.03607807]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [ 8681.22306421 10208.24323183  3683.90925495  8797.2914928\n",
      "  8796.9697127   3512.58226815  7705.98414652 10026.33506127\n",
      "  3503.6360354   8273.38258467]\n",
      "\n",
      "# 7 Gradient out:  [1925228.85243079 2263999.7730198   816937.0452405  1950942.31303462\n",
      " 1950924.67124336  779026.93428819 1708941.42638839 2223528.34176135\n",
      "  777002.23742974 1834814.94098026]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [-53637.43955898 -63076.2838986  -22759.90635177 -54353.70390375\n",
      " -54353.45462722 -21704.10091183 -47611.55922718 -61948.14955001\n",
      " -21647.50865442 -51118.62463094]\n",
      "\n",
      "# 8 Gradient out:  [-11895331.92604483 -13988482.56817486  -5047574.79602749\n",
      " -12054206.66226337 -12054097.65962822  -4813341.10936563\n",
      " -10558965.54326118 -13738423.30968305  -4800831.19562718\n",
      " -11336695.11606026]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [331408.33092717 389723.67070536 140627.50269633 335834.75870318\n",
      " 335831.47962145 134101.28594581 294176.7260505  382757.51880226\n",
      " 133752.93883153 315844.36356511]\n",
      "\n",
      "# 9 Gradient out:  [73497196.52668639 86430059.27941091 31187242.3942899  74478829.2647891\n",
      " 74478155.774733   29739992.42905632 65240244.89242172 84885028.55637452\n",
      " 29662697.94409525 70045570.42807487]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [-2047658.05428179 -2407972.84292961  -868887.45650917 -2075006.5737495\n",
      " -2074988.05230419  -828566.93592731 -1817616.38260174 -2364927.14313435\n",
      "  -826413.3002939  -1951494.65964694]\n",
      "\n",
      "# 10 Gradient out:  [-4.54114094e+08 -5.34021840e+08 -1.92695327e+08 -4.60179268e+08\n",
      " -4.60175107e+08 -1.83753263e+08 -4.03097208e+08 -5.24475623e+08\n",
      " -1.83275687e+08 -4.32787675e+08]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [12651781.25105548 14878039.01295257  5368561.02234881 12820759.27920832\n",
      " 12820643.10264241  5119431.54988395 11230432.59588261 14612078.56814055\n",
      "  5106126.28852515 12057619.42596803]\n",
      "\n",
      "# 11 Gradient out:  [2.80581601e+09 3.29953870e+09 1.19059866e+09 2.84329065e+09\n",
      " 2.84326494e+09 1.13534870e+09 2.49060008e+09 3.24055588e+09\n",
      " 1.13239792e+09 2.67404734e+09]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [-78171037.6422524  -91926329.08147186 -33170504.38907055\n",
      " -79215094.35773294 -79214378.28125134 -31631221.12751253\n",
      " -69389009.01248166 -90283045.99553582 -31549011.13956416\n",
      " -74499915.50579241]\n",
      "\n",
      "# 12 Gradient out:  [-1.73361796e+10 -2.03867236e+10 -7.35630282e+09 -1.75677226e+10\n",
      " -1.75675637e+10 -7.01493218e+09 -1.53885679e+10 -2.00222889e+10\n",
      " -6.99670031e+09 -1.65220259e+10]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [4.82992165e+08 5.67981412e+08 2.04949228e+08 4.89443036e+08\n",
      " 4.89438610e+08 1.95438520e+08 4.28731007e+08 5.57828131e+08\n",
      " 1.94930574e+08 4.60309553e+08]\n",
      "\n",
      "# 13 Gradient out:  [1.07114337e+11 1.25962608e+11 4.54520846e+10 1.08544962e+11\n",
      " 1.08543981e+11 4.33428719e+10 9.50807095e+10 1.23710890e+11\n",
      " 4.32302234e+10 1.02083960e+11]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [-2.98424375e+09 -3.50936331e+09 -1.26631134e+09 -3.02410148e+09\n",
      " -3.02407414e+09 -1.20754792e+09 -2.64898258e+09 -3.44662965e+09\n",
      " -1.20440949e+09 -2.84409564e+09]\n",
      "\n",
      "# 14 Gradient out:  [-6.61822935e+11 -7.78279965e+11 -2.80832919e+11 -6.70662279e+11\n",
      " -6.70656215e+11 -2.67800814e+11 -5.87471255e+11 -7.64367369e+11\n",
      " -2.67104797e+11 -6.30741949e+11]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [1.84386237e+10 2.16831582e+10 7.82410559e+09 1.86848910e+10\n",
      " 1.86847220e+10 7.46102647e+09 1.63671593e+10 2.12955483e+10\n",
      " 7.44163520e+09 1.75726963e+10]\n",
      "\n",
      "# 15 Gradient out:  [4.08917805e+12 4.80872630e+12 1.73517077e+12 4.14379334e+12\n",
      " 4.14375587e+12 1.65464983e+12 3.62978440e+12 4.72276512e+12\n",
      " 1.65034939e+12 3.89713924e+12]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [-1.13925963e+11 -1.33972835e+11 -4.83424783e+10 -1.15447565e+11\n",
      " -1.15446521e+11 -4.60991363e+10 -1.01127092e+11 -1.31577926e+11\n",
      " -4.59793242e+10 -1.08575693e+11]\n",
      "\n",
      "# 16 Gradient out:  [-2.52656356e+13 -2.97114787e+13 -1.07210280e+13 -2.56030849e+13\n",
      " -2.56028534e+13 -1.02235166e+13 -2.24271990e+13 -2.91803539e+13\n",
      " -1.01969456e+13 -2.40790934e+13]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [7.03909647e+11 8.27772424e+11 2.98691675e+11 7.13311104e+11\n",
      " 7.13304654e+11 2.84830831e+11 6.24829788e+11 8.12975098e+11\n",
      " 2.84090553e+11 6.70852156e+11]\n",
      "\n",
      "# 17 Gradient out:  [1.56107740e+14 1.83577087e+14 6.62415732e+13 1.58192724e+14\n",
      " 1.58191293e+14 6.31676203e+13 1.38570009e+14 1.80295448e+14\n",
      " 6.30034471e+13 1.48776501e+14]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [-4.34921748e+12 -5.11452331e+12 -1.84551392e+12 -4.40730588e+12\n",
      " -4.40726602e+12 -1.75987250e+12 -3.86061002e+12 -5.02309568e+12\n",
      " -1.75529857e+12 -4.14496652e+12]\n",
      "\n",
      "# 18 Gradient out:  [-9.64536450e+14 -1.13426017e+15 -4.09284074e+14 -9.77418854e+14\n",
      " -9.77410015e+14 -3.90291168e+14 -8.56176795e+14 -1.11398404e+15\n",
      " -3.89276798e+14 -9.19239223e+14]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [2.68723305e+13 3.16008941e+13 1.14028007e+13 2.72312389e+13\n",
      " 2.72309927e+13 1.08736516e+13 2.38533918e+13 3.10359940e+13\n",
      " 1.08453908e+13 2.56103336e+13]\n",
      "\n",
      "# 19 Gradient out:  [5.95954155e+15 7.00820650e+15 2.52882662e+15 6.03913753e+15\n",
      " 6.03908292e+15 2.41147593e+15 5.29002423e+15 6.88292723e+15\n",
      " 2.40520849e+15 5.67966545e+15]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [-1.66034959e+14 -1.95251140e+14 -7.04540141e+13 -1.68252532e+14\n",
      " -1.68251010e+14 -6.71845821e+13 -1.47381967e+14 -1.91760815e+14\n",
      " -6.70099688e+13 -1.58237511e+14]\n",
      "\n",
      "# 20 Gradient out:  [-3.68219734e+16 -4.33013162e+16 -1.56247566e+16 -3.73137698e+16\n",
      " -3.73134324e+16 -1.48996868e+16 -3.26852543e+16 -4.25272584e+16\n",
      " -1.48609624e+16 -3.50927145e+16]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [1.02587335e+15 1.20639016e+15 4.35311309e+14 1.03957497e+15\n",
      " 1.03956557e+15 4.15110604e+14 9.10622878e+14 1.18482463e+15\n",
      " 4.14031728e+14 9.77695578e+14]\n",
      "\n",
      "# 21 Gradient out:  [2.27510407e+17 2.67544055e+17 9.65400389e+16 2.30549049e+17\n",
      " 2.30546965e+17 9.20600799e+16 2.01951032e+17 2.62761416e+17\n",
      " 9.18208150e+16 2.16825906e+17]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [-6.33852133e+15 -7.45387309e+15 -2.68964002e+15 -6.42317898e+15\n",
      " -6.42312090e+15 -2.56482676e+15 -5.62642799e+15 -7.32062705e+15\n",
      " -2.55816075e+15 -6.04084732e+15]\n",
      "\n",
      "# 22 Gradient out:  [-1.40570916e+18 -1.65306341e+18 -5.96487954e+17 -1.42448390e+18\n",
      " -1.42447101e+18 -5.68807816e+17 -1.24778651e+18 -1.62351312e+18\n",
      " -5.67329480e+17 -1.33969328e+18]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [3.91635601e+16 4.60549380e+16 1.66183678e+16 3.96866309e+16\n",
      " 3.96862720e+16 1.58471892e+16 3.47637784e+16 4.52316562e+16\n",
      " 1.58060022e+16 3.73243340e+16]\n",
      "\n",
      "# 23 Gradient out:  [8.68539719e+18 1.02137147e+19 3.68549550e+18 8.80139985e+18\n",
      " 8.80132026e+18 3.51446937e+18 7.70964698e+18 1.00311335e+19\n",
      " 3.50533524e+18 8.27750757e+18]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [-2.41978273e+17 -2.84557744e+17 -1.02679223e+17 -2.45210148e+17\n",
      " -2.45207931e+17 -9.79143739e+16 -2.14793523e+17 -2.79470967e+17\n",
      " -9.76598937e+16 -2.30614322e+17]\n",
      "\n",
      "# 24 Gradient out:  [-5.36641051e+19 -6.31070573e+19 -2.27714189e+19 -5.43808460e+19\n",
      " -5.43803542e+19 -2.17147069e+19 -4.76352776e+19 -6.19789504e+19\n",
      " -2.16582702e+19 -5.11438943e+19]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [1.49510117e+18 1.75818519e+18 6.34419877e+17 1.51506982e+18\n",
      " 1.51505612e+18 6.04979501e+17 1.32713587e+18 1.72675573e+18\n",
      " 6.03407154e+17 1.42488719e+18]\n",
      "\n",
      "# 25 Gradient out:  [3.31572191e+20 3.89916970e+20 1.40696826e+20 3.36000688e+20\n",
      " 3.35997650e+20 1.34167763e+20 2.94322123e+20 3.82946783e+20\n",
      " 1.33819060e+20 3.16000669e+20]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [-9.23771986e+18 -1.08632263e+19 -3.91986391e+18 -9.36109937e+18\n",
      " -9.36101472e+18 -3.73796187e+18 -8.19991964e+18 -1.06690344e+19\n",
      " -3.72824688e+18 -8.80389168e+18]\n",
      "\n",
      "# 26 Gradient out:  [-2.04867141e+21 -2.40916389e+21 -8.69317673e+20 -2.07603359e+21\n",
      " -2.07601481e+21 -8.28976820e+20 -1.81851596e+21 -2.36609748e+21\n",
      " -8.26822302e+20 -1.95246029e+21]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [5.70767184e+19 6.71201678e+19 2.42195013e+19 5.78390383e+19\n",
      " 5.78385153e+19 2.30955907e+19 5.06645051e+19 6.59203222e+19\n",
      " 2.30355651e+19 5.43962421e+19]\n",
      "\n",
      "# 27 Gradient out:  [1.26580415e+22 1.48854015e+22 5.37121723e+21 1.28271030e+22\n",
      " 1.28269870e+22 5.12196486e+21 1.12359895e+22 1.46193088e+22\n",
      " 5.10865283e+21 1.20635858e+22]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [-3.52657564e+20 -4.14712610e+20 -1.49644033e+20 -3.57367679e+20\n",
      " -3.57364447e+20 -1.42699773e+20 -3.13038686e+20 -4.07299174e+20\n",
      " -1.42328895e+20 -3.36095816e+20]\n",
      "\n",
      "# 28 Gradient out:  [-7.82097186e+22 -9.19718158e+22 -3.31869182e+22 -7.92542920e+22\n",
      " -7.92535753e+22 -3.16468729e+22 -6.94233444e+22 -9.03277202e+22\n",
      " -3.15646224e+22 -7.45367797e+22]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [2.17895074e+21 2.56236769e+21 9.24599412e+20 2.20805293e+21\n",
      " 2.20803296e+21 8.81693199e+20 1.93415921e+21 2.51656260e+21\n",
      " 8.79401671e+20 2.07662135e+21]\n",
      "\n",
      "# 29 Gradient out:  [4.83231160e+23 5.68262462e+23 2.05050642e+23 4.89685223e+23\n",
      " 4.89680795e+23 1.95535227e+23 4.28943153e+23 5.58104156e+23\n",
      " 1.95027030e+23 4.60537324e+23]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [-1.34629930e+22 -1.58319955e+22 -5.71278423e+21 -1.36428055e+22\n",
      " -1.36426821e+22 -5.44768138e+21 -1.19505097e+22 -1.55489814e+22\n",
      " -5.43352281e+21 -1.28307346e+22]\n",
      "\n",
      "# 30 Gradient out:  [-2.98572042e+24 -3.51109982e+24 -1.26693794e+24 -3.02559788e+24\n",
      " -3.02557052e+24 -1.20814544e+24 -2.65029335e+24 -3.44833512e+24\n",
      " -1.20500546e+24 -2.84550296e+24]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [8.31832390e+22 9.78204970e+22 3.52973441e+22 8.42942391e+22\n",
      " 8.42934769e+22 3.36593641e+22 7.38381209e+22 9.60718498e+22\n",
      " 3.35718831e+22 7.92767303e+22]\n",
      "\n",
      "# 31 Gradient out:  [1.84477475e+25 2.16938875e+25 7.82797713e+24 1.86941367e+25\n",
      " 1.86939677e+25 7.46471835e+24 1.63752582e+25 2.13060858e+25\n",
      " 7.44531749e+24 1.75813917e+25]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [-5.13960846e+23 -6.04399467e+23 -2.18090243e+23 -5.20825336e+23\n",
      " -5.20820626e+23 -2.07969723e+23 -4.56220550e+23 -5.93595173e+23\n",
      " -2.07429208e+23 -4.89823861e+23]\n",
      "\n",
      "# 32 Gradient out:  [-1.13982336e+26 -1.34039128e+26 -4.83663992e+25 -1.15504691e+26\n",
      " -1.15503646e+26 -4.61219472e+25 -1.01177132e+26 -1.31643033e+26\n",
      " -4.60020758e+25 -1.08629419e+26]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [3.17558866e+24 3.73437804e+24 1.34750518e+24 3.21800201e+24\n",
      " 3.21797291e+24 1.28497395e+24 2.81883108e+24 3.66762200e+24\n",
      " 1.28163429e+24 3.02645447e+24]\n",
      "\n",
      "# 33 Gradient out:  [7.04257957e+26 8.28182025e+26 2.98839474e+26 7.13664066e+26\n",
      " 7.13657613e+26 2.84971771e+26 6.25138968e+26 8.13377376e+26\n",
      " 2.84231127e+26 6.71184108e+26]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [-1.96208786e+25 -2.30734475e+25 -8.32577466e+24 -1.98829362e+25\n",
      " -1.98827564e+25 -7.93941549e+24 -1.74165953e+25 -2.26609846e+25\n",
      " -7.91878088e+24 -1.86994293e+25]\n",
      "\n",
      "# 34 Gradient out:  [-4.35136957e+27 -5.11705409e+27 -1.84642713e+27 -4.40948671e+27\n",
      " -4.40944684e+27 -1.76074332e+27 -3.86252034e+27 -5.02558122e+27\n",
      " -1.75616713e+27 -4.14701755e+27]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [1.21230713e+26 1.42562957e+26 5.14421202e+25 1.22849877e+26\n",
      " 1.22848766e+26 4.90549388e+25 1.07611198e+26 1.40014491e+26\n",
      " 4.89274446e+25 1.15537392e+26]\n",
      "\n",
      "# 35 Gradient out:  [2.68856276e+28 3.16165309e+28 1.14084431e+28 2.72447135e+28\n",
      " 2.72444672e+28 1.08790321e+28 2.38651950e+28 3.10513513e+28\n",
      " 1.08507574e+28 2.56230061e+28]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [-7.49043201e+26 -8.80847861e+26 -3.17843305e+26 -7.59047465e+26\n",
      " -7.59040601e+26 -3.03093725e+26 -6.64892869e+26 -8.65101754e+26\n",
      " -3.02305982e+26 -7.13866117e+26]\n",
      "\n",
      "# 36 Gradient out:  [-1.66117117e+29 -1.95347755e+29 -7.04888764e+28 -1.68335787e+29\n",
      " -1.68334265e+29 -6.72178265e+28 -1.47454895e+29 -1.91855702e+29\n",
      " -6.70431268e+28 -1.58315811e+29]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [4.62808231e+27 5.44245832e+27 1.96384531e+27 4.68989524e+27\n",
      " 4.68985283e+27 1.87271269e+27 4.10814613e+27 5.34516850e+27\n",
      " 1.86784550e+27 4.41073511e+27]\n",
      "\n",
      "# 37 Gradient out:  [1.02638098e+30 1.20698711e+30 4.35526711e+29 1.04008938e+30\n",
      " 1.04007997e+30 4.15316010e+29 9.11073475e+29 1.18541091e+30\n",
      " 4.14236601e+29 9.78179364e+29]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [-2.85953412e+28 -3.36270926e+28 -1.21339300e+28 -2.89772622e+28\n",
      " -2.89770001e+28 -1.15708526e+28 -2.53828329e+28 -3.30259720e+28\n",
      " -1.15407799e+28 -2.72524270e+28]\n",
      "\n",
      "# 38 Gradient out:  [-6.34165778e+30 -7.45756143e+30 -2.69097091e+30 -6.42635732e+30\n",
      " -6.42629921e+30 -2.56609589e+30 -5.62921207e+30 -7.32424946e+30\n",
      " -2.55942659e+30 -6.04383646e+30]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [1.76680854e+29 2.07770329e+29 7.49714122e+28 1.79040614e+29\n",
      " 1.79038995e+29 7.14923494e+28 1.56831862e+29 2.04056210e+29\n",
      " 7.13065402e+28 1.68383446e+29]\n",
      "\n",
      "# 39 Gradient out:  [3.91829391e+31 4.60777270e+31 1.66265909e+31 3.97062687e+31\n",
      " 3.97059097e+31 1.58550308e+31 3.47809803e+31 4.52540378e+31\n",
      " 1.58138234e+31 3.73428029e+31]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [-1.09165070e+30 -1.28374196e+30 -4.63222770e+29 -1.10623085e+30\n",
      " -1.10622085e+30 -4.41726829e+29 -9.69010553e+29 -1.26079368e+30\n",
      " -4.40578777e+29 -1.04038385e+30]\n",
      "\n",
      "# 40 Gradient out:  [-2.42098009e+32 -2.84698550e+32 -1.02730031e+32 -2.45331484e+32\n",
      " -2.45329265e+32 -9.79628242e+31 -2.14899807e+32 -2.79609256e+32\n",
      " -9.77082180e+31 -2.30728435e+32]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [6.74493713e+30 7.93180344e+30 2.86209541e+30 6.83502289e+30\n",
      " 6.83496109e+30 2.72927932e+30 5.98718551e+30 7.79001388e+30\n",
      " 2.72218590e+30 6.42817673e+30]\n",
      "\n",
      "# 41 Gradient out:  [1.49584097e+33 1.75905518e+33 6.34733802e+32 1.51581951e+33\n",
      " 1.51580580e+33 6.05278858e+32 1.32779257e+33 1.72761017e+33\n",
      " 6.03705734e+32 1.42559226e+33]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [-4.16746646e+31 -4.90079066e+31 -1.76839108e+31 -4.22312738e+31\n",
      " -4.22308919e+31 -1.68632855e+31 -3.69927760e+31 -4.81318373e+31\n",
      " -1.68194577e+31 -3.97175103e+31]\n",
      "\n",
      "# 42 Gradient out:  [-9.24229089e+33 -1.08686016e+34 -3.92180355e+33 -9.36573145e+33\n",
      " -9.36564676e+33 -3.73981150e+33 -8.20397715e+33 -1.06743136e+34\n",
      " -3.73009170e+33 -8.80824804e+33]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [2.57493530e+32 3.02803129e+32 1.09262850e+32 2.60932629e+32\n",
      " 2.60930269e+32 1.04192486e+32 2.28565738e+32 2.97390196e+32\n",
      " 1.03921689e+32 2.45400941e+32]\n",
      "\n",
      "# 43 Gradient out:  [5.71049612e+34 6.71533803e+34 2.42314857e+34 5.78676584e+34\n",
      " 5.78671351e+34 2.31070190e+34 5.06895750e+34 6.59529411e+34\n",
      " 2.30469636e+34 5.44231586e+34]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [-1.59096465e+33 -1.87091720e+33 -6.75097860e+32 -1.61221366e+33\n",
      " -1.61219908e+33 -6.43769814e+32 -1.41222969e+33 -1.83747253e+33\n",
      " -6.42096651e+32 -1.51624867e+33]\n",
      "\n",
      "# 44 Gradient out:  [-3.52832067e+35 -4.14917819e+35 -1.49718081e+35 -3.57544512e+35\n",
      " -3.57541279e+35 -1.42770384e+35 -3.13193585e+35 -4.07500715e+35\n",
      " -1.42399323e+35 -3.36262124e+35]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [9.83002760e+33 1.15597589e+34 4.17119928e+33 9.96131801e+33\n",
      " 9.96122793e+33 3.97763398e+33 8.72568531e+33 1.13531157e+34\n",
      " 3.96729607e+33 9.36838306e+33]\n",
      "\n",
      "# 45 Gradient out:  [2.18002893e+36 2.56363560e+36 9.25056925e+35 2.20914552e+36\n",
      " 2.20912554e+36 8.82129480e+35 1.93511628e+36 2.51780785e+36\n",
      " 8.79836819e+35 2.07764891e+36]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [-6.07363858e+34 -7.14238050e+34 -2.57724168e+34 -6.15475844e+34\n",
      " -6.15470279e+34 -2.45764429e+34 -5.39130317e+34 -7.01470273e+34\n",
      " -2.45125685e+34 -5.78840417e+34]\n",
      "\n",
      "# 46 Gradient out:  [-1.34696548e+37 -1.58398295e+37 -5.71561104e+36 -1.36495562e+37\n",
      " -1.36494328e+37 -5.45037701e+36 -1.19564231e+37 -1.55566754e+37\n",
      " -5.43621144e+36 -1.28370835e+37]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [3.75269400e+35 4.41303316e+35 1.59238968e+35 3.80281520e+35\n",
      " 3.80278081e+35 1.51849453e+35 3.33110223e+35 4.33414542e+35\n",
      " 1.51454795e+35 3.57645739e+35]\n",
      "\n",
      "# 47 Gradient out:  [8.32244000e+37 9.78689007e+37 3.53148100e+37 8.43359498e+37\n",
      " 8.43351872e+37 3.36760195e+37 7.38746577e+37 9.61193883e+37\n",
      " 3.35884952e+37 7.93159582e+37]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [-2.31866155e+36 -2.72666258e+36 -9.83883240e+35 -2.34962973e+36\n",
      " -2.34960848e+36 -9.38225949e+35 -2.05817439e+36 -2.67792054e+36\n",
      " -9.35787492e+35 -2.20977097e+36]\n",
      "\n",
      "# 48 Gradient out:  [-5.14215165e+38 -6.04698537e+38 -2.18198159e+38 -5.21083052e+38\n",
      " -5.21078340e+38 -2.08072632e+38 -4.56446298e+38 -5.93888897e+38\n",
      " -2.07531849e+38 -4.90066237e+38]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [1.43262184e+37 1.68471176e+37 6.07907876e+36 1.45175602e+37\n",
      " 1.45174290e+37 5.79697795e+36 1.27167571e+37 1.65459571e+37\n",
      " 5.78191155e+36 1.36534207e+37]\n",
      "\n",
      "# 49 Gradient out:  [3.17716002e+39 3.73622589e+39 1.34817196e+39 3.21959435e+39\n",
      " 3.21956523e+39 1.28560978e+39 2.82022590e+39 3.66943682e+39\n",
      " 1.28226847e+39 3.02795203e+39]\n",
      "\n",
      "     Weights  out:  [ 0.22581081  0.49178763 -0.20376756  0.23933421  0.23932473 -0.22253183\n",
      "  0.12918775  0.44344556 -0.22356515  0.18227382] [-8.85168146e+37 -1.04092590e+38 -3.75605530e+37 -8.96990502e+37\n",
      " -8.96982391e+37 -3.58175484e+37 -7.85725025e+37 -1.02231822e+38\n",
      " -3.57244583e+37 -8.43598268e+37]\n",
      "\n",
      "Lineal error cuadrático medio (ECM): 9.511659802398694e+78\n",
      "\n",
      "# 0 Gradient out:  [0.72988648 1.037505   1.04558309 0.46489128 0.42144186 0.52190587\n",
      " 0.97100845 0.42248703 1.0506688  0.90704491]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.23485134  0.11678331 -0.27534556 -0.07659941 -0.20567717 -0.02689801\n",
      "  0.21001243  0.42362321 -0.01407816  0.17431434]\n",
      "\n",
      "# 1 Gradient out:  [-1.16422229 -1.87589816 -1.93142465 -0.61991524 -0.37266575 -0.79079692\n",
      " -1.60779869 -0.37908188 -1.96561666 -1.46259044]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.08887404  0.32428431 -0.06622895  0.01637885 -0.1213888   0.07748317\n",
      "  0.40421412  0.50812062  0.1960556   0.35572332]\n",
      "\n",
      "# 2 Gradient out:  [2.23484827 3.3848845  3.45910422 1.32488499 0.98812056 1.58284716\n",
      " 3.00302846 0.99697793 3.50540287 2.76756327]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.3217185  -0.05089532 -0.45251388 -0.1076042  -0.19592195 -0.08067622\n",
      "  0.08265438  0.43230424 -0.19706773  0.06320523]\n",
      "\n",
      "# 3 Gradient out:  [-0.16506095 -0.24809949 -0.25464439 -0.10154335 -0.0725265  -0.12138459\n",
      " -0.21691696 -0.07329737 -0.25871711 -0.20001499]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [0.12525115 0.62608158 0.23930697 0.1573728  0.00170216 0.23589321\n",
      " 0.68326008 0.63169983 0.50401284 0.61671788]\n",
      "\n",
      "# 4 Gradient out:  [-0.24232482 -0.36819363 -0.37807057 -0.14599143 -0.10216219 -0.17605543\n",
      " -0.32099928 -0.10332278 -0.38420833 -0.29536856]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [ 0.09223896  0.57646168  0.18837809  0.13706413 -0.01280314  0.2116163\n",
      "  0.63987668  0.61704035  0.45226942  0.57671489]\n",
      "\n",
      "# 5 Gradient out:  [-0.41750047 -0.6447585  -0.66248074 -0.24344142 -0.16469038 -0.29770641\n",
      " -0.55970804 -0.16676477 -0.67346931 -0.51340115]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [ 0.043774    0.50282295  0.11276398  0.10786584 -0.03323558  0.17640521\n",
      "  0.57567683  0.5963758   0.37542776  0.51764118]\n",
      "\n",
      "# 6 Gradient out:  [-0.92779665 -1.47450728 -1.51695243 -0.50906277 -0.32010979 -0.63985509\n",
      " -1.26967533 -0.32503954 -1.54315811 -1.15816431]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.03972609  0.37387125 -0.01973217  0.05917756 -0.06617365  0.11686393\n",
      "  0.46373522  0.56302284  0.24073389  0.41496095]\n",
      "\n",
      "# 7 Gradient out:  [0.97589538 1.48729442 1.50786434 0.54953969 0.44824993 0.65295844\n",
      " 1.35262309 0.45066271 1.52038249 1.24659704]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.22528543  0.0789698  -0.32312266 -0.042635   -0.13019561 -0.01110709\n",
      "  0.20980015  0.49801494 -0.06789773  0.18332808]\n",
      "\n",
      "# 8 Gradient out:  [-0.89126576 -1.41605974 -1.4567995  -0.48928716 -0.30794082 -0.6148031\n",
      " -1.21950518 -0.3126754  -1.48196041 -1.11246987]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.03010635  0.37642868 -0.02154979  0.06727294 -0.04054563  0.1194846\n",
      "  0.48032477  0.58814748  0.23617877  0.43264749]\n",
      "\n",
      "# 9 Gradient out:  [0.59798947 0.90264679 0.90832356 0.33229039 0.29774036 0.38765412\n",
      " 0.84150628 0.29839645 0.91158563 0.77770121]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.2083595   0.09321673 -0.31290969 -0.03058449 -0.10213379 -0.00347602\n",
      "  0.23642374  0.5256124  -0.06021331  0.21015352]\n",
      "\n",
      "# 10 Gradient out:  [-1.24333658 -2.01268537 -2.07383413 -0.65685288 -0.38520478 -0.84257895\n",
      " -1.71974021 -0.39228283 -2.11153682 -1.56288403]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.08876161  0.27374609 -0.13124498  0.03587359 -0.04258572  0.0740548\n",
      "  0.40472499  0.58529169  0.12210381  0.36569376]\n",
      "\n",
      "# 11 Gradient out:  [2.01211553 2.98537379 3.05265335 1.2487547  0.9471035  1.46978351\n",
      " 2.65205597 0.95527463 3.09509516 2.45353436]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.33742892 -0.12879098 -0.5460118  -0.09549699 -0.11962668 -0.09446099\n",
      "  0.06077695  0.50683512 -0.30020355  0.05311695]\n",
      "\n",
      "# 12 Gradient out:  [-0.42942754 -0.67454566 -0.69355743 -0.24155323 -0.15698169 -0.30004856\n",
      " -0.58299734 -0.15920161 -0.70532868 -0.53302629]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [0.06499418 0.46828378 0.06451887 0.15425395 0.06979402 0.19949572\n",
      " 0.59118814 0.69789005 0.31881548 0.54382383]\n",
      "\n",
      "# 13 Gradient out:  [-0.98286632 -1.57597253 -1.62218599 -0.52888853 -0.32324599 -0.67094235\n",
      " -1.35327695 -0.32861534 -1.65072529 -1.23231408]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.02089132  0.33337465 -0.07419262  0.1059433   0.03839769  0.139486\n",
      "  0.47458868  0.66604973  0.17774975  0.43721857]\n",
      "\n",
      "# 14 Gradient out:  [1.40202786 2.22434445 2.26612556 0.73272904 0.53516195 0.90827388\n",
      " 1.98073479 0.53998495 2.29154911 1.81088947]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-2.17464588e-01  1.81801392e-02 -3.98629820e-01  1.65597473e-04\n",
      " -2.62515109e-02  5.29753309e-03  2.03933286e-01  6.00326657e-01\n",
      " -1.52395310e-01  1.90755753e-01]\n",
      "\n",
      "# 15 Gradient out:  [-0.44023698 -0.6924815  -0.71204115 -0.24689581 -0.15988164 -0.30709226\n",
      " -0.59827649 -0.16216509 -0.72415026 -0.54685102]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [0.06294098 0.46304903 0.05459529 0.1467114  0.08078088 0.18695231\n",
      " 0.60008024 0.70832365 0.30591451 0.55293365]\n",
      "\n",
      "# 16 Gradient out:  [-1.01563223 -1.63055789 -1.67853801 -0.54507924 -0.33160471 -0.69243231\n",
      " -1.39945865 -0.33717869 -1.70816732 -1.27404985]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.02510641  0.32455273 -0.08781294  0.09733224  0.04880455  0.12553386\n",
      "  0.48042495  0.67589063  0.16108446  0.44356344]\n",
      "\n",
      "# 17 Gradient out:  [1.64085065 2.58939276 2.64141418 0.87529131 0.63262937 1.0809996\n",
      " 2.29804985 0.63868641 2.67329236 2.1025931 ]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.22823286 -0.00155885 -0.42352054 -0.0116836  -0.01751639 -0.0129526\n",
      "  0.20053322  0.60845489 -0.180549    0.18875347]\n",
      "\n",
      "# 18 Gradient out:  [-0.29177743 -0.45518087 -0.46788618 -0.16656455 -0.11008225 -0.20555566\n",
      " -0.39412129 -0.11156881 -0.47576177 -0.3608195 ]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [0.09993727 0.5163197  0.10476229 0.16337466 0.10900948 0.20324731\n",
      " 0.66014319 0.73619217 0.35410947 0.60927209]\n",
      "\n",
      "# 19 Gradient out:  [-0.56112124 -0.88872985 -0.91410293 -0.31000069 -0.1970787  -0.38820553\n",
      " -0.76637312 -0.20003622 -0.92979749 -0.69956847]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [0.04158179 0.42528353 0.01118506 0.13006175 0.08699303 0.16213618\n",
      " 0.58131893 0.71387841 0.25895711 0.53710819]\n",
      "\n",
      "# 20 Gradient out:  [-1.2583405  -2.03321619 -2.09560996 -0.66885639 -0.39225055 -0.85641342\n",
      " -1.73632913 -0.39950184 -2.13417273 -1.57847716]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.07064246  0.24753756 -0.17163553  0.06806161  0.04757729  0.08449508\n",
      "  0.42804431  0.67387117  0.07299761  0.3971945 ]\n",
      "\n",
      "# 21 Gradient out:  [1.96480324 2.89517797 2.96121789 1.23751993 0.94284158 1.44966794\n",
      " 2.57297886 0.95093155 3.00309962 2.38353271]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.32231056 -0.15910568 -0.59075752 -0.06570967 -0.03087282 -0.08678761\n",
      "  0.08077848  0.5939708  -0.35383693  0.08149907]\n",
      "\n",
      "# 22 Gradient out:  [-0.50397685 -0.80392181 -0.82708557 -0.27396173 -0.17082143 -0.34552653\n",
      " -0.69204367 -0.17351928 -0.84140641 -0.63086679]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [0.07065009 0.41992992 0.00148606 0.18179432 0.1576955  0.20314598\n",
      " 0.59537425 0.78415711 0.24678299 0.55820561]\n",
      "\n",
      "# 23 Gradient out:  [-1.18541842 -1.91499575 -1.97307601 -0.62910769 -0.37135379 -0.80494504\n",
      " -1.63762726 -0.37811444 -2.00899448 -1.4889617 ]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.03014529  0.25914556 -0.16393106  0.12700197  0.12353121  0.13404067\n",
      "  0.45696552  0.74945325  0.07850171  0.43203225]\n",
      "\n",
      "# 24 Gradient out:  [2.10223911 3.19034862 3.26374661 1.2458871  0.91554134 1.49168874\n",
      " 2.82221533 0.92442171 3.30992536 2.6       ]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.26722897 -0.1238536  -0.55854626  0.00118043  0.04926045 -0.02694833\n",
      "  0.12944007  0.67383037 -0.32329718  0.13423991]\n",
      "\n",
      "# 25 Gradient out:  [-0.22336686 -0.35371772 -0.36378716 -0.12338876 -0.07857124 -0.154463\n",
      " -0.30514206 -0.07974659 -0.37001992 -0.27856241]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [0.15321885 0.51421613 0.09420306 0.25035785 0.23236872 0.27138941\n",
      " 0.69388313 0.85871471 0.33868789 0.65423991]\n",
      "\n",
      "# 26 Gradient out:  [-0.38192489 -0.61047065 -0.62807986 -0.20659073 -0.12816085 -0.26108252\n",
      " -0.52534088 -0.1302117  -0.63896588 -0.47872219]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [0.10854548 0.44347258 0.02144563 0.2256801  0.21665447 0.24049681\n",
      " 0.63285472 0.84276539 0.2646839  0.59852743]\n",
      "\n",
      "# 27 Gradient out:  [-0.85146902 -1.37660143 -1.41739457 -0.44928033 -0.26770067 -0.57492082\n",
      " -1.17982393 -0.27244294 -1.44259207 -1.07271184]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [ 0.0321605   0.32137845 -0.10417034  0.18436195  0.1910223   0.18828031\n",
      "  0.52778655  0.81672305  0.13689073  0.50278299]\n",
      "\n",
      "# 28 Gradient out:  [ 0.16567572  0.36407117  0.35693213 -0.02449746 -0.00603487  0.00394414\n",
      "  0.35078472 -0.00714478  0.35143459  0.30761845]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.1381333   0.04605817 -0.38764925  0.09450589  0.13748217  0.07329615\n",
      "  0.29182176  0.76223446 -0.15162769  0.28824062]\n",
      "\n",
      "# 29 Gradient out:  [-0.80467014 -1.24919134 -1.29734557 -0.48723255 -0.28098258 -0.60498916\n",
      " -1.04591126 -0.28675997 -1.32777566 -0.95688715]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.10499816  0.1188724  -0.31626283  0.0896064   0.1362752   0.07408497\n",
      "  0.3619787   0.76080551 -0.08134077  0.34976431]\n",
      "\n",
      "# 30 Gradient out:  [2.08935011 3.17175112 3.24505877 1.23792848 0.90822206 1.48261186\n",
      " 2.80489342 0.91710103 3.29121214 2.58389521]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.26593219 -0.13096587 -0.57573194 -0.00784011  0.08007868 -0.04691286\n",
      "  0.15279645  0.70345351 -0.3468959   0.15838688]\n",
      "\n",
      "# 31 Gradient out:  [-0.2329015  -0.37008034 -0.38066618 -0.12767243 -0.0805464  -0.16037132\n",
      " -0.3189789  -0.08178135 -0.38721653 -0.29100422]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [0.15193784 0.50338436 0.07327981 0.23974558 0.26172309 0.24960951\n",
      " 0.71377513 0.88687372 0.31134653 0.67516592]\n",
      "\n",
      "# 32 Gradient out:  [-0.40696229 -0.65265345 -0.67157074 -0.21846155 -0.1341912  -0.27704214\n",
      " -0.56115132 -0.13639326 -0.68326197 -0.51103106]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [ 0.10535754  0.42936829 -0.00285342  0.2142111   0.24561381  0.21753525\n",
      "  0.64997935  0.87051745  0.23390322  0.61696508]\n",
      "\n",
      "# 33 Gradient out:  [-0.93196345 -1.51004303 -1.55513339 -0.48954647 -0.28893883 -0.62802566\n",
      " -1.2929     -0.2941819  -1.582991   -1.17500619]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [ 0.02396508  0.2988376  -0.13716757  0.17051878  0.21877557  0.16212682\n",
      "  0.53774909  0.8432388   0.09725083  0.51475887]\n",
      "\n",
      "# 34 Gradient out:  [0.88303237 1.51695964 1.54138719 0.35484655 0.23188932 0.48482934\n",
      " 1.34799237 0.23449265 1.55548187 1.21587092]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.16242761 -0.00317101 -0.44819425  0.07260949  0.16098781  0.03652169\n",
      "  0.27916909  0.78440242 -0.21934737  0.27975763]\n",
      "\n",
      "# 35 Gradient out:  [-0.9526908  -1.5417171  -1.58768482 -0.50193666 -0.29744001 -0.6430569\n",
      " -1.32039865 -0.30278513 -1.61608499 -1.20027622]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [ 0.01417886  0.30022092 -0.13991681  0.1435788   0.20736567  0.13348756\n",
      "  0.54876756  0.83130095  0.091749    0.52293181]\n",
      "\n",
      "# 36 Gradient out:  [1.06548816 1.78812636 1.81996848 0.46985961 0.31448462 0.62102265\n",
      " 1.58539283 0.31800188 1.83879746 1.4353405 ]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.1763593  -0.0081225  -0.45745378  0.04319147  0.14787767  0.00487618\n",
      "  0.28468784  0.77074392 -0.23146799  0.28287657]\n",
      "\n",
      "# 37 Gradient out:  [-0.74368868 -1.19861267 -1.23382665 -0.3950331  -0.23823433 -0.50373374\n",
      " -1.02854602 -0.24232913 -1.25557973 -0.9357487 ]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [ 0.03673833  0.34950277 -0.09346008  0.13716339  0.21077459  0.12908071\n",
      "  0.6017664   0.8343443   0.1362915   0.56994467]\n",
      "\n",
      "# 38 Gradient out:  [-0.72791472 -1.12163593 -1.16662059 -0.45072094 -0.25902391 -0.55700311\n",
      " -0.9352427  -0.26443999 -1.19512331 -0.85666879]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.1119994   0.10978024 -0.34022541  0.05815677  0.16312773  0.02833396\n",
      "  0.3960572   0.78587847 -0.11482445  0.38279493]\n",
      "\n",
      "# 39 Gradient out:  [2.0843251  3.20235303 3.27590399 1.20163267 0.86914451 1.4530754\n",
      " 2.82830604 0.87798564 3.32198733 2.59966421]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.25758235 -0.11454695 -0.57354953 -0.03198742  0.11132294 -0.08306666\n",
      "  0.20900866  0.73299047 -0.35384911  0.21146117]\n",
      "\n",
      "# 40 Gradient out:  [-0.19750945 -0.31256338 -0.32146412 -0.10928059 -0.06967654 -0.13671193\n",
      " -0.26966586 -0.07071621 -0.32697577 -0.24620864]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [0.15928267 0.52592366 0.08163127 0.20833911 0.28515185 0.20754842\n",
      " 0.77466987 0.9085876  0.31054835 0.73139401]\n",
      "\n",
      "# 41 Gradient out:  [-0.31971551 -0.5102178  -0.52491145 -0.17358186 -0.10815603 -0.21900019\n",
      " -0.43924472 -0.10986882 -0.53399958 -0.40039176]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [0.11978078 0.46341098 0.01733845 0.18648299 0.27121654 0.18020603\n",
      " 0.7207367  0.89444436 0.2451532  0.68215228]\n",
      "\n",
      "# 42 Gradient out:  [-0.65577298 -1.05812569 -1.08919686 -0.34727703 -0.2088862  -0.44334619\n",
      " -0.90792596 -0.21249917 -1.10838952 -0.82584507]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [ 0.05583768  0.36136742 -0.08764384  0.15176662  0.24958533  0.13640599\n",
      "  0.63288775  0.8724706   0.13835328  0.60207393]\n",
      "\n",
      "# 43 Gradient out:  [-1.15107886 -1.83231448 -1.89393507 -0.64395981 -0.37489149 -0.81414659\n",
      " -1.55375691 -0.38217853 -1.93246058 -1.41587087]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.07531691  0.14974228 -0.30548322  0.08231122  0.20780809  0.04773675\n",
      "  0.45130256  0.82997076 -0.08332462  0.43690492]\n",
      "\n",
      "# 44 Gradient out:  [1.83804962 2.67306657 2.73537793 1.18960385 0.91399933 1.38150639\n",
      " 2.37762627 0.92175266 2.77527889 2.20817957]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.30553269 -0.21672061 -0.68427023 -0.04648074  0.13282979 -0.11509256\n",
      "  0.14055118  0.75353506 -0.46981674  0.15373074]\n",
      "\n",
      "# 45 Gradient out:  [-0.75252085 -1.22437292 -1.26086798 -0.39087621 -0.2283272  -0.50364719\n",
      " -1.0479716  -0.23256725 -1.28340107 -0.95170436]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [ 0.06207724  0.3178927  -0.13719465  0.19144003  0.31562966  0.16120871\n",
      "  0.61607643  0.93788559  0.08523904  0.59536666]\n",
      "\n",
      "# 46 Gradient out:  [-0.63218212 -0.92436336 -0.96525668 -0.43853017 -0.2677582  -0.52289455\n",
      " -0.76726017 -0.27282334 -0.99163554 -0.71002332]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.08842693  0.07301812 -0.38936824  0.11326478  0.26996422  0.06047928\n",
      "  0.40648211  0.89137214 -0.17144117  0.40502578]\n",
      "\n",
      "# 47 Gradient out:  [1.88086509 2.97917215 3.0478328  1.00829733 0.69508494 1.25308241\n",
      " 2.61996561 0.70323198 3.09049541 2.39475811]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [-0.21486336 -0.11185455 -0.58241958  0.02555875  0.21641258 -0.04409963\n",
      "  0.25303008  0.83680747 -0.36976828  0.26302112]\n",
      "\n",
      "# 48 Gradient out:  [-0.23415509 -0.37539213 -0.38625748 -0.12576846 -0.07736873 -0.15942287\n",
      " -0.32284043 -0.07863451 -0.39297524 -0.29403034]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [0.16130966 0.48397988 0.02714698 0.22721821 0.35542957 0.20651685\n",
      " 0.7770232  0.97745387 0.2483308  0.74197274]\n",
      "\n",
      "# 49 Gradient out:  [-0.41258005 -0.66677275 -0.68629908 -0.21749796 -0.13047333 -0.27809193\n",
      " -0.57218375 -0.13274372 -0.69835874 -0.52031794]\n",
      "\n",
      "     Weights  out:  [-0.00472406  0.36198082  0.41077054 -0.26171359 -0.45968372 -0.16959792\n",
      "  0.19344804 -0.45246237  0.44552949  0.12355814] [ 0.11447864  0.40890145 -0.05010451  0.20206452  0.33995582  0.17463227\n",
      "  0.71245511  0.96172696  0.16973575  0.68316667]\n",
      "\n",
      "Tanh error cuadrático medio (ECM): 0.9006872175945636\n",
      "\n",
      "# 0 Gradient out:  [3.53100128 3.0226318  2.67498964 3.50737449 1.03914285 1.12492485\n",
      " 1.96343527 1.01711557 3.59692896 0.98056061]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [-2.16737849e-01  3.94132752e-01 -2.73133533e-01 -1.61651644e-01\n",
      "  4.09764040e-01  7.30256177e-02 -4.89744758e-01 -5.34220178e-02\n",
      " -1.41648318e-01  3.22957699e-04]\n",
      "\n",
      "# 1 Gradient out:  [-12.25038922 -10.39320141  -9.22971116 -12.15719918  -3.22560502\n",
      "  -3.61422294  -6.8725564   -3.12587491 -12.51516241  -2.96163875]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [ 0.48946241  0.99865911  0.26186439  0.53982325  0.61759261  0.29801059\n",
      " -0.0970577   0.1500011   0.57773747  0.19643508]\n",
      "\n",
      "# 2 Gradient out:  [42.11732145 35.80744604 31.75218524 41.80732407 11.38280626 12.62958318\n",
      " 23.51110844 11.06292765 42.99384783 10.53531176]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [-1.96061544 -1.07998117 -1.58407784 -1.89161658 -0.02752839 -0.424834\n",
      " -1.47156898 -0.47517389 -1.92529501 -0.39589267]\n",
      "\n",
      "# 3 Gradient out:  [-145.04718252 -123.25463355 -109.35361831 -143.96974409  -38.97074963\n",
      "  -43.35310376  -81.12936195  -37.84621623 -148.09813262  -35.99218594]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [6.46284885 6.08150804 4.76635921 6.46984823 2.24903286 2.10108263\n",
      " 3.23065271 1.73741164 6.67347456 1.71116968]\n",
      "\n",
      "# 4 Gradient out:  [499.38082489 424.40365986 376.472012   495.68074268 134.35455408\n",
      " 149.35456649 279.12725433 130.50572031 509.85376243 124.15939069]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [-22.54658765 -18.56941867 -17.10436445 -22.32410059  -5.54511707\n",
      "  -6.56953812 -12.99521969  -5.8318316  -22.94615197  -5.48726751]\n",
      "\n",
      "# 5 Gradient out:  [-1719.37933977 -1461.18670754 -1296.23443952 -1706.63078151\n",
      "  -462.43879585  -514.1715928   -961.25728109  -449.16444974\n",
      " -1755.46815855  -427.27709084]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [77.32957733 66.3113133  58.19003795 76.81204795 21.32579375 23.30137518\n",
      " 42.83023118 20.26931246 79.02460052 19.34461063]\n",
      "\n",
      "# 6 Gradient out:  [5919.85061423 5030.92816933 4462.91334314 5875.96597195 1592.30415664\n",
      " 1770.33399996 3309.39026861 1546.62302692 6044.07539863 1471.30122906]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [-266.54629063 -225.92602821 -201.05684996 -264.51410835  -71.16196542\n",
      "  -79.53294338 -149.42122504  -69.56357749 -272.06903119  -66.11080754]\n",
      "\n",
      "# 7 Gradient out:  [-20382.10812266 -17321.50409822 -15365.90761672 -20231.00417389\n",
      "  -5482.2203469   -6095.26564357 -11394.51307681  -5324.91713818\n",
      " -20809.84445728  -5065.54673379]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [917.42383222 780.25960566 691.52581867 910.67908604 247.29886591\n",
      " 274.53385661 512.45682869 239.7610279  936.74604854 228.14943828]\n",
      "\n",
      "# 8 Gradient out:  [70175.87822553 59638.20799317 52904.97562618 69655.63377543\n",
      " 18875.44432017 20986.08130962 39231.20746228 18333.86975662\n",
      " 71648.55159584 17440.8904853 ]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [-3158.99779231 -2684.04121399 -2381.65570467 -3135.52174874\n",
      "  -849.14520347  -944.5192721  -1766.44578667  -825.22239974\n",
      " -3225.22284292  -784.95990848]\n",
      "\n",
      "# 9 Gradient out:  [-241616.42327316 -205335.06429184 -182152.54984294 -239825.20673513\n",
      "  -64988.31718636  -72255.35279435 -135073.80130594  -63123.64671733\n",
      " -246686.88444819  -60049.07142743]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [10876.17785279  9243.60038464  8199.33942057 10795.60500634\n",
      "  2925.94366056  3252.69698982  6079.79570578  2841.55155158\n",
      " 11104.48747625  2703.21818858]\n",
      "\n",
      "# 10 Gradient out:  [831888.46410993 706971.30404974 627153.51781752 825721.2907785\n",
      " 223755.67908947 248776.09054504 465060.57071469 217335.61704979\n",
      " 849346.09920557 206749.85110925]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [-37447.10680184 -31823.41247372 -28231.17054802 -37169.43634068\n",
      " -10071.71977671 -11198.37356905 -20934.96455541  -9783.17779188\n",
      " -38232.88941339  -9306.59609691]\n",
      "\n",
      "# 11 Gradient out:  [-2864202.59843647 -2434111.19630188 -2159297.63033492 -2842968.93368535\n",
      "  -770393.60106119  -856539.28277678 -1601209.75490344  -748289.22311199\n",
      " -2924309.4868653   -711842.2594743 ]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [128930.58602015 109570.84833622  97199.53301548 127974.82181502\n",
      "  34679.41604118  38556.84453996  72077.14958753  33683.94561808\n",
      " 131636.33042772  32043.37412494]\n",
      "\n",
      "# 12 Gradient out:  [ 9861486.23100371  8380676.04969346  7434489.33094174  9788378.45952184\n",
      "  2652475.0882821   2949075.68817577  5512985.41644715  2576369.45426738\n",
      " 10068434.9898491   2450882.12800285]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [-443909.93366714 -377251.39092415 -334659.9930515  -440618.96492205\n",
      " -119399.30417106 -132751.0120154  -248164.80139316 -115973.89900432\n",
      " -453225.56694534 -110325.07776992]\n",
      "\n",
      "# 13 Gradient out:  [-33953223.25929871 -28854774.83579242 -25597041.949607\n",
      " -33701512.25858288  -9132505.61527805 -10153705.36081833\n",
      " -18981279.60104022  -8870472.92134441 -34665750.51141659\n",
      "  -8438418.41526115]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [1528387.3125336  1298883.81901454 1152237.87313685 1517056.72698232\n",
      "  411095.71348536  457064.12561976  854432.28189627  399299.99184915\n",
      " 1560461.43102448  379851.34783065]\n",
      "\n",
      "# 14 Gradient out:  [1.16901382e+08 9.93473591e+07 8.81309430e+07 1.16034738e+08\n",
      " 3.14433338e+07 3.49593375e+07 6.53527883e+07 3.05411519e+07\n",
      " 1.19354623e+08 2.90535827e+07]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [-5262257.33932614 -4472071.14814395 -3967170.51678455 -5223245.72473426\n",
      " -1415405.40957024 -1573676.94654391 -2941823.63831177 -1374794.59241973\n",
      " -5372688.67125884 -1307832.33522158]\n",
      "\n",
      "# 15 Gradient out:  [-4.02492955e+08 -3.42054229e+08 -3.03435964e+08 -3.99509088e+08\n",
      " -1.08259800e+08 -1.20365446e+08 -2.25010487e+08 -1.05153577e+08\n",
      " -4.10939493e+08 -1.00031857e+08]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [18118019.10428946 15397400.66566174 13659018.07461454 17983701.88113375\n",
      "  4873261.34205432  5418190.54667676 10128734.02342947  4733435.77991974\n",
      " 18498235.85643001  4502884.20558214]\n",
      "\n",
      "# 16 Gradient out:  [1.38578839e+09 1.17769709e+09 1.04473391e+09 1.37551490e+09\n",
      " 3.72739878e+08 4.14419772e+08 7.74713985e+08 3.62045110e+08\n",
      " 1.41486993e+09 3.44410964e+08]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [-62380571.8839716  -53013445.05046756 -47028174.81838192\n",
      " -61918115.6990824  -16778698.74984781 -18654898.71430288\n",
      " -34873363.3239307  -16297279.54463994 -63689662.76954196\n",
      " -15503487.18253657]\n",
      "\n",
      "# 17 Gradient out:  [-4.77128718e+09 -4.05482614e+09 -3.59703222e+09 -4.73591541e+09\n",
      " -1.28334817e+09 -1.42685258e+09 -2.66735016e+09 -1.24652595e+09\n",
      " -4.87141529e+09 -1.18581136e+09]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [2.14777107e+08 1.82525972e+08 1.61918607e+08 2.13184865e+08\n",
      " 5.77692769e+07 6.42290557e+07 1.20069434e+08 5.61117425e+07\n",
      " 2.19284324e+08 5.33787056e+07]\n",
      "\n",
      "# 18 Gradient out:  [1.64276028e+10 1.39608183e+10 1.23846280e+10 1.63058174e+10\n",
      " 4.41858418e+09 4.91267169e+09 9.18372075e+09 4.29180479e+09\n",
      " 1.67723452e+10 4.08276367e+09]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [-7.39480328e+08 -6.28439256e+08 -5.57487837e+08 -7.33998217e+08\n",
      " -1.98900357e+08 -2.21141460e+08 -4.13400599e+08 -1.93193447e+08\n",
      " -7.54998734e+08 -1.83783566e+08]\n",
      "\n",
      "# 19 Gradient out:  [-5.65604467e+10 -4.80672760e+10 -4.26404325e+10 -5.61411379e+10\n",
      " -1.52132419e+10 -1.69143915e+10 -3.16196681e+10 -1.47767388e+10\n",
      " -5.77473991e+10 -1.40570076e+10]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [2.54604023e+09 2.16372440e+09 1.91943775e+09 2.52716526e+09\n",
      " 6.84816478e+08 7.61392877e+08 1.42334355e+09 6.65167511e+08\n",
      " 2.59947030e+09 6.32769169e+08]\n",
      "\n",
      "# 20 Gradient out:  [1.94738342e+11 1.65496246e+11 1.46811555e+11 1.93294656e+11\n",
      " 5.23793864e+10 5.82364663e+10 1.08866922e+11 5.08765008e+10\n",
      " 1.98825034e+11 4.83984569e+10]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [-8.76604911e+09 -7.44973080e+09 -6.60864875e+09 -8.70106232e+09\n",
      " -2.35783190e+09 -2.62148542e+09 -4.90059006e+09 -2.29018025e+09\n",
      " -8.95000951e+09 -2.17863234e+09]\n",
      "\n",
      "# 21 Gradient out:  [-6.70486603e+11 -5.69805694e+11 -5.05474062e+11 -6.65515975e+11\n",
      " -1.80342898e+11 -2.00508899e+11 -3.74830205e+11 -1.75168443e+11\n",
      " -6.84557137e+11 -1.66636507e+11]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [3.01816193e+10 2.56495185e+10 2.27536622e+10 2.99578689e+10\n",
      " 8.11804539e+09 9.02580785e+09 1.68727943e+10 7.88511991e+09\n",
      " 3.08149973e+10 7.50105904e+09]\n",
      "\n",
      "# 22 Gradient out:  [2.30849395e+12 1.96184830e+12 1.74035367e+12 2.29138002e+12\n",
      " 6.20922905e+11 6.90354705e+11 1.29054519e+12 6.03107192e+11\n",
      " 2.35693898e+12 5.73731625e+11]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [-1.03915701e+11 -8.83116204e+10 -7.83411502e+10 -1.03145326e+11\n",
      " -2.79505342e+10 -3.10759719e+10 -5.80932467e+10 -2.71485688e+10\n",
      " -1.06096430e+11 -2.58262423e+10]\n",
      "\n",
      "# 23 Gradient out:  [-7.94817423e+12 -6.75466880e+12 -5.99205994e+12 -7.88925072e+12\n",
      " -2.13784551e+12 -2.37690008e+12 -4.44336361e+12 -2.07650578e+12\n",
      " -8.11497108e+12 -1.97536533e+12]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [3.57783089e+11 3.04058039e+11 2.69729583e+11 3.55130677e+11\n",
      " 9.62340468e+10 1.06994969e+11 2.00015792e+11 9.34728697e+10\n",
      " 3.65291366e+11 8.89200827e+10]\n",
      "\n",
      "# 24 Gradient out:  [2.73656656e+13 2.32564111e+13 2.06307391e+13 2.71627912e+13\n",
      " 7.36062944e+12 8.18369740e+12 1.52985578e+13 7.14943598e+12\n",
      " 2.79399493e+13 6.80120810e+12]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [-1.23185176e+12 -1.04687572e+12 -9.28682405e+11 -1.22271947e+12\n",
      " -3.31335055e+11 -3.68385048e+11 -6.88656931e+11 -3.21828286e+11\n",
      " -1.25770285e+12 -3.06152983e+11]\n",
      "\n",
      "# 25 Gradient out:  [-9.42203368e+13 -8.00721210e+13 -7.10318986e+13 -9.35218377e+13\n",
      " -2.53427414e+13 -2.81765749e+13 -5.26731302e+13 -2.46155996e+13\n",
      " -9.61976029e+13 -2.34166465e+13]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [4.24128136e+12 3.60440650e+12 3.19746541e+12 4.20983877e+12\n",
      " 1.14079083e+12 1.26835443e+12 2.37105463e+12 1.10805891e+12\n",
      " 4.33028700e+12 1.05408864e+12]\n",
      "\n",
      "# 26 Gradient out:  [3.24401825e+14 2.75689337e+14 2.44563736e+14 3.21996884e+14\n",
      " 8.72553828e+13 9.70123079e+13 1.81354261e+14 8.47518243e+13\n",
      " 3.31209578e+14 8.06238136e+13]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [-1.46027860e+13 -1.24100177e+13 -1.10089143e+13 -1.44945288e+13\n",
      " -3.92775744e+12 -4.36696054e+12 -8.16357142e+12 -3.81506100e+12\n",
      " -1.49092336e+13 -3.62924067e+12]\n",
      "\n",
      "# 27 Gradient out:  [-1.11691964e+15 -9.49201917e+14 -8.42036072e+14 -1.10863939e+15\n",
      " -3.00421400e+14 -3.34014618e+14 -6.24405043e+14 -2.91801616e+14\n",
      " -1.14035881e+15 -2.77588822e+14]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [5.02775790e+13 4.27278498e+13 3.79038329e+13 4.99048480e+13\n",
      " 1.35233191e+13 1.50355010e+13 2.81072809e+13 1.31353039e+13\n",
      " 5.13326820e+13 1.24955221e+13]\n",
      "\n",
      "# 28 Gradient out:  [3.84556860e+15 3.26811435e+15 2.89914097e+15 3.81705961e+15\n",
      " 1.03435472e+15 1.15001660e+15 2.14983455e+15 1.00467670e+15\n",
      " 3.92626999e+15 9.55741867e+14]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [-1.73106348e+14 -1.47112534e+14 -1.30503382e+14 -1.71823030e+14\n",
      " -4.65609608e+13 -5.17674225e+13 -9.67737277e+13 -4.52250193e+13\n",
      " -1.76739081e+14 -4.30222423e+13]\n",
      "\n",
      "# 29 Gradient out:  [-1.32403419e+16 -1.12521595e+16 -9.98177947e+15 -1.31421851e+16\n",
      " -3.56129655e+15 -3.95952188e+15 -7.40190788e+15 -3.45911472e+15\n",
      " -1.35181978e+16 -3.29063148e+15]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [5.96007372e+14 5.06510336e+14 4.49324813e+14 5.91588892e+14\n",
      " 1.60309984e+14 1.78235898e+14 3.33193183e+14 1.55710320e+14\n",
      " 6.08514917e+14 1.48126131e+14]\n",
      "\n",
      "# 30 Gradient out:  [4.55866666e+16 3.87413292e+16 3.43673944e+16 4.52487115e+16\n",
      " 1.22615896e+16 1.36326845e+16 2.54848635e+16 1.19097763e+16\n",
      " 4.65433281e+16 1.13296863e+16]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [-2.05206101e+15 -1.74392157e+15 -1.54703108e+15 -2.03684813e+15\n",
      " -5.51949326e+14 -6.13668478e+14 -1.14718839e+15 -5.36112625e+14\n",
      " -2.09512465e+15 -5.10000164e+14]\n",
      "\n",
      "# 31 Gradient out:  [-1.56955476e+17 -1.33386892e+17 -1.18327379e+17 -1.55791893e+17\n",
      " -4.22168099e+16 -4.69375072e+16 -8.77447113e+16 -4.10055121e+16\n",
      " -1.60249274e+17 -3.90082549e+16]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [7.06527231e+15 6.00434428e+15 5.32644781e+15 7.01289417e+15\n",
      " 1.90036859e+15 2.11286842e+15 3.94978432e+15 1.84584263e+15\n",
      " 7.21354097e+15 1.75593709e+15]\n",
      "\n",
      "# 32 Gradient out:  [5.40399714e+17 4.59252777e+17 4.07402680e+17 5.36393480e+17\n",
      " 1.45353017e+17 1.61606438e+17 3.02106164e+17 1.41182503e+17\n",
      " 5.51740302e+17 1.34305921e+17]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [-2.43258230e+16 -2.06730342e+16 -1.83390280e+16 -2.41454844e+16\n",
      " -6.54299339e+15 -7.27463302e+15 -1.35991579e+16 -6.35525979e+15\n",
      " -2.48363139e+16 -6.04571388e+15]\n",
      "\n",
      "# 33 Gradient out:  [-1.86060313e+18 -1.58121319e+18 -1.40269264e+18 -1.84680962e+18\n",
      " -5.00452297e+17 -5.56413034e+17 -1.04015539e+18 -4.86093164e+17\n",
      " -1.89964892e+18 -4.62417004e+17]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [8.37541198e+16 7.11775212e+16 6.31415080e+16 8.31332117e+16\n",
      " 2.25276100e+16 2.50466546e+16 4.68220748e+16 2.18812408e+16\n",
      " 8.55117465e+16 2.08154703e+16]\n",
      "\n",
      "# 34 Gradient out:  [6.40608039e+18 5.44413724e+18 4.82948871e+18 6.35858914e+18\n",
      " 1.72306366e+18 1.91573720e+18 3.58126831e+18 1.67362498e+18\n",
      " 6.54051554e+18 1.59210766e+18]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [-2.88366506e+17 -2.45065116e+17 -2.17397020e+17 -2.86228712e+17\n",
      " -7.75628494e+16 -8.62359522e+16 -1.61209003e+17 -7.53373920e+16\n",
      " -2.94418038e+17 -7.16679305e+16]\n",
      "\n",
      "# 35 Gradient out:  [-2.20562168e+19 -1.87442342e+19 -1.66279914e+19 -2.18927038e+19\n",
      " -5.93253024e+18 -6.59590768e+18 -1.23303526e+19 -5.76231224e+18\n",
      " -2.25190787e+19 -5.48164705e+18]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [9.92849572e+17 8.43762332e+17 7.48500722e+17 9.85489117e+17\n",
      " 2.67049883e+17 2.96911487e+17 5.55044660e+17 2.59387605e+17\n",
      " 1.01368507e+18 2.46753602e+17]\n",
      "\n",
      "# 36 Gradient out:  [7.59398366e+19 6.45366382e+19 5.72503873e+19 7.53768593e+19\n",
      " 2.04257775e+19 2.27097946e+19 4.24535619e+19 1.98397148e+19\n",
      " 7.75334762e+19 1.88733810e+19]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [-3.41839378e+18 -2.90508451e+18 -2.57709756e+18 -3.39305164e+18\n",
      " -9.19456165e+17 -1.02227005e+18 -1.91102587e+18 -8.93074843e+17\n",
      " -3.49013067e+18 -8.49575809e+17]\n",
      "\n",
      "# 37 Gradient out:  [-2.61461829e+20 -2.22200471e+20 -1.97113816e+20 -2.59523491e+20\n",
      " -7.03262134e+19 -7.81901133e+19 -1.46168157e+20 -6.83083919e+19\n",
      " -2.66948751e+20 -6.49812921e+19]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [1.17695735e+19 1.00022431e+19 8.87297989e+18 1.16823202e+19\n",
      " 3.16569934e+18 3.51968886e+18 6.57968652e+18 3.07486811e+18\n",
      " 1.20165646e+19 2.92510038e+18]\n",
      "\n",
      "# 38 Gradient out:  [9.00216424e+20 7.65039066e+20 6.78665391e+20 8.93542701e+20\n",
      " 2.42134053e+20 2.69209561e+20 5.03258835e+20 2.35186667e+20\n",
      " 9.19107965e+20 2.23731420e+20]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [-4.05227923e+19 -3.44378511e+19 -3.05497833e+19 -4.02223780e+19\n",
      " -1.08995433e+19 -1.21183338e+19 -2.26539449e+19 -1.05868103e+19\n",
      " -4.13731856e+19 -1.00711580e+19]\n",
      "\n",
      "# 39 Gradient out:  [-3.09945667e+21 -2.63403929e+21 -2.33665363e+21 -3.07647896e+21\n",
      " -8.33670642e+20 -9.26891963e+20 -1.73272661e+21 -8.09750705e+20\n",
      " -3.16450049e+21 -7.70310144e+20]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [1.39520492e+20 1.18569962e+20 1.05183295e+20 1.38486162e+20\n",
      " 3.75272672e+19 4.17235783e+19 7.79978221e+19 3.64505232e+19\n",
      " 1.42448407e+20 3.46751260e+19]\n",
      "\n",
      "# 40 Gradient out:  [1.06714690e+22 9.06903100e+21 8.04512834e+21 1.05923564e+22\n",
      " 2.87033869e+21 3.19130089e+21 5.96579989e+21 2.78798204e+21\n",
      " 1.08954157e+22 2.65218768e+21]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [-4.80370841e+20 -4.08237897e+20 -3.62147430e+20 -4.76809629e+20\n",
      " -1.29206861e+20 -1.43654814e+20 -2.68547500e+20 -1.25499618e+20\n",
      " -4.90451690e+20 -1.19386903e+20]\n",
      "\n",
      "# 41 Gradient out:  [-3.67420042e+22 -3.12247898e+22 -2.76994798e+22 -3.64696187e+22\n",
      " -9.88261284e+21 -1.09876898e+22 -2.05403254e+22 -9.59905784e+21\n",
      " -3.75130556e+22 -9.13151613e+21]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [1.65392295e+21 1.40556830e+21 1.24687824e+21 1.64166165e+21\n",
      " 4.44860877e+20 4.94605364e+20 9.24612478e+20 4.32096790e+20\n",
      " 1.68863144e+21 4.11050634e+20]\n",
      "\n",
      "# 42 Gradient out:  [1.26503191e+23 1.07507351e+23 9.53696635e+22 1.25565364e+23\n",
      " 3.40259625e+22 3.78307566e+22 7.07206031e+22 3.30496790e+22\n",
      " 1.29157930e+23 3.14399269e+22]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [-5.69447789e+21 -4.83938965e+21 -4.29301773e+21 -5.65226208e+21\n",
      " -1.53166169e+21 -1.70293260e+21 -3.18345259e+21 -1.48771478e+21\n",
      " -5.81397967e+21 -1.41525259e+21]\n",
      "\n",
      "# 43 Gradient out:  [-4.35552104e+23 -3.70149185e+23 -3.28358972e+23 -4.32323155e+23\n",
      " -1.17151824e+23 -1.30251779e+23 -2.43491941e+23 -1.13790468e+23\n",
      " -4.44692407e+23 -1.08248071e+23]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [1.96061603e+22 1.66620805e+22 1.47809150e+22 1.94608107e+22\n",
      " 5.27353081e+21 5.86321872e+21 1.09606680e+22 5.12222102e+21\n",
      " 2.00176064e+22 4.87273279e+21]\n",
      "\n",
      "# 44 Gradient out:  [1.49961147e+24 1.27442838e+24 1.13054414e+24 1.48849415e+24\n",
      " 4.03355230e+23 4.48458542e+23 8.38345870e+23 3.91782037e+23\n",
      " 1.53108165e+24 3.72699492e+23]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [-6.75042606e+22 -5.73677564e+22 -5.08908794e+22 -6.70038202e+22\n",
      " -1.81568340e+22 -2.01871371e+22 -3.77377203e+22 -1.76358725e+22\n",
      " -6.89208750e+22 -1.67768813e+22]\n",
      "\n",
      "# 45 Gradient out:  [-5.16318148e+24 -4.38787322e+24 -3.89247795e+24 -5.12490442e+24\n",
      " -1.38875722e+24 -1.54404850e+24 -2.88643556e+24 -1.34891057e+24\n",
      " -5.27153371e+24 -1.28320912e+24]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [2.32418033e+23 1.97517920e+23 1.75217949e+23 2.30695011e+23\n",
      " 6.25142120e+22 6.95045713e+22 1.29931454e+23 6.07205348e+22\n",
      " 2.37295455e+23 5.77630171e+22]\n",
      "\n",
      "# 46 Gradient out:  [1.77768999e+25 1.51075036e+25 1.34018514e+25 1.76451115e+25\n",
      " 4.78150888e+24 5.31617874e+24 9.93803457e+24 4.64431634e+24\n",
      " 1.81499580e+25 4.41810543e+24]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [-8.00218263e+23 -6.80056725e+23 -6.03277641e+23 -7.94285873e+23\n",
      " -2.15237232e+23 -2.39305129e+23 -4.47355658e+23 -2.09061578e+23\n",
      " -8.17011287e+23 -1.98878807e+23]\n",
      "\n",
      "# 47 Gradient out:  [-6.12060939e+25 -5.20153284e+25 -4.61427459e+25 -6.07523447e+25\n",
      " -1.64627963e+25 -1.83036714e+25 -3.42167802e+25 -1.59904406e+25\n",
      " -6.24905378e+25 -1.52115935e+25]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [2.75516172e+24 2.34144401e+24 2.07709264e+24 2.73473643e+24\n",
      " 7.41064544e+23 8.23930620e+23 1.54025126e+24 7.19801690e+23\n",
      " 2.81298032e+24 6.84742278e+23]\n",
      "\n",
      "# 48 Gradient out:  [2.10733365e+26 1.79089441e+26 1.58870064e+26 2.09171100e+26\n",
      " 5.66816182e+25 6.30197750e+25 1.17808812e+26 5.50552916e+25\n",
      " 2.15155721e+26 5.23737112e+25]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [-9.48605706e+24 -8.06162167e+24 -7.15145653e+24 -9.41573251e+24\n",
      " -2.55149471e+24 -2.83680367e+24 -5.30310478e+24 -2.47828643e+24\n",
      " -9.68512723e+24 -2.35757643e+24]\n",
      "\n",
      "# 49 Gradient out:  [-7.25557671e+26 -6.16607238e+26 -5.46991665e+26 -7.20178775e+26\n",
      " -1.95155537e+26 -2.16977892e+26 -4.05617248e+26 -1.89556073e+26\n",
      " -7.40783901e+26 -1.80323358e+26]\n",
      "\n",
      "     Weights  out:  [ 0.23157413  0.10196362  0.03371848  0.2239712  -0.43100631 -0.37505156\n",
      " -0.10202429 -0.44731045  0.25414328 -0.47636155] [3.26606158e+25 2.77562666e+25 2.46225564e+25 3.24184875e+25\n",
      " 8.78482893e+24 9.76715134e+24 1.82586576e+25 8.53277189e+24\n",
      " 3.33460170e+25 8.11716581e+24]\n",
      "\n",
      "Lineal error cuadrático medio (ECM): 1.536458432423578e+53\n",
      "\n",
      "# 0 Gradient out:  [-2.03320835 -1.01340036 -1.77347791 -0.43650048 -1.26113626 -0.55940801\n",
      " -1.19755492 -0.38031225 -0.4169449  -1.90550725]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [ 0.18108025  0.36305317  0.33909016 -0.47424223 -0.47663715  0.20770724\n",
      "  0.16443593  0.26551597  0.26422516  0.49847735]\n",
      "\n",
      "# 1 Gradient out:  [3.48700436 1.90575196 3.16481321 1.06607469 2.34940007 1.21731415\n",
      " 2.23474364 0.99789248 1.04245786 3.33116489]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [-0.22556141  0.1603731  -0.01560542 -0.56154232 -0.7288644   0.09582564\n",
      " -0.07507506  0.18945352  0.18083618  0.1173759 ]\n",
      "\n",
      "# 2 Gradient out:  [-0.49211381 -0.26633962 -0.43508267 -0.1395053  -0.32179377 -0.16636915\n",
      " -0.30754941 -0.12709203 -0.13520092 -0.46388736]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [ 0.47183946  0.54152349  0.61735722 -0.34832738 -0.25898439  0.33928847\n",
      "  0.37187367  0.38903202  0.38932775  0.78360888]\n",
      "\n",
      "# 3 Gradient out:  [-0.86984921 -0.46139902 -0.76690184 -0.23185532 -0.56177825 -0.28039306\n",
      " -0.53599508 -0.20948808 -0.22409331 -0.81898966]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [ 0.3734167   0.48825557  0.53034069 -0.37622844 -0.32334314  0.30601464\n",
      "  0.31036379  0.36361361  0.36228757  0.69083141]\n",
      "\n",
      "# 4 Gradient out:  [-1.86088103 -0.94602652 -1.62870489 -0.42978228 -1.16920572 -0.53948481\n",
      " -1.11190942 -0.37946149 -0.41228997 -1.74649276]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [ 0.19944685  0.39597577  0.37696032 -0.42259951 -0.43569879  0.24993603\n",
      "  0.20316477  0.32171599  0.3174689   0.52703347]\n",
      "\n",
      "# 5 Gradient out:  [2.55505323 1.40516107 2.34453269 0.80880761 1.74448028 0.90758496\n",
      " 1.65660673 0.76510815 0.79366082 2.45487242]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [-0.17272935  0.20677046  0.05121934 -0.50855596 -0.66953994  0.14203906\n",
      " -0.01921711  0.2458237   0.23501091  0.17773492]\n",
      "\n",
      "# 6 Gradient out:  [-0.91802188 -0.4814418  -0.80813196 -0.2360978  -0.58879945 -0.28792411\n",
      " -0.56122366 -0.21223827 -0.22781587 -0.86376844]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [ 0.33828129  0.48780267  0.52012588 -0.34679444 -0.32064388  0.32355606\n",
      "  0.31210424  0.39884533  0.39374308  0.66870941]\n",
      "\n",
      "# 7 Gradient out:  [-1.96470097 -0.99379871 -1.71669531 -0.44503499 -1.22955229 -0.56219616\n",
      " -1.16904116 -0.39122258 -0.42633255 -1.84238823]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [ 0.15467692  0.39151432  0.35849948 -0.394014   -0.43840377  0.26597124\n",
      "  0.19985951  0.35639767  0.3481799   0.49595572]\n",
      "\n",
      "# 8 Gradient out:  [3.11764505 1.68653152 2.83724872 0.93283938 2.09570638 1.06453218\n",
      " 1.98988033 0.87397095 0.91243187 2.98295772]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [-0.23826328  0.19275457  0.01516042 -0.483021   -0.68431423  0.153532\n",
      " -0.03394873  0.27815316  0.26291339  0.12747808]\n",
      "\n",
      "# 9 Gradient out:  [-0.61169526 -0.32162136 -0.53877648 -0.15871631 -0.39304163 -0.19309553\n",
      " -0.37469522 -0.14287927 -0.15322043 -0.57568204]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [ 0.38526573  0.53006088  0.58261017 -0.29645312 -0.26517296  0.36643844\n",
      "  0.36402734  0.45294735  0.44539977  0.72406962]\n",
      "\n",
      "# 10 Gradient out:  [-1.18971631 -0.61357159 -1.04465745 -0.28958218 -0.75513107 -0.35803208\n",
      " -0.71877317 -0.25811348 -0.2786542  -1.11816323]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [ 0.26292668  0.46573661  0.47485487 -0.32819639 -0.34378128  0.32781933\n",
      "  0.2890883   0.42437149  0.41475568  0.60893321]\n",
      "\n",
      "# 11 Gradient out:  [-2.02458296 -1.0096231  -1.74903385 -0.42635303 -1.24470619 -0.55646483\n",
      " -1.18450883 -0.36604193 -0.40540915 -1.88764787]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [ 0.02498342  0.34302229  0.26592338 -0.38611282 -0.49480749  0.25621292\n",
      "  0.14533366  0.3727488   0.35902484  0.38530056]\n",
      "\n",
      "# 12 Gradient out:  [3.44535364 1.90763025 3.11093421 1.08135732 2.32559157 1.23774698\n",
      " 2.21769794 1.0093874  1.05651879 3.28107363]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [-0.37993317  0.14109767 -0.08388339 -0.47138343 -0.74374873  0.14491995\n",
      " -0.0915681   0.29954041  0.27794301  0.00777099]\n",
      "\n",
      "# 13 Gradient out:  [-0.77175347 -0.39698441 -0.67781058 -0.18651294 -0.48936852 -0.23083593\n",
      " -0.46563684 -0.16614147 -0.17943925 -0.72542825]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [ 0.30913755  0.52262372  0.53830345 -0.25511196 -0.27863042  0.39246935\n",
      "  0.35197148  0.50141789  0.48924677  0.66398572]\n",
      "\n",
      "# 14 Gradient out:  [-1.63156398 -0.82611769 -1.42717428 -0.37206081 -1.02281374 -0.46853448\n",
      " -0.972311   -0.32769532 -0.35665164 -1.53070229]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [ 0.15478686  0.44322683  0.40274134 -0.29241455 -0.37650412  0.34630216\n",
      "  0.25884412  0.4681896   0.45335892  0.51890007]\n",
      "\n",
      "# 15 Gradient out:  [0.49239597 0.23109653 0.50433498 0.12823876 0.3487102  0.12318749\n",
      " 0.31786002 0.13357844 0.12997353 0.50382782]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [-0.17152593  0.2780033   0.11730648 -0.36682671 -0.58106687  0.25259527\n",
      "  0.06438192  0.40265054  0.38202859  0.21275961]\n",
      "\n",
      "# 16 Gradient out:  [-1.5553387  -0.79694543 -1.32263278 -0.34706007 -0.95470037 -0.45648589\n",
      " -0.91452519 -0.29505592 -0.32907414 -1.43746425]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [-0.07304674  0.3242226   0.21817348 -0.34117896 -0.51132483  0.27723276\n",
      "  0.12795392  0.42936622  0.4080233   0.31352517]\n",
      "\n",
      "# 17 Gradient out:  [3.46971088 1.88950396 3.13323011 1.04384836 2.32365591 1.20135444\n",
      " 2.21153772 0.97179446 1.01895713 3.30516695]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [-0.38411448  0.16483352 -0.04635308 -0.41059098 -0.70226491  0.18593559\n",
      " -0.05495112  0.37035504  0.34220847  0.02603232]\n",
      "\n",
      "# 18 Gradient out:  [-0.6114391  -0.31212139 -0.53662841 -0.14411864 -0.38604234 -0.17942184\n",
      " -0.3670521  -0.12790792 -0.13848868 -0.57457373]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [ 0.3098277   0.54273431  0.58029294 -0.2018213  -0.23753373  0.42620647\n",
      "  0.38735643  0.56471393  0.54599989  0.68706571]\n",
      "\n",
      "# 19 Gradient out:  [-1.18645257 -0.59901767 -1.03877788 -0.2686781  -0.74344226 -0.33838578\n",
      " -0.7063486  -0.23666812 -0.25755899 -1.11366682]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [ 0.18753988  0.48031003  0.47296726 -0.23064503 -0.31474219  0.3903221\n",
      "  0.31394601  0.53913235  0.51830216  0.57215097]\n",
      "\n",
      "# 20 Gradient out:  [-2.04098206 -1.04277885 -1.76183386 -0.466398   -1.2692363  -0.59774289\n",
      " -1.21129487 -0.40474212 -0.44505198 -1.90102479]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [-0.04975064  0.3605065   0.26521168 -0.28438065 -0.46343065  0.32264495\n",
      "  0.17267629  0.49179873  0.46679036  0.3494176 ]\n",
      "\n",
      "# 21 Gradient out:  [3.36215676 1.86663951 3.03002121 1.06085311 2.26917337 1.21578612\n",
      " 2.16529221 0.98885925 1.03606021 3.19787103]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [-0.45794705  0.15195073 -0.08715509 -0.37766025 -0.71727791  0.20309637\n",
      " -0.06958269  0.4108503   0.37777996 -0.03078735]\n",
      "\n",
      "# 22 Gradient out:  [-0.8634073  -0.43260999 -0.75579211 -0.19068938 -0.53896815 -0.24150242\n",
      " -0.51164648 -0.16739448 -0.18259526 -0.81043246]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [ 0.2144843   0.52527863  0.51884915 -0.16548963 -0.26344323  0.44625359\n",
      "  0.36347575  0.60862215  0.584992    0.60878685]\n",
      "\n",
      "# 23 Gradient out:  [-1.84596663 -0.9238894  -1.60836131 -0.40223542 -1.14666537 -0.51430736\n",
      " -1.08949446 -0.35049946 -0.38427872 -1.7283744 ]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [ 0.04180284  0.43875663  0.36769073 -0.20362751 -0.37123686  0.39795311\n",
      "  0.26114646  0.57514326  0.54847295  0.44670036]\n",
      "\n",
      "# 24 Gradient out:  [2.07010105 0.99083666 1.89240973 0.43714168 1.32056584 0.52170105\n",
      " 1.23510392 0.40193289 0.4247695  1.98918128]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [-0.32739048  0.25397875  0.04601847 -0.28407459 -0.60056994  0.29509164\n",
      "  0.04324757  0.50504337  0.47161721  0.10102548]\n",
      "\n",
      "# 25 Gradient out:  [-1.54873609 -0.77387143 -1.35210078 -0.33705737 -0.96309227 -0.42986344\n",
      " -0.91450913 -0.29437241 -0.32223287 -1.45169262]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [ 0.08662973  0.45214608  0.42450042 -0.19664625 -0.33645677  0.39943185\n",
      "  0.29026835  0.58542994  0.55657111  0.49886174]\n",
      "\n",
      "# 26 Gradient out:  [-0.24765761 -0.20725142 -0.15613087 -0.14206959 -0.16295896 -0.1838741\n",
      " -0.17496014 -0.1187827  -0.13420866 -0.19538588]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [-0.22311749  0.2973718   0.15408026 -0.26405773 -0.52907522  0.31345916\n",
      "  0.10736653  0.52655546  0.49212454  0.20852321]\n",
      "\n",
      "# 27 Gradient out:  [0.90530264 0.38643691 0.86583083 0.14423255 0.57558748 0.16398181\n",
      " 0.52628062 0.13921265 0.14229195 0.893091  ]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [-0.27264901  0.25592151  0.12285409 -0.29247165 -0.56166701  0.27668434\n",
      "  0.0723745   0.50279892  0.4652828   0.16944604]\n",
      "\n",
      "# 28 Gradient out:  [-2.03622583 -1.04292491 -1.75690318 -0.4687718  -1.26733284 -0.60013099\n",
      " -1.20992601 -0.4069875  -0.44739081 -1.89598444]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [-0.09158848  0.33320889  0.29602025 -0.26362514 -0.44654952  0.3094807\n",
      "  0.17763062  0.53064145  0.49374119  0.34806424]\n",
      "\n",
      "# 29 Gradient out:  [3.34785631 1.85670485 3.01585117 1.05300114 2.25758119 1.20782787\n",
      " 2.15413148 0.98097461 1.02820324 3.18350198]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [-0.49883365  0.12462391 -0.05536038 -0.35737949 -0.70001608  0.1894545\n",
      " -0.06435458  0.44924395  0.40426303 -0.03113265]\n",
      "\n",
      "# 30 Gradient out:  [-0.88137394 -0.43987505 -0.77111369 -0.19193744 -0.54888349 -0.24400403\n",
      " -0.5208811  -0.16807438 -0.18364529 -0.82710699]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [ 0.17073761  0.49596488  0.54780985 -0.14677927 -0.24849985  0.43102007\n",
      "  0.36647172  0.64543887  0.60990368  0.60556774]\n",
      "\n",
      "# 31 Gradient out:  [-1.88286769 -0.94119639 -1.63932328 -0.40802821 -1.16812842 -0.52287802\n",
      " -1.1098975  -0.35495668 -0.38961149 -1.762246  ]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [-0.00553717  0.40798987  0.39358711 -0.18516676 -0.35827655  0.38221927\n",
      "  0.2622955   0.611824    0.57317462  0.44014634]\n",
      "\n",
      "# 32 Gradient out:  [2.28615465 1.10251084 2.08069641 0.48987369 1.45713653 0.5873969\n",
      " 1.36528493 0.44849818 0.47537889 2.19121564]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [-0.38211071  0.21975059  0.06572246 -0.2667724  -0.59190223  0.27764366\n",
      "  0.040316    0.54083266  0.49525232  0.08769714]\n",
      "\n",
      "# 33 Gradient out:  [-1.36873677 -0.68174037 -1.19538984 -0.29496885 -0.85015996 -0.37680197\n",
      " -0.80691006 -0.25738209 -0.281912   -1.28327584]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [ 0.07512022  0.44025276  0.48186174 -0.16879766 -0.30047492  0.39512305\n",
      "  0.31337298  0.6305323   0.5903281   0.52594027]\n",
      "\n",
      "# 34 Gradient out:  [-1.4111806  -0.77103186 -1.19167844 -0.38138582 -0.88978726 -0.48379494\n",
      " -0.85972522 -0.33118731 -0.3641384  -1.29750768]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [-0.19862714  0.30390469  0.24278377 -0.22779143 -0.47050691  0.31976265\n",
      "  0.15199097  0.57905588  0.5339457   0.2692851 ]\n",
      "\n",
      "# 35 Gradient out:  [3.28507224 1.74438774 2.95943747 0.92102352 2.16923812 1.07350728\n",
      " 2.05950746 0.8514193  0.89697004 3.1260968 ]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [-0.48086326  0.14969832  0.00444808 -0.3040686  -0.64846437  0.22300366\n",
      " -0.01995407  0.51281842  0.46111802  0.00978357]\n",
      "\n",
      "# 36 Gradient out:  [-0.72872079 -0.362962   -0.6376193  -0.15768158 -0.45343006 -0.20070609\n",
      " -0.43018857 -0.13797593 -0.15083329 -0.68390621]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [ 0.17615119  0.49857587  0.59633558 -0.11986389 -0.21461674  0.43770512\n",
      "  0.39194742  0.68310228  0.64051203  0.63500293]\n",
      "\n",
      "# 37 Gradient out:  [-1.50406792 -0.74680108 -1.31207528 -0.31997556 -0.93182938 -0.41059641\n",
      " -0.88432174 -0.27830898 -0.30550387 -1.40933786]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [ 0.03040703  0.42598347  0.46881172 -0.15140021 -0.30530275  0.3975639\n",
      "  0.30590971  0.65550709  0.61034537  0.49822169]\n",
      "\n",
      "# 38 Gradient out:  [-0.58836232 -0.39223806 -0.45859492 -0.24123417 -0.38741529 -0.30083681\n",
      " -0.38925586 -0.20950505 -0.23047307 -0.51686423]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [-0.27040655  0.27662325  0.20639666 -0.21539532 -0.49166863  0.31544462\n",
      "  0.12904536  0.5998453   0.5492446   0.21635411]\n",
      "\n",
      "# 39 Gradient out:  [1.97691959 0.9320217  1.80892243 0.39774894 1.2537971  0.47784641\n",
      " 1.17037572 0.36475449 0.38613052 1.90103422]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [-0.38807902  0.19817564  0.11467768 -0.26364215 -0.56915169  0.25527726\n",
      "  0.05119419  0.55794429  0.50314998  0.11298127]\n",
      "\n",
      "# 40 Gradient out:  [-1.65025656 -0.82348582 -1.43966435 -0.3570069  -1.02486144 -0.45638538\n",
      " -0.97316352 -0.31125834 -0.34112078 -1.54625432]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [ 0.0073049   0.38457998  0.47646216 -0.18409237 -0.31839227  0.35084654\n",
      "  0.28526933  0.63089518  0.58037609  0.49318811]\n",
      "\n",
      "# 41 Gradient out:  [0.52890506 0.17670051 0.53127284 0.02691468 0.32425564 0.027181\n",
      " 0.28564887 0.03115285 0.02815535 0.53776762]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [-0.32274641  0.21988281  0.18852929 -0.25549375 -0.52336456  0.25956946\n",
      "  0.09063663  0.56864352  0.51215193  0.18393725]\n",
      "\n",
      "# 42 Gradient out:  [-1.45982524 -0.78272412 -1.23610538 -0.37423545 -0.91362018 -0.4788725\n",
      " -0.88041008 -0.32344445 -0.35674853 -1.34477534]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [-0.2169654   0.25522291  0.29478386 -0.25011081 -0.45851343  0.26500566\n",
      "  0.1477664   0.57487409  0.517783    0.29149077]\n",
      "\n",
      "# 43 Gradient out:  [3.35904925 1.79952409 3.0277063  0.96533735 2.22848883 1.12044198\n",
      " 2.1177052  0.89441323 0.9408355  3.19707635]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [-0.50893045  0.09867809  0.04756278 -0.3249579  -0.64123746  0.16923116\n",
      " -0.02831562  0.51018519  0.44643329  0.0225357 ]\n",
      "\n",
      "# 44 Gradient out:  [-0.68442398 -0.34275888 -0.59925142 -0.15100581 -0.42723989 -0.19122111\n",
      " -0.40553643 -0.13257339 -0.14460124 -0.64250521]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [ 0.1628794   0.45858291  0.65310404 -0.13189043 -0.1955397   0.39331956\n",
      "  0.39522542  0.68906784  0.63460039  0.66195097]\n",
      "\n",
      "# 45 Gradient out:  [-1.38585799 -0.68992842 -1.21020436 -0.29810708 -0.86050652 -0.38102722\n",
      " -0.81670261 -0.26001701 -0.28487567 -1.29925316]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [ 0.02599461  0.39003113  0.53325376 -0.16209159 -0.28098767  0.35507534\n",
      "  0.31411814  0.66255316  0.60568015  0.53344993]\n",
      "\n",
      "# 46 Gradient out:  [-1.33676303 -0.73545205 -1.12535983 -0.36671383 -0.84352132 -0.46528557\n",
      " -0.81621744 -0.31821017 -0.35005796 -1.2269592 ]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [-0.25117699  0.25204545  0.29121289 -0.22171301 -0.45308898  0.2788699\n",
      "  0.15077762  0.61054976  0.54870501  0.2735993 ]\n",
      "\n",
      "# 47 Gradient out:  [3.25423702 1.71449894 2.93263063 0.89319365 2.1414367  1.04393668\n",
      " 2.03114657 0.82469126 0.86949986 3.09774345]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [-0.5185296   0.10495504  0.06614092 -0.29505578 -0.62179324  0.18581278\n",
      " -0.01246587  0.54690773  0.47869342  0.02820746]\n",
      "\n",
      "# 48 Gradient out:  [-0.72520142 -0.36145653 -0.63456368 -0.15730125 -0.45140834 -0.20010345\n",
      " -0.42829955 -0.13769221 -0.15048699 -0.68060675]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [ 0.13231781  0.44785483  0.65266705 -0.11641705 -0.1935059   0.39460012\n",
      "  0.39376344  0.71184598  0.65259339  0.64775615]\n",
      "\n",
      "# 49 Gradient out:  [-1.49636124 -0.74302661 -1.30550669 -0.31849964 -0.92719295 -0.40858482\n",
      " -0.87990537 -0.27708494 -0.30411516 -1.40220284]\n",
      "\n",
      "     Weights  out:  [ 0.47570012 -0.07301935  0.26769779 -0.38815023  0.02868017 -0.29777047\n",
      "  0.00272496 -0.44075843 -0.40536949  0.3559941 ] [-0.01272248  0.37556352  0.52575431 -0.1478773  -0.28378757  0.35457943\n",
      "  0.30810353  0.68430754  0.62249599  0.5116348 ]\n",
      "\n",
      "Tanh error cuadrático medio (ECM): 0.4836065683100306\n",
      "\n",
      "# 0 Gradient out:  [2.24427938 1.88643512 0.82648604 1.73403054 2.24812206 2.91492603\n",
      " 1.67112568 0.941721   2.80247951 1.2605339 ]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [ 0.36555788 -0.3062162   0.30784326  0.04549122 -0.2078027  -0.32317114\n",
      " -0.40624981  0.09159911  0.26653392 -0.14656766]\n",
      "\n",
      "# 1 Gradient out:  [ -9.06571483  -7.6123205   -2.6382173   -7.00335093  -9.08189742\n",
      " -12.45278912  -6.74974612  -3.32204556 -11.78538018  -4.98777873]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [ 0.81441376  0.07107083  0.47314047  0.39229732  0.24182171  0.25981407\n",
      " -0.07202467  0.2799433   0.82702982  0.10553912]\n",
      "\n",
      "# 2 Gradient out:  [37.31665854 31.31425623 11.46768154 28.7889328  37.38289827 50.61520506\n",
      " 27.73962273 14.06534739 48.07990603 20.56014414]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [-0.99872921 -1.45139327 -0.05450299 -1.00837286 -1.57455777 -2.23074376\n",
      " -1.42197389 -0.38446581 -1.53004622 -0.89201663]\n",
      "\n",
      "# 3 Gradient out:  [-152.84534167 -128.30288305  -46.44970561 -117.98778922 -153.11677709\n",
      " -207.9186291  -113.69935165  -57.30195994 -197.32700691  -84.24619993]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [6.4646025  4.81145797 2.23903332 4.7494137  5.90202188 7.89229725\n",
      " 4.12595065 2.42860367 8.08593499 3.2200122 ]\n",
      "\n",
      "# 4 Gradient out:  [626.83842237 526.12487113 190.94737562 483.78486316 627.95169274\n",
      " 852.12746934 466.18465589 235.24437671 808.89417919 345.41865293]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [-24.10446584 -20.84911864  -7.0509078  -18.84814414 -24.72133354\n",
      " -33.69142857 -18.61391968  -9.03178832 -31.37946639 -13.62922779]\n",
      "\n",
      "# 5 Gradient out:  [-2569.90992124 -2157.08221345  -782.45229095 -1983.53991518\n",
      " -2574.47385713 -3494.09707245 -1911.39816018  -964.26771131\n",
      " -3316.64781025 -1416.27478616]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [101.26321864  84.37585559  31.13856732  77.90882849 100.86900501\n",
      " 136.7340653   74.6230115   38.01708702 130.39936945  55.4545028 ]\n",
      "\n",
      "# 6 Gradient out:  [10536.97131949  8844.23280458  3208.50332581  8132.63779371\n",
      " 10555.68444537 14325.73436285  7836.82926593  3953.76619399\n",
      " 13598.36817521  5806.75047121]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [-412.71876561 -347.0405871  -125.35189087 -318.79915455 -414.02576641\n",
      " -562.08534919 -307.65662054 -154.83645524 -532.93019261 -227.80045444]\n",
      "\n",
      "# 7 Gradient out:  [-43202.09160614 -36261.8826462  -13154.71303906 -33344.36179355\n",
      " -43278.81582932 -58736.71234759 -32131.55216069 -16210.52931098\n",
      " -55754.27846401 -23808.15042801]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [1694.67549829 1421.80597382  516.34877429 1307.72840419 1697.11112266\n",
      " 2303.06152338 1259.70923265  635.91678356 2186.74344244  933.5496398 ]\n",
      "\n",
      "# 8 Gradient out:  [177131.57002418 148676.12281181  53935.50819288 136714.02832251\n",
      " 177446.14524778 240824.09726797 131741.40361353  66464.36588919\n",
      " 228596.10732992  97614.8502028 ]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [-6945.74282294 -5830.57055542 -2114.59383352 -5361.14395452\n",
      " -6958.6520432  -9444.28094614 -5166.60119949 -2606.18907864\n",
      " -8964.11225037 -3828.0804458 ]\n",
      "\n",
      "# 9 Gradient out:  [-726250.7921543  -609581.75100562 -221138.7952203  -560536.45657136\n",
      " -727540.5700695  -987394.71921863 -540148.3988975  -272508.11432099\n",
      " -937258.98232125 -400227.37981848]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [28480.5711819  23904.65400694  8672.50780505 21981.66170999\n",
      " 28530.57700635 38720.53850746 21181.67952322 10686.6840992\n",
      " 36755.10921562 15694.88959476]\n",
      "\n",
      "# 10 Gradient out:  [2977675.73930295 2499324.91888107  906683.74482286 2298235.94220933\n",
      " 2982963.91382786 4048382.44499741 2214643.54908603 1117301.11418372\n",
      " 3842822.83824288 1640958.17671104]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [-116769.58724896  -98011.69619419  -35555.25123901  -90125.62960429\n",
      " -116977.53700755 -158758.40533627  -86848.00025628  -43814.938765\n",
      " -150696.68724863  -64350.58636893]\n",
      "\n",
      "# 11 Gradient out:  [-12208664.30404922 -10247394.93873943  -3717462.15134131\n",
      "  -9422917.1127982  -12230346.16294805 -16598631.93752475\n",
      "  -9080182.8854715   -4581007.26872597 -15755823.98104285\n",
      "  -6728035.57592411]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [478765.56061163 401853.28758203 145781.49772557 369521.55883758\n",
      " 479615.24575802 650918.08366321 356080.70956092 179645.28407175\n",
      " 617867.88039995 263841.04897327]\n",
      "\n",
      "# 12 Gradient out:  [50056319.08154172 42014986.76944824 15241837.21525716 38634573.89964287\n",
      " 50145216.11649682 68055471.94321635 37229341.21237285 18782428.26329217\n",
      " 64599904.6009082  27585383.93858519]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [-1962967.30019822 -1647625.70016586  -597710.9325427  -1515061.86372206\n",
      " -1966453.98683158 -2668808.30384174 -1459955.86753338  -736556.16967345\n",
      " -2533296.91580862 -1081766.06621155]\n",
      "\n",
      "# 13 Gradient out:  [-2.05234169e+08 -1.72264182e+08 -6.24925252e+07 -1.58404270e+08\n",
      " -2.05598652e+08 -2.79031868e+08 -1.52642724e+08 -7.70091793e+07\n",
      " -2.64863817e+08 -1.13101871e+08]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [ 8048296.51611012  6755371.65372379  2450656.51050873  6211852.91620651\n",
      "  8062589.23646778 10942286.08480153  5985912.37494119  3019929.48298499\n",
      " 10386684.00437302  4435310.72150549]\n",
      "\n",
      "# 14 Gradient out:  [8.41473460e+08 7.06294369e+08 2.56223424e+08 6.49467824e+08\n",
      " 8.42967867e+08 1.14404883e+09 6.25845112e+08 3.15742651e+08\n",
      " 1.08595890e+09 4.63725039e+08]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [-32998537.20578529 -27697464.84607111 -10047848.52336297\n",
      " -25469001.00776027 -33057141.2119652  -44864087.54562809\n",
      " -24542632.44484454 -12381906.37198626 -42586079.35225359\n",
      " -18185063.51524541]\n",
      "\n",
      "# 15 Gradient out:  [-3.45009600e+09 -2.89585292e+09 -1.05053273e+09 -2.66286038e+09\n",
      " -3.45622316e+09 -4.69067474e+09 -2.56600572e+09 -1.29456544e+09\n",
      " -4.45250223e+09 -1.90130287e+09]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [1.35296155e+08 1.13561409e+08 4.11968363e+07 1.04424564e+08\n",
      " 1.35536432e+08 1.83945679e+08 1.00626390e+08 5.07666239e+07\n",
      " 1.74605701e+08 7.45599443e+07]\n",
      "\n",
      "# 16 Gradient out:  [1.41456183e+10 1.18731856e+10 4.30725262e+09 1.09179010e+10\n",
      " 1.41707401e+10 1.92320720e+10 1.05207906e+10 5.30780262e+09\n",
      " 1.82555492e+10 7.79546560e+09]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [-5.54723045e+08 -4.65609175e+08 -1.68909709e+08 -4.28147513e+08\n",
      " -5.55708200e+08 -7.54189269e+08 -4.12574755e+08 -2.08146464e+08\n",
      " -7.15894746e+08 -3.05700629e+08]\n",
      "\n",
      "# 17 Gradient out:  [-5.79979565e+10 -4.86808344e+10 -1.76600163e+10 -4.47641053e+10\n",
      " -5.81009574e+10 -7.88527479e+10 -4.31359268e+10 -2.17623365e+10\n",
      " -7.48489408e+10 -3.19619167e+10]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [2.27440062e+09 1.90902795e+09 6.92540814e+08 1.75543269e+09\n",
      " 2.27843982e+09 3.09222513e+09 1.69158337e+09 8.53414060e+08\n",
      " 2.93521509e+09 1.25339249e+09]\n",
      "\n",
      "# 18 Gradient out:  [2.37795400e+11 1.99594592e+11 7.24072171e+10 1.83535748e+11\n",
      " 2.38217710e+11 3.23301403e+11 1.76860110e+11 8.92269971e+10\n",
      " 3.06885533e+11 1.31045941e+11]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [-9.32519069e+09 -7.82713893e+09 -2.83946244e+09 -7.19738838e+09\n",
      " -9.34175167e+09 -1.26783245e+10 -6.93560199e+09 -3.49905323e+09\n",
      " -1.20345731e+10 -5.13899085e+09]\n",
      "\n",
      "# 19 Gradient out:  [-9.74976628e+11 -8.18350828e+11 -2.96874307e+11 -7.52508521e+11\n",
      " -9.76708128e+11 -1.32555681e+12 -7.25137970e+11 -3.65836500e+11\n",
      " -1.25825067e+12 -5.37296892e+11]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [3.82338892e+10 3.20917794e+10 1.16419810e+10 2.95097612e+10\n",
      " 3.83017904e+10 5.19819561e+10 2.84364199e+10 1.43463462e+10\n",
      " 4.93425335e+10 2.10701972e+10]\n",
      "\n",
      "# 20 Gradient out:  [3.99746768e+12 3.35529170e+12 1.21720400e+12 3.08533395e+12\n",
      " 4.00456695e+12 5.43486927e+12 2.97311291e+12 1.49995348e+12\n",
      " 5.15890972e+12 2.20295226e+12]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [-1.56761436e+11 -1.31578386e+11 -4.77328804e+10 -1.20991943e+11\n",
      " -1.57039835e+11 -2.13129406e+11 -1.16591174e+11 -5.88209538e+10\n",
      " -2.02307601e+11 -8.63891812e+10]\n",
      "\n",
      "# 21 Gradient out:  [-1.63898779e+13 -1.37569145e+13 -4.99061567e+12 -1.26500702e+13\n",
      " -1.64189853e+13 -2.22833180e+13 -1.21899566e+13 -6.14990697e+12\n",
      " -2.11518659e+13 -9.03224775e+12]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [6.42732100e+11 5.39479954e+11 1.95707919e+11 4.96074847e+11\n",
      " 6.43873554e+11 8.73844447e+11 4.78031408e+11 2.41169742e+11\n",
      " 8.29474343e+11 3.54201270e+11]\n",
      "\n",
      "# 22 Gradient out:  [6.71995669e+13 5.64042457e+13 2.04618493e+13 5.18661117e+13\n",
      " 6.73189094e+13 9.13630553e+13 4.99796161e+13 2.52150192e+13\n",
      " 8.67240280e+13 3.70328041e+13]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [-2.63524348e+12 -2.21190295e+12 -8.02415215e+11 -2.03393919e+12\n",
      " -2.63992351e+12 -3.58281915e+12 -1.95995991e+12 -9.88811652e+11\n",
      " -3.40089884e+12 -1.45224828e+12]\n",
      "\n",
      "# 23 Gradient out:  [-2.75522602e+14 -2.31261081e+14 -8.38949150e+13 -2.12654437e+14\n",
      " -2.76011913e+14 -3.74594478e+14 -2.04919682e+14 -1.03383221e+14\n",
      " -3.55574164e+14 -1.51836909e+14]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [1.08046699e+13 9.06894618e+12 3.28995465e+12 8.33928316e+12\n",
      " 1.08238584e+13 1.46897919e+13 8.03596330e+12 4.05419218e+12\n",
      " 1.39439068e+13 5.95431254e+12]\n",
      "\n",
      "# 24 Gradient out:  [1.12966061e+15 9.48185497e+14 3.43974616e+14 8.71897042e+14\n",
      " 1.13166682e+15 1.53586176e+15 8.40184042e+14 4.23877941e+14\n",
      " 1.45787723e+15 6.22541217e+14]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [-4.42998504e+13 -3.71832701e+13 -1.34890284e+13 -3.41916041e+13\n",
      " -4.43785243e+13 -6.02291037e+13 -3.29479730e+13 -1.66224520e+13\n",
      " -5.71709260e+13 -2.44130693e+13]\n",
      "\n",
      "# 25 Gradient out:  [-4.63168210e+15 -3.88762230e+15 -1.41031833e+15 -3.57483466e+15\n",
      " -4.63990769e+15 -6.29713326e+15 -3.44480930e+15 -1.73792717e+15\n",
      " -5.97739162e+15 -2.55245954e+15]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [1.81632272e+14 1.52453829e+14 5.53058949e+13 1.40187804e+14\n",
      " 1.81954840e+14 2.46943248e+14 1.35088835e+14 6.81531361e+13\n",
      " 2.34404521e+14 1.00095174e+14]\n",
      "\n",
      "# 26 Gradient out:  [1.89901983e+16 1.59395047e+16 5.78239703e+15 1.46570550e+16\n",
      " 1.90239238e+16 2.58186565e+16 1.41239425e+16 7.12561459e+15\n",
      " 2.45076950e+16 1.04652504e+16]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [-7.44704148e+14 -6.25070631e+14 -2.26757772e+14 -5.74779129e+14\n",
      " -7.46026698e+14 -1.01248340e+15 -5.53873025e+14 -2.79432297e+14\n",
      " -9.61073803e+14 -4.10396734e+14]\n",
      "\n",
      "# 27 Gradient out:  [-7.78610501e+16 -6.53530074e+16 -2.37082045e+16 -6.00948801e+16\n",
      " -7.79993266e+16 -1.05858174e+17 -5.79090843e+16 -2.92154840e+16\n",
      " -1.00483146e+17 -4.29082083e+16]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [3.05333551e+15 2.56283030e+15 9.29721634e+14 2.35663187e+15\n",
      " 3.05875806e+15 4.15124791e+15 2.27091548e+15 1.14569062e+15\n",
      " 3.94046519e+15 1.68265334e+15]\n",
      "\n",
      "# 28 Gradient out:  [3.19235377e+17 2.67951587e+17 9.72051826e+16 2.46392923e+17\n",
      " 3.19802320e+17 4.34025407e+17 2.37431018e+17 1.19785387e+17\n",
      " 4.11987443e+17 1.75926449e+17]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [-1.25188745e+16 -1.05077712e+16 -3.81191926e+15 -9.66234416e+15\n",
      " -1.25411073e+16 -1.70203868e+16 -9.31090139e+15 -4.69740617e+15\n",
      " -1.61561640e+16 -6.89898831e+15]\n",
      "\n",
      "# 29 Gradient out:  [-1.30888584e+18 -1.09861896e+18 -3.98547581e+17 -1.01022703e+18\n",
      " -1.31121034e+18 -1.77953244e+18 -9.73482639e+17 -4.91127891e+17\n",
      " -1.68917535e+18 -7.21309900e+17]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [5.13282009e+16 4.30825463e+16 1.56291173e+16 3.96162404e+16\n",
      " 5.14193567e+16 6.97846946e+16 3.81753022e+16 1.92596713e+16\n",
      " 6.62413247e+16 2.82863015e+16]\n",
      "\n",
      "# 30 Gradient out:  [5.36651720e+18 4.50440930e+18 1.63407104e+18 4.14199664e+18\n",
      " 5.37604782e+18 7.29619892e+18 3.99134223e+18 2.01365634e+18\n",
      " 6.92572898e+18 2.95741757e+18]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [-2.10448967e+17 -1.76641246e+17 -6.40803988e+16 -1.62429166e+17\n",
      " -2.10822712e+17 -2.86121794e+17 -1.56521226e+17 -7.89659068e+16\n",
      " -2.71593746e+17 -1.15975678e+17]\n",
      "\n",
      "# 31 Gradient out:  [-2.20030701e+19 -1.84683716e+19 -6.69979771e+18 -1.69824560e+19\n",
      " -2.20421462e+19 -2.99148908e+19 -1.63647631e+19 -8.25612217e+18\n",
      " -2.83959399e+19 -1.21256047e+19]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [8.62854473e+17 7.24240615e+17 2.62733809e+17 6.65970162e+17\n",
      " 8.64386851e+17 1.17311799e+18 6.41747221e+17 3.23765362e+17\n",
      " 1.11355205e+18 4.75507836e+17]\n",
      "\n",
      "# 32 Gradient out:  [9.02140206e+19 7.57215264e+19 2.74696070e+19 6.96291760e+19\n",
      " 9.03742353e+19 1.22653001e+20 6.70965948e+19 3.38506387e+19\n",
      " 1.16425203e+20 4.97157691e+19]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [-3.53775954e+18 -2.96943370e+18 -1.07722573e+18 -2.73052105e+18\n",
      " -3.54404239e+18 -4.80986018e+18 -2.63120541e+18 -1.32745907e+18\n",
      " -4.56563594e+18 -1.94961310e+18]\n",
      "\n",
      "# 33 Gradient out:  [-3.69883361e+20 -3.10463190e+20 -1.12627178e+20 -2.85484157e+20\n",
      " -3.70540252e+20 -5.02885294e+20 -2.75100409e+20 -1.38789824e+20\n",
      " -4.77350918e+20 -2.03837892e+20]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [1.45050446e+19 1.21748716e+19 4.41669567e+18 1.11953141e+19\n",
      " 1.45308047e+19 1.97207400e+19 1.07881136e+19 5.44266866e+18\n",
      " 1.87194047e+19 7.99354071e+18]\n",
      "\n",
      "# 34 Gradient out:  [1.51654587e+21 1.27291930e+21 4.61778766e+20 1.17050364e+21\n",
      " 1.51923917e+21 2.06186246e+21 1.12792960e+21 5.69047317e+20\n",
      " 1.95716986e+21 8.35748633e+20]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [-5.94716276e+19 -4.99177665e+19 -1.81087399e+19 -4.59015172e+19\n",
      " -5.95772457e+19 -8.08563187e+19 -4.42319683e+19 -2.23152960e+19\n",
      " -7.67507788e+19 -3.27740376e+19]\n",
      "\n",
      "# 35 Gradient out:  [-6.21793686e+21 -5.21905206e+21 -1.89332302e+21 -4.79914117e+21\n",
      " -6.22897955e+21 -8.45377039e+21 -4.62458482e+21 -2.33313107e+21\n",
      " -8.02452389e+21 -3.42662383e+21]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [2.43837547e+20 2.04666094e+20 7.42470133e+19 1.88199211e+20\n",
      " 2.44270588e+20 3.31516173e+20 1.81353951e+20 9.14941673e+19\n",
      " 3.14683192e+20 1.34375689e+20]\n",
      "\n",
      "# 36 Gradient out:  [2.54939462e+22 2.13984534e+22 7.76274771e+21 1.96767914e+22\n",
      " 2.55392219e+22 3.46610093e+22 1.89610990e+22 9.56598935e+21\n",
      " 3.29010707e+22 1.40493809e+22]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [-9.99749826e+20 -8.39144318e+20 -3.04417591e+20 -7.71629022e+20\n",
      " -1.00152532e+21 -1.35923791e+21 -7.43563013e+20 -3.75132046e+20\n",
      " -1.29022159e+21 -5.50949078e+20]\n",
      "\n",
      "# 37 Gradient out:  [-1.04526840e+23 -8.77350528e+22 -3.18277713e+22 -8.06761264e+22\n",
      " -1.04712473e+23 -1.42112396e+23 -7.77417410e+22 -3.92211794e+22\n",
      " -1.34896533e+23 -5.76033769e+22]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [4.09903941e+21 3.44054636e+21 1.24813195e+21 3.16372925e+21\n",
      " 4.10631906e+21 5.57296395e+21 3.04865679e+21 1.53806582e+21\n",
      " 5.28999255e+21 2.25892711e+21]\n",
      "\n",
      "# 38 Gradient out:  [4.28566852e+23 3.59719431e+23 1.30495935e+23 3.30777373e+23\n",
      " 4.29327961e+23 5.82670080e+23 3.18746202e+23 1.60809390e+23\n",
      " 5.53084572e+23 2.36177598e+23]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [-1.68063286e+22 -1.41064642e+22 -5.11742230e+21 -1.29714960e+22\n",
      " -1.68361756e+22 -2.28495152e+22 -1.24996914e+22 -6.30617006e+21\n",
      " -2.16893140e+22 -9.26174828e+21]\n",
      "\n",
      "# 39 Gradient out:  [-1.75715201e+24 -1.47487310e+24 -5.35041835e+23 -1.35620878e+24\n",
      " -1.76027261e+24 -2.38898528e+24 -1.30688019e+24 -6.59328976e+23\n",
      " -2.26768277e+24 -9.68343534e+23]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [6.89070419e+22 5.78374221e+22 2.09817648e+22 5.31839786e+22\n",
      " 6.90294167e+22 9.36845007e+22 5.12495490e+22 2.58557080e+22\n",
      " 8.89276003e+22 3.79737712e+22]\n",
      "\n",
      "# 40 Gradient out:  [7.20443770e+24 6.04707578e+24 2.19370638e+24 5.56054432e+24\n",
      " 7.21723235e+24 9.79499526e+24 5.35829391e+24 2.70329175e+24\n",
      " 9.29764707e+24 3.97027157e+24]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [-2.82523360e+23 -2.37137198e+23 -8.60266023e+22 -2.18057777e+23\n",
      " -2.83025105e+23 -3.84112555e+23 -2.10126489e+23 -1.06010087e+23\n",
      " -3.64608954e+23 -1.55694936e+23]\n",
      "\n",
      "# 41 Gradient out:  [-2.95386638e+25 -2.47934046e+25 -8.99433904e+24 -2.27985939e+25\n",
      " -2.95911227e+25 -4.01601186e+25 -2.19693541e+25 -1.10836723e+25\n",
      " -3.81209586e+25 -1.62783720e+25]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [1.15836418e+24 9.72277958e+23 3.52714673e+23 8.94051088e+23\n",
      " 1.16042137e+24 1.57488650e+24 8.61532293e+23 4.34648262e+23\n",
      " 1.49492046e+24 6.38359378e+23]\n",
      "\n",
      "# 42 Gradient out:  [1.21110446e+26 1.01654574e+26 3.68773759e+25 9.34757202e+25\n",
      " 1.21325531e+26 1.64659102e+26 9.00757827e+25 4.54437782e+25\n",
      " 1.56298413e+26 6.67423857e+25]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [-4.74936859e+24 -3.98640296e+24 -1.44615313e+24 -3.66566770e+24\n",
      " -4.75780318e+24 -6.45713722e+24 -3.53233852e+24 -1.78208619e+24\n",
      " -6.12927126e+24 -2.61731503e+24]\n",
      "\n",
      "# 43 Gradient out:  [-4.96560717e+26 -4.16790374e+26 -1.51199643e+26 -3.83256542e+26\n",
      " -4.97442579e+26 -6.75113045e+26 -3.69316576e+26 -1.86322451e+26\n",
      " -6.40833676e+26 -2.73648129e+26]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [1.94727206e+25 1.63445118e+25 5.92932205e+24 1.50294763e+25\n",
      " 1.95073030e+25 2.64746832e+25 1.44828180e+25 7.30666945e+24\n",
      " 2.51304114e+25 1.07311621e+25]\n",
      "\n",
      "# 44 Gradient out:  [2.03593128e+27 1.70886768e+27 6.19928387e+26 1.57137678e+27\n",
      " 2.03954698e+27 2.76800746e+27 1.51422202e+27 7.63934185e+26\n",
      " 2.62745981e+27 1.12197515e+27]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [-7.98394228e+25 -6.70135630e+25 -2.43106066e+25 -6.16218320e+25\n",
      " -7.99812128e+25 -1.08547926e+26 -5.93804972e+25 -2.99578207e+25\n",
      " -1.03036324e+26 -4.39984637e+25]\n",
      "\n",
      "# 45 Gradient out:  [-8.34745088e+27 -7.00646881e+27 -2.54174677e+27 -6.44274717e+27\n",
      " -8.36227546e+27 -1.13490109e+28 -6.20840891e+27 -3.13217992e+27\n",
      " -1.07727564e+28 -4.60017121e+27]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [3.27346834e+26 2.74759974e+26 9.96750707e+25 2.52653525e+26\n",
      " 3.27928182e+26 4.45053566e+26 2.43463907e+26 1.22829016e+26\n",
      " 4.22455639e+26 1.80396567e+26]\n",
      "\n",
      "# 46 Gradient out:  [3.42250923e+28 2.87269785e+28 1.04213273e+28 2.64156831e+28\n",
      " 3.42858741e+28 4.65316839e+28 2.54548809e+28 1.28421417e+28\n",
      " 4.41690029e+28 1.88610016e+28]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [-1.34214334e+27 -1.12653379e+27 -4.08674283e+26 -1.03589591e+27\n",
      " -1.34452691e+27 -1.82474861e+27 -9.98217876e+26 -5.03606967e+26\n",
      " -1.73209564e+27 -7.39637675e+26]\n",
      "\n",
      "# 47 Gradient out:  [-1.40325108e+29 -1.17782483e+29 -4.27281208e+28 -1.08306021e+29\n",
      " -1.40574317e+29 -1.90782935e+29 -1.04366670e+29 -5.26536174e+28\n",
      " -1.81095789e+29 -7.73313352e+28]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [5.50287513e+27 4.61886192e+27 1.67559118e+27 4.24724071e+27\n",
      " 5.51264791e+27 7.48158816e+27 4.09275831e+27 2.06482137e+27\n",
      " 7.10170494e+27 3.03256265e+27]\n",
      "\n",
      "# 48 Gradient out:  [5.75342083e+29 4.82915853e+29 1.75188078e+29 4.44061742e+29\n",
      " 5.76363856e+29 7.82222460e+29 4.27910145e+29 2.15883261e+29\n",
      " 7.42504531e+29 3.17063511e+29]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [-2.25621465e+28 -1.89376347e+28 -6.87003298e+27 -1.74139636e+28\n",
      " -2.26022155e+28 -3.06749988e+28 -1.67805757e+28 -8.46590212e+27\n",
      " -2.91174528e+28 -1.24337044e+28]\n",
      "\n",
      "# 49 Gradient out:  [-2.35894002e+30 -1.97998645e+30 -7.18282533e+29 -1.82068207e+30\n",
      " -2.36312935e+30 -3.20716304e+30 -1.75445947e+30 -8.85135433e+29\n",
      " -3.04431694e+30 -1.29998105e+30]\n",
      "\n",
      "     Weights  out:  [ 0.09864337  0.00344795 -0.45378255 -0.03552647  0.09975808  0.44888904\n",
      " -0.0519588  -0.34511932  0.34390927 -0.17716317] [9.25062702e+28 7.76455359e+28 2.81675827e+28 7.13983849e+28\n",
      " 9.26705558e+28 1.25769493e+29 6.88014533e+28 3.47107501e+28\n",
      " 1.19383453e+29 5.09789979e+28]\n",
      "\n",
      "Lineal error cuadrático medio (ECM): 3.223292068730659e+60\n",
      "\n",
      "# 0 Gradient out:  [2.44910935 2.81585699 1.63955549 2.15617585 0.9016492  1.1675212\n",
      " 1.33552789 1.65776122 1.80336392 1.16662609]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.45126372  0.0422615  -0.29200287  0.43811519  0.25830087 -0.25857914\n",
      " -0.12381786 -0.35833975  0.23626509 -0.2967696 ]\n",
      "\n",
      "# 1 Gradient out:  [-0.9594915  -1.15032188 -0.62783264 -0.83485715 -0.24546417 -0.40530911\n",
      " -0.49249134 -0.63537241 -0.69441862 -0.40481125]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [ 0.03855815  0.6054329   0.03590822  0.86935036  0.43863071 -0.0250749\n",
      "  0.14328771 -0.02678751  0.59693788 -0.06344438]\n",
      "\n",
      "# 2 Gradient out:  [-1.60588788 -1.94893404 -1.03056389 -1.38825272 -0.34493242 -0.63574344\n",
      " -0.79247192 -1.04366864 -1.14590961 -0.63484125]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.15334015  0.37536852 -0.0896583   0.70237893  0.38953788 -0.10613672\n",
      "  0.04478945 -0.15386199  0.45805415 -0.14440663]\n",
      "\n",
      "# 3 Gradient out:  [2.60523936 3.00781609 1.72807983 2.28720313 0.91924552 1.21275725\n",
      " 1.39719021 1.74781747 1.90549708 1.21177077]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.47451772 -0.01441829 -0.29577108  0.42472839  0.32055139 -0.23328541\n",
      " -0.11370494 -0.36259572  0.22887223 -0.27137488]\n",
      "\n",
      "# 4 Gradient out:  [-0.89318053 -1.07212923 -0.58180707 -0.77619025 -0.22327712 -0.37303698\n",
      " -0.4547941  -0.58888535 -0.64432293 -0.37257027]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [ 0.04653015  0.58714493  0.04984489  0.88216901  0.5044005   0.00926604\n",
      "  0.1657331  -0.01303223  0.60997165 -0.02902072]\n",
      "\n",
      "# 5 Gradient out:  [-1.61156618 -1.9482648  -1.0432119  -1.39685665 -0.36932836 -0.65486243\n",
      " -0.80866276 -1.05615256 -1.15719173 -0.65397808]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.13210596  0.37271909 -0.06651653  0.72693096  0.45974507 -0.06534136\n",
      "  0.07477428 -0.1308093   0.48110706 -0.10353478]\n",
      "\n",
      "# 6 Gradient out:  [2.32796615 2.67954361 1.54211578 2.04406876 0.83546981 1.08695544\n",
      " 1.24808034 1.5597807  1.70118149 1.08610105]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.45441919 -0.01693387 -0.27515891  0.44755963  0.3858794  -0.19631384\n",
      " -0.08695827 -0.34203981  0.24966871 -0.23433039]\n",
      "\n",
      "# 7 Gradient out:  [-1.0325543  -1.24163479 -0.66966664 -0.89614502 -0.25084085 -0.42596899\n",
      " -0.52149322 -0.67791711 -0.74251816 -0.42542337]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [ 0.01117404  0.51897485  0.03326425  0.85637339  0.55297336  0.02107724\n",
      "  0.1626578  -0.03008367  0.58990501 -0.01711018]\n",
      "\n",
      "# 8 Gradient out:  [-1.55098256 -1.88622545 -1.00689652 -1.34399672 -0.33564672 -0.62593378\n",
      " -0.77898277 -1.01930982 -1.11584523 -0.62504533]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.19533682  0.27064789 -0.10066908  0.67714438  0.50280519 -0.06411655\n",
      "  0.05835916 -0.16566709  0.44140138 -0.10219486]\n",
      "\n",
      "# 9 Gradient out:  [2.76095063 3.20087131 1.8178676  2.41818243 0.93465034 1.25866561\n",
      " 1.46018423 1.83910337 2.0085257  1.25758218]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.50553333 -0.1065972  -0.30204838  0.40834504  0.43567585 -0.18930331\n",
      " -0.0974374  -0.36952905  0.21823233 -0.22720392]\n",
      "\n",
      "# 10 Gradient out:  [-0.85307438 -1.02664735 -0.55069397 -0.73947896 -0.2030491  -0.3480819\n",
      " -0.42739014 -0.55756759 -0.61140636 -0.34762937]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [ 0.04665679  0.53357706  0.06152514  0.89198153  0.62260592  0.06242981\n",
      "  0.19459945 -0.00170838  0.61993747  0.02431251]\n",
      "\n",
      "# 11 Gradient out:  [-1.58297277 -1.91181666 -1.02827825 -1.37343038 -0.36932225 -0.64919157\n",
      " -0.79936893 -1.04090757 -1.13951843 -0.64832758]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.12395808  0.32824759 -0.04861366  0.74408573  0.5819961  -0.00718657\n",
      "  0.10912142 -0.1132219   0.4976562  -0.04521336]\n",
      "\n",
      "# 12 Gradient out:  [1.98255045 2.28180655 1.2866719  1.73244882 0.68646984 0.89205271\n",
      " 1.02934942 1.30229222 1.42767522 0.89133548]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.44055264 -0.05411574 -0.25426931  0.46939966  0.50813165 -0.13702488\n",
      " -0.05075237 -0.32140341  0.26975251 -0.17487888]\n",
      "\n",
      "# 13 Gradient out:  [-1.27483127 -1.53703682 -0.82347493 -1.1049239  -0.29818503 -0.51882926\n",
      " -0.63861139 -0.83374104 -0.91405949 -0.51814366]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.04404255  0.40224557  0.00306507  0.81588942  0.64542561  0.04138566\n",
      "  0.15511751 -0.06094497  0.55528756  0.00338822]\n",
      "\n",
      "# 14 Gradient out:  [-0.60175621 -0.76608805 -0.42124178 -0.52719502 -0.09021333 -0.25718548\n",
      " -0.33182502 -0.42546257 -0.45671677 -0.25671842]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.2990088   0.09483821 -0.16162991  0.59490464  0.58578861 -0.06238019\n",
      "  0.02739524 -0.22769318  0.37247566 -0.10024051]\n",
      "\n",
      "# 15 Gradient out:  [1.68589858 1.93667981 1.07604503 1.4679597  0.5740363  0.73827134\n",
      " 0.85346285 1.08971291 1.19976038 0.73768014]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.41936004 -0.05837941 -0.24587827  0.48946564  0.56774594 -0.11381729\n",
      " -0.03896977 -0.31278569  0.28113231 -0.1515842 ]\n",
      "\n",
      "# 16 Gradient out:  [-1.47040916 -1.77507062 -0.95202186 -1.27488434 -0.34142175 -0.59965565\n",
      " -0.73880094 -0.96381924 -1.05601512 -0.59885681]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.08218033  0.32895656 -0.03066926  0.78305758  0.6825532   0.03383698\n",
      "  0.1317228  -0.09484311  0.52108438 -0.00404817]\n",
      "\n",
      "# 17 Gradient out:  [0.92297636 1.03963257 0.55972356 0.79676612 0.32796453 0.38166468\n",
      " 0.43559937 0.56780223 0.63382504 0.38141879]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.37626216 -0.02605757 -0.22107364  0.52808071  0.61426885 -0.08609415\n",
      " -0.01603739 -0.28760696  0.30988136 -0.12381953]\n",
      "\n",
      "# 18 Gradient out:  [-1.53726818 -1.8661925  -1.0161755  -1.33823649 -0.35556173 -0.64596964\n",
      " -0.79600262 -1.02807749 -1.12042698 -0.64509296]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.19166689  0.18186894 -0.10912892  0.68743393  0.67986176 -0.00976121\n",
      "  0.07108249 -0.17404651  0.43664637 -0.04753577]\n",
      "\n",
      "# 19 Gradient out:  [2.75990379 3.20695063 1.80676742 2.41320749 0.90917855 1.23986729\n",
      " 1.4446309  1.82823437 1.99942689 1.23876442]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.49912052 -0.19136955 -0.31236402  0.41978664  0.60874941 -0.13895514\n",
      " -0.08811803 -0.37966201  0.21256097 -0.17655437]\n",
      "\n",
      "# 20 Gradient out:  [-0.87965141 -1.06170087 -0.56256088 -0.76051808 -0.1980648  -0.35004733\n",
      " -0.43323492 -0.56976915 -0.62622577 -0.34957271]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [ 0.05286023  0.45002057  0.04898946  0.90242814  0.79058512  0.10901832\n",
      "  0.20080814 -0.01401514  0.61244635  0.07119852]\n",
      "\n",
      "# 21 Gradient out:  [-1.60033091 -1.93508924 -1.04286337 -1.3892969  -0.37119796 -0.65893993\n",
      " -0.81175716 -1.05556337 -1.1546081  -0.65805765]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.12307005  0.2376804  -0.06352272  0.75032452  0.75097216  0.03900885\n",
      "  0.11416116 -0.12796897  0.4872012   0.00128398]\n",
      "\n",
      "# 22 Gradient out:  [2.14516653 2.48906056 1.36357271 1.86331262 0.67531121 0.91459303\n",
      " 1.07237336 1.38113409 1.52183923 0.91376257]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.44313623 -0.14933745 -0.27209539  0.47246514  0.67673257 -0.09277914\n",
      " -0.04819027 -0.33908164  0.25627957 -0.13032755]\n",
      "\n",
      "# 23 Gradient out:  [-1.20865347 -1.45998944 -0.77567069 -1.04568145 -0.27216957 -0.48355891\n",
      " -0.59837837 -0.7855186  -0.86257009 -0.48290188]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-1.41029239e-02  3.48474660e-01  6.19152959e-04  8.45127665e-01\n",
      "  8.11794812e-01  9.01394708e-02  1.66284402e-01 -6.28548253e-02\n",
      "  5.60647422e-01  5.24249615e-02]\n",
      "\n",
      "# 24 Gradient out:  [-0.98723501 -1.21228942 -0.69512936 -0.87124415 -0.23995099 -0.45901642\n",
      " -0.56130972 -0.70187744 -0.75306177 -0.45839267]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.25583362  0.05647677 -0.15451498  0.63599137  0.7573609  -0.00657231\n",
      "  0.04660873 -0.21995854  0.3881334  -0.04415541]\n",
      "\n",
      "# 25 Gradient out:  [2.4058363  2.79692046 1.54293    2.09341903 0.75926116 1.03921732\n",
      " 1.21851722 1.56233977 1.7175193  1.03826333]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.45328062 -0.18598111 -0.29354086  0.46174254  0.7093707  -0.0983756\n",
      " -0.06565322 -0.36033403  0.23752105 -0.13583395]\n",
      "\n",
      "# 26 Gradient out:  [-1.05461068 -1.27427125 -0.67401823 -0.91149268 -0.23412828 -0.41813246\n",
      " -0.51849596 -0.68267226 -0.75041848 -0.41755904]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [ 0.02788664  0.37340298  0.01504514  0.88042635  0.86122293  0.10946787\n",
      "  0.17805023 -0.04786608  0.58102491  0.07181872]\n",
      "\n",
      "# 27 Gradient out:  [-1.51302028 -1.83548689 -1.01225095 -1.32110271 -0.3631222  -0.6521334\n",
      " -0.79912139 -1.02369963 -1.11236061 -0.65127001]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.1830355   0.11854873 -0.1197585   0.69812782  0.81439728  0.02584138\n",
      "  0.07435103 -0.18440053  0.43094121 -0.01169309]\n",
      "\n",
      "# 28 Gradient out:  [2.72508553 3.17218978 1.77352989 2.3788721  0.87583183 1.20699483\n",
      " 1.41177999 1.79496287 1.96585951 1.20589122]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.48563955 -0.24854865 -0.32220869  0.43390727  0.74177283 -0.1045853\n",
      " -0.08547324 -0.38914046  0.20846909 -0.14194709]\n",
      "\n",
      "# 29 Gradient out:  [-0.91984668 -1.11221222 -0.58514285 -0.79406867 -0.20005139 -0.36066814\n",
      " -0.44857171 -0.59275202 -0.65234119 -0.36016652]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [ 0.05937755  0.38588931  0.03249729  0.90968169  0.9169392   0.13681366\n",
      "  0.19688276 -0.03014788  0.601641    0.09923115]\n",
      "\n",
      "# 30 Gradient out:  [-1.61095506 -1.94983806 -1.0560863  -1.40030731 -0.37520782 -0.67001646\n",
      " -0.82464356 -1.06873727 -1.16724089 -0.66911972]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.12459178  0.16344686 -0.08453128  0.75086796  0.87692892  0.06468004\n",
      "  0.10716841 -0.14869829  0.47117276  0.02719785]\n",
      "\n",
      "# 31 Gradient out:  [2.34616958 2.73440529 1.48676597 2.0351264  0.70954233 0.98589622\n",
      " 1.16393294 1.50609535 1.66065985 0.98495034]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.44678279 -0.22652075 -0.29574854  0.4708065   0.80188736 -0.06932326\n",
      " -0.0577603  -0.36244574  0.23772458 -0.1066261 ]\n",
      "\n",
      "# 32 Gradient out:  [-1.11477367 -1.34852929 -0.71092604 -0.96283564 -0.24276754 -0.43892704\n",
      " -0.5457253  -0.72011016 -0.79198601 -0.4383164 ]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [ 0.02245112  0.32036031  0.00160465  0.87783178  0.94379583  0.12785599\n",
      "  0.17502629 -0.06122667  0.56985655  0.09036397]\n",
      "\n",
      "# 33 Gradient out:  [-1.35514789 -1.64621405 -0.92961879 -1.19025031 -0.34162233 -0.61173277\n",
      " -0.74422533 -0.93937838 -1.01447747 -0.61094349]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.20050361  0.05065445 -0.14058055  0.68526465  0.89524232  0.04007058\n",
      "  0.06588123 -0.2052487   0.41145935  0.00270069]\n",
      "\n",
      "# 34 Gradient out:  [2.66867407 3.11075402 1.72541117 2.32559041 0.83807926 1.16457831\n",
      " 1.3670832  1.7466555  1.91607794 1.16348802]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.47153319 -0.27858836 -0.32650431  0.44721459  0.82691785 -0.08227597\n",
      " -0.08296383 -0.39312438  0.20856385 -0.11948801]\n",
      "\n",
      "# 35 Gradient out:  [-0.96061785 -1.16263087 -0.60962594 -0.82868557 -0.20522762 -0.37402025\n",
      " -0.46633127 -0.61760601 -0.6800907  -0.3734933 ]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [ 0.06220162  0.34356244  0.01857792  0.91233267  0.9945337   0.15063969\n",
      "  0.19045281 -0.04379328  0.59177944  0.1132096 ]\n",
      "\n",
      "# 36 Gradient out:  [-1.60159144 -1.93968201 -1.0583182  -1.39468236 -0.37809134 -0.67595414\n",
      " -0.83014314 -1.0707161  -1.16707312 -0.67505559]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.12992195  0.11103627 -0.10334727  0.74659556  0.95348818  0.07583564\n",
      "  0.09718655 -0.16731448  0.4557613   0.03851094]\n",
      "\n",
      "# 37 Gradient out:  [2.48531153 2.90130855 1.58120057 2.15727159 0.74761039 1.04897625\n",
      " 1.23965163 1.60154951 1.76404684 1.04795653]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.45024024 -0.27690014 -0.31501091  0.46765908  0.87786991 -0.05935519\n",
      " -0.06884208 -0.3814577   0.22234668 -0.09650018]\n",
      "\n",
      "# 38 Gradient out:  [-1.05700963 -1.27981856 -0.67134421 -0.91195413 -0.22520921 -0.41187742\n",
      " -0.51368169 -0.68011415 -0.74875963 -0.41129567]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [ 0.04682207  0.30336157  0.00122921  0.8991134   1.02739199  0.15044006\n",
      "  0.17908825 -0.0611478   0.57515604  0.11309113]\n",
      "\n",
      "# 39 Gradient out:  [-1.48957605 -1.80601199 -1.0082784  -1.30446726 -0.36961349 -0.65774467\n",
      " -0.80187586 -1.01929284 -1.10441865 -0.65689347]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.16457986  0.04739786 -0.13303963  0.71672258  0.98235015  0.06806458\n",
      "  0.07635191 -0.19717063  0.42540412  0.03083199]\n",
      "\n",
      "# 40 Gradient out:  [2.64545683 3.08781864 1.70317655 2.30264561 0.81529003 1.14239462\n",
      " 1.34502407 1.72440025 1.89363513 1.14130307]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.46249507 -0.31380454 -0.33469531  0.45582912  0.90842745 -0.06348436\n",
      " -0.08402326 -0.4010292   0.20452039 -0.1005467 ]\n",
      "\n",
      "# 41 Gradient out:  [-0.99379563 -1.20385737 -0.62934124 -0.8567683  -0.20883024 -0.38448235\n",
      " -0.48046984 -0.637628   -0.70250483 -0.38393421]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [ 0.0665963   0.30375919  0.00594     0.91635825  1.07148545  0.16499456\n",
      "  0.18498155 -0.05614915  0.58324741  0.12771391]\n",
      "\n",
      "# 42 Gradient out:  [-1.57221583 -1.90496664 -1.04838896 -1.37200314 -0.37784467 -0.67503104\n",
      " -0.82670097 -1.06035516 -1.15316873 -0.67414256]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.13216283  0.06298772 -0.11992825  0.74500459  1.02971941  0.08809809\n",
      "  0.08888758 -0.18367475  0.44274645  0.05092707]\n",
      "\n",
      "# 43 Gradient out:  [2.53355145 2.96129099 1.61235682 2.19889586 0.75479848 1.06736136\n",
      " 1.26337096 1.63309743 1.79861006 1.06630972]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.44660599 -0.31800561 -0.32960604  0.47060396  0.95415047 -0.04690811\n",
      " -0.07645261 -0.39574578  0.2121127  -0.08390144]\n",
      "\n",
      "# 44 Gradient out:  [-1.05447825 -1.27780013 -0.66803978 -0.90912226 -0.22090682 -0.4079997\n",
      " -0.51003962 -0.67682749 -0.74560937 -0.40741658]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [ 0.0601043   0.27425259 -0.00713468  0.91038313  1.10511017  0.16656416\n",
      "  0.17622158 -0.06912629  0.57183471  0.1293605 ]\n",
      "\n",
      "# 45 Gradient out:  [-1.48436407 -1.79950586 -1.00799987 -1.30096156 -0.3713514  -0.65974909\n",
      " -0.80325466 -1.01890457 -1.10313202 -0.65890019]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.15079135  0.01869256 -0.14074264  0.72855868  1.0609288   0.08496422\n",
      "  0.07421366 -0.20449179  0.42271284  0.04787718]\n",
      "\n",
      "# 46 Gradient out:  [2.60058703 3.03967831 1.66395369 2.25988701 0.78288982 1.10693827\n",
      " 1.30808585 1.68504929 1.85327778 1.10585532]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.44766417 -0.34120861 -0.34234261  0.46836637  0.98665852 -0.0469856\n",
      " -0.08643727 -0.40827271  0.20208643 -0.08390285]\n",
      "\n",
      "# 47 Gradient out:  [-1.03370667 -1.2530715  -0.65382663 -0.89083396 -0.21466084 -0.39831234\n",
      " -0.49854731 -0.66246493 -0.7300817  -0.39773967]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [ 0.07245324  0.26672705 -0.00955187  0.92034377  1.14323649  0.17440205\n",
      "  0.1751799  -0.07126285  0.57274199  0.13726821]\n",
      "\n",
      "# 48 Gradient out:  [-1.51599558 -1.83757461 -1.02410412 -1.32702973 -0.37473972 -0.66719194\n",
      " -0.81366168 -1.03535713 -1.1223848  -0.66632785]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.1342881   0.01611275 -0.1403172   0.74217698  1.10030432  0.09473959\n",
      "  0.07547043 -0.20375583  0.42672565  0.05772028]\n",
      "\n",
      "# 49 Gradient out:  [2.56206141 2.99713061 1.63135076 2.22364007 0.7586866  1.07870158\n",
      " 1.27803044 1.65231091 1.81949234 1.07762958]\n",
      "\n",
      "     Weights  out:  [ 0.14651784  0.32160868 -0.08341733  0.05715169 -0.47739524 -0.26282465\n",
      " -0.18491384 -0.07815019 -0.0376496  -0.2633157 ] [-0.43748721 -0.35140217 -0.34513803  0.47677103  1.02535637 -0.0386988\n",
      " -0.0872619  -0.41082726  0.20224869 -0.07554529]\n",
      "\n",
      "Tanh error cuadrático medio (ECM): 0.9509268567976827\n",
      "\n",
      "# 0 Gradient out:  [6.26999767 6.29507646 3.53729355 3.68455795 1.7654102  2.11196427\n",
      " 1.6760861  6.39946627 1.67276009 4.08283232]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [-0.47403409 -0.27617618 -0.12433561  0.42391965 -0.46457141 -0.30941688\n",
      "  0.02585195  0.09312503  0.29255439 -0.48927636]\n",
      "\n",
      "# 1 Gradient out:  [-24.72439781 -24.84053356 -13.46724524 -14.04659282  -5.90878347\n",
      "  -7.50326688  -5.49685049 -25.32356145  -5.48158744 -15.60353351]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [ 0.77996544  0.98283912  0.5831231   1.16083124 -0.11148937  0.11297597\n",
      "  0.36106917  1.37301828  0.6271064   0.3272901 ]\n",
      "\n",
      "# 2 Gradient out:  [95.63319064 96.06594758 52.39421088 54.64687254 23.62365709 29.57653967\n",
      " 22.08837912 97.86549487 22.03144826 60.71088816]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [-4.16491412 -3.9852676  -2.11032595 -1.64848732 -1.29324607 -1.38767741\n",
      " -0.73830093 -3.69169401 -0.46921108 -2.7934166 ]\n",
      "\n",
      "# 3 Gradient out:  [-371.17251112 -372.86823937 -203.17385433 -211.89747564  -91.11409308\n",
      " -114.42628903  -85.09767808 -379.92051556  -84.87461249 -235.37042155]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [14.96172401 15.22792192  8.36851623  9.28088719  3.43148535  4.52763053\n",
      "  3.6793749  15.88140497  3.93707857  9.34876103]\n",
      "\n",
      "# 4 Gradient out:  [1439.74465323 1446.30641877  788.18027578  822.0434365   353.85315227\n",
      "  444.07674016  330.57326069 1473.59457458  329.71010778  913.17089565]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [-59.27277822 -59.34572596 -32.26625464 -33.09860794 -14.79133326\n",
      " -18.35762728 -13.34016072 -60.10269814 -13.03784393 -37.72532328]\n",
      "\n",
      "# 5 Gradient out:  [-5585.18776221 -5610.65835464 -3057.56031637 -3188.89622888\n",
      " -1372.37513906 -1722.57698605 -1282.00874828 -5716.58340343\n",
      " -1278.65823344 -3542.31689549]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [228.67615243 229.9155578  125.36980052 131.31007936  55.97929719\n",
      "  70.45772075  52.77449142 234.61621677  52.90417763 144.90885585]\n",
      "\n",
      "# 6 Gradient out:  [21666.2414355  21765.03234632 11860.95768529 12370.47234374\n",
      "  5324.00851461  6682.32749826  4973.51296621 22175.87433846\n",
      "  4960.51763051 13741.57066605]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [-888.36140001 -892.21611313 -486.14226275 -506.46916642 -218.49573062\n",
      " -274.05767646 -203.62725823 -908.70046391 -202.82746906 -563.55452325]\n",
      "\n",
      "# 7 Gradient out:  [-84048.54636162 -84431.79531246 -46011.56487819 -47988.06009924\n",
      " -20652.91638708 -25922.35463413 -19293.20360807 -86025.61545586\n",
      " -19242.78949767 -53306.77588705]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [3444.88688709 3460.79035613 1886.0492743  1967.62530233  846.3059723\n",
      " 1062.4078232   791.07533501 3526.47440378  789.27605704 2184.75960996]\n",
      "\n",
      "# 8 Gradient out:  [326044.42749888 327531.12668073 178489.78041672 186157.11436708\n",
      "  80117.75332026 100558.97395195  74843.15835837 333713.87122834\n",
      "  74647.59204189 206789.79368121]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [-13364.82238523 -13425.56870636  -7316.26370133  -7629.98671752\n",
      "  -3284.27730512  -4122.06310363  -3067.56538661 -13678.64868739\n",
      "  -3059.28184249  -8476.59556745]\n",
      "\n",
      "# 9 Gradient out:  [-1264804.32106072 -1270571.59794705  -692404.66291772  -722148.04815909\n",
      "  -310795.81164665  -390092.38609558  -290334.33993825 -1294556.00793858\n",
      "  -289575.68933775  -802187.03537274]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [51844.06311454 52080.65662979 28381.69238201 29601.4361559\n",
      " 12739.27335894 15989.73168676 11901.06628507 53064.12555828\n",
      " 11870.23656588 32881.3631688 ]\n",
      "\n",
      "# 10 Gradient out:  [4906478.60419786 4928851.23613465 2686003.24045106 2801384.98677137\n",
      " 1205651.41508642 1513261.61216349 1126276.52641562 5021892.43662534\n",
      " 1123333.54128493 3111875.48324848]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [-201116.8010976  -202033.66295962 -110099.24020153 -114828.17347592\n",
      "  -49419.88897039  -62028.74553236  -46165.80170258 -205847.07602944\n",
      "  -46044.90130167 -127556.04390575]\n",
      "\n",
      "# 11 Gradient out:  [-19033404.36868177 -19120193.17562072 -10419649.32566188\n",
      " -10867242.68585581  -4677010.2104171   -5870303.94845867\n",
      "  -4369095.9709893  -19481122.3169282   -4357679.4254888\n",
      " -12071709.49077102]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [780178.91974197 783736.58426731 427101.40788868 445448.82387836\n",
      " 191710.39404689 240623.57690034 179089.50358054 798531.41129563\n",
      " 178621.80695532 494819.05274394]\n",
      "\n",
      "# 12 Gradient out:  [73835129.4371631  74171803.96915635 40420312.57306772 42156634.34650927\n",
      " 18143241.68324756 22772313.4099574  16948768.73356315 75571934.39880253\n",
      " 16904481.22414323 46829049.37712506]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [-3026501.95399439 -3040302.05085683 -1656828.4572437  -1727999.71329281\n",
      "  -743691.64803653  -933437.21279139  -694729.69061732 -3097693.05209001\n",
      "  -692914.07814244 -1919522.84541026]\n",
      "\n",
      "# 13 Gradient out:  [-2.86424132e+08 -2.87730174e+08 -1.56800063e+08 -1.63535671e+08\n",
      " -7.03819753e+07 -8.83392522e+07 -6.57483289e+07 -2.93161615e+08\n",
      " -6.55765270e+07 -1.81661087e+08]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [11740523.93343823 11794058.74297444  6427234.05736985  6703327.15600905\n",
      "  2884956.68861298  3621025.46920009  2695024.05609531 12016693.8276705\n",
      "  2687982.16668621  7446287.03001475]\n",
      "\n",
      "# 14 Gradient out:  [1.11110774e+09 1.11617418e+09 6.08264961e+08 6.34393994e+08\n",
      " 2.73028521e+08 3.42689095e+08 2.55053498e+08 1.13724404e+09\n",
      " 2.54387038e+08 7.04706818e+08]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [-45544302.56627759 -45751975.97186313 -24932778.61775935\n",
      " -26003807.02776116 -11191438.36955217 -14046824.97762144\n",
      " -10454641.71984253 -46615629.08498421 -10427323.23982902\n",
      " -28885930.29066315]\n",
      "\n",
      "# 15 Gradient out:  [-4.31025276e+09 -4.32990671e+09 -2.35960531e+09 -2.46096609e+09\n",
      " -1.05914296e+09 -1.32937299e+09 -9.89413543e+08 -4.41164174e+09\n",
      " -9.86828184e+08 -2.73372635e+09]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [1.76677245e+08 1.77482861e+08 9.67202136e+07 1.00874992e+08\n",
      " 4.34142659e+07 5.44909940e+07 4.05560580e+07 1.80833180e+08\n",
      " 4.04500844e+07 1.12055433e+08]\n",
      "\n",
      "# 16 Gradient out:  [1.67205017e+10 1.67967441e+10 9.15347356e+09 9.54667625e+09\n",
      " 4.10866894e+09 5.15695589e+09 3.83817186e+09 1.71138138e+10\n",
      " 3.82814263e+09 1.06047786e+10]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [-6.85373306e+08 -6.88498481e+08 -3.75200849e+08 -3.91318225e+08\n",
      " -1.68414326e+08 -2.11383604e+08 -1.57326651e+08 -7.01495168e+08\n",
      " -1.56915552e+08 -4.34689837e+08]\n",
      "\n",
      "# 17 Gradient out:  [-6.48628265e+10 -6.51585890e+10 -3.55085140e+10 -3.70338413e+10\n",
      " -1.59385098e+10 -2.00050657e+10 -1.48891869e+10 -6.63885783e+10\n",
      " -1.48502812e+10 -4.11384734e+10]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [2.65872703e+09 2.67085034e+09 1.45549386e+09 1.51801702e+09\n",
      " 6.53319463e+08 8.20007573e+08 6.10307721e+08 2.72126759e+09\n",
      " 6.08712973e+08 1.68626588e+09]\n",
      "\n",
      "# 18 Gradient out:  [2.51618423e+11 2.52765756e+11 1.37746021e+11 1.43663131e+11\n",
      " 6.18292931e+10 7.76044362e+10 5.77587185e+10 2.57537179e+11\n",
      " 5.76077936e+10 1.59585981e+11]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [-1.03138383e+10 -1.03608675e+10 -5.64620893e+09 -5.88875123e+09\n",
      " -2.53438251e+09 -3.18100557e+09 -2.36752967e+09 -1.05564481e+10\n",
      " -2.36134326e+09 -6.54142880e+09]\n",
      "\n",
      "# 19 Gradient out:  [-9.76088064e+11 -9.80538845e+11 -5.34349773e+11 -5.57303656e+11\n",
      " -2.39850621e+11 -3.01046175e+11 -2.24059888e+11 -9.99048335e+11\n",
      " -2.23474415e+11 -6.19072202e+11]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [4.00098463e+10 4.01922838e+10 2.19029953e+10 2.28438749e+10\n",
      " 9.83147611e+09 1.23398817e+10 9.18421403e+09 4.09509878e+10\n",
      " 9.16021547e+09 2.53757674e+10]\n",
      "\n",
      "# 20 Gradient out:  [3.78647913e+12 3.80374478e+12 2.07287062e+12 2.16191422e+12\n",
      " 9.30437944e+11 1.16783014e+12 8.69181913e+11 3.87554752e+12\n",
      " 8.66910721e+11 2.40152919e+12]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [-1.55207766e+11 -1.55915485e+11 -8.49669593e+10 -8.86168564e+10\n",
      " -3.81386481e+10 -4.78693534e+10 -3.56277636e+10 -1.58858679e+11\n",
      " -3.55346674e+10 -9.84386729e+10]\n",
      "\n",
      "# 21 Gradient out:  [-1.46886585e+13 -1.47556361e+13 -8.04116107e+12 -8.38658252e+12\n",
      " -3.60939140e+12 -4.53029253e+12 -3.37176460e+12 -1.50341761e+13\n",
      " -3.36295410e+12 -9.31610629e+12]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [6.02088060e+11 6.04833470e+11 3.29607164e+11 3.43765988e+11\n",
      " 1.47948941e+11 1.85696675e+11 1.38208619e+11 6.16250825e+11\n",
      " 1.37847477e+11 3.81867164e+11]\n",
      "\n",
      "# 22 Gradient out:  [5.69808206e+13 5.72406426e+13 3.11935877e+13 3.25335601e+13\n",
      " 1.40016928e+13 1.75740886e+13 1.30798816e+13 5.83211660e+13\n",
      " 1.30457036e+13 3.61394052e+13]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [-2.33564364e+12 -2.34629374e+12 -1.27862505e+12 -1.33355052e+12\n",
      " -5.73929338e+11 -7.20361831e+11 -5.36144300e+11 -2.39058439e+12\n",
      " -5.34743343e+11 -1.48135409e+12]\n",
      "\n",
      "# 23 Gradient out:  [-2.21042236e+14 -2.22050148e+14 -1.21007390e+14 -1.26205464e+14\n",
      " -5.43159163e+13 -6.81740944e+13 -5.07399901e+13 -2.26241757e+14\n",
      " -5.06074054e+13 -1.40193399e+14]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [9.06052049e+12 9.10183479e+12 4.96009248e+12 5.17316151e+12\n",
      " 2.22640922e+12 2.79445589e+12 2.07983202e+12 9.27364881e+12\n",
      " 2.07439737e+12 5.74652695e+12]\n",
      "\n",
      "# 24 Gradient out:  [8.57475720e+14 8.61385651e+14 4.69416617e+14 4.89581188e+14\n",
      " 2.10704435e+14 2.64463623e+14 1.96832561e+14 8.77645903e+14\n",
      " 1.96318234e+14 5.43843739e+14]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [-3.51479268e+13 -3.53081948e+13 -1.92413855e+13 -2.00679312e+13\n",
      " -8.63677404e+12 -1.08403630e+13 -8.06816601e+12 -3.59747025e+13\n",
      " -8.04708371e+12 -2.22921529e+13]\n",
      "\n",
      "# 25 Gradient out:  [-3.32635347e+15 -3.34152103e+15 -1.82097937e+15 -1.89920256e+15\n",
      " -8.17372915e+14 -1.02591767e+15 -7.63560599e+14 -3.40459844e+15\n",
      " -7.61565398e+14 -2.10969998e+15]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [1.36347217e+14 1.36968935e+14 7.46419379e+13 7.78483065e+13\n",
      " 3.35041129e+13 4.20523617e+13 3.12983463e+13 1.39554478e+14\n",
      " 3.12165630e+13 8.64765948e+13]\n",
      "\n",
      "# 26 Gradient out:  [1.29037210e+16 1.29625596e+16 7.06401464e+15 7.36746114e+15\n",
      " 3.17078510e+15 3.97978010e+15 2.96203425e+15 1.32072519e+16\n",
      " 2.95429439e+15 8.18403098e+15]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [-5.28923477e+14 -5.31335271e+14 -2.89553935e+14 -3.01992206e+14\n",
      " -1.29970470e+14 -1.63131172e+14 -1.21413774e+14 -5.41365210e+14\n",
      " -1.21096517e+14 -3.35463401e+14]\n",
      "\n",
      "# 27 Gradient out:  [-5.00566209e+16 -5.02848699e+16 -2.74030029e+16 -2.85801445e+16\n",
      " -1.23002340e+16 -1.54385192e+16 -1.14904395e+16 -5.12340901e+16\n",
      " -1.14604148e+16 -3.17478142e+16]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [2.05182072e+15 2.06117664e+15 1.12324899e+15 1.17150002e+15\n",
      " 5.04186549e+14 6.32824847e+14 4.70993077e+14 2.10008517e+15\n",
      " 4.69762361e+14 1.30134279e+15]\n",
      "\n",
      "# 28 Gradient out:  [1.94181609e+17 1.95067041e+17 1.06302805e+17 1.10869218e+17\n",
      " 4.77155507e+16 5.98897096e+16 4.45741641e+16 1.98749294e+17\n",
      " 4.44576908e+16 1.23157367e+17]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [-7.95950347e+15 -7.99579733e+15 -4.35735159e+15 -4.54452887e+15\n",
      " -1.95586025e+15 -2.45487899e+15 -1.82709483e+15 -8.14673285e+15\n",
      " -1.82232059e+15 -5.04822005e+15]\n",
      "\n",
      "# 29 Gradient out:  [-7.53276920e+17 -7.56711724e+17 -4.12374012e+17 -4.30088224e+17\n",
      " -1.85100037e+17 -2.32326513e+17 -1.72913847e+17 -7.70996062e+17\n",
      " -1.72462020e+17 -4.77756894e+17]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [3.08768183e+16 3.10176109e+16 1.69032093e+16 1.76293148e+16\n",
      " 7.58724988e+15 9.52306294e+15 7.08773799e+15 3.16031259e+16\n",
      " 7.06921758e+15 1.95832534e+16]\n",
      "\n",
      "# 30 Gradient out:  [2.92214140e+18 2.93546582e+18 1.59969746e+18 1.66841512e+18\n",
      " 7.18047331e+17 9.01250128e+17 6.70774184e+17 2.99087819e+18\n",
      " 6.69021436e+17 1.85333330e+18]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [-1.19778566e+17 -1.20324734e+17 -6.55715932e+16 -6.83883300e+16\n",
      " -2.94327576e+16 -3.69422396e+16 -2.74950315e+16 -1.22596086e+17\n",
      " -2.74231863e+16 -7.59681253e+16]\n",
      "\n",
      "# 31 Gradient out:  [-1.13356856e+19 -1.13873743e+19 -6.20560917e+18 -6.47218144e+18\n",
      " -2.78547739e+18 -3.49616487e+18 -2.60209355e+18 -1.16023321e+19\n",
      " -2.59529422e+18 -7.18952328e+18]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [4.64649714e+17 4.66768431e+17 2.54367898e+17 2.65294694e+17\n",
      " 1.14176709e+17 1.43307786e+17 1.06659805e+17 4.75579551e+17\n",
      " 1.06381101e+17 2.94698534e+17]\n",
      "\n",
      "# 32 Gradient out:  [4.39738367e+19 4.41743492e+19 2.40730427e+19 2.51071403e+19\n",
      " 1.08055332e+19 1.35624600e+19 1.00941434e+19 4.50082220e+19\n",
      " 1.00677672e+19 2.78898809e+19]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [-1.80248741e+18 -1.81070642e+18 -9.86753936e+17 -1.02914159e+18\n",
      " -4.42918770e+17 -5.55925189e+17 -4.13758904e+17 -1.84488686e+18\n",
      " -4.12677743e+17 -1.14320612e+18]\n",
      "\n",
      "# 33 Gradient out:  [-1.70585033e+20 -1.71362870e+20 -9.33850923e+19 -9.73966042e+19\n",
      " -4.19172487e+19 -5.26120273e+19 -3.91575975e+19 -1.74597662e+20\n",
      " -3.90552778e+19 -1.08191521e+20]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [6.99227992e+18 7.02416342e+18 3.82785461e+18 3.99228647e+18\n",
      " 1.71818788e+18 2.15656682e+18 1.60506978e+18 7.15675754e+18\n",
      " 1.60087570e+18 4.43477006e+18]\n",
      "\n",
      "# 34 Gradient out:  [6.61740158e+20 6.64757571e+20 3.62263116e+20 3.77824731e+20\n",
      " 1.62607037e+20 2.04094642e+20 1.51901689e+20 6.77306103e+20\n",
      " 1.51504767e+20 4.19700795e+20]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [-2.71247268e+19 -2.72484105e+19 -1.48491638e+19 -1.54870344e+19\n",
      " -6.66526187e+18 -8.36583865e+18 -6.22644971e+18 -2.77627748e+19\n",
      " -6.21017986e+18 -1.72035341e+19]\n",
      "\n",
      "# 35 Gradient out:  [-2.56704840e+21 -2.57875366e+21 -1.40530530e+21 -1.46567253e+21\n",
      " -6.30791600e+20 -7.91731946e+20 -5.89262996e+20 -2.62743242e+21\n",
      " -5.87723238e+20 -1.62811980e+21]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [1.05223305e+20 1.05703104e+20 5.76034593e+19 6.00779117e+19\n",
      " 2.58561455e+19 3.24530897e+19 2.41538881e+19 1.07698446e+20\n",
      " 2.40907735e+19 6.67366249e+19]\n",
      "\n",
      "# 36 Gradient out:  [9.95819491e+21 1.00036024e+22 5.45151548e+21 5.68569440e+21\n",
      " 2.44699154e+21 3.07131764e+21 2.28589214e+21 1.01924390e+22\n",
      " 2.27991906e+21 6.31586624e+21]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [-4.08186375e+20 -4.10047629e+20 -2.23457601e+20 -2.33056594e+20\n",
      " -1.00302175e+20 -1.25893300e+20 -9.36987110e+19 -4.17788039e+20\n",
      " -9.34538742e+19 -2.58887335e+20]\n",
      "\n",
      "# 37 Gradient out:  [-3.86302206e+22 -3.88063673e+22 -2.11477329e+22 -2.20561689e+22\n",
      " -9.49246563e+21 -1.19143760e+22 -8.86752254e+21 -3.95389095e+22\n",
      " -8.84435151e+21 -2.45007563e+22]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [1.58345261e+21 1.59067286e+21 8.66845496e+20 9.04082286e+20\n",
      " 3.89096133e+20 4.88370229e+20 3.63479718e+20 1.62069976e+21\n",
      " 3.62529937e+20 1.00428591e+21]\n",
      "\n",
      "# 38 Gradient out:  [1.49855868e+23 1.50539183e+23 8.20371155e+22 8.55611563e+22\n",
      " 3.68235453e+22 4.62187150e+22 3.43992415e+22 1.53380890e+23\n",
      " 3.43093556e+22 9.50442954e+22]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [-6.14259152e+21 -6.17060060e+21 -3.36270108e+21 -3.50715150e+21\n",
      " -1.50939699e+21 -1.89450497e+21 -1.41002479e+21 -6.28708214e+21\n",
      " -1.40634036e+21 -3.89586534e+21]\n",
      "\n",
      "# 39 Gradient out:  [-5.81326767e+23 -5.83977510e+23 -3.18241599e+23 -3.31912196e+23\n",
      " -1.42847343e+23 -1.79293454e+23 -1.33442888e+23 -5.95001169e+23\n",
      " -1.33094199e+23 -3.68699562e+23]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [2.38285821e+22 2.39372361e+22 1.30447220e+22 1.36050798e+22\n",
      " 5.85531207e+21 7.34923803e+21 5.46982352e+21 2.43890958e+22\n",
      " 5.45553075e+21 1.51129938e+22]\n",
      "\n",
      "# 40 Gradient out:  [2.25510561e+24 2.26538848e+24 1.23453530e+24 1.28756682e+24\n",
      " 5.54139019e+23 6.95522203e+23 5.17656890e+23 2.30815189e+24\n",
      " 5.16304241e+23 1.43027381e+24]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [-9.24367713e+22 -9.28582658e+22 -5.06035978e+22 -5.27773595e+22\n",
      " -2.27141564e+22 -2.85094527e+22 -2.12187541e+22 -9.46111379e+22\n",
      " -2.11633090e+22 -5.86269186e+22]\n",
      "\n",
      "# 41 Gradient out:  [-8.74809423e+24 -8.78798392e+24 -4.78905781e+24 -4.99477975e+24\n",
      " -2.14963783e+24 -2.69809703e+24 -2.00811493e+24 -8.95387342e+24\n",
      " -2.00286768e+24 -5.54837432e+24]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [3.58584352e+23 3.60219430e+23 1.96303463e+23 2.04736005e+23\n",
      " 8.81136473e+22 1.10594988e+23 8.23126239e+22 3.67019240e+23\n",
      " 8.20975392e+22 2.27427844e+23]\n",
      "\n",
      "# 42 Gradient out:  [3.39359505e+25 3.40906922e+25 1.85779011e+25 1.93759457e+25\n",
      " 8.33895947e+24 1.04665639e+25 7.78995826e+24 3.47342173e+25\n",
      " 7.76960293e+24 2.15234715e+25]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [-1.39103449e+24 -1.39737735e+24 -7.61508099e+23 -7.94219946e+23\n",
      " -3.41813919e+23 -4.29024419e+23 -3.19310362e+23 -1.42375544e+24\n",
      " -3.18475997e+23 -8.82247021e+23]\n",
      "\n",
      "# 43 Gradient out:  [-1.31645671e+26 -1.32245951e+26 -7.20681231e+25 -7.51639292e+25\n",
      " -3.23488189e+25 -4.06023057e+25 -3.02191119e+25 -1.34742339e+26\n",
      " -3.01401487e+25 -8.34946955e+25]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [5.39615561e+24 5.42076108e+24 2.95407211e+24 3.08096919e+24\n",
      " 1.32597797e+24 1.66428837e+24 1.23868129e+24 5.52308801e+24\n",
      " 1.23544459e+24 3.42244728e+24]\n",
      "\n",
      "# 44 Gradient out:  [5.10685057e+26 5.13013686e+26 2.79569492e+26 2.91578865e+26\n",
      " 1.25488808e+26 1.57506058e+26 1.17227165e+26 5.22697771e+26\n",
      " 1.16920848e+26 3.23895900e+26]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [-2.09329787e+25 -2.10284292e+25 -1.14595525e+25 -1.19518166e+25\n",
      " -5.14378581e+24 -6.45617276e+24 -4.80514109e+24 -2.14253798e+25\n",
      " -4.79258515e+24 -1.32764918e+25]\n",
      "\n",
      "# 45 Gradient out:  [-1.98106952e+27 -1.99010283e+27 -1.08451695e+27 -1.13110418e+27\n",
      " -4.86801111e+26 -6.11003683e+26 -4.54752221e+26 -2.02766971e+27\n",
      " -4.53563943e+26 -1.25646969e+27]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [8.12040326e+25 8.15743080e+25 4.44543459e+25 4.63639563e+25\n",
      " 1.99539758e+25 2.50450388e+25 1.86402919e+25 8.31141745e+25\n",
      " 1.85915844e+25 5.15026883e+25]\n",
      "\n",
      "# 46 Gradient out:  [7.68504265e+27 7.72008502e+27 4.20710072e+27 4.38782373e+27\n",
      " 1.88841798e+27 2.37022947e+27 1.76409267e+27 7.86581595e+27\n",
      " 1.75948305e+27 4.87414655e+27]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [-3.15009871e+26 -3.16446258e+26 -1.72449044e+26 -1.79856879e+26\n",
      " -7.74062464e+25 -9.71556978e+25 -7.23101522e+25 -3.22419768e+26\n",
      " -7.21212042e+25 -1.99791250e+26]\n",
      "\n",
      "# 47 Gradient out:  [-2.98121191e+28 -2.99480569e+28 -1.63203503e+28 -1.70214181e+28\n",
      " -7.32562516e+27 -9.19468721e+27 -6.84333752e+27 -3.05133820e+28\n",
      " -6.82545573e+27 -1.89079806e+28]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [1.22199866e+27 1.22757075e+27 6.68971100e+26 6.97707866e+26\n",
      " 3.00277350e+26 3.76890197e+26 2.80508381e+26 1.25074342e+27\n",
      " 2.79775406e+26 7.75038060e+26]\n",
      "\n",
      "# 48 Gradient out:  [1.15648343e+29 1.16175678e+29 6.33105434e+28 6.60301531e+28\n",
      " 2.84178527e+28 3.56683916e+28 2.65469435e+28 1.18368709e+29\n",
      " 2.64775758e+28 7.33485807e+28]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [-4.74042516e+27 -4.76204063e+27 -2.59509895e+27 -2.70657574e+27\n",
      " -1.16484768e+27 -1.46204725e+27 -1.08815912e+27 -4.85193298e+27\n",
      " -1.08531574e+27 -3.00655807e+27]\n",
      "\n",
      "# 49 Gradient out:  [-4.48627591e+29 -4.50673250e+29 -2.45596745e+29 -2.56146762e+29\n",
      " -1.10239650e+29 -1.38366225e+29 -1.02981946e+29 -4.59180544e+29\n",
      " -1.02712851e+29 -2.84536694e+29]\n",
      "\n",
      "     Weights  out:  [ 0.38097902  0.38980257 -0.06390495 -0.04565573 -0.41400695 -0.30402146\n",
      " -0.45085097  0.4297205  -0.45231119  0.00240803] [1.83892434e+28 1.84730949e+28 1.00670097e+28 1.04994549e+28\n",
      " 4.51872285e+27 5.67163107e+27 4.22122959e+27 1.88218089e+28\n",
      " 4.21019942e+27 1.16631581e+28]\n",
      "\n",
      "Lineal error cuadrático medio (ECM): 5.994040386691483e+58\n",
      "\n",
      "# 0 Gradient out:  [-0.61987622 -0.31688105 -0.143051   -0.34214326 -0.13268976 -0.86669646\n",
      " -0.67969865 -0.45477302 -0.51711154 -0.33416935]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [ 0.15439944  0.39795184  0.24302006 -0.24114564  0.35690752  0.24856392\n",
      "  0.45452485 -0.46248394  0.11559849 -0.43002783]\n",
      "\n",
      "# 1 Gradient out:  [0.67688972 0.5184609  0.48688836 0.52471945 0.48455404 0.89472508\n",
      " 0.73115843 0.56563696 0.59991842 0.52265053]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [ 0.0304242   0.33457563  0.21440986 -0.30957429  0.33036957  0.07522463\n",
      "  0.31858512 -0.55343855  0.01217618 -0.4968617 ]\n",
      "\n",
      "# 2 Gradient out:  [-0.82501677 -0.4661348  -0.26396944 -0.4954245  -0.25167594 -1.12636508\n",
      " -0.89821112 -0.62705044 -0.70100171 -0.48617347]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [ 0.16580214  0.43826781  0.31178753 -0.2046304   0.42728037  0.25416965\n",
      "  0.46481681 -0.44031115  0.13215986 -0.39233159]\n",
      "\n",
      "# 3 Gradient out:  [0.85038393 0.60636425 0.53998222 0.61826605 0.53566273 1.15612699\n",
      " 0.92625413 0.68727488 0.7395651  0.61439332]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [ 0.00079878  0.34504086  0.25899364 -0.3037153   0.37694519  0.02889663\n",
      "  0.28517459 -0.56572124 -0.00804048 -0.48956629]\n",
      "\n",
      "# 4 Gradient out:  [-0.9275279  -0.53876692 -0.32161925 -0.57018653 -0.30829678 -1.25833981\n",
      " -1.00795195 -0.71190596 -0.79207096 -0.56025979]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [ 0.17087557  0.46631371  0.36699008 -0.18006209  0.48407773  0.26012203\n",
      "  0.47042541 -0.42826627  0.13987254 -0.36668762]\n",
      "\n",
      "# 5 Gradient out:  [0.87189732 0.60215896 0.52697385 0.61563799 0.52222628 1.20519863\n",
      " 0.95455184 0.69283823 0.75058407 0.611258  ]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-0.01463001  0.35856032  0.30266623 -0.29409939  0.42241838  0.00845406\n",
      "  0.26883502 -0.57064746 -0.01854165 -0.47873958]\n",
      "\n",
      "# 6 Gradient out:  [-0.93011475 -0.54668649 -0.32977666 -0.57790326 -0.31639237 -1.25391972\n",
      " -1.0087994  -0.71819999 -0.79719139 -0.56804501]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [ 0.15974945  0.47899211  0.408061   -0.1709718   0.52686363  0.24949379\n",
      "  0.45974539 -0.43207981  0.13157516 -0.35648798]\n",
      "\n",
      "# 7 Gradient out:  [0.86315845 0.58235602 0.5043292  0.59644606 0.49949374 1.2089661\n",
      " 0.94889858 0.67702811 0.73714619 0.59186766]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-0.02627349  0.36965482  0.34210567 -0.28655245  0.46358516 -0.00129015\n",
      "  0.25798551 -0.57571981 -0.02786312 -0.47009698]\n",
      "\n",
      "# 8 Gradient out:  [-0.91663315 -0.54371322 -0.32953231 -0.57436573 -0.31625399 -1.22825491\n",
      " -0.99230745 -0.71150726 -0.78824591 -0.56469079]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [ 0.1463582   0.48612602  0.44297151 -0.16726324  0.56348391  0.24050307\n",
      "  0.44776523 -0.44031419  0.11956612 -0.35172345]\n",
      "\n",
      "# 9 Gradient out:  [0.855821   0.56655504 0.48631919 0.5811161  0.48141413 1.21115166\n",
      " 0.94391017 0.66429407 0.72622582 0.57638484]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-0.03696843  0.37738337  0.37706505 -0.28213638  0.50023311 -0.00514792\n",
      "  0.24930374 -0.58261564 -0.03808306 -0.46466161]\n",
      "\n",
      "# 10 Gradient out:  [-0.90496267 -0.54068191 -0.32883704 -0.57086288 -0.31565418 -1.20665139\n",
      " -0.9781835  -0.70539292 -0.78028199 -0.56134092]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [ 0.13419577  0.49069438  0.47432888 -0.16591316  0.59651594  0.23708242\n",
      "  0.43808577 -0.44975683  0.1071621  -0.34938464]\n",
      "\n",
      "# 11 Gradient out:  [0.84836836 0.5531024  0.47135906 0.56799408 0.46641162 1.21047494\n",
      " 0.93812913 0.65300649 0.71622553 0.56315541]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-0.04679677  0.382558    0.40856148 -0.28008574  0.5333851  -0.00424786\n",
      "  0.24244907 -0.59083541 -0.0488943  -0.46165282]\n",
      "\n",
      "# 12 Gradient out:  [-0.89437836 -0.53740595 -0.32764761 -0.5671793  -0.31455591 -1.18775564\n",
      " -0.96554721 -0.6994807  -0.77280804 -0.55778932]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [ 0.1228769   0.49317848  0.50283329 -0.16648692  0.62666742  0.23784713\n",
      "  0.4300749  -0.46023412  0.09435081 -0.34902174]\n",
      "\n",
      "# 13 Gradient out:  [0.84164507 0.54201407 0.45918285 0.55714647 0.45420639 1.2086728\n",
      " 0.93261972 0.64349486 0.7076506  0.55222958]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-5.59987675e-02  3.85697291e-01  4.37303765e-01 -2.79922785e-01\n",
      "  5.63756242e-01  2.95998542e-04  2.36965454e-01 -6.00130255e-01\n",
      " -6.02107991e-02 -4.60579605e-01]\n",
      "\n",
      "# 14 Gradient out:  [-0.8853319  -0.53431505 -0.32632753 -0.56375057 -0.31331664 -1.17199651\n",
      " -0.95484413 -0.69422307 -0.76627965 -0.55446983]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [ 0.11233025  0.4941001   0.52914033 -0.16849349  0.65459752  0.24203056\n",
      "  0.4234894  -0.47143128  0.08131932 -0.35013369]\n",
      "\n",
      "# 15 Gradient out:  [0.83589128 0.53302145 0.44936427 0.54833458 0.44436523 1.20654412\n",
      " 0.92775981 0.63567962 0.70052985 0.543359  ]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-0.06473614  0.38723709  0.46387483 -0.2812436   0.59193419  0.00763126\n",
      "  0.23252057 -0.6102759  -0.07193661 -0.46102766]\n",
      "\n",
      "# 16 Gradient out:  [-0.87785626 -0.53156697 -0.32503642 -0.56073016 -0.31209439 -1.15923701\n",
      " -0.94606496 -0.68974142 -0.76079061 -0.55153736]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [ 0.10244212  0.49384138  0.55374768 -0.17157669  0.68080724  0.24894008\n",
      "  0.41807253 -0.48313997  0.06816936 -0.35235585]\n",
      "\n",
      "# 17 Gradient out:  [0.83116739 0.52582934 0.44150343 0.54128371 0.43648398 1.2045433\n",
      " 0.92370691 0.62939654 0.69477494 0.53626237]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-0.07312913  0.38752799  0.4887404  -0.28372272  0.61838836  0.01709268\n",
      "  0.22885954 -0.62108826 -0.08398876 -0.46266333]\n",
      "\n",
      "# 18 Gradient out:  [-0.87185058 -0.52921766 -0.32385376 -0.55816694 -0.31096859 -1.14918014\n",
      " -0.93906025 -0.6860406  -0.75631173 -0.54904313]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [ 0.09310435  0.49269386  0.57704109 -0.17546598  0.70568516  0.25800134\n",
      "  0.41360092 -0.49520895  0.05496623 -0.35541085]\n",
      "\n",
      "# 19 Gradient out:  [0.82742163 0.52014258 0.43523876 0.53571239 0.43019868 1.20289184\n",
      " 0.92047669 0.62443897 0.69023131 0.53065377]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-0.08126577  0.38685033  0.51227033 -0.28709937  0.64349144  0.02816531\n",
      "  0.22578887 -0.63241707 -0.09629612 -0.46521948]\n",
      "\n",
      "# 20 Gradient out:  [-0.86714331 -0.52726204 -0.32280967 -0.55604756 -0.30997031 -1.14145443\n",
      " -0.93360896 -0.68305871 -0.75274518 -0.54697649]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [ 0.08421855  0.49087884  0.59931809 -0.17995689  0.72953117  0.26874368\n",
      "  0.40988421 -0.50752928  0.04175014 -0.35908872]\n",
      "\n",
      "# 21 Gradient out:  [0.82454597 0.51568774 0.43025601 0.53135616 0.42519391 1.20167033\n",
      " 0.91800766 0.62059264 0.68672018 0.52626581]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-0.08921011  0.38542643  0.53475615 -0.2911664   0.66753711  0.04045279\n",
      "  0.22316242 -0.64414102 -0.10879889 -0.46848402]\n",
      "\n",
      "# 22 Gradient out:  [-0.86353822 -0.5256635  -0.32190654 -0.55432703 -0.30910333 -1.13567645\n",
      " -0.92946859 -0.68070332 -0.74996426 -0.54529519]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [ 0.07569909  0.48856398  0.62080735 -0.18489517  0.7525759   0.28078686\n",
      "  0.40676395 -0.52002249  0.02854514 -0.36323086]\n",
      "\n",
      "# 23 Gradient out:  [0.82241069 0.51222345 0.42628979 0.52797947 0.42120383 1.20087886\n",
      " 0.91620216 0.61765538 0.68406347 0.52286106]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-0.09700856  0.38343128  0.55642605 -0.29576057  0.69075523  0.05365157\n",
      "  0.22087023 -0.65616316 -0.12144771 -0.4722899 ]\n",
      "\n",
      "# 24 Gradient out:  [-0.86084144 -0.52437191 -0.32113239 -0.55294746 -0.30835718 -1.13148614\n",
      " -0.92640421 -0.67887323 -0.74783699 -0.54394385]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [ 0.06747358  0.48587597  0.641684   -0.19016468  0.774996    0.29382734\n",
      "  0.40411067 -0.53263208  0.01536498 -0.36771769]\n",
      "\n",
      "# 25 Gradient out:  [0.82088516 0.50954399 0.42312088 0.52538031 0.4180092  1.20047591\n",
      " 0.91495159 0.61544719 0.68209741 0.52023628]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-0.10469471  0.38100159  0.57745753 -0.30075417  0.71332456  0.06753011\n",
      "  0.21882982 -0.66840673 -0.13420241 -0.47650646]\n",
      "\n",
      "# 26 Gradient out:  [-0.85887591 -0.52333434 -0.3204689  -0.55184905 -0.30771506 -1.12856447\n",
      " -0.9242037  -0.67747101 -0.74623936 -0.54286489]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [ 0.05948232  0.48291039  0.6620817  -0.19567811  0.7969264   0.30762529\n",
      "  0.40182014 -0.54531729  0.00221707 -0.3724592 ]\n",
      "\n",
      "# 27 Gradient out:  [0.81984902 0.50747857 0.42057151 0.52339023 0.41543246 1.20040251\n",
      " 0.91415078 0.61381412 0.68067903 0.51822226]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-0.11229286  0.37824352  0.59798792 -0.30604792  0.73538339  0.0819124\n",
      "  0.2169794  -0.68081149 -0.1470308  -0.48103218]\n",
      "\n",
      "# 28 Gradient out:  [-0.85748791 -0.52250092 -0.31989623 -0.55097613 -0.30715843 -1.12663978\n",
      " -0.92268423 -0.67640925 -0.74506181 -0.54200453]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [ 0.05167695  0.47973923  0.68210222 -0.20136987  0.81846988  0.3219929\n",
      "  0.39980956 -0.55804867 -0.010895   -0.37738773]\n",
      "\n",
      "# 29 Gradient out:  [0.81919738 0.50588831 0.41849964 0.52187185 0.41333183 1.20059614\n",
      " 0.91370534 0.61262827 0.67968788 0.5166811 ]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-0.11982064  0.37523905  0.61812298 -0.3115651   0.75703819  0.09666494\n",
      "  0.21527271 -0.69333052 -0.15990736 -0.48578863]\n",
      "\n",
      "# 30 Gradient out:  [-0.85654858 -0.52182764 -0.3193955  -0.55027989 -0.30666959 -1.1254873\n",
      " -0.92169326 -0.67561314 -0.7442114  -0.54131551]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [ 0.04401884  0.47641671  0.7018229  -0.20719073  0.83970456  0.33678417\n",
      "  0.39801378 -0.57080486 -0.02396978 -0.38245241]\n",
      "\n",
      "# 31 Gradient out:  [0.81884215 0.50466214 0.41679313 0.52071499 0.41159548 1.20099818\n",
      " 0.91353449 0.61178576 0.67902512 0.51550233]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-0.12729088  0.37205118  0.63794381 -0.31724671  0.77837064  0.11168671\n",
      "  0.21367513 -0.70592749 -0.17281206 -0.49071551]\n",
      "\n",
      "# 32 Gradient out:  [-0.85595258 -0.52127727 -0.31895003 -0.54971922 -0.30623281 -1.12492506\n",
      " -0.92110653 -0.67502062 -0.74361156 -0.54075797]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [ 0.03647755  0.47298361  0.72130243 -0.21310371  0.86068974  0.35188635\n",
      "  0.39638202 -0.58357034 -0.03700704 -0.38761505]\n",
      "\n",
      "# 33 Gradient out:  [0.8187113  0.50371234 0.41536431 0.5198325  0.41013603 1.20155725\n",
      " 0.91357131 0.61120359 0.67861124 0.51459861]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-0.13471296  0.36872816  0.65751242 -0.32304755  0.79944317  0.12690133\n",
      "  0.21216072 -0.71857446 -0.18572935 -0.49576664]\n",
      "\n",
      "# 34 Gradient out:  [-0.85561543 -0.52081926 -0.31854574 -0.54926047 -0.30583479 -1.12480811\n",
      " -0.92082466 -0.67458141 -0.74320051 -0.54029926]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [ 0.0290293   0.46947063  0.74058529 -0.21908105  0.88147038  0.36721278\n",
      "  0.39487498 -0.59633374 -0.0500071  -0.39284692]\n",
      "\n",
      "# 35 Gradient out:  [0.81874707 0.50297034 0.41414519 0.51915617 0.40888573 1.20223017\n",
      " 0.91376167 0.61081634 0.67838321 0.5139016 ]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-0.14209379  0.36530677  0.67687614 -0.32893315  0.82030342  0.14225116\n",
      "  0.21071005 -0.73125003 -0.19864721 -0.50090677]\n",
      "\n",
      "# 36 Gradient out:  [-0.85547034 -0.52042901 -0.31817109 -0.54887663 -0.30546459 -1.12502245\n",
      " -0.9207692  -0.67425547 -0.74292923 -0.53991315]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [ 0.02165563  0.46590084  0.75970518 -0.22510191  0.90208057  0.3826972\n",
      "  0.39346238 -0.60908676 -0.06297057 -0.39812645]\n",
      "\n",
      "# 37 Gradient out:  [0.8189038  0.50238299 0.41308338 0.51863307 0.4077924  1.20298171\n",
      " 0.91406249 0.61057295 0.67829166 0.5133583 ]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-0.14943844  0.36181504  0.69607096 -0.33487724  0.84098765  0.15769271\n",
      "  0.20930854 -0.74393785 -0.21155641 -0.50610908]\n",
      "\n",
      "# 38 Gradient out:  [-0.85546512 -0.52008708 -0.31781681 -0.54854636 -0.30511346 -1.12547929\n",
      " -0.92087893 -0.67401133 -0.74275925 -0.53957891]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [ 0.01434232  0.46229164  0.77868763 -0.23115063  0.92254613  0.39828905\n",
      "  0.39212104 -0.62182326 -0.07589808 -0.40343742]\n",
      "\n",
      "# 39 Gradient out:  [0.81914582 0.50190934 0.41213868 0.51822238 0.40681603 1.20378367\n",
      " 0.91443999 0.61043389 0.67829825 0.51292783]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-0.15675071  0.35827422  0.71512427 -0.3408599   0.86152344  0.17319319\n",
      "  0.20794525 -0.75662553 -0.22444993 -0.5113532 ]\n",
      "\n",
      "# 40 Gradient out:  [-0.8555593  -0.51977826 -0.31747562 -0.54825298 -0.30477449 -1.12610999\n",
      " -0.92110643 -0.67382449 -0.74266071 -0.53928035]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [ 0.00707846  0.45865609  0.79755201 -0.23721542  0.94288664  0.41394992\n",
      "  0.39083325 -0.63453875 -0.08879028 -0.40876764]\n",
      "\n",
      "# 41 Gradient out:  [0.81944552 0.50151801 0.41128042 0.51789281 0.40592606 1.20461383\n",
      " 0.91486786 0.61036877 0.67837343 0.51257889]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-0.1640334   0.35470044  0.73405689 -0.34686602  0.88193175  0.18872792\n",
      "  0.20661197 -0.76930365 -0.23732242 -0.51662371]\n",
      "\n",
      "# 42 Gradient out:  [-0.85572171 -0.51949077 -0.31714183 -0.54798358 -0.30444229 -1.12686182\n",
      " -0.92141522 -0.67367604 -0.74261058 -0.53900491]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-1.44299474e-04  4.55004039e-01  8.16312968e-01 -2.43287455e-01\n",
      "  9.63116959e-01  4.29650691e-01  3.89585539e-01 -6.47229894e-01\n",
      " -1.01647735e-01 -4.14107931e-01]\n",
      "\n",
      "# 43 Gradient out:  [0.81978161 0.50118505 0.41048523 0.51762046 0.40509925 1.20545491\n",
      " 0.91532584 0.61035429 0.67849451 0.51228753]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-0.17128864  0.35110588  0.7528846  -0.35288417  0.9022285   0.20427833\n",
      "  0.20530249 -0.7819651  -0.25016985 -0.52190891]\n",
      "\n",
      "# 44 Gradient out:  [-0.85592849 -0.51921555 -0.31681108 -0.54772825 -0.3041127  -1.12769443\n",
      " -0.92177737 -0.67355146 -0.74259117 -0.53874295]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-0.00733232  0.45134289  0.83498165 -0.24936008  0.98324835  0.44536931\n",
      "  0.38836766 -0.65989424 -0.11447095 -0.41945141]\n",
      "\n",
      "# 45 Gradient out:  [0.82013782 0.50089222 0.40973538 0.51738714 0.40431794 1.20629351\n",
      " 0.91579837 0.61037271 0.67864421 0.51203556]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-0.17851802  0.34749979  0.77161943 -0.35890573  0.92242581  0.21983042\n",
      "  0.20401219 -0.79460454 -0.26298918 -0.5272    ]\n",
      "\n",
      "# 46 Gradient out:  [-0.85616144 -0.51894566 -0.31648    -0.5474794  -0.30378258 -1.12857709\n",
      " -0.92217158 -0.67343967 -0.74258901 -0.5384871 ]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-0.01449046  0.44767823  0.85356651 -0.2554283   1.0032894   0.46108912\n",
      "  0.38717186 -0.67253    -0.12726034 -0.42479289]\n",
      "\n",
      "# 47 Gradient out:  [0.82050174 0.50062571 0.40901744 0.51717904 0.40356877 1.2071194\n",
      " 0.91627357 0.61041054 0.67880935 0.51180916]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-0.18572274  0.3438891   0.79027051 -0.36492418  0.94253288  0.23537371\n",
      "  0.20273755 -0.80721793 -0.27577814 -0.53249031]\n",
      "\n",
      "# 48 Gradient out:  [-0.85640672 -0.51867585 -0.31614607 -0.54723126 -0.30344949 -1.12948644\n",
      " -0.92258168 -0.67333224 -0.74259384 -0.53823176]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-0.0216224   0.44401424  0.87207399 -0.26148837  1.02324664  0.47679759\n",
      "  0.38599226 -0.68513582 -0.14001627 -0.43012847]\n",
      "\n",
      "# 49 Gradient out:  [0.82086396 0.50037503 0.40832125 0.51698571 0.40284163 1.20792476\n",
      " 0.91674243 0.61045756 0.67897996 0.51159788]\n",
      "\n",
      "     Weights  out:  [-0.06374583 -0.28541783 -0.46411801 -0.26517365 -0.47922107  0.11364316\n",
      " -0.02066892 -0.18122657 -0.13684739 -0.2714842 ] [-0.19290374  0.34027907  0.80884478 -0.37093463  0.96255674  0.2509003\n",
      "  0.20147592 -0.81980227 -0.28853504 -0.53777482]\n",
      "\n",
      "Tanh error cuadrático medio (ECM): 0.5100486435656747\n",
      "\n",
      "# 0 Gradient out:  [0.64233315 0.46436027 0.36936571 0.64470264 0.37434652 0.64551966\n",
      " 0.64478957 0.5406298  0.4983457  0.61128563]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [-0.26648283 -0.34300423  0.16307117  0.09160537  0.28025479  0.48884083\n",
      "  0.07245588 -0.2398131  -0.41889136  0.25890676]\n",
      "\n",
      "# 1 Gradient out:  [-4.08044213 -2.18357628 -1.17633892 -3.951691   -0.67289443 -3.88404759\n",
      " -3.9458266  -2.64554541 -2.39100096 -3.15369008]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [-0.1380162  -0.25013217  0.23694431  0.2205459   0.3551241   0.61794476\n",
      "  0.2014138  -0.13168714 -0.31922222  0.38116389]\n",
      "\n",
      "# 2 Gradient out:  [22.26106458 12.47077848  7.26699687 21.68238085  4.9787625  21.37543881\n",
      " 21.65587351 15.04710779 13.62605461 17.80446566]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [-0.95410463 -0.68684743  0.00167653 -0.5697923   0.22054521 -0.15886476\n",
      " -0.58775152 -0.66079622 -0.79742241 -0.24957413]\n",
      "\n",
      "# 3 Gradient out:  [-124.30528747  -69.16467957  -39.86357661 -120.94991626  -26.62848896\n",
      " -119.17421994 -120.7964307   -83.46293212  -75.57781389  -98.84350885]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [3.49810829 1.80730827 1.4550759  3.76668387 1.21629771 4.116223\n",
      " 3.74342318 2.34862534 1.92778851 3.31131901]\n",
      "\n",
      "# 4 Gradient out:  [691.50368131 385.14683259 222.34312003 672.95968061 149.16478743\n",
      " 663.14175946 672.11119218 464.80105204 420.87225227 550.40566053]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [-21.3629492  -12.02562765  -6.51763942 -20.42329938  -4.10940008\n",
      " -19.71862099 -20.41586296 -14.34396109 -13.18777427 -16.45738276]\n",
      "\n",
      "# 5 Gradient out:  [-3849.14706524 -2143.54259916 -1237.16329439 -3745.80458107\n",
      "  -829.38680328 -3691.0956096  -3741.07634938 -2586.78923822\n",
      " -2342.3430779  -3063.22773143]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [116.93778706  65.00373887  37.95098459 114.16863674  25.72355741\n",
      " 112.90973091 114.00637548  78.61624932  70.98667619  93.62374934]\n",
      "\n",
      "# 6 Gradient out:  [21423.54368312 11930.76449655  6886.17249562 20848.47994141\n",
      "  4617.00872751 20544.03934804 20822.16877086 14397.93715689\n",
      " 13037.31412624 17049.77929423]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [-652.89162599 -363.70478096 -209.48167429 -634.99227947 -140.15380325\n",
      " -625.30939101 -634.2088944  -438.74159832 -397.48193939 -519.02179694]\n",
      "\n",
      "# 7 Gradient out:  [-119240.88668429  -66405.00527317  -38327.31187881 -116040.0329355\n",
      "  -25696.98809789 -114345.49574845 -115893.58299627  -80136.82269312\n",
      "  -72563.85327962  -94896.55732746]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [3631.81711063 2022.44811835 1167.75282483 3534.70370881  783.24794225\n",
      " 3483.49847859 3530.22485977 2440.84583306 2209.98088585 2890.9340619 ]\n",
      "\n",
      "# 8 Gradient out:  [663678.75509572 369601.49983812 213324.90318923 645863.34974204\n",
      " 143026.64242678 636431.83987095 645048.23410183 446031.13544414\n",
      " 403880.90163926 528181.95161029]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [-20216.36022623 -11258.55293629  -6497.70955093 -19673.30287829\n",
      "  -4356.14967732 -19385.6006711  -19648.49173948 -13586.51870557\n",
      " -12302.78977007 -16088.37740359]\n",
      "\n",
      "# 9 Gradient out:  [-3693948.4348671  -2057153.08558941 -1187338.1039854  -3594790.12222591\n",
      "  -796066.83396821 -3542295.52615746 -3590253.29106295 -2482550.16265252\n",
      " -2247947.62932535 -2939790.64449765]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [112519.39079292  62661.74703134  36167.27108692 109499.36707012\n",
      "  24249.17880803 107900.76730309 109361.15508088  75619.70838326\n",
      "  68473.39055778  89548.01291847]\n",
      "\n",
      "# 10 Gradient out:  [20560028.35122944 11449842.0466504   6608566.95325969 20008126.41466238\n",
      "  4430803.23891027 19715948.49221772 19982875.01749415 13817546.11201951\n",
      " 12511779.32953162 16362486.28823785]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [-626270.2961805  -348768.87008654 -201300.34971016 -609458.65737506\n",
      " -134964.18798561 -600558.3379284  -608689.50313171 -420890.32414724\n",
      " -381116.13530729 -498410.11598106]\n",
      "\n",
      "# 11 Gradient out:  [-1.14434400e+08 -6.37283070e+07 -3.67824099e+07 -1.11362586e+08\n",
      " -2.46612645e+07 -1.09736362e+08 -1.11222040e+08 -7.69066346e+07\n",
      " -6.96389094e+07 -9.10714350e+07]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [3485735.37406539 1941199.53924354 1120413.04094177 3392166.62555741\n",
      "  751196.45979644 3342631.36051515 3387885.50036712 2342618.89825666\n",
      " 2121239.73059903 2774087.14166651]\n",
      "\n",
      "# 12 Gradient out:  [6.36926737e+08 3.54703330e+08 2.04726030e+08 6.19829430e+08\n",
      " 1.37261338e+08 6.10778084e+08 6.19047170e+08 4.28052159e+08\n",
      " 3.87600962e+08 5.06891566e+08]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [-19401144.53573335 -10804461.85564688  -6236068.92959775\n",
      " -18880350.61907372  -4181056.44582523 -18604641.13569766\n",
      " -18856522.55565441 -13038708.01218091 -11806542.14880423\n",
      " -15440199.84994535]\n",
      "\n",
      "# 13 Gradient out:  [-3.54505000e+09 -1.97423184e+09 -1.13947801e+09 -3.44988866e+09\n",
      " -7.63978458e+08 -3.39951006e+09 -3.44553470e+09 -2.38248172e+09\n",
      " -2.15733571e+09 -2.82129143e+09]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [1.07984203e+08 6.01362042e+07 3.47091370e+07 1.05085535e+08\n",
      " 2.32712112e+07 1.03550976e+08 1.04952911e+08 7.25717239e+07\n",
      " 6.57136503e+07 8.59381133e+07]\n",
      "\n",
      "# 14 Gradient out:  [1.97312796e+10 1.09883134e+10 6.34218396e+09 1.92016241e+10\n",
      " 4.25220309e+09 1.89212235e+10 1.91773906e+10 1.32605782e+10\n",
      " 1.20074453e+10 1.57029351e+10]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [-6.01025798e+08 -3.34710163e+08 -1.93186466e+08 -5.84892196e+08\n",
      " -1.29524481e+08 -5.76351036e+08 -5.84154028e+08 -4.03924620e+08\n",
      " -3.65753491e+08 -4.78320173e+08]\n",
      "\n",
      "# 15 Gradient out:  [-1.09821693e+11 -6.11594994e+10 -3.52997573e+10 -1.06873701e+11\n",
      " -2.36672001e+10 -1.05313028e+11 -1.06738820e+11 -7.38066252e+10\n",
      " -6.68318529e+10 -8.74004604e+10]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [3.34523012e+09 1.86295251e+09 1.07525033e+09 3.25543263e+09\n",
      " 7.20916137e+08 3.20789366e+09 3.25132408e+09 2.24819103e+09\n",
      " 2.03573557e+09 2.66226684e+09]\n",
      "\n",
      "# 16 Gradient out:  [6.11253024e+11 3.40405687e+11 1.96473782e+11 5.94844889e+11\n",
      " 1.31728507e+11 5.86158391e+11 5.94094160e+11 4.10797917e+11\n",
      " 3.71977257e+11 4.86459407e+11]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [-1.86191085e+10 -1.03689474e+10 -5.98470114e+09 -1.81193076e+10\n",
      " -4.01252389e+09 -1.78547120e+10 -1.80964400e+10 -1.25131340e+10\n",
      " -1.13306350e+10 -1.48178252e+10]\n",
      "\n",
      "# 17 Gradient out:  [-3.40215351e+12 -1.89465304e+12 -1.09354709e+12 -3.31082800e+12\n",
      " -7.33183451e+11 -3.26248010e+12 -3.30664954e+12 -2.28644689e+12\n",
      " -2.07037623e+12 -2.70756874e+12]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [1.03631496e+11 5.77121900e+10 3.33100553e+10 1.00849670e+11\n",
      " 2.23331775e+10 9.93769661e+10 1.00722392e+11 6.96464494e+10\n",
      " 6.30648163e+10 8.24740561e+10]\n",
      "\n",
      "# 18 Gradient out:  [1.89359366e+13 1.05453883e+13 6.08653853e+12 1.84276309e+13\n",
      " 4.08080215e+12 1.81585329e+13 1.84043742e+13 1.27260611e+13\n",
      " 1.15234403e+13 1.50699696e+13]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [-5.76799206e+11 -3.21218419e+11 -1.85399363e+11 -5.61315930e+11\n",
      " -1.24303513e+11 -5.53119054e+11 -5.60607517e+11 -3.87642929e+11\n",
      " -3.51010429e+11 -4.59039691e+11]\n",
      "\n",
      "# 19 Gradient out:  [-1.05394920e+14 -5.86942371e+13 -3.38768687e+13 -1.02565757e+14\n",
      " -2.27132052e+13 -1.01067993e+14 -1.02436313e+14 -7.08315733e+13\n",
      " -6.41379452e+13 -8.38774582e+13]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [3.21038812e+12 1.78785925e+12 1.03190834e+12 3.12421025e+12\n",
      " 6.91856917e+11 3.07858752e+12 3.12026731e+12 2.15756929e+12\n",
      " 1.95367764e+12 2.55495423e+12]\n",
      "\n",
      "# 20 Gradient out:  [5.86614187e+14 3.26684363e+14 1.88554172e+14 5.70867442e+14\n",
      " 1.26418697e+14 5.62531086e+14 5.70146975e+14 3.94239172e+14\n",
      " 3.56983323e+14 4.66850842e+14]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [-1.78685958e+13 -9.95098818e+12 -5.74346539e+12 -1.73889411e+13\n",
      " -3.85078412e+12 -1.71350111e+13 -1.73669953e+13 -1.20087454e+13\n",
      " -1.08739114e+13 -1.42205374e+13]\n",
      "\n",
      "# 21 Gradient out:  [-3.26501700e+15 -1.81828197e+15 -1.04946759e+15 -3.17737270e+15\n",
      " -7.03629752e+14 -3.13097365e+15 -3.17336268e+15 -2.19428310e+15\n",
      " -1.98692197e+15 -2.59843006e+15]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [9.94542415e+13 5.53858845e+13 3.19673690e+13 9.67845472e+13\n",
      " 2.14329553e+13 9.53712061e+13 9.66623996e+13 6.68390890e+13\n",
      " 6.05227532e+13 7.91496310e+13]\n",
      "\n",
      "# 22 Gradient out:  [1.81726529e+16 1.01203170e+16 5.84119784e+15 1.76848363e+16\n",
      " 3.91631016e+15 1.74265853e+16 1.76625171e+16 1.22130896e+16\n",
      " 1.10589450e+16 1.44625181e+16]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [-5.53549158e+14 -3.08270510e+14 -1.77926149e+14 -5.38689993e+14\n",
      " -1.19292995e+14 -5.30823523e+14 -5.38010136e+14 -3.72017532e+14\n",
      " -3.36861642e+14 -4.40536381e+14]\n",
      "\n",
      "# 23 Gradient out:  [-1.01146583e+17 -5.63283465e+16 -3.25113349e+16 -9.84314608e+16\n",
      " -2.17976646e+16 -9.69940698e+16 -9.83072347e+16 -6.79764420e+16\n",
      " -6.15526256e+16 -8.04964637e+16]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [3.08098143e+15 1.71579290e+15 9.90313420e+14 2.99827728e+15\n",
      " 6.63969038e+14 2.95449354e+15 2.99449328e+15 2.07060039e+15\n",
      " 1.87492736e+15 2.45196725e+15]\n",
      "\n",
      "# 24 Gradient out:  [5.62968509e+17 3.13516129e+17 1.80953791e+17 5.47856496e+17\n",
      " 1.21322919e+17 5.39856168e+17 5.47165070e+17 3.78347888e+17\n",
      " 3.42593776e+17 4.48032674e+17]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [-1.71483352e+16 -9.54987641e+15 -5.51195355e+15 -1.66880149e+16\n",
      " -3.69556387e+15 -1.64443204e+16 -1.66669537e+16 -1.15246880e+16\n",
      " -1.04355978e+16 -1.36473255e+16]\n",
      "\n",
      "# 25 Gradient out:  [-3.13340829e+18 -1.74498932e+18 -1.00716488e+18 -3.04929682e+18\n",
      " -6.75267325e+17 -3.00476805e+18 -3.04544843e+18 -2.10583432e+18\n",
      " -1.90683166e+18 -2.49369062e+18]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [9.54453666e+16 5.31533494e+16 3.06788047e+16 9.28832843e+16\n",
      " 2.05690199e+16 9.15269131e+16 9.27660603e+16 6.41448897e+16\n",
      " 5.80831574e+16 7.59592093e+16]\n",
      "\n",
      "# 26 Gradient out:  [1.74401362e+19 9.71237984e+18 5.60574653e+18 1.69719829e+19\n",
      " 3.75844865e+18 1.67241417e+19 1.69505633e+19 1.17207954e+19\n",
      " 1.06131729e+19 1.38795523e+19]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [-5.31236291e+17 -2.95844515e+17 -1.70754171e+17 -5.16976079e+17\n",
      " -1.14484445e+17 -5.09426697e+17 -5.16323626e+17 -3.57021975e+17\n",
      " -3.23283174e+17 -4.22778915e+17]\n",
      "\n",
      "# 27 Gradient out:  [-9.70694923e+19 -5.40578220e+19 -3.12008440e+19 -9.44638128e+19\n",
      " -2.09190282e+19 -9.30843613e+19 -9.43445941e+19 -6.52363974e+19\n",
      " -5.90715170e+19 -7.72517529e+19]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [2.95679095e+18 1.64663145e+18 9.50395136e+17 2.87742050e+18\n",
      " 6.37205284e+17 2.83540164e+18 2.87378903e+18 1.98713710e+18\n",
      " 1.79935140e+18 2.35313154e+18]\n",
      "\n",
      "# 28 Gradient out:  [5.40275959e+20 3.00878690e+20 1.73659772e+20 5.25773092e+20\n",
      " 1.16432545e+20 5.18095247e+20 5.25109537e+20 3.63097163e+20\n",
      " 3.28784253e+20 4.29973042e+20]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [-1.64571075e+19 -9.16493295e+18 -5.28977366e+18 -1.60153421e+19\n",
      " -3.54660036e+18 -1.57814706e+19 -1.59951298e+19 -1.10601424e+19\n",
      " -1.00149520e+19 -1.30972190e+19]\n",
      "\n",
      "# 29 Gradient out:  [-3.00710455e+21 -1.67465100e+21 -9.66567331e+20 -2.92638351e+21\n",
      " -6.48048151e+20 -2.88364964e+21 -2.92269025e+21 -2.02095080e+21\n",
      " -1.82996968e+21 -2.39317310e+21]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [9.15980844e+19 5.10108050e+19 2.94421808e+19 8.91392764e+19\n",
      " 1.97399087e+19 8.78375788e+19 8.90267775e+19 6.15592901e+19\n",
      " 5.57418986e+19 7.28973894e+19]\n",
      "\n",
      "# 30 Gradient out:  [1.67371463e+22 9.32088607e+21 5.37978597e+21 1.62878637e+22\n",
      " 3.60695032e+21 1.60500126e+22 1.62673075e+22 1.12483449e+22\n",
      " 1.01853693e+22 1.33200851e+22]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [-5.09822826e+20 -2.83919396e+20 -1.63871285e+20 -4.96137426e+20\n",
      " -1.09869722e+20 -4.88892350e+20 -4.95511273e+20 -3.42630869e+20\n",
      " -3.10252038e+20 -4.05737231e+20]\n",
      "\n",
      "# 31 Gradient out:  [-9.31567436e+22 -5.18788194e+22 -2.99431774e+22 -9.06560958e+22\n",
      " -2.00758086e+22 -8.93322482e+22 -9.05416826e+22 -6.26068006e+22\n",
      " -5.66904187e+22 -7.41378322e+22]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [2.83760644e+21 1.58025782e+21 9.12085908e+20 2.76143531e+21\n",
      " 6.11520343e+20 2.72111018e+21 2.75795023e+21 1.90703812e+21\n",
      " 1.72682182e+21 2.25827978e+21]\n",
      "\n",
      "# 32 Gradient out:  [5.18498117e+23 2.88750649e+23 1.66659766e+23 5.04579843e+23\n",
      " 1.11739296e+23 4.97211482e+23 5.03943034e+23 3.48461174e+23\n",
      " 3.15531375e+23 4.12641372e+23]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [-1.57937423e+22 -8.79550607e+21 -5.07654957e+21 -1.53697838e+22\n",
      " -3.40364138e+21 -1.51453395e+22 -1.53503863e+22 -1.06143220e+22\n",
      " -9.61126192e+21 -1.25692867e+22]\n",
      "\n",
      "# 33 Gradient out:  [-2.88589197e+24 -1.60714794e+24 -9.27606222e+23 -2.80842469e+24\n",
      " -6.21926148e+23 -2.76741337e+24 -2.80488030e+24 -1.93948882e+24\n",
      " -1.75620591e+24 -2.29670732e+24]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [8.79058812e+22 4.89546238e+22 2.82554037e+22 8.55461847e+22\n",
      " 1.89442179e+22 8.42969569e+22 8.54382205e+22 5.90779129e+22\n",
      " 5.34950131e+22 6.99589877e+22]\n",
      "\n",
      "# 34 Gradient out:  [1.60624931e+25 8.94517291e+24 5.16293358e+24 1.56313205e+25\n",
      " 3.46155871e+24 1.54030569e+25 1.56115929e+25 1.07949383e+25\n",
      " 9.77480991e+24 1.27831692e+25]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [-4.89272512e+23 -2.72474963e+23 -1.57265841e+23 -4.76138753e+23\n",
      " -1.05441012e+23 -4.69185716e+23 -4.75537839e+23 -3.28819852e+23\n",
      " -2.97746170e+23 -3.89382475e+23]\n",
      "\n",
      "# 35 Gradient out:  [-8.94017128e+25 -4.97876497e+25 -2.87362057e+25 -8.70018630e+25\n",
      " -1.92665781e+25 -8.57313780e+25 -8.68920617e+25 -6.00831995e+25\n",
      " -5.44052995e+25 -7.11494298e+25]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [2.72322611e+24 1.51655962e+24 8.75320876e+23 2.65012534e+24\n",
      " 5.86870730e+23 2.61142566e+24 2.64678073e+24 1.83016782e+24\n",
      " 1.65721581e+24 2.16725137e+24]\n",
      "\n",
      "# 36 Gradient out:  [4.97598113e+26 2.77111475e+26 1.59941921e+26 4.84240866e+26\n",
      " 1.07235226e+26 4.77169515e+26 4.83629726e+26 3.34415144e+26\n",
      " 3.02812704e+26 3.96008319e+26]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [-1.51571165e+25 -8.44097032e+24 -4.87192026e+24 -1.47502473e+25\n",
      " -3.26644489e+24 -1.45348499e+25 -1.47316316e+25 -1.01864721e+25\n",
      " -9.22384409e+24 -1.20626346e+25]\n",
      "\n",
      "# 37 Gradient out:  [-2.76956530e+27 -1.54236583e+27 -8.90215586e+26 -2.69522063e+27\n",
      " -5.96857090e+26 -2.65586243e+27 -2.69181911e+27 -1.86131048e+27\n",
      " -1.68541547e+27 -2.20412994e+27]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [8.43625061e+25 4.69813247e+25 2.71164640e+25 8.20979260e+25\n",
      " 1.81806004e+25 8.08990530e+25 8.19943137e+25 5.66965568e+25\n",
      " 5.13386966e+25 6.71390292e+25]\n",
      "\n",
      "# 38 Gradient out:  [1.54150343e+28 8.58460429e+27 4.95482225e+27 1.50012417e+28\n",
      " 3.32202765e+27 1.47821791e+28 1.49823093e+28 1.03598080e+28\n",
      " 9.38079966e+27 1.22678958e+28]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [-4.69550554e+26 -2.61491842e+26 -1.50926653e+26 -4.56946201e+26\n",
      " -1.01190818e+26 -4.50273432e+26 -4.56369509e+26 -3.15565539e+26\n",
      " -2.85744397e+26 -3.73686959e+26]\n",
      "\n",
      "# 39 Gradient out:  [-8.57980426e+28 -4.77807724e+28 -2.75778855e+28 -8.34949277e+28\n",
      " -1.84899667e+28 -8.22756544e+28 -8.33895524e+28 -5.76613216e+28\n",
      " -5.22122906e+28 -6.82814861e+28]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [2.61345630e+27 1.45542902e+27 8.40037797e+26 2.54330214e+27\n",
      " 5.63214712e+26 2.50616239e+27 2.54009234e+27 1.75639606e+27\n",
      " 1.59041553e+27 2.07989221e+27]\n",
      "\n",
      "# 40 Gradient out:  [4.77540561e+29 2.65941462e+29 1.53494864e+29 4.64721728e+29\n",
      " 1.02912710e+29 4.57935414e+29 4.64135223e+29 3.20935292e+29\n",
      " 2.90606706e+29 3.80045724e+29]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [-1.45461522e+28 -8.10072546e+27 -4.67553931e+27 -1.41556834e+28\n",
      " -3.13477862e+27 -1.39489685e+28 -1.41378181e+28 -9.77586825e+27\n",
      " -8.85204258e+27 -1.15764050e+28]\n",
      "\n",
      "# 41 Gradient out:  [-2.65792762e+30 -1.48019501e+30 -8.54332120e+29 -2.58657969e+30\n",
      " -5.72798535e+29 -2.54880796e+30 -2.58331528e+30 -1.78628340e+30\n",
      " -1.61747850e+30 -2.11528425e+30]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [8.09619600e+28 4.50875668e+28 2.60234336e+28 7.87886622e+28\n",
      " 1.74477633e+28 7.76381143e+28 7.86892264e+28 5.44111901e+28\n",
      " 4.92692986e+28 6.44327397e+28]\n",
      "\n",
      "# 42 Gradient out:  [1.47936737e+31 8.23856972e+30 4.75509962e+30 1.43965606e+31\n",
      " 3.18812091e+30 1.41863281e+31 1.43783913e+31 9.94221722e+30\n",
      " 9.00267146e+30 1.17733924e+31]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [-4.50623564e+29 -2.50951436e+29 -1.44842990e+29 -4.38527276e+29\n",
      " -9.71119436e+28 -4.32123479e+29 -4.37973830e+29 -3.02845490e+29\n",
      " -2.74226401e+29 -3.58624110e+29]\n",
      "\n",
      "# 43 Gradient out:  [-8.23396318e+31 -4.58547898e+31 -2.64662558e+31 -8.01293526e+31\n",
      " -1.77446594e+31 -7.89592266e+31 -8.00282248e+31 -5.53370665e+31\n",
      " -5.01076790e+31 -6.55291456e+31]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [2.50811118e+30 1.39676251e+30 8.06176933e+29 2.44078484e+30\n",
      " 5.40512238e+29 2.40514215e+30 2.43770443e+30 1.68559795e+30\n",
      " 1.52630789e+30 1.99605438e+30]\n",
      "\n",
      "# 44 Gradient out:  [4.58291504e+32 2.55221697e+32 1.47307680e+32 4.45989382e+32\n",
      " 9.87644282e+31 4.39476615e+32 4.45426518e+32 3.07998795e+32\n",
      " 2.78892716e+32 3.64726560e+32]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [-1.39598152e+31 -7.77419545e+30 -4.48707422e+30 -1.35850857e+31\n",
      " -3.00841965e+30 -1.33867032e+31 -1.35679405e+31 -9.38181535e+30\n",
      " -8.49522792e+30 -1.11097747e+31]\n",
      "\n",
      "# 45 Gradient out:  [-2.55078991e+33 -1.42053022e+33 -8.19895071e+32 -2.48231793e+33\n",
      " -5.49709749e+32 -2.44606873e+33 -2.47918510e+33 -1.71428057e+33\n",
      " -1.55227998e+33 -2.03001981e+33]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [7.76984856e+31 4.32701439e+31 2.49744618e+31 7.56127907e+31\n",
      " 1.67444660e+31 7.45086199e+31 7.55173630e+31 5.22179437e+31\n",
      " 4.72833153e+31 6.18355373e+31]\n",
      "\n",
      "# 46 Gradient out:  [1.41973594e+34 7.90648338e+33 4.56342756e+33 1.38162534e+34\n",
      " 3.05961178e+33 1.36144951e+34 1.37988165e+34 9.54145900e+33\n",
      " 8.63978514e+33 1.12988218e+34]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [-4.32459497e+32 -2.40835900e+32 -1.39004552e+32 -4.20850795e+32\n",
      " -9.31974837e+31 -4.14705127e+32 -4.20319658e+32 -2.90638171e+32\n",
      " -2.63172681e+32 -3.44168425e+32]\n",
      "\n",
      "# 47 Gradient out:  [-7.90206252e+34 -4.40064411e+34 -2.53994344e+34 -7.68994396e+34\n",
      " -1.70293946e+34 -7.57764799e+34 -7.68023881e+34 -5.31064992e+34\n",
      " -4.80879017e+34 -6.28877485e+34]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [2.40701238e+33 1.34046078e+33 7.73680959e+32 2.34239988e+33\n",
      " 5.18724872e+32 2.30819390e+33 2.33944364e+33 1.61765363e+33\n",
      " 1.46478435e+33 1.91559595e+33]\n",
      "\n",
      "# 48 Gradient out:  [4.39818352e+35 2.44934033e+35 1.41369894e+35 4.28012113e+35\n",
      " 9.47833588e+34 4.21761868e+35 4.27471937e+35 2.95583753e+35\n",
      " 2.67650903e+35 3.50024893e+35]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [-1.33971127e+34 -7.46082744e+33 -4.30620592e+33 -1.30374880e+34\n",
      " -2.88715405e+33 -1.28471021e+34 -1.30210340e+34 -9.00364621e+33\n",
      " -8.15279600e+33 -1.06619537e+34]\n",
      "\n",
      "# 49 Gradient out:  [-2.44797079e+36 -1.36327044e+36 -7.86846135e+35 -2.38225883e+36\n",
      " -5.27551643e+35 -2.34747079e+36 -2.37925228e+36 -1.64518009e+36\n",
      " -1.48970954e+36 -1.94819227e+36]\n",
      "\n",
      "     Weights  out:  [ 0.39401301 -0.04884442 -0.26990189  0.34474421 -0.45723712  0.32178228\n",
      "  0.34268428  0.03762197 -0.00994261  0.13720885] [7.45665577e+34 4.15259791e+34 2.39677728e+34 7.25649345e+34\n",
      " 1.60695177e+34 7.15052715e+34 7.24733534e+34 5.01131043e+34\n",
      " 4.53773846e+34 5.93430248e+34]\n",
      "\n",
      "Lineal error cuadrático medio (ECM): 3.5980168711872375e+72\n",
      "\n",
      "# 0 Gradient out:  [3.02393112 0.87150911 0.9200676  1.30266202 2.06944228 2.76120576\n",
      " 3.02558385 1.63515054 2.00983224 2.32284442]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.46208343  0.02992096  0.15205054  0.43623674 -0.4111716  -0.17519413\n",
      "  0.04004358 -0.33345863  0.46494641 -0.01297493]\n",
      "\n",
      "# 1 Gradient out:  [-0.47737108 -0.11418648 -0.12464984 -0.19985469 -0.31797636 -0.4263697\n",
      " -0.47771769 -0.25391416 -0.30930949 -0.355313  ]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [ 0.1427028   0.20422279  0.33606406  0.69676914  0.00271685  0.37704702\n",
      "  0.64516035 -0.00642852  0.86691286  0.45159395]\n",
      "\n",
      "# 2 Gradient out:  [-0.87977613 -0.20179765 -0.22135056 -0.36198143 -0.58223081 -0.78439877\n",
      " -0.88042448 -0.46287252 -0.56608752 -0.6517936 ]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [ 0.04722858  0.18138549  0.31113409  0.6567982  -0.06087842  0.29177308\n",
      "  0.54961682 -0.05721136  0.80505097  0.38053135]\n",
      "\n",
      "# 3 Gradient out:  [-1.89137363 -0.41387818 -0.45837887 -0.77294479 -1.24435846 -1.67854388\n",
      " -1.89283897 -0.99116998 -1.21021983 -1.39188264]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.12872665  0.14102596  0.26686398  0.58440192 -0.17732458  0.13489333\n",
      "  0.37353192 -0.14978586  0.69183346  0.25017263]\n",
      "\n",
      "# 4 Gradient out:  [3.18727972 0.94907924 1.00242903 1.41071826 2.19698787 2.90790578\n",
      " 3.18906858 1.75407005 2.13629747 2.45538711]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.50700137  0.05825033  0.17518821  0.42981296 -0.42619627 -0.20081545\n",
      " -0.00503588 -0.34801986  0.4497895  -0.0282039 ]\n",
      "\n",
      "# 5 Gradient out:  [-0.45838926 -0.10698582 -0.11708586 -0.18978426 -0.30414501 -0.40907843\n",
      " -0.45872413 -0.24210948 -0.29575179 -0.34030068]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [0.13045457 0.24806617 0.37567401 0.71195661 0.0132013  0.38076571\n",
      " 0.63277784 0.00279415 0.87704899 0.46287352]\n",
      "\n",
      "# 6 Gradient out:  [-0.82867133 -0.1864507  -0.20493621 -0.33803353 -0.5467895  -0.73839039\n",
      " -0.82928467 -0.43363373 -0.53148399 -0.61273783]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [ 0.03877672  0.22666901  0.35225684  0.67399976 -0.0476277   0.29895002\n",
      "  0.54103301 -0.04562774  0.81789863  0.39481339]\n",
      "\n",
      "# 7 Gradient out:  [-1.80437189 -0.39284736 -0.435036   -0.73411536 -1.18600382 -1.60193708\n",
      " -1.80576252 -0.94288529 -1.15320358 -1.32766718]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.12695755  0.18937887  0.3112696   0.60639305 -0.1569856   0.15127194\n",
      "  0.37517608 -0.13235449  0.71160184  0.27226582]\n",
      "\n",
      "# 8 Gradient out:  [2.87762181 0.78819506 0.83442175 1.20269762 1.95034269 2.62439685\n",
      " 2.87920479 1.52620794 1.89209804 2.19782856]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.48783193  0.1108094   0.2242624   0.45956998 -0.39418637 -0.16911547\n",
      "  0.01402357 -0.32093154  0.48096112  0.00673239]\n",
      "\n",
      "# 9 Gradient out:  [-0.56624695 -0.12856661 -0.14112993 -0.23166275 -0.37411682 -0.50483033\n",
      " -0.56666386 -0.29684682 -0.36366275 -0.41915139]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [ 0.08769244  0.26844841  0.39114675  0.7001095  -0.00411783  0.3557639\n",
      "  0.58986453 -0.01568996  0.85938073  0.4462981 ]\n",
      "\n",
      "# 10 Gradient out:  [-1.12457405 -0.24596785 -0.27136979 -0.45401342 -0.73901788 -1.00071001\n",
      " -1.12541663 -0.58470128 -0.7181529  -0.8289525 ]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.02555695  0.24273509  0.36292076  0.65377695 -0.07894119  0.25479783\n",
      "  0.47653176 -0.07505932  0.78664818  0.36246782]\n",
      "\n",
      "# 11 Gradient out:  [-1.72353452 -0.40043899 -0.44603988 -0.75027707 -1.14855527 -1.51937209\n",
      " -1.72499581 -0.94080393 -1.12082647 -1.26950757]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.25047176  0.19354152  0.3086468   0.56297427 -0.22674477  0.05465583\n",
      "  0.25144843 -0.19199958  0.6430176   0.19667732]\n",
      "\n",
      "# 12 Gradient out:  [3.10340326 1.0117027  1.06613663 1.46316803 2.18157696 2.8333726\n",
      " 3.10518119 1.7802971  2.12673695 2.41563331]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.59517867  0.11345372  0.21943883  0.41291886 -0.45645582 -0.24921859\n",
      " -0.09355073 -0.38016036  0.4188523  -0.05722419]\n",
      "\n",
      "# 13 Gradient out:  [-0.72253463 -0.15660415 -0.17282309 -0.28988383 -0.47408008 -0.64310614\n",
      " -0.72307353 -0.37418632 -0.46056622 -0.53229997]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [ 0.02550199  0.31579426  0.43266615  0.70555246 -0.02014043  0.31745593\n",
      "  0.52748551 -0.02410094  0.84419969  0.42590247]\n",
      "\n",
      "# 14 Gradient out:  [-1.55450919 -0.33043193 -0.36645879 -0.62353121 -1.01783232 -1.38034968\n",
      " -1.55570013 -0.80506199 -0.9890973  -1.14182201]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.11900494  0.28447343  0.39810154  0.6475757  -0.11495645  0.1888347\n",
      "  0.38287081 -0.09893821  0.75208645  0.31944248]\n",
      "\n",
      "# 15 Gradient out:  [1.13932791 0.18735235 0.19625925 0.31800102 0.70740858 1.05143919\n",
      " 1.13974198 0.47566116 0.67511612 0.8427969 ]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.42990678  0.21838704  0.32480978  0.52286945 -0.31852291 -0.08723523\n",
      "  0.07173078 -0.2599506   0.55426699  0.09107807]\n",
      "\n",
      "# 16 Gradient out:  [-1.93748754 -0.4259154  -0.47298044 -0.8005074  -1.27674647 -1.71636048\n",
      " -1.93902488 -1.0224813  -1.24253198 -1.42487408]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.2020412   0.25585751  0.36406163  0.58646966 -0.17704119  0.12305261\n",
      "  0.29967918 -0.16481837  0.68929021  0.25963745]\n",
      "\n",
      "# 17 Gradient out:  [3.14140134 0.97303092 1.02793338 1.43437033 2.18456788 2.86444653\n",
      " 3.14320907 1.76437564 2.12709377 2.42967285]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.58953871  0.17067443  0.26946554  0.42636818 -0.43239049 -0.22021949\n",
      " -0.0881258  -0.36931463  0.44078381 -0.02533736]\n",
      "\n",
      "# 18 Gradient out:  [-0.59844311 -0.12851595 -0.14194748 -0.23901257 -0.39210788 -0.53257102\n",
      " -0.59888967 -0.30904483 -0.38086929 -0.44051908]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [ 0.03874156  0.36528062  0.47505222  0.71324225  0.00452309  0.35266982\n",
      "  0.54051602 -0.01643951  0.86620257  0.46059721]\n",
      "\n",
      "# 19 Gradient out:  [-1.21176452 -0.25412375 -0.28186329 -0.48123504 -0.79155957 -1.07656379\n",
      " -1.21268468 -0.62363259 -0.76885914 -0.88942468]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.08094706  0.33957743  0.44666272  0.66543973 -0.07389849  0.24615561\n",
      "  0.42073808 -0.07824847  0.79002871  0.37249339]\n",
      "\n",
      "# 20 Gradient out:  [-1.35814832 -0.36188034 -0.40208108 -0.65324313 -0.92975651 -1.19126196\n",
      " -1.35939609 -0.79176776 -0.91163341 -1.00999167]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.32329996  0.28875268  0.39029006  0.56919272 -0.2322104   0.03084285\n",
      "  0.17820114 -0.20297499  0.63625688  0.19460845]\n",
      "\n",
      "# 21 Gradient out:  [3.10382252 0.92907513 0.98333956 1.38825054 2.14353813 2.82762961\n",
      " 3.10561691 1.71988428 2.08556446 2.39067153]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.59492963  0.21637661  0.30987385  0.4385441  -0.4181617  -0.20740954\n",
      " -0.09367807 -0.36132854  0.4539302  -0.00738988]\n",
      "\n",
      "# 22 Gradient out:  [-0.59233173 -0.12506579 -0.13840101 -0.23486233 -0.38714782 -0.5268613\n",
      " -0.59277536 -0.30451432 -0.37596696 -0.43530883]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [ 0.02583488  0.40219164  0.50654176  0.7161942   0.01054592  0.35811639\n",
      "  0.52744531 -0.01735168  0.87104309  0.47074442]\n",
      "\n",
      "# 23 Gradient out:  [-1.19281493 -0.24691259 -0.27428991 -0.47115496 -0.77774184 -1.05930541\n",
      " -1.19372336 -0.61182563 -0.75531276 -0.87443529]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.09263147  0.37717848  0.47886156  0.66922174 -0.06688364  0.25274413\n",
      "  0.40889024 -0.07825455  0.7958497   0.38368266]\n",
      "\n",
      "# 24 Gradient out:  [-1.43699526 -0.38103722 -0.42278365 -0.68529015 -0.98228892 -1.26238745\n",
      " -1.43829378 -0.83286953 -0.9626043  -1.06919111]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.33119445  0.32779596  0.42400357  0.57499074 -0.22243201  0.04088304\n",
      "  0.17014557 -0.20061967  0.64478715  0.2087956 ]\n",
      "\n",
      "# 25 Gradient out:  [3.07593042 0.93192837 0.98634079 1.38851772 2.12995635 2.80193081\n",
      " 3.07772015 1.7147198  2.07316203 2.37216984]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.61859351  0.25158851  0.33944684  0.43793271 -0.4188898  -0.21159445\n",
      " -0.11751319 -0.36719358  0.45226629 -0.00504262]\n",
      "\n",
      "# 26 Gradient out:  [-0.6468706  -0.1335952  -0.14823063 -0.25418017 -0.42147078 -0.57495327\n",
      " -0.64735778 -0.33069994 -0.40918919 -0.47437437]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.00340742  0.43797419  0.536715    0.71563626  0.00710147  0.34879171\n",
      "  0.49803084 -0.02424962  0.86689869  0.46939135]\n",
      "\n",
      "# 27 Gradient out:  [-1.34282315 -0.27465884 -0.30578899 -0.52895668 -0.87426291 -1.19153785\n",
      " -1.34385461 -0.68762834 -0.84904389 -0.98302701]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.13278154  0.41125515  0.50706888  0.66480022 -0.07719268  0.23380106\n",
      "  0.36855928 -0.09038961  0.78506086  0.37451647]\n",
      "\n",
      "# 28 Gradient out:  [-0.55633468 -0.24377962 -0.26955977 -0.39885464 -0.43212786 -0.47374398\n",
      " -0.55706196 -0.43116019 -0.43277241 -0.43242483]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.40134617  0.35632338  0.44591108  0.55900889 -0.25204526 -0.00450651\n",
      "  0.09978836 -0.22791527  0.61525208  0.17791107]\n",
      "\n",
      "# 29 Gradient out:  [2.03577099 0.41190353 0.4407957  0.70206212 1.30955471 1.85359714\n",
      " 2.03683204 0.95933228 1.26122188 1.5139957 ]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.51261311  0.30756746  0.39199912  0.47923796 -0.33847084 -0.0992553\n",
      " -0.01162403 -0.31414731  0.52869759  0.0914261 ]\n",
      "\n",
      "# 30 Gradient out:  [-1.26795331 -0.26381372 -0.29295629 -0.5022378  -0.82738756 -1.1260484\n",
      " -1.26891965 -0.6515016  -0.80361416 -0.92989003]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.10545891  0.38994816  0.48015826  0.61965038 -0.07655989  0.27146412\n",
      "  0.39574238 -0.12228085  0.78094197  0.39422524]\n",
      "\n",
      "# 31 Gradient out:  [-1.06420902 -0.31573078 -0.35073763 -0.55800452 -0.74607683 -0.92768775\n",
      " -1.06526972 -0.6579971  -0.73479384 -0.79719369]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.35904957  0.33718542  0.42156701  0.51920282 -0.2420374   0.04625444\n",
      "  0.14195845 -0.25258117  0.62021914  0.20824724]\n",
      "\n",
      "# 32 Gradient out:  [2.95876539 0.80269421 0.85282991 1.24185808 2.00380929 2.69212149\n",
      " 2.96045925 1.57364797 1.9448269  2.25478052]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.57189138  0.27403926  0.35141948  0.40760192 -0.39125277 -0.13928311\n",
      " -0.0710955  -0.38418059  0.47326037  0.0488085 ]\n",
      "\n",
      "# 33 Gradient out:  [-0.59289259 -0.12584497 -0.1391867  -0.2356359  -0.38781546 -0.52743558\n",
      " -0.59333627 -0.30524501 -0.37664334 -0.43593964]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [ 0.0198617   0.43457811  0.52198546  0.65597354  0.00950909  0.39914119\n",
      "  0.52099635 -0.069451    0.86222575  0.4997646 ]\n",
      "\n",
      "# 34 Gradient out:  [-1.19597122 -0.24836011 -0.27578517 -0.47298209 -0.78014836 -1.06223762\n",
      " -1.19688116 -0.61390834 -0.75767498 -0.87703067]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.09871682  0.40940911  0.49414812  0.60884636 -0.068054    0.29365408\n",
      "  0.4023291  -0.1305      0.78689708  0.41257668]\n",
      "\n",
      "# 35 Gradient out:  [-1.4413046  -0.37763372 -0.41933408 -0.68259597 -0.98299657 -1.26608933\n",
      " -1.44260459 -0.83153832 -0.9630276  -1.07109006]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.33791106  0.35973709  0.43899109  0.51424994 -0.22408368  0.08120655\n",
      "  0.16295287 -0.25328167  0.63536209  0.23717054]\n",
      "\n",
      "# 36 Gradient out:  [3.09484171 0.93969509 0.99436278 1.39859658 2.14392608 2.8194273\n",
      " 3.09664042 1.72651189 2.08683405 2.38740979]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.62617198  0.28421035  0.35512427  0.37773074 -0.42068299 -0.17201132\n",
      " -0.12556805 -0.41958933  0.44275657  0.02295253]\n",
      "\n",
      "# 37 Gradient out:  [-0.63618606 -0.13202828 -0.14641293 -0.25049872 -0.4147984  -0.565538\n",
      " -0.63666473 -0.32565191 -0.40273661 -0.46675526]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.00720364  0.47214936  0.55399683  0.65745006  0.00810223  0.39187415\n",
      "  0.49376003 -0.07428696  0.86012338  0.50043449]\n",
      "\n",
      "# 38 Gradient out:  [-1.31536616 -0.26940557 -0.29982857 -0.51811343 -0.8565006  -1.16737401\n",
      " -1.3163746  -0.67353727 -0.83177449 -0.96312631]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.13444085  0.44574371  0.52471424  0.60735031 -0.07485745  0.27876654\n",
      "  0.36642708 -0.13941734  0.77957605  0.40708344]\n",
      "\n",
      "# 39 Gradient out:  [-0.76231582 -0.27558632 -0.30518513 -0.46604687 -0.56073256 -0.65794407\n",
      " -0.76317921 -0.52529065 -0.5566604  -0.58114001]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.39751408  0.3918626   0.46474853  0.50372763 -0.24615757  0.04529174\n",
      "  0.10315216 -0.27412479  0.61322116  0.21445818]\n",
      "\n",
      "# 40 Gradient out:  [2.50638551 0.58205646 0.62174102 0.95120273 1.65006782 2.2787761\n",
      " 2.50777658 1.25152111 1.59524943 1.88265396]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.54997725  0.33674533  0.4037115   0.41051825 -0.35830408 -0.08629707\n",
      " -0.04948368 -0.37918292  0.50188908  0.09823017]\n",
      "\n",
      "# 41 Gradient out:  [-0.86212647 -0.17967576 -0.19924584 -0.340526   -0.56252192 -0.76626246\n",
      " -0.86277698 -0.44217288 -0.546243   -0.63266281]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.04870015  0.45315663  0.52805971  0.6007588  -0.02829052  0.36945815\n",
      "  0.45207164 -0.1288787   0.82093896  0.47476097]\n",
      "\n",
      "# 42 Gradient out:  [-1.84706031 -0.3930586  -0.43730803 -0.74822895 -1.21070239 -1.63686007\n",
      " -1.84851193 -0.96262965 -1.17726751 -1.35524086]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.22112544  0.41722147  0.48821054  0.5326536  -0.14079491  0.21620566\n",
      "  0.27951624 -0.21731328  0.71169036  0.3482284 ]\n",
      "\n",
      "# 43 Gradient out:  [2.89607538 0.76170483 0.81090345 1.1946116  1.95038282 2.63291724\n",
      " 2.89774244 1.52341389 1.89182574 2.19949594]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.5905375   0.33860975  0.40074893  0.38300781 -0.38293538 -0.11116636\n",
      " -0.09018614 -0.40983921  0.47623686  0.07718023]\n",
      "\n",
      "# 44 Gradient out:  [-0.63891602 -0.13296917 -0.14741282 -0.25188906 -0.41674951 -0.56800614\n",
      " -0.63939655 -0.32730246 -0.4046472  -0.46888149]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.01132243  0.49095072  0.56292962  0.62193013  0.00714118  0.41541709\n",
      "  0.48936234 -0.10515643  0.85460201  0.51707942]\n",
      "\n",
      "# 45 Gradient out:  [-1.32426616 -0.27167286 -0.30229188 -0.52196439 -0.86249395 -1.17533491\n",
      " -1.32528103 -0.67837106 -0.83761104 -0.96979542]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.13910563  0.46435689  0.53344706  0.57155232 -0.07620872  0.30181586\n",
      "  0.36148304 -0.17061692  0.77367257  0.42330312]\n",
      "\n",
      "# 46 Gradient out:  [-0.71428099 -0.26353048 -0.29212008 -0.44580609 -0.52850113 -0.61477171\n",
      " -0.71511161 -0.49966024 -0.52532673 -0.54505985]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.40395886  0.41002231  0.47298869  0.46715944 -0.24870751  0.06674888\n",
      "  0.09642683 -0.30629113  0.60615036  0.22934404]\n",
      "\n",
      "# 47 Gradient out:  [2.42388712 0.55134338 0.58901768 0.90616756 1.58987618 2.20444042\n",
      " 2.42521758 1.19919141 1.53610581 1.81788582]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.54681506  0.35731622  0.41456467  0.37799823 -0.35440774 -0.05620546\n",
      " -0.04659549 -0.40622318  0.50108501  0.12033207]\n",
      "\n",
      "# 48 Gradient out:  [-0.91993936 -0.19209866 -0.21300293 -0.36380034 -0.6004336  -0.81762788\n",
      " -0.92063393 -0.47218014 -0.58308688 -0.67518081]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.06203763  0.4675849   0.53236821  0.55923174 -0.0364325   0.38468262\n",
      "  0.43844803 -0.16638489  0.80830618  0.48390923]\n",
      "\n",
      "# 49 Gradient out:  [-1.91930012 -0.41464741 -0.46125098 -0.7861294  -1.26140298 -1.69990427\n",
      " -1.92082309 -1.00730944 -1.22719543 -1.40943608]\n",
      "\n",
      "     Weights  out:  [ 0.33203141 -0.42872273 -0.38900038 -0.19301472  0.01330519  0.20663015\n",
      "  0.33305815 -0.09280307 -0.00083133  0.07505809] [-0.2460255   0.42916516  0.48976762  0.48647167 -0.15651922  0.22115705\n",
      "  0.25432124 -0.26082092  0.6916888   0.34887307]\n",
      "\n",
      "Tanh error cuadrático medio (ECM): 0.8803253731928353\n",
      "\n",
      "# 0 Gradient out:  [3.33722783 1.42096846 5.0072606  5.62809166 1.61843238 1.39660498\n",
      " 3.64841692 4.85848366 3.26268201 5.08087122]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [-0.18968816  0.12833228 -0.39336424 -0.05601792 -0.17892992  0.25681512\n",
      "  0.20694563  0.05647709 -0.36840089 -0.35668823]\n",
      "\n",
      "# 1 Gradient out:  [-13.42604185  -5.21191544 -20.08380122 -22.89640774  -6.15982891\n",
      "  -5.09531572 -14.63395936 -19.45201755 -13.13545858 -20.4017605 ]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [0.47775741 0.41252597 0.60808788 1.06960041 0.14475656 0.53613611\n",
      " 0.93662902 1.02817383 0.28413551 0.65948602]\n",
      "\n",
      "# 2 Gradient out:  [53.81397454 21.32732399 80.62388871 91.6037149  24.97823274 20.87805839\n",
      " 58.71143992 78.11928274 52.63709562 81.87922214]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [-2.20745096 -0.62985712 -3.40867236 -3.50968114 -1.08720923 -0.48292703\n",
      " -1.99016285 -2.86222968 -2.3429562  -3.42086608]\n",
      "\n",
      "# 3 Gradient out:  [-216.02444108  -85.22931631 -323.47163632 -367.82536415 -100.03010213\n",
      "  -83.40808679 -235.61868098 -313.39406311 -211.31459352 -328.52790921]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [ 8.55534395  3.63560768 12.71610538 14.81106184  3.90843732  3.69268465\n",
      "  9.75212513 12.76162686  8.18446292 12.95497834]\n",
      "\n",
      "# 4 Gradient out:  [ 866.75158496  342.30631923 1298.07607904 1475.77146792  401.54930507\n",
      "  335.01647966  945.44242477 1257.66188093  847.83803981 1318.34797337]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [-34.64954427 -13.41025558 -51.97822188 -58.75401099 -16.0975831\n",
      " -12.98893271 -37.37161107 -49.91718576 -34.07845578 -52.7506035 ]\n",
      "\n",
      "# 5 Gradient out:  [-3478.16706784 -1373.32482246 -5208.77098467 -5922.09455007\n",
      " -1611.19919448 -1344.05438158 -3793.86443985 -5046.57667637\n",
      " -3402.28709722 -5290.13355471]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [138.70077272  55.05100827 207.63699393 236.4002826   64.21227791\n",
      "  54.01436322 151.71687389 201.61519043 135.48915218 210.91899118]\n",
      "\n",
      "# 6 Gradient out:  [13956.87692848  5511.03572491 20901.56281499 23763.6781971\n",
      "  6465.41906104  5393.59894189 15223.76311064 20250.73894258\n",
      " 13652.37368121 21228.03436112]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [-556.93264085 -219.61395623 -834.11720301 -948.01862742 -258.02756099\n",
      " -214.7965131  -607.05601408 -807.70014484 -544.96826727 -847.10771977]\n",
      "\n",
      "# 7 Gradient out:  [-56005.53397374 -22114.17934108 -83872.56603176 -95357.77379788\n",
      " -25944.02227918 -21642.9173954  -61089.15049589 -81260.95585723\n",
      " -54783.65673166 -85182.62852199]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [2234.44274485  882.59318876 3346.19535999 3804.717012   1035.05625122\n",
      "  863.92327528 2437.69660804 3242.44764367 2185.50646898 3398.49915246]\n",
      "\n",
      "# 8 Gradient out:  [224735.84084361  88738.77069653 336559.40212567 382646.36142363\n",
      " 104106.81326871  86847.73411865 245135.18080793 326079.69216433\n",
      " 219832.74036576 341816.33550985]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [ -8966.6640499   -3540.24267946 -13428.31784636 -15266.83774758\n",
      "  -4153.74820461  -3464.6602038   -9780.13349113 -13009.74352777\n",
      "  -8771.22487735 -13638.02655194]\n",
      "\n",
      "# 9 Gradient out:  [ -901807.98183013  -356085.97266383 -1350527.27427563 -1535462.79239141\n",
      "  -417754.16686021  -348497.70545702  -983665.27060986 -1308474.84314477\n",
      "  -882133.10317299 -1371622.02661992]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [35980.50411882 14207.51145985 53883.56257877 61262.43453715\n",
      " 16667.61444913 13904.88661993 39246.90267045 52206.19490509\n",
      " 35195.3231958  54725.24055003]\n",
      "\n",
      "# 10 Gradient out:  [3618726.18579875 1428882.70578393 5419322.97247865 6161421.96971052\n",
      " 1676341.35999189 1398432.93497445 3947198.77228895 5250577.26602823\n",
      " 3539775.87764328 5503970.8408944 ]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [-144381.0922472   -57009.68307292 -216221.89227635 -245830.12394113\n",
      "  -66883.21892291  -55794.65447147 -157486.15145152 -209488.77372386\n",
      " -141231.2974388  -219599.16477395]\n",
      "\n",
      "# 11 Gradient out:  [-14521029.03055735  -5733743.15563403 -21746366.24418082\n",
      " -24724221.2499086   -6726732.01258897  -5611555.94316653\n",
      " -15839105.99166238 -21069232.57648357 -14204221.51917481\n",
      " -22086036.6496207 ]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [579364.14491255 228766.85808387 867642.70221938 986454.27000097\n",
      " 268385.05307546 223891.93252342 631953.60300627 840626.67948178\n",
      " 566723.87808985 881195.00340493]\n",
      "\n",
      "# 12 Gradient out:  [58269200.40570379 23008054.81624455 87262643.38164786 99212018.77021784\n",
      " 26992666.69734684 22517748.59084624 63558308.48868401 84545478.00860915\n",
      " 56997932.32582971 88625654.41511081]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [-2324841.66119892  -917981.77304294 -3481630.54661679 -3958389.97998075\n",
      " -1076961.34944233  -898419.25610989 -2535867.5953262  -3373219.83581493\n",
      " -2274120.42574511 -3536012.32651921]\n",
      "\n",
      "# 13 Gradient out:  [-2.33819499e+08 -9.23254789e+07 -3.50162819e+08 -3.98112628e+08\n",
      " -1.08314714e+08 -9.03580045e+07 -2.55043346e+08 -3.39259525e+08\n",
      " -2.28718223e+08 -3.55632237e+08]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [ 9328998.41994184  3683629.19020597 13970898.12971278 15884013.77406282\n",
      "  4321571.99002704  3605130.46205936 10175794.1024106  13535875.7659069\n",
      "  9125466.03942083 14189118.55650295]\n",
      "\n",
      "# 14 Gradient out:  [9.38258248e+08 3.70478692e+08 1.40511444e+09 1.59752484e+09\n",
      " 4.34639432e+08 3.62583718e+08 1.02342415e+09 1.36136229e+09\n",
      " 9.17788124e+08 1.42706182e+09]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [-37434901.30212077 -14781466.5802041  -56061665.76438596\n",
      " -63738511.73032043 -17341370.85335714 -14466470.43991633\n",
      " -40832875.01991324 -54316029.25110562 -36618178.51641952\n",
      " -56937328.74349943]\n",
      "\n",
      "# 15 Gradient out:  [-3.76499199e+09 -1.48663688e+09 -5.63836729e+09 -6.41046133e+09\n",
      " -1.74409762e+09 -1.45495635e+09 -4.10674114e+09 -5.46280102e+09\n",
      " -3.68285059e+09 -5.72643655e+09]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [1.50216748e+08 5.93142719e+07 2.24961222e+08 2.55766456e+08\n",
      " 6.95865155e+07 5.80502731e+07 1.63851956e+08 2.17956428e+08\n",
      " 1.46939446e+08 2.28475035e+08]\n",
      "\n",
      "# 16 Gradient out:  [1.51079564e+10 5.96549611e+09 2.26253355e+10 2.57235528e+10\n",
      " 6.99862069e+09 5.83837020e+09 1.64793089e+10 2.19208327e+10\n",
      " 1.47783438e+10 2.29787351e+10]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [-6.02781650e+08 -2.38013103e+08 -9.02712235e+08 -1.02632581e+09\n",
      " -2.79233009e+08 -2.32940996e+08 -6.57496272e+08 -8.74603776e+08\n",
      " -5.89630671e+08 -9.16812275e+08]\n",
      "\n",
      "# 17 Gradient out:  [-6.06243910e+10 -2.39380204e+10 -9.07897238e+10 -1.03222083e+11\n",
      " -2.80836869e+10 -2.34278964e+10 -6.61272802e+10 -8.79627329e+10\n",
      " -5.93017394e+10 -9.22078265e+10]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [2.41880963e+09 9.55086120e+08 3.62235487e+09 4.11838475e+09\n",
      " 1.12049113e+09 9.34733044e+08 2.63836551e+09 3.50956277e+09\n",
      " 2.36603809e+09 3.67893475e+09]\n",
      "\n",
      "# 18 Gradient out:  [2.43270280e+11 9.60571947e+10 3.64316097e+11 4.14203995e+11\n",
      " 1.12692701e+11 9.40101968e+10 2.65351977e+11 3.52972101e+11\n",
      " 2.37962815e+11 3.70006583e+11]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [-9.70606857e+09 -3.83251796e+09 -1.45355899e+10 -1.65260318e+10\n",
      " -4.49624625e+09 -3.75084624e+09 -1.05870905e+10 -1.40829838e+10\n",
      " -9.49430979e+09 -1.47626306e+10]\n",
      "\n",
      "# 19 Gradient out:  [-9.76181833e+11 -3.85453120e+11 -1.46190795e+12 -1.66209541e+12\n",
      " -4.52207181e+11 -3.77239037e+11 -1.06479007e+12 -1.41638737e+12\n",
      " -9.54884324e+11 -1.48474242e+12]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [3.89479874e+10 1.53789210e+10 5.83276295e+10 6.63147672e+10\n",
      " 1.80422940e+10 1.50511931e+10 4.24833048e+10 5.65114364e+10\n",
      " 3.80982532e+10 5.92386861e+10]\n",
      "\n",
      "# 20 Gradient out:  [3.91716971e+12 1.54672545e+12 5.86626520e+12 6.66956663e+12\n",
      " 1.81459254e+12 1.51376442e+12 4.27273206e+12 5.68360270e+12\n",
      " 3.83170821e+12 5.95789415e+12]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [-1.56288379e+11 -6.17117030e+10 -2.34053960e+11 -2.66104314e+11\n",
      " -7.23991422e+10 -6.03966143e+10 -1.70474710e+11 -2.26766038e+11\n",
      " -1.52878612e+11 -2.37709798e+11]\n",
      "\n",
      "# 21 Gradient out:  [-1.57186069e+13 -6.20661630e+12 -2.35398320e+13 -2.67632765e+13\n",
      " -7.28149887e+12 -6.07435207e+12 -1.71453883e+13 -2.28068538e+13\n",
      " -1.53756717e+13 -2.39075157e+13]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [6.27145562e+11 2.47633387e+11 9.39199081e+11 1.06780901e+12\n",
      " 2.90519365e+11 2.42356270e+11 6.84071702e+11 9.09954503e+11\n",
      " 6.13463031e+11 9.53869032e+11]\n",
      "\n",
      "# 22 Gradient out:  [6.30747763e+13 2.49055745e+13 9.44593657e+13 1.07394230e+14\n",
      " 2.92188052e+13 2.43748317e+13 6.88000876e+13 9.15181103e+13\n",
      " 6.16986643e+13 9.59347870e+13]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [-2.51657582e+12 -9.93689872e+11 -3.76876732e+12 -4.28484629e+12\n",
      " -1.16578041e+12 -9.72514143e+11 -2.74500596e+12 -3.65141625e+12\n",
      " -2.46167130e+12 -3.82763410e+12]\n",
      "\n",
      "# 23 Gradient out:  [-2.53103054e+14 -9.99397433e+13 -3.79041438e+14 -4.30945761e+14\n",
      " -1.17247642e+14 -9.78100074e+13 -2.76077273e+14 -3.67238927e+14\n",
      " -2.47581066e+14 -3.84961929e+14]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [1.00983795e+13 3.98742502e+12 1.51231058e+13 1.71939996e+13\n",
      " 4.67798063e+12 3.90245220e+12 1.10150116e+13 1.46522058e+13\n",
      " 9.87806156e+12 1.53593233e+13]\n",
      "\n",
      "# 24 Gradient out:  [1.01563826e+15 4.01032801e+14 1.52099700e+15 1.72927586e+15\n",
      " 4.70485003e+14 3.92486712e+14 1.10782796e+15 1.47363652e+15\n",
      " 9.93479921e+14 1.54475442e+15]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [-4.05222313e+13 -1.60005236e+13 -6.06851818e+13 -6.89951526e+13\n",
      " -1.87715478e+13 -1.56595493e+13 -4.42004431e+13 -5.87955797e+13\n",
      " -3.96381516e+13 -6.16330624e+13]\n",
      "\n",
      "# 25 Gradient out:  [-4.07549831e+15 -1.60924275e+15 -6.10337456e+15 -6.93914473e+15\n",
      " -1.88793680e+15 -1.57494947e+15 -4.44543218e+15 -5.91332900e+15\n",
      " -3.98658254e+15 -6.19870707e+15]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [1.62605420e+14 6.42060365e+13 2.43514218e+14 2.76860020e+14\n",
      " 7.53254528e+13 6.28377931e+13 1.77365150e+14 2.35931725e+14\n",
      " 1.59057833e+14 2.47317822e+14]\n",
      "\n",
      "# 26 Gradient out:  [1.63539394e+16 6.45748235e+15 2.44912916e+16 2.78450250e+16\n",
      " 7.57581074e+15 6.31987211e+15 1.78383900e+16 2.37286870e+16\n",
      " 1.59971430e+16 2.48738367e+16]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [-6.52494242e+14 -2.57642514e+14 -9.77160694e+14 -1.11096893e+15\n",
      " -3.02261906e+14 -2.52152100e+14 -7.11721287e+14 -9.46734075e+14\n",
      " -6.38258675e+14 -9.92423592e+14]\n",
      "\n",
      "# 27 Gradient out:  [-6.56242041e+16 -2.59122362e+16 -9.82773314e+16 -1.11735011e+17\n",
      " -3.03998040e+16 -2.53600413e+16 -7.15809275e+16 -9.52171930e+16\n",
      " -6.41924708e+16 -9.98123879e+16]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [2.61829363e+15 1.03385396e+15 3.92109763e+15 4.45803607e+15\n",
      " 1.21290024e+15 1.01182232e+15 2.85595672e+15 3.79900333e+15\n",
      " 2.56116992e+15 3.98234376e+15]\n",
      "\n",
      "# 28 Gradient out:  [2.63333260e+17 1.03979221e+17 3.94361964e+17 4.48364215e+17\n",
      " 1.21986690e+17 1.01763403e+17 2.87236078e+17 3.82082407e+17\n",
      " 2.57588078e+17 4.00521756e+17]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [-1.05065472e+16 -4.14859328e+15 -1.57343687e+16 -1.78889662e+16\n",
      " -4.86706055e+15 -4.06018593e+15 -1.14602288e+16 -1.52444353e+16\n",
      " -1.02773242e+16 -1.59801338e+16]\n",
      "\n",
      "# 29 Gradient out:  [-1.05668947e+18 -4.17242199e+17 -1.58247438e+18 -1.79917169e+18\n",
      " -4.89501599e+17 -4.08350685e+17 -1.15260541e+18 -1.53319963e+18\n",
      " -1.03363552e+18 -1.60719206e+18]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [4.21601048e+16 1.66472509e+16 6.31380242e+16 7.17838769e+16\n",
      " 1.95302775e+16 1.62924947e+16 4.59869867e+16 6.11720460e+16\n",
      " 4.12402913e+16 6.41242174e+16]\n",
      "\n",
      "# 30 Gradient out:  [4.24022642e+18 1.67428695e+18 6.35006767e+18 7.21961894e+18\n",
      " 1.96424556e+18 1.63860756e+18 4.62511270e+18 6.15234063e+18\n",
      " 4.14771675e+18 6.44925344e+18]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [-1.69177790e+17 -6.68011889e+16 -2.53356852e+17 -2.88050462e+17\n",
      " -7.83700423e+16 -6.53776423e+16 -1.84534095e+17 -2.45467881e+17\n",
      " -1.65486812e+17 -2.57314194e+17]\n",
      "\n",
      "# 31 Gradient out:  [-1.70149514e+19 -6.71848819e+18 -2.54812084e+19 -2.89704967e+19\n",
      " -7.88201845e+18 -6.57531586e+18 -1.85594023e+19 -2.46877800e+19\n",
      " -1.66437336e+19 -2.58792157e+19]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [6.78867494e+17 2.68056201e+17 1.01665668e+18 1.15587333e+18\n",
      " 3.14479070e+17 2.62343870e+17 7.40488445e+17 9.85000246e+17\n",
      " 6.64056538e+17 1.03253649e+18]\n",
      "\n",
      "# 32 Gradient out:  [6.82766776e+19 2.69595863e+19 1.02249616e+20 1.16251244e+20\n",
      " 3.16285377e+19 2.63850722e+19 7.44741665e+19 9.90657894e+19\n",
      " 6.67870748e+19 1.03846718e+20]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [-2.72412279e+18 -1.07564144e+18 -4.07958499e+18 -4.63822602e+18\n",
      " -1.26192462e+18 -1.05271930e+18 -2.97139201e+18 -3.95255576e+18\n",
      " -2.66469019e+18 -4.14330664e+18]\n",
      "\n",
      "# 33 Gradient out:  [-2.73976962e+20 -1.08181971e+20 -4.10301733e+20 -4.66486708e+20\n",
      " -1.26917287e+20 -1.05876592e+20 -2.98845911e+20 -3.97525846e+20\n",
      " -2.67999565e+20 -4.16710498e+20]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [1.09312127e+19 4.31627583e+18 1.63703382e+19 1.86120227e+19\n",
      " 5.06378292e+18 4.22429513e+18 1.19234413e+19 1.58606021e+19\n",
      " 1.06927248e+19 1.66260370e+19]\n",
      "\n",
      "# 34 Gradient out:  [1.09939995e+21 4.34106767e+20 1.64643662e+21 1.87189265e+21\n",
      " 5.09286830e+20 4.24855865e+20 1.19919272e+21 1.59517023e+21\n",
      " 1.07541417e+21 1.67215337e+21]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [-4.38641797e+19 -1.73201184e+19 -6.56900084e+19 -7.46853190e+19\n",
      " -2.03196744e+19 -1.69510232e+19 -4.78457409e+19 -6.36445671e+19\n",
      " -4.29071882e+19 -6.67160627e+19]\n",
      "\n",
      "# 35 Gradient out:  [-4.41161270e+21 -1.74196018e+21 -6.60673190e+21 -7.51142968e+21\n",
      " -2.04363867e+21 -1.70483866e+21 -4.81205575e+21 -6.40101291e+21\n",
      " -4.31536387e+21 -6.70992667e+21]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [1.76015810e+20 6.95012350e+19 2.63597316e+20 2.99693212e+20\n",
      " 8.15376915e+19 6.80201499e+19 1.91992803e+20 2.55389480e+20\n",
      " 1.72175646e+20 2.67714611e+20]\n",
      "\n",
      "# 36 Gradient out:  [1.77026810e+22 6.99004365e+21 2.65111367e+22 3.01414591e+22\n",
      " 8.20060280e+21 6.84108443e+21 1.93095572e+22 2.56856387e+22\n",
      " 1.73164589e+22 2.69252311e+22]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [-7.06306729e+20 -2.78890800e+20 -1.05774906e+21 -1.20259272e+21\n",
      " -3.27190042e+20 -2.72947582e+20 -7.70418346e+20 -1.02481310e+21\n",
      " -6.90897127e+20 -1.07427072e+21]\n",
      "\n",
      "# 37 Gradient out:  [-7.10363617e+22 -2.80492694e+22 -1.06382457e+23 -1.20950018e+23\n",
      " -3.29069358e+22 -2.74515339e+22 -7.74843478e+22 -1.03069943e+23\n",
      " -6.94865505e+22 -1.08044112e+23]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [2.83422947e+21 1.11911793e+21 4.24447828e+21 4.82569910e+21\n",
      " 1.31293052e+21 1.09526930e+21 3.09149310e+21 4.11231463e+21\n",
      " 2.77239466e+21 4.31077550e+21]\n",
      "\n",
      "# 38 Gradient out:  [2.85050873e+23 1.12554593e+23 4.26885774e+23 4.85341697e+23\n",
      " 1.32047173e+23 1.10156032e+23 3.10925004e+23 4.13593496e+23\n",
      " 2.78831875e+23 4.33553575e+23]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [-1.13730429e+22 -4.49073595e+21 -1.70320131e+22 -1.93643045e+22\n",
      " -5.26845663e+21 -4.39503748e+21 -1.24053765e+22 -1.65016739e+22\n",
      " -1.11249154e+22 -1.72980470e+22]\n",
      "\n",
      "# 39 Gradient out:  [-1.14383674e+24 -4.51652986e+23 -1.71298416e+24 -1.94755293e+24\n",
      " -5.29871762e+23 -4.42028171e+23 -1.24766305e+24 -1.65964563e+24\n",
      " -1.11888148e+24 -1.73974036e+24]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [4.56371318e+22 1.80201826e+22 6.83451416e+22 7.77040348e+22\n",
      " 2.11409781e+22 1.76361689e+22 4.97796242e+22 6.62170254e+22\n",
      " 4.46414595e+22 6.94126681e+22]\n",
      "\n",
      "# 40 Gradient out:  [4.58992626e+24 1.81236870e+24 6.87377028e+24 7.81503516e+24\n",
      " 2.12624077e+24 1.77374676e+24 5.00655487e+24 6.65973630e+24\n",
      " 4.48978713e+24 6.98113609e+24]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [-1.83130216e+23 -7.23104147e+22 -2.74251691e+23 -3.11806552e+23\n",
      " -8.48333743e+22 -7.07694654e+22 -1.99752986e+23 -2.65712101e+23\n",
      " -1.79134836e+23 -2.78535403e+23]\n",
      "\n",
      "# 41 Gradient out:  [-1.84182080e+25 -7.27257516e+24 -2.75826939e+25 -3.13597508e+25\n",
      " -8.53206406e+24 -7.11759514e+24 -2.00900328e+25 -2.67238299e+25\n",
      " -1.80163752e+25 -2.80135256e+25]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [7.34855035e+23 2.90163324e+23 1.10050236e+24 1.25120048e+24\n",
      " 3.40414780e+23 2.83979886e+23 8.01557987e+23 1.06623516e+24\n",
      " 7.18822590e+23 1.11769181e+24]\n",
      "\n",
      "# 42 Gradient out:  [7.39075899e+25 2.91829966e+25 1.10682343e+26 1.25838713e+26\n",
      " 3.42370056e+25 2.85611011e+25 8.06161980e+25 1.07235941e+26\n",
      " 7.22951367e+25 1.12411162e+26]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [-2.94878657e+24 -1.16435171e+24 -4.41603642e+24 -5.02074967e+24\n",
      " -1.36599803e+24 -1.13953914e+24 -3.21644857e+24 -4.27853083e+24\n",
      " -2.88445244e+24 -4.48501331e+24]\n",
      "\n",
      "# 43 Gradient out:  [-2.96572383e+26 -1.17103952e+26 -4.44140127e+26 -5.04958787e+26\n",
      " -1.37384406e+26 -1.14608443e+26 -3.23492323e+26 -4.30310587e+26\n",
      " -2.90102018e+26 -4.51077435e+26]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [1.18327314e+25 4.67224761e+24 1.77204323e+25 2.01469930e+25\n",
      " 5.48140308e+24 4.57268108e+24 1.29067910e+25 1.71686573e+25\n",
      " 1.15745749e+25 1.79972190e+25]\n",
      "\n",
      "# 44 Gradient out:  [1.19006963e+27 4.69908409e+26 1.78222150e+27 2.02627133e+27\n",
      " 5.51288719e+26 4.59894567e+26 1.29809251e+27 1.72672707e+27\n",
      " 1.16410570e+27 1.81005916e+27]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [-4.74817451e+25 -1.87485427e+25 -7.11075930e+25 -8.08447645e+25\n",
      " -2.19954781e+25 -1.83490075e+25 -5.17916735e+25 -6.88934601e+25\n",
      " -4.64458286e+25 -7.22182680e+25]\n",
      "\n",
      "# 45 Gradient out:  [-4.77544710e+27 -1.88562307e+27 -7.15160211e+27 -8.13091211e+27\n",
      " -2.21218158e+27 -1.84544006e+27 -5.20891548e+27 -6.92891707e+27\n",
      " -4.67126044e+27 -7.26330756e+27]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [1.90532181e+26 7.52331390e+25 2.85336707e+26 3.24409502e+26\n",
      " 8.82622657e+25 7.36299058e+25 2.07826829e+26 2.76451954e+26\n",
      " 1.86375311e+26 2.89793563e+26]\n",
      "\n",
      "# 46 Gradient out:  [1.91626560e+28 7.56652634e+27 2.86975625e+28 3.26272847e+28\n",
      " 8.87692269e+27 7.40528216e+27 2.09020545e+28 2.78039840e+28\n",
      " 1.87445814e+28 2.91458081e+28]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [-7.64557239e+26 -3.01891475e+26 -1.14498372e+27 -1.30177292e+27\n",
      " -3.54174050e+26 -2.95458107e+26 -8.33956267e+26 -1.10933146e+27\n",
      " -7.47876776e+26 -1.16286795e+27]\n",
      "\n",
      "# 47 Gradient out:  [-7.68948706e+28 -3.03625480e+28 -1.15156028e+29 -1.30925005e+29\n",
      " -3.56208357e+28 -2.97155161e+28 -8.38746348e+28 -1.11570324e+29\n",
      " -7.52172434e+28 -1.16954724e+29]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [3.06797397e+27 1.21141379e+27 4.59452878e+27 5.22368402e+27\n",
      " 1.42121049e+27 1.18559833e+27 3.34645464e+27 4.45146533e+27\n",
      " 3.00103951e+27 4.66629366e+27]\n",
      "\n",
      "# 48 Gradient out:  [3.08559581e+29 1.21837192e+29 4.62091885e+29 5.25368784e+29\n",
      " 1.42937364e+29 1.19240817e+29 3.36567602e+29 4.47703368e+29\n",
      " 3.01827690e+29 4.69309594e+29]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [-1.23110002e+28 -4.86109581e+27 -1.84366768e+28 -2.09613169e+28\n",
      " -5.70295664e+27 -4.75750489e+27 -1.34284723e+28 -1.78625995e+28\n",
      " -1.20424092e+28 -1.87246510e+28]\n",
      "\n",
      "# 49 Gradient out:  [-1.23817121e+30 -4.88901699e+29 -1.85425735e+30 -2.10817146e+30\n",
      " -5.73571331e+29 -4.78483107e+29 -1.35056028e+30 -1.79651988e+30\n",
      " -1.21115784e+30 -1.88322018e+30]\n",
      "\n",
      "     Weights  out:  [-0.03787543 -0.45164366  0.20118348  0.36106489 -0.367808   -0.46387813\n",
      "  0.00201891  0.17385162 -0.04758676  0.21574985] [4.94009161e+28 1.95063426e+28 7.39817003e+28 8.41124399e+28\n",
      " 2.28845162e+28 1.90906585e+28 5.38850481e+28 7.16780741e+28\n",
      " 4.83231287e+28 7.51372678e+28]\n",
      "\n",
      "Lineal error cuadrático medio (ECM): 1.4474769047815782e+60\n",
      "\n",
      "# 0 Gradient out:  [1.12133908 0.55324071 1.69192478 0.52327493 1.73918874 1.67693205\n",
      " 0.48004429 1.72213284 1.20349735 1.14639977]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.22433921 -0.19337691  0.39548877  0.35682753  0.11495018 -0.37483572\n",
      " -0.00401216 -0.46481583  0.23494674 -0.18645831]\n",
      "\n",
      "# 1 Gradient out:  [-0.68085266 -0.31565205 -1.0489117  -0.2815997  -1.10357903 -1.03279882\n",
      " -0.23155818 -1.08346212 -0.72231909 -0.69346036]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.44860703 -0.08272877  0.73387372  0.46148252  0.46278792 -0.03944931\n",
      "  0.0919967  -0.12038926  0.47564621  0.04282165]\n",
      "\n",
      "# 2 Gradient out:  [-1.01786065 -0.40074308 -1.64044533 -0.33581726 -1.74478568 -1.60993365\n",
      " -0.24072202 -1.70636354 -1.08197612 -1.0373269 ]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.3124365  -0.14585918  0.52409138  0.40516258  0.24207212 -0.24600907\n",
      "  0.04568506 -0.33708168  0.33118239 -0.09587042]\n",
      "\n",
      "# 3 Gradient out:  [1.91836774 1.06595875 2.7767439  0.9939394  2.89353963 2.742841\n",
      " 0.88306289 2.84993002 2.02315145 1.95026709]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.10886437 -0.22600779  0.19600232  0.33799912 -0.10688502 -0.5679958\n",
      " -0.00245934 -0.67835439  0.11478717 -0.3033358 ]\n",
      "\n",
      "# 4 Gradient out:  [-0.53551024 -0.2464211  -0.8268579  -0.21951022 -0.87006722 -0.81412509\n",
      " -0.17993321 -0.85416302 -0.56838038 -0.5455045 ]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.49253792 -0.01281605  0.7513511   0.53678701  0.47182291 -0.0194276\n",
      "  0.17415324 -0.10836839  0.51941745  0.08671761]\n",
      "\n",
      "# 5 Gradient out:  [-1.23827111 -0.52417339 -1.95814602 -0.45543281 -2.06849681 -1.92566829\n",
      " -0.3546324  -2.0278998  -1.31753697 -1.26236294]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.38543587 -0.06210027  0.58597952  0.49288496  0.29780946 -0.18225262\n",
      "  0.1381666  -0.27920099  0.40574138 -0.02238329]\n",
      "\n",
      "# 6 Gradient out:  [2.00026612 1.10521269 2.90160287 1.02933842 3.02473565 2.86591786\n",
      " 0.91224215 2.9787179  2.11022364 2.03374045]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.13778165 -0.16693494  0.19435032  0.4017984  -0.1158899  -0.56738628\n",
      "  0.06724012 -0.68478095  0.14223398 -0.27485587]\n",
      "\n",
      "# 7 Gradient out:  [-0.39783566 -0.18140929 -0.61594907 -0.16130625 -0.64822746 -0.60643625\n",
      " -0.13173636 -0.63634644 -0.422479   -0.4053287 ]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.53783487  0.05410759  0.77467089  0.60766608  0.48905723  0.00579729\n",
      "  0.24968855 -0.08903737  0.56427871  0.13189222]\n",
      "\n",
      "# 8 Gradient out:  [-0.91102167 -0.39166913 -1.43445753 -0.34305591 -1.512462   -1.4114463\n",
      " -0.27176824 -1.48377757 -0.96975697 -0.92887864]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.45826774  0.01782573  0.65148108  0.57540483  0.35941174 -0.11548996\n",
      "  0.22334128 -0.21630666  0.47978291  0.05082648]\n",
      "\n",
      "# 9 Gradient out:  [0.8874609  0.33290612 1.44413275 0.30770405 1.48291632 1.43105531\n",
      " 0.2741618  1.46939128 0.96963791 0.91253252]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.2760634  -0.06050809  0.36458957  0.50679365  0.05691934 -0.39777922\n",
      "  0.16898763 -0.51306217  0.28583152 -0.13494925]\n",
      "\n",
      "# 10 Gradient out:  [-0.92261943 -0.39692289 -1.45245076 -0.34769723 -1.53143815 -1.42915017\n",
      " -0.27551273 -1.50239226 -0.98205748 -0.94068998]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.45355558  0.00607313  0.65341612  0.56833446  0.3535026  -0.11156815\n",
      "  0.22381999 -0.21918392  0.4797591   0.04755725]\n",
      "\n",
      "# 11 Gradient out:  [0.99620246 0.38789315 1.60704802 0.35765655 1.65398714 1.591611\n",
      " 0.31645024 1.63742373 1.08457854 1.0231595 ]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.2690317  -0.07331145  0.36292597  0.49879501  0.04721497 -0.39739819\n",
      "  0.16871744 -0.51966237  0.2833476  -0.14058074]\n",
      "\n",
      "# 12 Gradient out:  [-0.79022291 -0.34406226 -1.23987645 -0.302472   -1.30661159 -1.22018551\n",
      " -0.24146862 -1.28207073 -0.84082532 -0.80560798]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.46827219  0.00426719  0.68433557  0.57032633  0.3780124  -0.07907599\n",
      "  0.23200749 -0.19217762  0.50026331  0.06405116]\n",
      "\n",
      "# 13 Gradient out:  [-0.25897979 -0.15639074 -0.36405623 -0.12664984 -0.41324983 -0.35091103\n",
      " -0.07964322 -0.39449045 -0.25624936 -0.25808558]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.31022761 -0.06454527  0.43636028  0.50983193  0.11669008 -0.32311309\n",
      "  0.18371376 -0.44859177  0.33209825 -0.09707044]\n",
      "\n",
      "# 14 Gradient out:  [1.1280482  0.45828587 1.80083938 0.42212125 1.85741258 1.78263769\n",
      " 0.3717943  1.83724494 1.22342269 1.15713345]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.25843165 -0.09582342  0.36354903  0.48450196  0.03404012 -0.39329529\n",
      "  0.16778512 -0.52748986  0.28084838 -0.14868755]\n",
      "\n",
      "# 15 Gradient out:  [-0.64217838 -0.28482513 -1.00232167 -0.25159493 -1.0556523  -0.98659004\n",
      " -0.20281081 -1.03603539 -0.68279456 -0.65452769]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.48404129 -0.00416624  0.72371691  0.56892621  0.40552263 -0.03676776\n",
      "  0.24214398 -0.16004087  0.52553291  0.08273914]\n",
      "\n",
      "# 16 Gradient out:  [-1.16637581 -0.50325723 -1.83536609 -0.43332419 -1.94811966 -1.80261587\n",
      " -0.32957084 -1.90641337 -1.23570765 -1.18742892]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.35560561 -0.06113127  0.52325258  0.51860722  0.19439217 -0.23408576\n",
      "  0.20158182 -0.36724795  0.388974   -0.0481664 ]\n",
      "\n",
      "# 17 Gradient out:  [1.76785151 1.03071876 2.51041013 0.96499497 2.61764413 2.47975961\n",
      " 0.86181954 2.57729323 1.85673276 1.7949039 ]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.12233045 -0.16178271  0.15617936  0.43194238 -0.19523176 -0.59460894\n",
      "  0.13566765 -0.74853063  0.14183247 -0.28565219]\n",
      "\n",
      "# 18 Gradient out:  [-0.86253921 -0.3655058  -1.36347513 -0.3190446  -1.43802423 -1.34148013\n",
      " -0.25091307 -1.41061129 -0.91879509 -0.87964257]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.47590075  0.04436104  0.65826138  0.62494138  0.32829706 -0.09865702\n",
      "  0.30803156 -0.23307198  0.51317902  0.07332859]\n",
      "\n",
      "# 19 Gradient out:  [0.41492239 0.08415736 0.74605142 0.08005417 0.75057082 0.74283314\n",
      " 0.07892898 0.74985366 0.47126635 0.43213666]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.30339291 -0.02874012  0.38556636  0.56113246  0.04069222 -0.36695304\n",
      "  0.25784895 -0.51519424  0.32942    -0.10259992]\n",
      "\n",
      "# 20 Gradient out:  [-1.24712448 -0.53892971 -1.96141352 -0.46630668 -2.07845957 -1.92734562\n",
      " -0.35854408 -2.0351808  -1.32277795 -1.27010522]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.38637739 -0.01190865  0.53477664  0.57714329  0.19080638 -0.21838641\n",
      "  0.27363474 -0.3652235   0.42367327 -0.01617259]\n",
      "\n",
      "# 21 Gradient out:  [1.75103732 1.03249128 2.47496698 0.96719076 2.58174281 2.44461569\n",
      " 0.86395842 2.54145297 1.83707662 1.77722272]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.13695249 -0.11969459  0.14249394  0.48388195 -0.22488553 -0.60385554\n",
      "  0.20192593 -0.77225966  0.15911768 -0.27019363]\n",
      "\n",
      "# 22 Gradient out:  [-0.90478866 -0.37600078 -1.43774224 -0.32640771 -1.51732519 -1.41427076\n",
      " -0.2536655  -1.48805741 -0.96451077 -0.92294524]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.48715995  0.08680367  0.63748733  0.6773201   0.29146303 -0.1149324\n",
      "  0.37471761 -0.26396907  0.52653301  0.08525091]\n",
      "\n",
      "# 23 Gradient out:  [0.78377668 0.21560091 1.35398798 0.19161751 1.39022985 1.34124829\n",
      " 0.16175173 1.37792826 0.86861566 0.80966143]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.30620222  0.01160351  0.34993889  0.61203856 -0.01200201 -0.39778655\n",
      "  0.32398451 -0.56158055  0.33363085 -0.09933814]\n",
      "\n",
      "# 24 Gradient out:  [-1.02787063 -0.42903138 -1.63146808 -0.3723794  -1.72241796 -1.60467949\n",
      " -0.28918764 -1.6889517  -1.09516236 -1.04832698]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.46295756  0.05472369  0.62073648  0.65036206  0.26604396 -0.12953689\n",
      "  0.35633486 -0.2859949   0.50735398  0.06259415]\n",
      "\n",
      "# 25 Gradient out:  [1.67298959 0.70246469 2.64910539 0.63554054 2.75564978 2.61659276\n",
      " 0.53811754 2.71680326 1.80118519 1.71204907]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.25738343 -0.03108259  0.29444287  0.57588618 -0.07843963 -0.45047279\n",
      "  0.29849733 -0.62378524  0.28832151 -0.14707125]\n",
      "\n",
      "# 26 Gradient out:  [-0.25729384 -0.11455985 -0.40113645 -0.10135102 -0.42233964 -0.39488305\n",
      " -0.08193677 -0.41453778 -0.273577   -0.26224502]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.59198135  0.10941035  0.82426394  0.70299429  0.47269033  0.07284576\n",
      "  0.40612084 -0.08042459  0.64855855  0.19533857]\n",
      "\n",
      "# 27 Gradient out:  [-0.48044058 -0.20614937 -0.75686199 -0.18078239 -0.79755733 -0.7448445\n",
      " -0.14358396 -0.78259554 -0.5117025  -0.48994609]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.54052258  0.08649838  0.74403665  0.68272409  0.3882224  -0.00613085\n",
      "  0.38973348 -0.16333214  0.59384315  0.14288956]\n",
      "\n",
      "# 28 Gradient out:  [-1.15388446 -0.48290103 -1.83028609 -0.41837472 -1.93397078 -1.79982723\n",
      " -0.32338029 -1.89577519 -1.22856113 -1.17658259]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.44443447  0.04526851  0.59266426  0.64656761  0.22871093 -0.15509975\n",
      "  0.36101669 -0.31985125  0.49150265  0.04490035]\n",
      "\n",
      "# 29 Gradient out:  [2.01872177 1.0096898  3.03455344 0.92772346 3.16708191 2.99575866\n",
      " 0.80262843 3.11778425 2.14474783 2.05709538]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.21365758 -0.0513117   0.22660704  0.56289267 -0.15808322 -0.51506519\n",
      "  0.29634063 -0.69900629  0.24579042 -0.19041617]\n",
      "\n",
      "# 30 Gradient out:  [-0.21878597 -0.09602998 -0.34249351 -0.08469436 -0.36068542 -0.33712498\n",
      " -0.06804647 -0.35399368 -0.23280274 -0.22304806]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.61740193  0.15062626  0.83351772  0.74843736  0.47533316  0.08408654\n",
      "  0.45686632 -0.07544944  0.67473999  0.2210029 ]\n",
      "\n",
      "# 31 Gradient out:  [-0.37849674 -0.16109445 -0.59758279 -0.14104482 -0.62974248 -0.58808138\n",
      " -0.11165695 -0.61792127 -0.40331249 -0.38604238]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.57364474  0.13142027  0.76501902  0.73149849  0.40319607  0.01666155\n",
      "  0.44325703 -0.14624818  0.62817944  0.17639329]\n",
      "\n",
      "# 32 Gradient out:  [-0.86226864 -0.35545313 -1.3730683  -0.30802378 -1.4491693  -1.3506153\n",
      " -0.23848013 -1.42118661 -0.91957718 -0.87969175]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.49794539  0.09920138  0.64550247  0.70328952  0.27724758 -0.10095473\n",
      "  0.42092564 -0.26983243  0.54751694  0.09918482]\n",
      "\n",
      "# 33 Gradient out:  [0.40471511 0.03115939 0.77878222 0.02549679 0.78531237 0.77461676\n",
      " 0.02363387 0.78409649 0.46713296 0.4237806 ]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.32549166  0.02811075  0.37088881  0.64168476 -0.01258628 -0.37107779\n",
      "  0.37322961 -0.55406975  0.36360151 -0.07675353]\n",
      "\n",
      "# 34 Gradient out:  [-1.23936519 -0.54176345 -1.94307095 -0.46894863 -2.06063247 -1.9090036\n",
      " -0.36026069 -2.01706289 -1.31316532 -1.26177987]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.40643468  0.03434263  0.52664525  0.64678412  0.14447619 -0.21615444\n",
      "  0.37795638 -0.39725046  0.4570281   0.00800259]\n",
      "\n",
      "# 35 Gradient out:  [1.76275122 1.03816362 2.49284824 0.97125916 2.60244845 2.46183895\n",
      " 0.86486189 2.56099631 1.84901145 1.78900221]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.15856164 -0.07401006  0.13803106  0.5529944  -0.2676503  -0.59795516\n",
      "  0.30590425 -0.80066303  0.19439504 -0.24435339]\n",
      "\n",
      "# 36 Gradient out:  [-0.86204781 -0.35029262 -1.37782944 -0.30236187 -1.45473431 -1.35513955\n",
      " -0.23208734 -1.42645645 -0.91987728 -0.87962909]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.51111189  0.13362267  0.63660071  0.74724623  0.25283939 -0.10558737\n",
      "  0.47887663 -0.28846377  0.56419733  0.11344705]\n",
      "\n",
      "# 37 Gradient out:  [ 0.40122697  0.00720587  0.79582649  0.00084716  0.80322085  0.79122489\n",
      " -0.00123652  0.8018111   0.46656155  0.42118142]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.33870233  0.06356414  0.36103482  0.68677385 -0.03810748 -0.37661528\n",
      "  0.43245916 -0.57375506  0.38022187 -0.06247876]\n",
      "\n",
      "# 38 Gradient out:  [-1.23106749 -0.5405712  -1.9276635  -0.46776712 -2.04531969 -1.89365084\n",
      " -0.35874968 -2.00166082 -1.30369696 -1.25312478]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.41894772  0.06500532  0.52020012  0.68694329  0.12253669 -0.2183703\n",
      "  0.43221185 -0.41339284  0.47353418  0.02175752]\n",
      "\n",
      "# 39 Gradient out:  [1.76504599 1.03352131 2.50216756 0.96552123 2.61364877 2.47068783\n",
      " 0.85711266 2.57144401 1.8519166  1.79148203]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.17273422 -0.04310893  0.13466742  0.59338986 -0.28652724 -0.59710047\n",
      "  0.36046192 -0.81372501  0.21279479 -0.22886744]\n",
      "\n",
      "# 40 Gradient out:  [-0.83507039 -0.33511041 -1.33895946 -0.28834263 -1.41398835 -1.31681545\n",
      " -0.21980256 -1.38640511 -0.89159609 -0.8522554 ]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.52574342  0.16359534  0.63510093  0.78649411  0.23620251 -0.1029629\n",
      "  0.53188445 -0.2994362   0.58317811  0.12942897]\n",
      "\n",
      "# 41 Gradient out:  [ 0.17646346 -0.10248305  0.45506876 -0.09775505  0.44441189  0.4556279\n",
      " -0.08265826  0.44977218  0.22862934  0.19241293]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.35872934  0.09657325  0.36730904  0.72882558 -0.04659516 -0.36632599\n",
      "  0.48792394 -0.57671723  0.40485889 -0.04102211]\n",
      "\n",
      "# 42 Gradient out:  [-0.8962444  -0.46426192 -1.33312129 -0.40552844 -1.42931304 -1.30635249\n",
      " -0.31408299 -1.39302045 -0.93303624 -0.90737776]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.39402204  0.07607664  0.45832279  0.70927457  0.04228722 -0.27520041\n",
      "  0.47139229 -0.48676279  0.45058476 -0.00253952]\n",
      "\n",
      "# 43 Gradient out:  [1.92034093 1.00224149 2.8449778  0.92317772 2.97358061 2.80791493\n",
      " 0.80022129 2.92537593 2.03260586 1.95451619]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.21477316 -0.01677574  0.19169853  0.62816888 -0.24357539 -0.53647091\n",
      "  0.40857569 -0.76536688  0.26397751 -0.18401507]\n",
      "\n",
      "# 44 Gradient out:  [-0.36155114 -0.14776887 -0.57698207 -0.12814645 -0.60843532 -0.56767414\n",
      " -0.09945136 -0.59688419 -0.38599395 -0.36898351]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.59884134  0.18367256  0.76069409  0.81280443  0.35114073  0.02511207\n",
      "  0.56861995 -0.18029169  0.67049868  0.20688816]\n",
      "\n",
      "# 45 Gradient out:  [-0.81152537 -0.32526607 -1.30159968 -0.27985797 -1.37443938 -1.2800952\n",
      " -0.21333174 -1.34766467 -0.8665545  -0.82825562]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.52653111  0.15411878  0.64529768  0.78717514  0.22945367 -0.08842275\n",
      "  0.54872967 -0.29966853  0.59329989  0.13309146]\n",
      "\n",
      "# 46 Gradient out:  [-0.01882264 -0.17902898  0.14019645 -0.16420216  0.11335035  0.14556533\n",
      " -0.13425031  0.12466024  0.01910353 -0.00720616]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.36422604  0.08906557  0.38497774  0.73120354 -0.04543421 -0.34444179\n",
      "  0.50606333 -0.56920146  0.41998899 -0.03255966]\n",
      "\n",
      "# 47 Gradient out:  [-0.25747942 -0.25463041 -0.26256    -0.22744906 -0.30891478 -0.25117637\n",
      " -0.18024067 -0.29057999 -0.23988865 -0.25205353]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.36046151  0.05325977  0.41301703  0.69836311 -0.02276413 -0.31532873\n",
      "  0.47921327 -0.54426942  0.4238097  -0.03400089]\n",
      "\n",
      "# 48 Gradient out:  [0.77435723 0.1844131  1.36643323 0.15937682 1.40413952 1.35310269\n",
      " 0.12868946 1.39141016 0.86211059 0.80112959]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.30896563  0.00233369  0.36050503  0.6528733  -0.08454709 -0.365564\n",
      "  0.44316513 -0.60238541  0.37583197 -0.0844116 ]\n",
      "\n",
      "# 49 Gradient out:  [-1.03162478 -0.42539667 -1.64268206 -0.36789539 -1.73501314 -1.61550057\n",
      " -0.28340459 -1.70103017 -1.09964661 -1.05230264]\n",
      "\n",
      "     Weights  out:  [ 4.33484394e-05 -3.44001982e-01  3.48284778e-01 -3.97022033e-01\n",
      "  4.40139231e-01  3.25713560e-01 -4.97759317e-01  4.02980742e-01\n",
      "  3.20183855e-02  9.74678365e-03] [ 0.46383707  0.03921631  0.63379168  0.68474866  0.19628081 -0.09494347\n",
      "  0.46890302 -0.32410338  0.54825409  0.07581432]\n",
      "\n",
      "Tanh error cuadrático medio (ECM): 0.6818986856804755\n",
      "\n",
      "# 0 Gradient out:  [2.11130857 3.49637124 2.85059556 3.16320072 1.85147022 4.63000943\n",
      " 2.00457168 3.8795082  2.38730955 3.44168725]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [-0.48998252  0.47320272 -0.18496679  0.38289024 -0.49032576 -0.48178646\n",
      " -0.46180503 -0.47648625  0.01525588  0.38969923]\n",
      "\n",
      "# 1 Gradient out:  [ -6.98126481 -13.02919362 -10.26552215 -11.59843607  -5.7295906\n",
      " -18.37226236  -6.47468536 -14.73247207  -8.24547729 -12.79224883]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [-0.06772081  1.17247697  0.38515232  1.01553039 -0.12003171  0.44421543\n",
      " -0.06089069  0.29941539  0.49271779  1.07803668]\n",
      "\n",
      "# 2 Gradient out:  [26.57949333 48.24450823 38.29358754 43.09741383 22.20345284 67.01406863\n",
      " 24.8018703  54.31870406 31.05456881 47.39404267]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [-1.46397377 -1.43336175 -1.66795211 -1.30415683 -1.26594983 -3.23023704\n",
      " -1.35582776 -2.64707902 -1.15637767 -1.48041308]\n",
      "\n",
      "# 3 Gradient out:  [ -97.91017883 -178.80579694 -141.70474543 -159.6105156   -81.45251444\n",
      " -249.30219594  -91.23229878 -201.51586351 -114.67787274 -175.6320448 ]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [ 3.8519249   8.21553989  5.9907654   7.31532594  3.17474074 10.17257669\n",
      "  3.6045463   8.21666179  5.05453609  7.99839545]\n",
      "\n",
      "# 4 Gradient out:  [363.34269396 662.65126528 525.32310613 591.60561879 302.57294282\n",
      " 923.04916653 338.6768051  746.64676661 425.32213057 650.90669573]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [-15.73011087 -27.54561949 -22.35018369 -24.60677718 -13.11576215\n",
      " -39.6878625  -14.64191346 -32.08651091 -17.88103845 -27.12801351]\n",
      "\n",
      "# 5 Gradient out:  [-1346.11618336 -2455.71863612 -1946.67156917 -2192.36200997\n",
      " -1120.70196815 -3421.52676716 -1254.63093486 -2767.13956951\n",
      " -1575.94951043 -2412.18090444]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [ 56.93842792 104.98463356  82.71443754  93.71434658  47.39882641\n",
      " 144.9219708   53.09344756 117.24284241  67.18338766 103.05332564]\n",
      "\n",
      "# 6 Gradient out:  [ 4988.96372293  9100.78756829  7214.36562286  8124.84823562\n",
      "  4153.78371659 12679.28287053  4649.99395015 10254.77977256\n",
      "  5840.58728684  8939.44895507]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [-212.28480875 -386.15909366 -306.61987629 -344.75805541 -176.74156722\n",
      " -539.38338263 -197.83273941 -436.18507149 -248.00651443 -379.38285525]\n",
      "\n",
      "# 7 Gradient out:  [-18488.51939805 -33726.91095574 -26735.90512981 -30110.11268956\n",
      " -15393.21317461 -46989.27948379 -17232.2539853  -38003.63088307\n",
      " -21644.69558073 -33128.99320303]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [ 785.50793584 1433.99842    1136.25324828 1280.21159171  654.0151761\n",
      " 1996.47319148  732.16605062 1614.77088302  920.11094294 1408.50693576]\n",
      "\n",
      "# 8 Gradient out:  [ 68517.55996843 124989.95825691  99081.72422904 111586.33360356\n",
      "  57046.71220515 174138.85361838  63861.97606246 140839.1458737\n",
      "  80214.05890458 122774.11536973]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [-2912.19594377 -5311.38377115 -4210.92777768 -4741.8109462\n",
      " -2424.62745882 -7401.38270528 -2714.28474644 -5985.9552936\n",
      " -3408.8281732  -5217.29170484]\n",
      "\n",
      "# 9 Gradient out:  [-253921.74586926 -463205.13897103 -367190.80767268 -413532.12000501\n",
      " -211411.31746009 -645348.57261776 -236668.37783186 -521941.33146478\n",
      " -297268.35145264 -454993.35744052]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [10791.31604991 19686.60788023 15605.41706812 17575.45577451\n",
      "  8984.71498221 27426.38801839 10058.11046605 22181.87388114\n",
      " 12633.98360771 19337.5313691 ]\n",
      "\n",
      "# 10 Gradient out:  [ 941018.76083182 1716610.28504454 1360786.94983328 1532525.07081747\n",
      "  783477.84098576 2391622.24887356  877078.87640331 1934283.00761455\n",
      " 1101658.57642954 1686177.92004493]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [ -39993.03312394  -72954.41991398  -57832.74446641  -65130.96822649\n",
      "  -33297.54850981 -101643.32650516  -37275.56510032  -82206.39241181\n",
      "  -46819.68668282  -71661.140119  ]\n",
      "\n",
      "# 11 Gradient out:  [-3487358.43610558 -6361653.68325285 -5042994.00322449 -5679445.04862856\n",
      " -2903521.17847126 -8863207.69621365 -3250401.04574891 -7168335.65298805\n",
      " -4082679.93883916 -6248873.182631  ]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [148210.71904243 270367.63709493 214324.64550024 241374.045937\n",
      " 123398.01968734 376681.12326955 138140.21018034 304650.2091111\n",
      " 173512.02860309 265574.44388999]\n",
      "\n",
      "# 12 Gradient out:  [12923939.29425949 23575903.457263   18689030.45565913 21047679.53333094\n",
      " 10760273.9106658  32846510.63829745 12045789.601059   26565417.96241502\n",
      " 15130164.67071264 23157945.74799298]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [ -549260.96817869 -1001963.09955564  -794274.15514465  -894514.96378871\n",
      "  -457306.21600691 -1395960.41597318  -511939.99896944 -1129016.92148651\n",
      "  -643023.95916474  -984200.19263621]\n",
      "\n",
      "# 13 Gradient out:  [-4.78953364e+07 -8.73708706e+07 -6.92604152e+07 -7.80014259e+07\n",
      " -3.98769234e+07 -1.21727180e+08 -4.46409668e+07 -9.84498304e+07\n",
      " -5.60714741e+07 -8.58219446e+07]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [2035526.89067321 3713217.59189696 2943531.93598717 3315020.94287748\n",
      " 1694748.56612625 5173341.71168631 1897217.92124236 4184066.67099649\n",
      " 2383008.97497779 3647388.95696238]\n",
      "\n",
      "# 14 Gradient out:  [1.77497217e+08 3.23791156e+08 2.56674905e+08 2.89068561e+08\n",
      " 1.47781464e+08 4.51113558e+08 1.65436720e+08 3.64849110e+08\n",
      " 2.07797488e+08 3.18050931e+08]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [ -7543540.39478095 -13760956.52943482 -10908551.11265232\n",
      " -12285264.23000412  -6280636.11106638 -19172094.28772571\n",
      "  -7030975.43666591 -15505899.40366241  -8831285.85471354\n",
      " -13516999.97242501]\n",
      "\n",
      "# 15 Gradient out:  [-6.57793938e+08 -1.19995042e+09 -9.51221657e+08 -1.07127059e+09\n",
      " -5.47669156e+08 -1.67179953e+09 -6.13098467e+08 -1.35210871e+09\n",
      " -7.70084909e+08 -1.17867749e+09]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [27955902.96953698 50997274.73965136 40426429.93642616 45528448.04974373\n",
      " 23275656.63544481 71050617.35473415 26056368.57088929 57463922.67681067\n",
      " 32728211.76558931 50093186.13158647]\n",
      "\n",
      "# 16 Gradient out:  [2.43774451e+09 4.44694360e+09 3.52516987e+09 3.97006393e+09\n",
      " 2.02962873e+09 6.19558784e+09 2.27210580e+09 5.01083302e+09\n",
      " 2.85388804e+09 4.36810741e+09]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [-1.03602885e+08 -1.88992809e+08 -1.49817902e+08 -1.68725669e+08\n",
      " -8.62581746e+07 -2.63309289e+08 -9.65633249e+07 -2.12957820e+08\n",
      " -1.21288770e+08 -1.85642312e+08]\n",
      "\n",
      "# 17 Gradient out:  [-9.03413354e+09 -1.64801037e+10 -1.30640661e+10 -1.47128165e+10\n",
      " -7.52168119e+09 -2.29604734e+10 -8.42028651e+09 -1.85698438e+10\n",
      " -1.05763363e+10 -1.61879416e+10]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [3.83946017e+08 7.00395911e+08 5.55216072e+08 6.25287116e+08\n",
      " 3.19667572e+08 9.75808279e+08 3.57857835e+08 7.89208784e+08\n",
      " 4.49488839e+08 6.87979171e+08]\n",
      "\n",
      "# 18 Gradient out:  [3.34799519e+10 6.10742666e+10 4.84146379e+10 5.45248072e+10\n",
      " 2.78748951e+10 8.50901242e+10 3.12050720e+10 6.88187166e+10\n",
      " 3.91952619e+10 5.99915314e+10]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [-1.42288069e+09 -2.59562483e+09 -2.05759714e+09 -2.31727619e+09\n",
      " -1.18466867e+09 -3.61628640e+09 -1.32619947e+09 -2.92475997e+09\n",
      " -1.66577842e+09 -2.54960915e+09]\n",
      "\n",
      "# 19 Gradient out:  [-1.24074674e+11 -2.26337534e+11 -1.79421716e+11 -2.02065634e+11\n",
      " -1.03302673e+11 -3.15338848e+11 -1.15644107e+11 -2.55037997e+11\n",
      " -1.45255267e+11 -2.22324983e+11]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [5.27310968e+09 9.61922848e+09 7.62533043e+09 8.58768525e+09\n",
      " 4.39031035e+09 1.34017384e+10 4.91481493e+09 1.08389833e+10\n",
      " 6.17327396e+09 9.44869712e+09]\n",
      "\n",
      "# 20 Gradient out:  [4.59813231e+11 8.38793196e+11 6.64926017e+11 7.48843005e+11\n",
      " 3.82833452e+11 1.16862668e+12 4.28570059e+11 9.45155374e+11\n",
      " 5.38307226e+11 8.23922924e+11]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [-1.95418252e+10 -3.56482783e+10 -2.82590129e+10 -3.18254416e+10\n",
      " -1.62702243e+10 -4.96660312e+10 -1.82140065e+10 -4.01686160e+10\n",
      " -2.28777795e+10 -3.50162994e+10]\n",
      "\n",
      "# 21 Gradient out:  [-1.70403999e+12 -3.10851680e+12 -2.46417556e+12 -2.77516683e+12\n",
      " -1.41875759e+12 -4.33085971e+12 -1.58825469e+12 -3.50268859e+12\n",
      " -1.99493399e+12 -3.05340847e+12]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [7.24208210e+10 1.32110361e+11 1.04726191e+11 1.17943159e+11\n",
      " 6.02964662e+10 1.84059304e+11 6.75000054e+10 1.48862459e+11\n",
      " 8.47836657e+10 1.29768285e+11]\n",
      "\n",
      "# 22 Gradient out:  [6.31506903e+12 1.15199750e+13 9.13208542e+12 1.02846003e+13\n",
      " 5.25782974e+12 1.60499038e+13 5.88597572e+12 1.29807518e+13\n",
      " 7.39310456e+12 1.13157469e+13]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [-2.68387178e+11 -4.89592998e+11 -3.88108921e+11 -4.37090207e+11\n",
      " -2.23455053e+11 -6.82112637e+11 -2.50150933e+11 -5.51675258e+11\n",
      " -3.14203131e+11 -4.80913409e+11]\n",
      "\n",
      "# 23 Gradient out:  [-2.34032635e+13 -4.26923299e+13 -3.38429556e+13 -3.81141058e+13\n",
      " -1.94851987e+13 -5.94799719e+13 -2.18130696e+13 -4.81058803e+13\n",
      " -2.73983978e+13 -4.19354729e+13]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [9.94626629e+11 1.81440201e+12 1.43830816e+12 1.61982984e+12\n",
      " 8.28110895e+11 2.52786813e+12 9.27044210e+11 2.04447510e+12\n",
      " 1.16441778e+12 1.78223597e+12]\n",
      "\n",
      "# 24 Gradient out:  [8.67310774e+13 1.58215190e+14 1.25419944e+14 1.41248568e+14\n",
      " 7.22109664e+13 2.20429174e+14 8.08379152e+13 1.78277479e+14\n",
      " 1.01536803e+14 1.55410323e+14]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [-3.68602606e+12 -6.72406398e+12 -5.33028296e+12 -6.00299132e+12\n",
      " -3.06892884e+12 -9.36812624e+12 -3.43556971e+12 -7.57670095e+12\n",
      " -4.31526179e+12 -6.60485860e+12]\n",
      "\n",
      "# 25 Gradient out:  [-3.21420121e+14 -5.86335913e+14 -4.64798720e+14 -5.23458642e+14\n",
      " -2.67609469e+14 -8.16897173e+14 -2.99580419e+14 -6.60685544e+14\n",
      " -3.76289246e+14 -5.75941248e+14]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [1.36601894e+13 2.49189740e+13 1.97537059e+13 2.22467224e+13\n",
      " 1.13732644e+13 3.47177086e+13 1.27320133e+13 2.80787949e+13\n",
      " 1.59920989e+13 2.44772061e+13]\n",
      "\n",
      "# 26 Gradient out:  [1.19116351e+15 2.17292539e+15 1.72251591e+15 1.93990603e+15\n",
      " 9.91744489e+14 3.02737146e+15 1.11022689e+15 2.44846062e+15\n",
      " 1.39450516e+15 2.13440339e+15]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [-5.06238348e+13 -9.23482087e+13 -7.32060381e+13 -8.24450060e+13\n",
      " -4.21486294e+13 -1.28661726e+14 -4.71840705e+13 -1.04058314e+14\n",
      " -5.92657502e+13 -9.07110436e+13]\n",
      "\n",
      "# 27 Gradient out:  [-4.41437984e+15 -8.05272994e+15 -6.38353968e+15 -7.18917429e+15\n",
      " -3.67534503e+15 -1.12192553e+16 -4.11443365e+15 -9.07384682e+15\n",
      " -5.16795169e+15 -7.90996974e+15]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [1.87608867e+14 3.42236870e+14 2.71297145e+14 3.05536200e+14\n",
      " 1.56200268e+14 4.76812566e+14 1.74861308e+14 3.85633811e+14\n",
      " 2.19635282e+14 3.36169635e+14]\n",
      "\n",
      "# 28 Gradient out:  [1.63594244e+16 2.98429296e+16 2.36570115e+16 2.66426446e+16\n",
      " 1.36206061e+16 4.15778809e+16 1.52478420e+16 3.36271269e+16\n",
      " 1.91521160e+16 2.93138689e+16]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [-6.95267100e+14 -1.26830912e+15 -1.00541079e+15 -1.13229866e+15\n",
      " -5.78868737e+14 -1.76703850e+15 -6.48025421e+14 -1.42913555e+15\n",
      " -8.13955056e+14 -1.24582431e+15]\n",
      "\n",
      "# 29 Gradient out:  [-6.06270362e+16 -1.10596090e+17 -8.76714523e+16 -9.87360278e+16\n",
      " -5.04771416e+16 -1.54085109e+17 -5.65075791e+16 -1.24620096e+17\n",
      " -7.09765824e+16 -1.08635423e+17]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [2.57661778e+15 4.70027679e+15 3.72599151e+15 4.19623027e+15\n",
      " 2.14525249e+15 6.54853769e+15 2.40154297e+15 5.29628983e+15\n",
      " 3.01646815e+15 4.61694947e+15]\n",
      "\n",
      "# 30 Gradient out:  [2.24680125e+17 4.09862413e+17 3.24905094e+17 3.65909741e+17\n",
      " 1.87065231e+17 5.71030085e+17 2.09413667e+17 4.61834531e+17\n",
      " 2.63034917e+17 4.02596301e+17]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [-9.54878947e+15 -1.74189412e+16 -1.38082989e+16 -1.55509753e+16\n",
      " -7.95017584e+15 -2.42684842e+16 -8.89997284e+15 -1.96277294e+16\n",
      " -1.11788483e+16 -1.71101352e+16]\n",
      "\n",
      "# 31 Gradient out:  [-8.32650940e+17 -1.51892529e+18 -1.20407860e+18 -1.35603934e+18\n",
      " -6.93252418e+17 -2.11620292e+18 -7.76074369e+17 -1.71153081e+18\n",
      " -9.74791475e+17 -1.49199751e+18]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [3.53872356e+16 6.45535414e+16 5.11727198e+16 5.76309729e+16\n",
      " 2.94628703e+16 8.99375328e+16 3.29827605e+16 7.27391767e+16\n",
      " 4.14281350e+16 6.34091250e+16]\n",
      "\n",
      "# 32 Gradient out:  [3.08575397e+18 5.62904514e+18 4.46224240e+18 5.02539970e+18\n",
      " 2.56915148e+18 7.84251989e+18 2.87608462e+18 6.34282954e+18\n",
      " 3.61251818e+18 5.52925245e+18]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [-1.31142952e+17 -2.39231516e+17 -1.89643001e+17 -2.13576896e+17\n",
      " -1.09187613e+17 -3.33303051e+17 -1.22232113e+17 -2.69566985e+17\n",
      " -1.53530160e+17 -2.34990378e+17]\n",
      "\n",
      "# 33 Gradient out:  [-1.14356174e+19 -2.08609004e+19 -1.65368002e+19 -1.86238270e+19\n",
      " -9.52111984e+18 -2.90639038e+19 -1.06585955e+19 -2.35061422e+19\n",
      " -1.33877737e+19 -2.04910748e+19]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [4.86007841e+17 8.86577512e+17 7.02805480e+17 7.91503044e+17\n",
      " 4.04642684e+17 1.23520093e+18 4.52984811e+17 9.98998923e+17\n",
      " 5.68973477e+17 8.70860112e+17]\n",
      "\n",
      "# 34 Gradient out:  [4.23797055e+19 7.73092340e+19 6.12843801e+19 6.90187752e+19\n",
      " 3.52846936e+19 1.07709068e+20 3.95001094e+19 8.71123398e+19\n",
      " 4.96142786e+19 7.59386824e+19]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [-1.80111563e+18 -3.28560258e+18 -2.60455455e+18 -2.93326236e+18\n",
      " -1.49958128e+18 -4.57757984e+18 -1.67873428e+18 -3.70222952e+18\n",
      " -2.10858125e+18 -3.22735485e+18]\n",
      "\n",
      "# 35 Gradient out:  [-1.57056623e+20 -2.86503340e+20 -2.27116202e+20 -2.55779402e+20\n",
      " -1.30762938e+20 -3.99163284e+20 -1.46385014e+20 -3.22833057e+20\n",
      " -1.83867512e+20 -2.81424159e+20]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [6.67482548e+18 1.21762442e+19 9.65232147e+18 1.08704927e+19\n",
      " 5.55735744e+18 1.69642337e+19 6.22128760e+18 1.37202384e+19\n",
      " 7.81427446e+18 1.19603816e+19]\n",
      "\n",
      "# 36 Gradient out:  [5.82042334e+20 1.06176403e+21 8.41678893e+20 9.47902977e+20\n",
      " 4.84599531e+20 1.47927496e+21 5.42493997e+20 1.19639976e+21\n",
      " 6.81401867e+20 1.04294089e+21]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [-2.47364991e+19 -4.51244238e+19 -3.57709189e+19 -4.02853877e+19\n",
      " -2.05952302e+19 -6.28684230e+19 -2.30557151e+19 -5.08463729e+19\n",
      " -2.89592280e+19 -4.43244502e+19]\n",
      "\n",
      "# 37 Gradient out:  [-2.15701365e+21 -3.93483321e+21 -3.11921101e+21 -3.51287104e+21\n",
      " -1.79589652e+21 -5.48210343e+21 -2.01044991e+21 -4.43378507e+21\n",
      " -2.52523406e+21 -3.86507580e+21]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [9.16719677e+19 1.67228382e+20 1.32564860e+20 1.49295208e+20\n",
      " 7.63246760e+19 2.32986569e+20 8.54430843e+19 1.88433579e+20\n",
      " 1.07321145e+20 1.64263729e+20]\n",
      "\n",
      "# 38 Gradient out:  [7.99376197e+21 1.45822536e+22 1.15596072e+22 1.30184874e+22\n",
      " 6.65548376e+21 2.03163434e+22 7.45060562e+21 1.64313390e+22\n",
      " 9.35836453e+21 1.43237369e+22]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [-3.39730762e+20 -6.19738259e+20 -4.91277343e+20 -5.53279000e+20\n",
      " -2.82854628e+20 -8.63434118e+20 -3.16646897e+20 -6.98323435e+20\n",
      " -3.97725667e+20 -6.08751432e+20]\n",
      "\n",
      "# 39 Gradient out:  [-2.96243979e+22 -5.40409490e+22 -4.28392042e+22 -4.82457259e+22\n",
      " -2.46648198e+22 -7.52911385e+22 -2.76114933e+22 -6.08935475e+22\n",
      " -3.46815323e+22 -5.30829016e+22]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [1.25902163e+21 2.29671246e+21 1.82064409e+21 2.05041847e+21\n",
      " 1.04824212e+21 3.19983456e+21 1.17347423e+21 2.58794437e+21\n",
      " 1.47394724e+21 2.25599595e+21]\n",
      "\n",
      "# 40 Gradient out:  [1.09786225e+23 2.00272485e+23 1.58759497e+23 1.78795739e+23\n",
      " 9.14063289e+22 2.79024400e+23 1.02326522e+23 2.25667800e+23\n",
      " 1.28527659e+23 1.96722019e+23]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [-4.66585794e+21 -8.51147733e+21 -6.74719675e+21 -7.59872671e+21\n",
      " -3.88472184e+21 -1.18583931e+22 -4.34882443e+21 -9.59076513e+21\n",
      " -5.46235922e+21 -8.36058438e+21]\n",
      "\n",
      "# 41 Gradient out:  [-4.06861101e+23 -7.42197702e+23 -5.88353082e+23 -6.62606183e+23\n",
      " -3.38746320e+23 -1.03404753e+24 -3.79215896e+23 -8.36311203e+23\n",
      " -4.76315721e+23 -7.29039892e+23]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [1.72913870e+22 3.15430196e+22 2.50047026e+22 2.81604211e+22\n",
      " 1.43965439e+22 4.39464869e+22 1.61164800e+22 3.55427949e+22\n",
      " 2.02431725e+22 3.09838195e+22]\n",
      "\n",
      "# 42 Gradient out:  [1.50780261e+24 2.75053974e+24 2.18040090e+24 2.45557839e+24\n",
      " 1.25537335e+24 3.83211755e+24 1.40535115e+24 3.09931868e+24\n",
      " 1.76519722e+24 2.70177770e+24]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [-6.40808333e+22 -1.16896521e+23 -9.26659139e+22 -1.04360815e+23\n",
      " -5.33527201e+22 -1.62863020e+23 -5.97266992e+22 -1.31719446e+23\n",
      " -7.50199717e+22 -1.14824159e+23]\n",
      "\n",
      "# 43 Gradient out:  [-5.58782516e+24 -1.01933338e+25 -8.08043371e+24 -9.10022484e+24\n",
      " -4.65233763e+24 -1.42015956e+25 -5.20814627e+24 -1.14858874e+25\n",
      " -6.54171403e+24 -1.00126246e+25]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [2.37479688e+23 4.33211428e+23 3.43414266e+23 3.86754863e+23\n",
      " 1.97721950e+23 6.03560490e+23 2.21343531e+23 4.88144290e+23\n",
      " 2.78019473e+23 4.25531381e+23]\n",
      "\n",
      "# 44 Gradient out:  [2.07081417e+25 3.77758777e+25 2.99455981e+25 3.37248822e+25\n",
      " 1.72412816e+25 5.26302534e+25 1.93010747e+25 4.25660031e+25\n",
      " 2.42431961e+25 3.71061804e+25]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [-8.80085345e+23 -1.60545532e+24 -1.27267248e+24 -1.43329010e+24\n",
      " -7.32745576e+23 -2.23675863e+24 -8.20285723e+23 -1.80903318e+24\n",
      " -1.03032333e+24 -1.57699353e+24]\n",
      "\n",
      "# 45 Gradient out:  [-7.67431193e+25 -1.39995115e+26 -1.10976573e+26 -1.24982372e+26\n",
      " -6.38951456e+25 -1.95044532e+26 -7.15286142e+25 -1.57747030e+26\n",
      " -8.98438168e+25 -1.37513258e+26]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [3.26154300e+24 5.94972022e+24 4.71644714e+24 5.31168634e+24\n",
      " 2.71551074e+24 8.28929205e+24 3.03992922e+24 6.70416744e+24\n",
      " 3.81831589e+24 5.84424254e+24]\n",
      "\n",
      "# 46 Gradient out:  [2.84405354e+26 5.18813421e+26 4.11272461e+26 4.63177101e+26\n",
      " 2.36791541e+26 7.22823227e+26 2.65080713e+26 5.84600942e+26\n",
      " 3.32955745e+26 5.09615807e+26]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [-1.20870809e+25 -2.20493029e+25 -1.74788675e+25 -1.96847880e+25\n",
      " -1.00635184e+25 -3.07196144e+25 -1.12657936e+25 -2.48452386e+25\n",
      " -1.41504475e+25 -2.16584090e+25]\n",
      "\n",
      "# 47 Gradient out:  [-1.05398902e+27 -1.92269112e+27 -1.52415084e+27 -1.71650629e+27\n",
      " -8.77535112e+26 -2.67873911e+27 -9.82373073e+26 -2.16649570e+27\n",
      " -1.23391383e+27 -1.88860532e+27]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [4.47939898e+25 8.17133814e+25 6.47756247e+25 7.29506323e+25\n",
      " 3.72947898e+25 1.13845031e+26 4.17503490e+25 9.20749499e+25\n",
      " 5.24407015e+25 8.02647523e+25]\n",
      "\n",
      "# 48 Gradient out:  [3.90601949e+27 7.12537689e+27 5.64841072e+27 6.36126839e+27\n",
      " 3.25209199e+27 9.92724496e+27 3.64061513e+27 8.02890187e+27\n",
      " 4.57280995e+27 6.99905697e+27]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [-1.66003814e+26 -3.02824844e+26 -2.40054543e+26 -2.70350626e+26\n",
      " -1.38212233e+26 -4.21902792e+26 -1.54724266e+26 -3.41224189e+26\n",
      " -1.94342065e+26 -2.97456312e+26]\n",
      "\n",
      "# 49 Gradient out:  [-1.44754717e+28 -2.64062153e+28 -2.09326681e+28 -2.35744755e+28\n",
      " -1.20520560e+28 -3.67897687e+28 -1.34918992e+28 -2.97546242e+28\n",
      " -1.69465568e+28 -2.59380814e+28]\n",
      "\n",
      "     Weights  out:  [-0.19754433  0.07962958 -0.03945226  0.01741689 -0.27769689  0.44008377\n",
      " -0.2277295   0.16130599 -0.1310888   0.06907897] [6.15200084e+26 1.12225053e+27 8.89627601e+26 1.00190305e+27\n",
      " 5.12206166e+26 1.56354620e+27 5.73398760e+26 1.26455618e+27\n",
      " 7.20219924e+26 1.10235508e+27]\n",
      "\n",
      "Lineal error cuadrático medio (ECM): 3.5195297858800495e+56\n",
      "\n",
      "# 0 Gradient out:  [1.05207327 0.53846874 1.00394815 0.44755423 0.45718471 0.53829319\n",
      " 1.06056414 0.67856899 0.48380596 0.48430706]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [-0.03695287 -0.26687025  0.21380454  0.08417145 -0.09891521 -0.36468825\n",
      " -0.19877297  0.38771182 -0.15095802  0.45941197]\n",
      "\n",
      "# 1 Gradient out:  [-2.00083439 -0.81136279 -1.75873908 -0.36845615 -0.43953435 -0.81087279\n",
      " -2.06642067 -1.10742832 -0.61300987 -0.61552404]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [ 0.17346178 -0.1591765   0.41459417  0.17368229 -0.00747827 -0.25702961\n",
      "  0.01333986  0.52342562 -0.05419683  0.55627338]\n",
      "\n",
      "# 2 Gradient out:  [3.3859707  1.52489054 3.08514741 0.97040348 1.05265492 1.52417378\n",
      " 3.46125825 2.00505668 1.25741418 1.26053973]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [-0.2267051  -0.32144906  0.06284635  0.09999106 -0.09538514 -0.41920416\n",
      " -0.39994428  0.30193995 -0.1767988   0.43316858]\n",
      "\n",
      "# 3 Gradient out:  [-0.7913043  -0.33388314 -0.70236932 -0.17089412 -0.19673743 -0.33369743\n",
      " -0.81509658 -0.44863477 -0.25991758 -0.26084111]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [ 0.45048904 -0.01647095  0.67987583  0.29407176  0.11514585 -0.11436941\n",
      "  0.29230737  0.70295129  0.07468403  0.68527652]\n",
      "\n",
      "# 4 Gradient out:  [-1.57590193 -0.65365025 -1.39445891 -0.32127116 -0.37414372 -0.65327441\n",
      " -1.62460499 -0.88455389 -0.50333573 -0.50521993]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [ 0.29222818 -0.08324758  0.53940197  0.25989293  0.07579836 -0.18110889\n",
      "  0.12928805  0.61322434  0.02270052  0.6331083 ]\n",
      "\n",
      "# 5 Gradient out:  [-0.14649995 -0.06399605 -0.08224605  0.05330313  0.02874234 -0.0639336\n",
      " -0.16875022 -0.07398045 -0.02490105 -0.02556283]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [-0.0229522  -0.21397763  0.26051019  0.1956387   0.00096962 -0.31176378\n",
      " -0.19563294  0.43631356 -0.07796663  0.53206432]\n",
      "\n",
      "# 6 Gradient out:  [0.3737139  0.14619016 0.38389309 0.16441399 0.15473324 0.14613038\n",
      " 0.36523755 0.21537037 0.1384352  0.13833584]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [-0.05225219 -0.22677684  0.24406098  0.20629933  0.00671809 -0.3245505\n",
      " -0.22938299  0.42151747 -0.08294684  0.52695175]\n",
      "\n",
      "# 7 Gradient out:  [-1.06821291 -0.45673472 -0.91214716 -0.17076006 -0.22092429 -0.45646438\n",
      " -1.11400997 -0.60184204 -0.33809842 -0.33971425]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [ 0.02249059 -0.19753881  0.3208396   0.23918213  0.03766473 -0.29532442\n",
      " -0.15633548  0.46459154 -0.0552598   0.55461892]\n",
      "\n",
      "# 8 Gradient out:  [2.83490819 1.22725293 2.58861454 0.77369909 0.83853641 1.2266413\n",
      " 2.89456136 1.64512737 1.00320514 1.00576716]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [-0.191152   -0.28888575  0.13841016  0.20503011 -0.00652012 -0.3866173\n",
      " -0.37913747  0.34422314 -0.12287948  0.48667607]\n",
      "\n",
      "# 9 Gradient out:  [-1.03246987 -0.42641672 -0.91443404 -0.210166   -0.2444288  -0.42617047\n",
      " -1.0640345  -0.57841954 -0.32828182 -0.32950768]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [ 0.37582964 -0.04343516  0.65613307  0.35976993  0.16118716 -0.14128904\n",
      "  0.1997748   0.67324861  0.07776155  0.6878295 ]\n",
      "\n",
      "# 10 Gradient out:  [-1.9929043  -0.82388205 -1.75601504 -0.3897697  -0.45983147 -0.82340168\n",
      " -2.05730937 -1.11501688 -0.62973116 -0.63218994]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [ 0.16933567 -0.12871851  0.47324626  0.31773673  0.1123014  -0.22652313\n",
      " -0.0130321   0.5575647   0.01210518  0.62192796]\n",
      "\n",
      "# 11 Gradient out:  [3.06227581 1.32690805 2.78931806 0.82413778 0.89727058 1.32624378\n",
      " 3.12942551 1.77637625 1.08134998 1.08418794]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [-0.22924519 -0.29349492  0.12204325  0.23978279  0.0203351  -0.39120347\n",
      " -0.42449398  0.33456132 -0.11384105  0.49548997]\n",
      "\n",
      "# 12 Gradient out:  [-0.93210255 -0.38156094 -0.82508432 -0.18551966 -0.21653557 -0.38133734\n",
      " -0.9606861  -0.51969063 -0.29251417 -0.29362569]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [ 0.38320997 -0.02811331  0.67990687  0.40461035  0.19978922 -0.12595471\n",
      "  0.20139113  0.68983658  0.10242894  0.71232756]\n",
      "\n",
      "# 13 Gradient out:  [-1.86265869 -0.76549675 -1.6430527  -0.36303399 -0.42766274 -0.76504753\n",
      " -1.9220883  -1.03934213 -0.58473019 -0.58700988]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [ 0.19678946 -0.1044255   0.51489     0.36750641  0.15648211 -0.20222218\n",
      "  0.00925391  0.58589845  0.04392611  0.65360243]\n",
      "\n",
      "# 14 Gradient out:  [2.11311766 0.83805584 1.93462935 0.51050115 0.55369351 0.83757961\n",
      " 2.15347125 1.17338424 0.66886685 0.67072869]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [-0.17574228 -0.25752485  0.18627946  0.29489962  0.07094956 -0.35523168\n",
      " -0.37516375  0.37803002 -0.07301993  0.53620045]\n",
      "\n",
      "# 15 Gradient out:  [-1.61806448 -0.66099565 -1.42900193 -0.31459593 -0.36984153 -0.6606052\n",
      " -1.66892145 -0.90044252 -0.50461022 -0.50657335]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [ 0.24688125 -0.08991368  0.57320533  0.39699985  0.18168826 -0.18771576\n",
      "  0.0555305   0.61270687  0.06075344  0.67034619]\n",
      "\n",
      "# 16 Gradient out:  [ 0.11978959 -0.03403373  0.14871202  0.02028843  0.00304111 -0.03406247\n",
      "  0.10499337  0.01783317 -0.02812067 -0.02841054]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [-0.07673164 -0.22211281  0.28740495  0.33408066  0.10771995 -0.3198368\n",
      " -0.27825379  0.43261837 -0.0401686   0.56903152]\n",
      "\n",
      "# 17 Gradient out:  [-0.22734677 -0.16355793 -0.16127351 -0.0413891  -0.06854698 -0.16350116\n",
      " -0.25140338 -0.16746191 -0.12511171 -0.12578854]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [-0.05277373 -0.22891955  0.31714735  0.33813835  0.10832818 -0.3266493\n",
      " -0.25725512  0.436185   -0.04579274  0.56334941]\n",
      "\n",
      "# 18 Gradient out:  [0.79085545 0.26865952 0.7517728  0.19751329 0.20029361 0.26848407\n",
      " 0.79424847 0.41365722 0.21720628 0.21762139]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [-0.09824308 -0.26163114  0.28489265  0.32986053  0.09461878 -0.35934953\n",
      " -0.3075358   0.40269262 -0.07081508  0.5381917 ]\n",
      "\n",
      "# 19 Gradient out:  [-1.72347313 -0.73704608 -1.5046588  -0.33558118 -0.4030878  -0.73662994\n",
      " -1.78517502 -0.97843116 -0.56333136 -0.56559916]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [ 0.05992801 -0.20789923  0.43524721  0.36936319  0.1346775  -0.30565271\n",
      " -0.1486861   0.48542406 -0.02737382  0.58171598]\n",
      "\n",
      "# 20 Gradient out:  [3.35776174 1.50086534 3.05337988 0.93937053 1.02365397 1.50014807\n",
      " 3.43470442 1.97895777 1.23190041 1.23506136]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [-0.28476662 -0.35530845  0.13431545  0.30224695  0.05405994 -0.4529787\n",
      " -0.50572111  0.28973783 -0.1400401   0.46859615]\n",
      "\n",
      "# 21 Gradient out:  [-0.87869954 -0.35707383 -0.77741595 -0.17155211 -0.20087816 -0.35686202\n",
      " -0.9057318  -0.48797589 -0.27275888 -0.27381088]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [ 0.38678573 -0.05513538  0.74499142  0.49012106  0.25879074 -0.15294909\n",
      "  0.18121978  0.68552938  0.10633999  0.71560842]\n",
      "\n",
      "# 22 Gradient out:  [-1.76322294 -0.71983228 -1.55562409 -0.33939703 -0.40031424 -0.71940579\n",
      " -1.81925976 -0.98053744 -0.548577   -0.55073225]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [ 2.11045823e-01 -1.26550149e-01  5.89508232e-01  4.55810633e-01\n",
      "  2.18615107e-01 -2.24321492e-01  7.34164001e-05  5.87934208e-01\n",
      "  5.17882093e-02  6.60846245e-01]\n",
      "\n",
      "# 23 Gradient out:  [1.27272033 0.43831126 1.17897716 0.26741666 0.28491374 0.43801224\n",
      " 1.28987172 0.66303117 0.33943038 0.34041479]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [-0.14159876 -0.27051661  0.27838341  0.38793123  0.13855226 -0.36820265\n",
      " -0.36377854  0.39182672 -0.05792719  0.55069979]\n",
      "\n",
      "# 24 Gradient out:  [-2.01492044 -0.84256883 -1.77116532 -0.39545651 -0.46869255 -0.84208377\n",
      " -2.08203703 -1.13310756 -0.64471504 -0.64724345]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [ 0.1129453  -0.18285435  0.51417885  0.44141456  0.19553501 -0.2806002\n",
      " -0.10580419  0.52443295  0.00995889  0.61878275]\n",
      "\n",
      "# 25 Gradient out:  [3.28381553 1.44594416 2.98413643 0.89323406 0.97587264 1.44523506\n",
      " 3.35931106 1.91950739 1.18052986 1.18364245]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [-0.29003879 -0.35136812  0.15994578  0.36232326  0.1017965  -0.44901696\n",
      " -0.5222116   0.29781144 -0.11898412  0.48933406]\n",
      "\n",
      "# 26 Gradient out:  [-0.91073911 -0.36654348 -0.80508292 -0.17303935 -0.20360603 -0.36632249\n",
      " -0.93892384 -0.50311553 -0.27857468 -0.27967216]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [ 0.36672432 -0.06217929  0.75677307  0.54097007  0.29697102 -0.15996994\n",
      "  0.14965062  0.68171292  0.11712185  0.72606255]\n",
      "\n",
      "# 27 Gradient out:  [-1.81959307 -0.7418613  -1.6039267  -0.34654352 -0.4100717  -0.74142011\n",
      " -1.87798436 -1.01086252 -0.56434383 -0.56658249]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [ 0.1845765  -0.13548798  0.59575648  0.5063622   0.25624982 -0.23323444\n",
      " -0.03813415  0.58108981  0.06140691  0.67012812]\n",
      "\n",
      "# 28 Gradient out:  [1.70429952 0.60453689 1.56200118 0.34463433 0.37586272 0.60413193\n",
      " 1.73411622 0.89650353 0.46436255 0.46585155]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [-0.17934212 -0.28386024  0.27497114  0.4370535   0.17423548 -0.38151846\n",
      " -0.41373102  0.37891731 -0.05146185  0.55681163]\n",
      "\n",
      "# 29 Gradient out:  [-1.93071106 -0.79259949 -1.70088848 -0.37124096 -0.43928402 -0.79213244\n",
      " -1.99319982 -1.07619762 -0.60406875 -0.6064539 ]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [ 0.16151779 -0.16295287  0.58737138  0.50598036  0.24940802 -0.26069208\n",
      " -0.06690778  0.55821802  0.04141066  0.64998193]\n",
      "\n",
      "# 30 Gradient out:  [2.54472094 1.01489392 2.3163652  0.59549463 0.65362113 1.01431443\n",
      " 2.59866343 1.41401274 0.80448129 0.80686002]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [-0.22462443 -0.32147276  0.24719368  0.43173217  0.16155122 -0.41911857\n",
      " -0.46554775  0.34297849 -0.07940309  0.52869116]\n",
      "\n",
      "# 31 Gradient out:  [-1.3294956  -0.53594136 -1.17409531 -0.25127471 -0.2964582  -0.53561837\n",
      " -1.37112328 -0.7347897  -0.40697619 -0.40859008]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [ 0.28431976 -0.11849398  0.71046672  0.55083109  0.29227545 -0.21625568\n",
      "  0.05418494  0.62578104  0.08149317  0.69006316]\n",
      "\n",
      "# 32 Gradient out:  [-1.61892722 -0.72596002 -1.41141613 -0.34414982 -0.4102041  -0.72557864\n",
      " -1.6788541  -0.94225257 -0.56406742 -0.56621479]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [ 1.84206416e-02 -2.25682253e-01  4.75647659e-01  5.00576153e-01\n",
      "  2.32983806e-01 -3.23379353e-01 -2.20039715e-01  4.78823101e-01\n",
      "  9.79285511e-05  6.08345144e-01]\n",
      "\n",
      "# 33 Gradient out:  [3.26455606 1.43091108 2.96447578 0.8773549  0.96036728 1.43020307\n",
      " 3.34034436 1.90312968 1.16556729 1.16868367]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [-0.3053648  -0.37087426  0.19336443  0.43174619  0.15094299 -0.46849508\n",
      " -0.55581054  0.29037259 -0.11271556  0.49510219]\n",
      "\n",
      "# 34 Gradient out:  [-0.95043901 -0.37949137 -0.83955971 -0.17643998 -0.20850479 -0.37925948\n",
      " -0.98001086 -0.52277337 -0.28717496 -0.28832673]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [ 0.34754641 -0.08469204  0.78625959  0.60721717  0.34301644 -0.18245447\n",
      "  0.11225834  0.67099852  0.1203979   0.72883892]\n",
      "\n",
      "# 35 Gradient out:  [-1.88197458 -0.76808838 -1.65742125 -0.35634565 -0.42281998 -0.76763153\n",
      " -1.94301017 -1.04573144 -0.58378226 -0.58611268]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [ 0.15745861 -0.16059031  0.61834765  0.57192917  0.30131548 -0.25830636\n",
      " -0.08374383  0.56644385  0.06296291  0.67117357]\n",
      "\n",
      "# 36 Gradient out:  [2.15684547 0.796769   1.96426973 0.44420336 0.49045696 0.79625899\n",
      " 2.20031901 1.15406019 0.6148514  0.6168615 ]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [-0.21893631 -0.31420799  0.28686339  0.50066004  0.21675149 -0.41183267\n",
      " -0.47234587  0.35729756 -0.05379354  0.55395104]\n",
      "\n",
      "# 37 Gradient out:  [-1.66047096 -0.67040553 -1.46420963 -0.31075884 -0.36824504 -0.67000125\n",
      " -1.7133624  -0.91795219 -0.50828166 -0.51031933]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [ 0.21243279 -0.15485419  0.67971734  0.58950071  0.31484288 -0.25258087\n",
      " -0.03228206  0.5881096   0.06917674  0.67732334]\n",
      "\n",
      "# 38 Gradient out:  [ 3.89120462e-01  2.45475755e-02  3.84179891e-01  1.79101926e-02\n",
      "  8.60170993e-03  2.44365194e-02  3.82085372e-01  1.30994398e-01\n",
      " -2.18981578e-04 -1.54017742e-04]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [-0.11966141 -0.2889353   0.38687541  0.52734895  0.24119387 -0.38658112\n",
      " -0.37495455  0.40451916 -0.03247959  0.57525947]\n",
      "\n",
      "# 39 Gradient out:  [-0.8207814  -0.43131567 -0.69599181 -0.20070255 -0.24505918 -0.43113011\n",
      " -0.8604334  -0.51786034 -0.34293043 -0.34421593]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [-0.04183731 -0.28402578  0.46371139  0.53093098  0.24291421 -0.38169382\n",
      " -0.29853747  0.43071804 -0.03252339  0.57522867]\n",
      "\n",
      "# 40 Gradient out:  [2.41394602 0.95816809 2.20026752 0.56580335 0.61950914 0.95761873\n",
      " 2.46386918 1.33878569 0.75983578 0.76206239]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [-0.20599359 -0.37028892  0.32451303  0.49079047  0.19390238 -0.46791984\n",
      " -0.47062415  0.32714597 -0.10110948  0.50638548]\n",
      "\n",
      "# 41 Gradient out:  [-1.41823163 -0.57336133 -1.252493   -0.26973269 -0.3179813  -0.57301731\n",
      " -1.46267251 -0.78499992 -0.43591343 -0.43763459]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [ 0.27679561 -0.1786553   0.76456653  0.60395114  0.31780421 -0.27639609\n",
      "  0.02214969  0.59490311  0.05085768  0.65879796]\n",
      "\n",
      "# 42 Gradient out:  [-1.26062994 -0.5881264  -1.08955592 -0.27314388 -0.32940592 -0.5878307\n",
      " -1.31149129 -0.74767952 -0.45845929 -0.46022751]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [-0.00685072 -0.29332756  0.51406793  0.55000461  0.25420795 -0.39099955\n",
      " -0.27038482  0.43790313 -0.03632501  0.57127104]\n",
      "\n",
      "# 43 Gradient out:  [3.08072135 1.30784036 2.7996085  0.7901406  0.86574129 1.30716033\n",
      " 3.15013939 1.76652889 1.05575333 1.0586759 ]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [-0.2589767  -0.41095284  0.29615675  0.49537583  0.18832676 -0.5085657\n",
      " -0.53268307  0.28836722 -0.12801686  0.47922554]\n",
      "\n",
      "# 44 Gradient out:  [-0.97571813 -0.39253779 -0.86235522 -0.18489897 -0.21773143 -0.39230091\n",
      " -1.00598401 -0.5388597  -0.29820227 -0.29937974]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [ 0.35716757 -0.14938477  0.85607845  0.65340395  0.36147502 -0.24713363\n",
      "  0.0973448   0.641673    0.0831338   0.69096072]\n",
      "\n",
      "# 45 Gradient out:  [-1.93353357 -0.79076946 -1.70321507 -0.3685241  -0.43663883 -0.79030075\n",
      " -1.99610053 -1.07562755 -0.60169731 -0.6040877 ]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [ 0.16202394 -0.22789233  0.68360741  0.61642416  0.31792873 -0.32559381\n",
      " -0.103852    0.53390106  0.02349335  0.63108477]\n",
      "\n",
      "# 46 Gradient out:  [2.51387405 0.99168443 2.28725334 0.57557308 0.63306768 0.9911081\n",
      " 2.56727511 1.38895375 0.78260501 0.78496597]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [-0.22468277 -0.38604622  0.34296439  0.54271934  0.23060096 -0.48365396\n",
      " -0.5030721   0.31877555 -0.09684611  0.51026723]\n",
      "\n",
      "# 47 Gradient out:  [-1.36503455 -0.54886411 -1.20512638 -0.25593154 -0.30244352 -0.54853188\n",
      " -1.40788273 -0.75336045 -0.41618538 -0.41784605]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [ 0.27809204 -0.18770933  0.80041506  0.65783395  0.3572145  -0.28543234\n",
      "  0.01038292  0.5965663   0.05967489  0.66726043]\n",
      "\n",
      "# 48 Gradient out:  [-1.50830687 -0.68609937 -1.31208061 -0.32489843 -0.38806072 -0.68574533\n",
      " -1.56552054 -0.88407925 -0.53436294 -0.53639264]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [ 0.00508513 -0.29748216  0.55938978  0.60664765  0.2967258  -0.39513872\n",
      " -0.27119363  0.44589421 -0.02356219  0.58369121]\n",
      "\n",
      "# 49 Gradient out:  [3.23397061 1.3988984  2.93578981 0.84913691 0.93103683 1.39819083\n",
      " 3.30886616 1.87199372 1.13437588 1.13747345]\n",
      "\n",
      "     Weights  out:  [ 0.3626649  -0.17975368  0.22025917 -0.46143436 -0.39702813 -0.17997932\n",
      "  0.41432282 -0.0539729  -0.28048877 -0.27905562] [-0.29657624 -0.43470203  0.29697366  0.54166796  0.21911365 -0.53228778\n",
      " -0.58429774  0.26907836 -0.13043478  0.47641269]\n",
      "\n",
      "Tanh error cuadrático medio (ECM): 1.0208728804389087\n",
      "\n",
      "# 0 Gradient out:  [1.4797476  1.03822711 0.69968972 1.33839106 0.70034519 1.20766552\n",
      " 1.47219765 1.44082374 1.28597538 1.08356135]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [-0.03084795 -0.45502492 -0.23181152  0.11853006  0.16802248  0.41852458\n",
      "  0.33897241  0.08735852 -0.43116136 -0.40188461]\n",
      "\n",
      "# 1 Gradient out:  [-9.34202679 -5.17851538 -1.9391559  -7.50751826 -1.94922659 -6.40014132\n",
      " -9.24530941 -8.77868164 -7.02743679 -5.50010663]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [ 0.26510157 -0.2473795  -0.09187357  0.38620827  0.30809152  0.66005768\n",
      "  0.63341194  0.37552327 -0.17396629 -0.18517234]\n",
      "\n",
      "# 2 Gradient out:  [52.19927824 29.99468669 12.74130054 42.74695979 12.79237632 36.75548726\n",
      " 51.70307098 49.3320467  40.17509513 31.77881317]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [-1.60330379 -1.28308258 -0.47970475 -1.11529538 -0.0817538  -0.61997058\n",
      " -1.21564994 -1.38021306 -1.57945365 -1.28519367]\n",
      "\n",
      "# 3 Gradient out:  [-297.12849681 -169.81312952  -70.86771067 -242.55639621  -71.16359336\n",
      " -208.30200072 -294.25907219 -280.52753371 -227.8246922  -179.96546274]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [8.83655186 4.71585476 2.06855535 7.43409657 2.47672147 6.73112687\n",
      " 9.12496425 8.48619628 6.45556538 5.07056897]\n",
      "\n",
      "# 4 Gradient out:  [1686.31658243  964.54259564  403.61752711 1377.32801567  405.29174733\n",
      " 1183.02855541 1670.07630589 1592.37505593 1293.79466018 1022.17804966]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [-50.5891475  -29.24677114 -12.10498678 -41.07718267 -11.7559972\n",
      " -34.92927327 -49.72685018 -47.61931046 -39.10937306 -30.92252358]\n",
      "\n",
      "# 5 Gradient out:  [-9574.99756432 -5476.04846195 -2290.54826934 -7819.84629495\n",
      " -2300.05951564 -6716.53213629 -9482.73959952 -9041.32077883\n",
      " -7345.47943    -5803.27675808]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [286.67416899 163.66174798  68.61851864 234.38842047  69.30235226\n",
      " 201.67643781 284.28841099 270.85570073 219.64955898 173.51308635]\n",
      "\n",
      "# 6 Gradient out:  [54363.24632794 31091.53126163 13005.91492991 44398.82554597\n",
      " 13059.91137084 38134.66189909 53839.48494491 51333.49809036\n",
      " 41705.59565533 32949.44987952]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [-1628.32534388  -931.54794441  -389.49113523 -1329.58083852\n",
      "  -390.70955086 -1141.62998945 -1612.25950891 -1537.40845504\n",
      " -1249.44632702  -987.14226527]\n",
      "\n",
      "# 7 Gradient out:  [-308657.89842179 -176527.71314237  -73842.71761978 -252082.31574958\n",
      "  -74149.29768725 -216516.29470161 -305684.09664916 -291455.64818976\n",
      " -236790.94294835 -187076.35961803]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [9244.32392171 5286.75830792 2211.69185076 7550.18427067 2221.2727233\n",
      " 6485.30239037 9155.63748007 8729.29116303 7091.67280404 5602.74771064]\n",
      "\n",
      "# 8 Gradient out:  [1752461.743777   1002268.84883261  419256.31838737 1431244.13898587\n",
      "  420996.97814966 1229311.53309913 1735577.48426923 1654793.08100564\n",
      " 1344424.59695319 1062160.775953  ]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [-52487.25576265 -30018.78432055 -12556.8516732  -42866.27887924\n",
      " -12608.58681415 -36817.95654995 -51981.18184976 -49561.83847492\n",
      " -40266.51578563 -31812.52421297]\n",
      "\n",
      "# 9 Gradient out:  [-9949925.70496465 -5690566.41030251 -2380404.63991801 -8126152.72835869\n",
      " -2390287.56235161 -6979643.03388341 -9854062.15391021 -9395393.54514543\n",
      " -7633218.69978856 -6030613.84361964]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [298005.09299275 170434.98544597  71294.41200427 243382.54891793\n",
      "  71590.80881579 209044.35006987 295134.31500409 281396.77772621\n",
      " 228618.40360501 180619.63097763]\n",
      "\n",
      "# 10 Gradient out:  [56492540.63290335 32309241.98439718 13515187.49581898 46137733.35847267\n",
      " 13571299.6083912  39628212.79989631 55948257.66330058 53344082.14976907\n",
      " 43339009.39452837 34239924.14976464]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [-1691980.04800018  -967678.29661453  -404786.51597933 -1381847.99675381\n",
      "  -406466.70365454 -1186884.25670681 -1675678.11577796 -1597681.93130288\n",
      " -1298025.3363527  -1025503.1377463 ]\n",
      "\n",
      "# 11 Gradient out:  [-3.20746835e+08 -1.83441689e+08 -7.67349730e+07 -2.61955503e+08\n",
      " -7.70535599e+07 -2.24996498e+08 -3.17656568e+08 -3.02870880e+08\n",
      " -2.46065231e+08 -1.94403494e+08]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [9606528.07858049 5494170.1002649  2298250.98318447 7845698.67494073\n",
      " 2307793.2180237  6738758.30327245 9513973.41688216 9071134.49865094\n",
      " 7369776.54255298 5822481.69220663]\n",
      "\n",
      "# 12 Gradient out:  [1.82109940e+09 1.04152407e+09 4.35676984e+08 1.48730076e+09\n",
      " 4.37485819e+08 1.27745918e+09 1.80355384e+09 1.71960536e+09\n",
      " 1.39708080e+09 1.10376174e+09]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [-54542838.85852443 -31194167.74380099 -13048743.62316573\n",
      " -44545401.93988097 -13102918.76606074 -38260541.24238318\n",
      " -54017340.09147069 -51503041.46338358 -41843269.61430321\n",
      " -33058217.0631472 ]\n",
      "\n",
      "# 13 Gradient out:  [-1.03396282e+10 -5.91344531e+09 -2.47363655e+09 -8.44442476e+09\n",
      " -2.48390655e+09 -7.25301043e+09 -1.02400100e+10 -9.76337708e+09\n",
      " -7.93218429e+09 -6.26681118e+09]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [3.09677041e+08 1.77110647e+08 7.40866531e+07 2.52914749e+08\n",
      " 7.43942451e+07 2.17231294e+08 3.06693427e+08 2.92418031e+08\n",
      " 2.37572890e+08 1.87694132e+08]\n",
      "\n",
      "# 14 Gradient out:  [5.87051491e+10 3.35746781e+10 1.40445284e+10 4.79447814e+10\n",
      " 1.41028382e+10 4.11803064e+10 5.81395485e+10 5.54333768e+10\n",
      " 4.50364415e+10 3.55809780e+10]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [-1.75824860e+09 -1.00557842e+09 -4.20640657e+08 -1.43597020e+09\n",
      " -4.22387065e+08 -1.23337079e+09 -1.74130858e+09 -1.66025739e+09\n",
      " -1.34886397e+09 -1.06566810e+09]\n",
      "\n",
      "# 15 Gradient out:  [-3.33309327e+11 -1.90626436e+11 -7.97404043e+10 -2.72215352e+11\n",
      " -8.00714691e+10 -2.33808796e+11 -3.30098026e+11 -3.14733236e+11\n",
      " -2.55702715e+11 -2.02017575e+11]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [9.98278121e+09 5.70935720e+09 2.38826503e+09 8.15298607e+09\n",
      " 2.39818058e+09 7.00269050e+09 9.88660112e+09 9.42641798e+09\n",
      " 7.65842433e+09 6.05052750e+09]\n",
      "\n",
      "# 16 Gradient out:  [1.89242527e+12 1.08231680e+12 4.52740874e+11 1.54555294e+12\n",
      " 4.54620556e+11 1.32749263e+12 1.87419251e+12 1.78695608e+12\n",
      " 1.45179940e+12 1.14699210e+12]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [-5.66790843e+10 -3.24159301e+10 -1.35598158e+10 -4.62900844e+10\n",
      " -1.36161132e+10 -3.97590688e+10 -5.61330040e+10 -5.35202292e+10\n",
      " -4.34821187e+10 -3.43529875e+10]\n",
      "\n",
      "# 17 Gradient out:  [-1.07445940e+13 -6.14505357e+12 -2.57051994e+12 -8.77516232e+12\n",
      " -2.58119218e+12 -7.53708460e+12 -1.06410742e+13 -1.01457732e+13\n",
      " -8.24285925e+12 -6.51225950e+12]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [3.21805970e+11 1.84047431e+11 7.69883590e+10 2.62820504e+11\n",
      " 7.73079979e+10 2.25739457e+11 3.18705499e+11 3.03870987e+11\n",
      " 2.46877761e+11 1.95045432e+11]\n",
      "\n",
      "# 18 Gradient out:  [6.10044173e+13 3.48896767e+13 1.45946018e+13 4.98226049e+13\n",
      " 1.46551954e+13 4.27931900e+13 6.04166642e+13 5.76045016e+13\n",
      " 4.68003559e+13 3.69745562e+13]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [-1.82711284e+12 -1.04496328e+12 -4.37115629e+11 -1.49221196e+12\n",
      " -4.38930438e+11 -1.28167746e+12 -1.80950934e+12 -1.72528366e+12\n",
      " -1.40169409e+12 -1.10740647e+12]\n",
      "\n",
      "# 19 Gradient out:  [-3.46363847e+14 -1.98092584e+14 -8.28635473e+13 -2.82877042e+14\n",
      " -8.32075787e+13 -2.42966241e+14 -3.43026771e+14 -3.27060198e+14\n",
      " -2.65717665e+14 -2.09929872e+14]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [1.03737706e+13 5.93297205e+12 2.48180472e+12 8.47230903e+12\n",
      " 2.49210864e+12 7.27696054e+12 1.02738235e+13 9.79561665e+12\n",
      " 7.95837710e+12 6.28750477e+12]\n",
      "\n",
      "# 20 Gradient out:  [1.96654472e+15 1.12470724e+15 4.70473096e+14 1.60608666e+15\n",
      " 4.72426398e+14 1.37948571e+15 1.94759785e+15 1.85694469e+15\n",
      " 1.50866113e+15 1.19191563e+15]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [-5.88989989e+13 -3.36855447e+13 -1.40909047e+13 -4.81030994e+13\n",
      " -1.41494071e+13 -4.13162876e+13 -5.83315306e+13 -5.56164229e+13\n",
      " -4.51851560e+13 -3.56984697e+13]\n",
      "\n",
      "# 21 Gradient out:  [-1.11654209e+16 -6.38573307e+15 -2.67119790e+15 -9.11885367e+15\n",
      " -2.68228813e+15 -7.83228493e+15 -1.10578465e+16 -1.05431464e+16\n",
      " -8.56570221e+15 -6.76732113e+15]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [3.34409945e+14 1.91255902e+14 8.00037144e+13 2.73114232e+14\n",
      " 8.03358724e+13 2.34580854e+14 3.31188040e+14 3.15772514e+14\n",
      " 2.56547069e+14 2.02684656e+14]\n",
      "\n",
      "# 22 Gradient out:  [6.33937395e+16 3.62561791e+16 1.51662195e+16 5.17739761e+16\n",
      " 1.52291863e+16 4.44692444e+16 6.27829663e+16 5.98606614e+16\n",
      " 4.86333565e+16 3.84227157e+16]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [-1.89867423e+15 -1.08589071e+15 -4.54235866e+14 -1.55065650e+15\n",
      " -4.56121755e+14 -1.33187613e+15 -1.88038127e+15 -1.79285678e+15\n",
      " -1.45659337e+15 -1.15077957e+15]\n",
      "\n",
      "# 23 Gradient out:  [-3.59929666e+17 -2.05851154e+17 -8.61090126e+16 -2.93956312e+17\n",
      " -8.64665184e+16 -2.52482349e+17 -3.56461888e+17 -3.39869962e+17\n",
      " -2.76124865e+17 -2.18152066e+17]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [1.07800737e+16 6.16534510e+15 2.57900803e+15 8.80413871e+15\n",
      " 2.58971551e+15 7.56197275e+15 1.06762120e+16 1.01792755e+16\n",
      " 8.27007793e+15 6.53376358e+15]\n",
      "\n",
      "# 24 Gradient out:  [2.04356716e+18 1.16875795e+18 4.88899824e+17 1.66899126e+18\n",
      " 4.90929630e+17 1.43351517e+18 2.02387821e+18 1.92967449e+18\n",
      " 1.56774992e+18 1.23859865e+18]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [-6.12058595e+16 -3.50048856e+16 -1.46427945e+16 -4.99871237e+16\n",
      " -1.47035882e+16 -4.29344971e+16 -6.06161656e+16 -5.77947169e+16\n",
      " -4.69548950e+16 -3.70966496e+16]\n",
      "\n",
      "# 25 Gradient out:  [-1.16027300e+19 -6.63583913e+18 -2.77581906e+18 -9.47600616e+18\n",
      " -2.78734365e+18 -8.13904718e+18 -1.14909424e+19 -1.09560833e+19\n",
      " -8.90118977e+18 -7.03237261e+18]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [3.47507573e+17 1.98746704e+17 8.31371704e+16 2.83811128e+17\n",
      " 8.34823378e+16 2.43768538e+17 3.44159477e+17 3.28140181e+17\n",
      " 2.66595089e+17 2.10623080e+17]\n",
      "\n",
      "# 26 Gradient out:  [6.58766429e+19 3.76762024e+19 1.57602254e+19 5.38017753e+19\n",
      " 1.58256584e+19 4.62109438e+19 6.52419478e+19 6.22051869e+19\n",
      " 5.05381491e+19 3.99275945e+19]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [-1.97303843e+18 -1.12842112e+18 -4.72026641e+17 -1.61139010e+18\n",
      " -4.73986393e+17 -1.38404090e+18 -1.95402900e+18 -1.86307649e+18\n",
      " -1.51364286e+18 -1.19585144e+18]\n",
      "\n",
      "# 27 Gradient out:  [-3.74026808e+20 -2.13913598e+20 -8.94815910e+19 -3.05469517e+20\n",
      " -8.98530990e+19 -2.62371169e+20 -3.70423210e+20 -3.53181439e+20\n",
      " -2.86939676e+20 -2.26696293e+20]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [1.12022901e+19 6.40681935e+18 2.68001844e+18 9.14896496e+18\n",
      " 2.69114530e+18 7.85814785e+18 1.10943606e+19 1.05779609e+19\n",
      " 8.59398695e+18 6.78966745e+18]\n",
      "\n",
      "# 28 Gradient out:  [2.12360629e+21 1.21453397e+21 5.08048261e+20 1.73435961e+21\n",
      " 5.10157567e+20 1.48966077e+21 2.10314620e+21 2.00525285e+21\n",
      " 1.62915301e+21 1.28711007e+21]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [-6.36030715e+19 -3.63759003e+19 -1.52162997e+19 -5.19449385e+19\n",
      " -1.52794745e+19 -4.46160859e+19 -6.29902814e+19 -6.00583268e+19\n",
      " -4.87939483e+19 -3.85495911e+19]\n",
      "\n",
      "# 29 Gradient out:  [-1.20571670e+22 -6.89574093e+21 -2.88453784e+21 -9.84714703e+21\n",
      " -2.89651382e+21 -8.45782420e+21 -1.19410010e+22 -1.13851935e+22\n",
      " -9.24981716e+21 -7.30780519e+21]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [3.61118187e+20 2.06530893e+20 8.63933524e+19 2.94926983e+20\n",
      " 8.67520388e+19 2.53316069e+20 3.57638958e+20 3.40992244e+20\n",
      " 2.77036654e+20 2.18872424e+20]\n",
      "\n",
      "# 30 Gradient out:  [6.84567926e+22 3.91518429e+22 1.63774964e+22 5.59089961e+22\n",
      " 1.64454922e+22 4.80208592e+22 6.77972388e+22 6.46415389e+22\n",
      " 5.25175455e+22 4.14914138e+22]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [-2.05031521e+21 -1.17261729e+21 -4.90514216e+20 -1.67450242e+21\n",
      " -4.92550725e+20 -1.43824877e+21 -2.03056124e+21 -1.93604645e+21\n",
      " -1.57292678e+21 -1.24268862e+21]\n",
      "\n",
      "# 31 Gradient out:  [-3.88676085e+23 -2.22291820e+23 -9.29862610e+22 -3.17433653e+23\n",
      " -9.33723197e+22 -2.72647298e+23 -3.84931346e+23 -3.67014277e+23\n",
      " -2.98178065e+23 -2.35575166e+23]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [1.16410433e+22 6.65775128e+21 2.78498507e+21 9.50729681e+21\n",
      " 2.79654772e+21 8.16592306e+21 1.15288865e+22 1.09922613e+22\n",
      " 8.93058231e+21 7.05559415e+21]\n",
      "\n",
      "# 32 Gradient out:  [2.20678026e+24 1.26210287e+24 5.27946673e+23 1.80228820e+24\n",
      " 5.30138592e+23 1.54800540e+24 2.18551882e+24 2.08379135e+24\n",
      " 1.69296104e+24 1.33752152e+24]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [-6.60941736e+22 -3.78006127e+22 -1.58122671e+22 -5.39794337e+22\n",
      " -1.58779162e+22 -4.63635365e+22 -6.54573828e+22 -6.24105941e+22\n",
      " -5.07050307e+22 -4.00594390e+22]\n",
      "\n",
      "# 33 Gradient out:  [-1.25294026e+25 -7.16582215e+24 -2.99751475e+24 -1.02328241e+25\n",
      " -3.00995978e+24 -8.78908657e+24 -1.24086868e+25 -1.18311103e+25\n",
      " -9.61209902e+24 -7.59402548e+24]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [3.75261879e+23 2.14619961e+23 8.97770674e+22 3.06478206e+23\n",
      " 9.01498022e+22 2.63237543e+23 3.71646381e+23 3.54347676e+23\n",
      " 2.87887177e+23 2.27444865e+23]\n",
      "\n",
      "# 34 Gradient out:  [7.11379974e+25 4.06852789e+25 1.70189437e+25 5.80987492e+25\n",
      " 1.70896026e+25 4.99016624e+25 7.04526113e+25 6.71733141e+25\n",
      " 5.45744676e+25 4.31164823e+25]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [-2.13061863e+24 -1.21854447e+24 -5.09725883e+23 -1.74008662e+24\n",
      " -5.11842154e+23 -1.49457977e+24 -2.11009098e+24 -2.01187438e+24\n",
      " -1.63453263e+24 -1.29136023e+24]\n",
      "\n",
      "# 35 Gradient out:  [-4.03899120e+26 -2.30998186e+26 -9.66281964e+25 -3.29866380e+26\n",
      " -9.70293756e+25 -2.83325906e+26 -4.00007714e+26 -3.81388898e+26\n",
      " -3.09856621e+26 -2.44801793e+26]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [1.20969808e+25 6.91851130e+24 2.89406285e+24 9.87966321e+24\n",
      " 2.90607837e+24 8.48575272e+24 1.19804313e+25 1.14227884e+25\n",
      " 9.28036090e+24 7.33193624e+24]\n",
      "\n",
      "# 36 Gradient out:  [2.29321186e+27 1.31153487e+27 5.48624433e+26 1.87287730e+27\n",
      " 5.50902202e+26 1.60863516e+27 2.27111768e+27 2.16540592e+27\n",
      " 1.75926820e+27 1.38990740e+27]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [-6.86828432e+25 -3.92811258e+25 -1.64315764e+25 -5.60936128e+25\n",
      " -1.64997967e+25 -4.81794285e+25 -6.80211115e+25 -6.48549912e+25\n",
      " -5.26909632e+25 -4.16284223e+25]\n",
      "\n",
      "# 37 Gradient out:  [-1.30201339e+28 -7.44648147e+27 -3.11491656e+27 -1.06336068e+28\n",
      " -3.12784901e+27 -9.13332328e+27 -1.28946901e+28 -1.22944921e+28\n",
      " -9.98857015e+27 -7.89145597e+27]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [3.89959529e+26 2.23025848e+26 9.32933102e+25 3.18481848e+26\n",
      " 9.36806437e+25 2.73547604e+26 3.86202425e+26 3.68226192e+26\n",
      " 2.99162676e+26 2.36353057e+26]\n",
      "\n",
      "# 38 Gradient out:  [7.39242153e+28 4.22787740e+28 1.76855141e+28 6.03742669e+28\n",
      " 1.77589405e+28 5.18561300e+28 7.32119851e+28 6.98042497e+28\n",
      " 5.67119520e+28 4.48051989e+28]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [-2.21406725e+27 -1.26627045e+27 -5.29690001e+26 -1.80823952e+27\n",
      " -5.31889159e+26 -1.55311705e+27 -2.19273560e+27 -2.09067222e+27\n",
      " -1.69855135e+27 -1.34193814e+27]\n",
      "\n",
      "# 39 Gradient out:  [-4.19718387e+29 -2.40045549e+29 -1.00412773e+29 -3.42786052e+29\n",
      " -1.00829665e+29 -2.94422756e+29 -4.15674569e+29 -3.96326521e+29\n",
      " -3.21992583e+29 -2.54389793e+29]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [1.25707758e+28 7.18948435e+27 3.00741282e+27 1.02666139e+28\n",
      " 3.01989894e+27 8.81810894e+27 1.24496614e+28 1.18701777e+28\n",
      " 9.64383905e+27 7.61910165e+27]\n",
      "\n",
      "# 40 Gradient out:  [2.38302867e+30 1.36290294e+30 5.70112067e+29 1.94623113e+30\n",
      " 5.72479048e+29 1.67163958e+30 2.36006914e+30 2.25021703e+30\n",
      " 1.82817237e+30 1.44434504e+30]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [-7.13729016e+28 -4.08196254e+28 -1.70751418e+28 -5.82905966e+28\n",
      " -1.71460341e+28 -5.00664423e+28 -7.06852523e+28 -6.73951265e+28\n",
      " -5.47546776e+28 -4.32588569e+28]\n",
      "\n",
      "# 41 Gradient out:  [-1.35300854e+31 -7.73813320e+30 -3.23691657e+30 -1.10500867e+31\n",
      " -3.25035554e+30 -9.49104250e+30 -1.33997285e+31 -1.27760228e+31\n",
      " -1.03797863e+31 -8.20053574e+30]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [4.05232832e+29 2.31760963e+29 9.69472715e+28 3.30955629e+29\n",
      " 9.73497755e+28 2.84261474e+29 4.01328576e+29 3.82648279e+29\n",
      " 3.10879796e+29 2.45610151e+29]\n",
      "\n",
      "# 42 Gradient out:  [7.68195593e+31 4.39346806e+31 1.83781917e+31 6.27389085e+31\n",
      " 1.84544939e+31 5.38871469e+31 7.60794336e+31 7.25382295e+31\n",
      " 5.89331539e+31 4.65600564e+31]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [-2.30078426e+30 -1.31586568e+30 -5.50436041e+29 -1.87906172e+30\n",
      " -5.52721332e+29 -1.61394703e+30 -2.27861712e+30 -2.17255629e+30\n",
      " -1.76507746e+30 -1.39449700e+30]\n",
      "\n",
      "# 43 Gradient out:  [-4.36157237e+32 -2.49447264e+32 -1.04345578e+32 -3.56211741e+32\n",
      " -1.04778798e+32 -3.05954230e+32 -4.31955037e+32 -4.11849197e+32\n",
      " -3.34603867e+32 -2.64353320e+32]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [1.30631276e+31 7.47107043e+30 3.12520230e+30 1.06687200e+31\n",
      " 3.13817746e+30 9.16348235e+30 1.29372696e+31 1.23350896e+31\n",
      " 1.00215533e+31 7.91751428e+30]\n",
      "\n",
      "# 44 Gradient out:  [2.47636328e+33 1.41628292e+33 5.92441293e+32 2.02245796e+33\n",
      " 5.94900980e+32 1.73711165e+33 2.45250451e+33 2.33834989e+33\n",
      " 1.89977526e+33 1.50091481e+33]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [-7.41683198e+31 -4.24183824e+31 -1.77439133e+31 -6.05736283e+31\n",
      " -1.78175822e+31 -5.20273637e+31 -7.34537378e+31 -7.00347497e+31\n",
      " -5.68992201e+31 -4.49531498e+31]\n",
      "\n",
      "# 45 Gradient out:  [-1.40600099e+34 -8.04120787e+33 -3.36369487e+33 -1.14828786e+34\n",
      " -3.37766020e+33 -9.86277229e+33 -1.39245474e+34 -1.32764134e+34\n",
      " -1.07863250e+34 -8.52172105e+33]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [4.21104336e+32 2.40838201e+32 1.00744345e+32 3.43917963e+32\n",
      " 1.01162614e+32 2.95394967e+32 4.17047164e+32 3.97635228e+32\n",
      " 3.23055832e+32 2.55229811e+32]\n",
      "\n",
      "# 46 Gradient out:  [7.98283034e+34 4.56554430e+34 1.90979990e+34 6.51961644e+34\n",
      " 1.91772897e+34 5.59977114e+34 7.90591897e+34 7.53792894e+34\n",
      " 6.12413523e+34 4.83836453e+34]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [-2.39089765e+33 -1.36740337e+33 -5.71994629e+32 -1.95265776e+33\n",
      " -5.74369426e+32 -1.67715949e+33 -2.36786231e+33 -2.25764745e+33\n",
      " -1.83420916e+33 -1.44911440e+33]\n",
      "\n",
      "# 47 Gradient out:  [-4.53239938e+35 -2.59217211e+35 -1.08432417e+35 -3.70163266e+35\n",
      " -1.08882604e+35 -3.17937350e+35 -4.48873153e+35 -4.27979839e+35\n",
      " -3.47709090e+35 -2.74707083e+35]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [1.35747630e+34 7.76368522e+33 3.24760516e+33 1.10865751e+34\n",
      " 3.26108851e+33 9.52238279e+33 1.34439756e+34 1.28182104e+34\n",
      " 1.04140613e+34 8.22761466e+33]\n",
      "\n",
      "# 48 Gradient out:  [2.57335347e+36 1.47175359e+36 6.15645074e+35 2.10167032e+36\n",
      " 6.18201099e+35 1.80514803e+36 2.54856024e+36 2.42993459e+36\n",
      " 1.97418258e+36 1.55970021e+36]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [-7.70732245e+34 -4.40797569e+34 -1.84388782e+34 -6.29460781e+34\n",
      " -1.85154324e+34 -5.40650872e+34 -7.63306549e+34 -7.27777574e+34\n",
      " -5.91277566e+34 -4.67138020e+34]\n",
      "\n",
      "# 49 Gradient out:  [-1.46106896e+37 -8.35615288e+36 -3.49543863e+36 -1.19326214e+37\n",
      " -3.50995093e+36 -1.02490614e+37 -1.44699215e+37 -1.37964025e+37\n",
      " -1.12087863e+37 -8.85548602e+36]\n",
      "\n",
      "     Weights  out:  [ 0.47614299 -0.02196517 -0.38526885  0.18382177 -0.38327729  0.07967996\n",
      "  0.45061084  0.35278415  0.1361011   0.00446972] [4.37597469e+35 2.50270962e+35 1.04690137e+35 3.57387985e+35\n",
      " 1.05124787e+35 3.06964519e+35 4.33381392e+35 4.13209161e+35\n",
      " 3.35708760e+35 2.65226239e+35]\n",
      "\n",
      "Lineal error cuadrático medio (ECM): 1.2433783017190398e+74\n",
      "\n",
      "# 0 Gradient out:  [1.98750667 1.73992216 1.40989828 0.74995278 2.08475993 0.67257675\n",
      " 0.71506851 0.76912767 2.26416414 2.17824743]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [-0.37176232 -0.421164   -0.49772527 -0.29178248 -0.33803312  0.38682809\n",
      " -0.10587601 -0.4139984  -0.15408072  0.10414446]\n",
      "\n",
      "# 1 Gradient out:  [-1.65313444 -1.38607568 -1.0695109  -0.36590836 -1.76935158 -0.27142538\n",
      " -0.32286823 -0.38963098 -1.9863326  -1.88465318]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.02573902 -0.07317957 -0.21574562 -0.14179193  0.07891887  0.52134344\n",
      "  0.0371377  -0.26017287  0.29875211  0.53979395]\n",
      "\n",
      "# 2 Gradient out:  [2.82615146 2.47180023 1.99488654 1.0501026  2.9637555  0.94180404\n",
      " 1.00122307 1.0770198  3.21513876 3.09504502]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [-0.30488787 -0.3503947  -0.4296478  -0.2149736  -0.27495145  0.46705836\n",
      " -0.02743595 -0.33809906 -0.09851441  0.16286331]\n",
      "\n",
      "# 3 Gradient out:  [-0.59567625 -0.51764543 -0.42299657 -0.21642904 -0.62922485 -0.18856707\n",
      " -0.2038378  -0.22332416 -0.69329315 -0.66274692]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.26034242  0.14396534 -0.03067049 -0.00495308  0.31779965  0.65541917\n",
      "  0.17280866 -0.1226951   0.54451334  0.78187232]\n",
      "\n",
      "# 4 Gradient out:  [-1.31511505 -1.12861429 -0.90268704 -0.4096028  -1.39515908 -0.34383943\n",
      " -0.37979949 -0.42596709 -1.54639031 -1.4747241 ]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.14120717  0.04043626 -0.1152698  -0.04823889  0.19195468  0.61770575\n",
      "  0.1320411  -0.16735994  0.40585471  0.64932293]\n",
      "\n",
      "# 5 Gradient out:  [1.15720431 1.03601023 0.82971623 0.50137575 1.19038947 0.48276363\n",
      " 0.4928706  0.5063093  1.23612365 1.2149212 ]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [-0.12181584 -0.1852866  -0.29580721 -0.13015945 -0.08707713  0.54893787\n",
      "  0.05608121 -0.25255335  0.09657665  0.35437811]\n",
      "\n",
      "# 6 Gradient out:  [-1.54904404 -1.32386711 -1.05216022 -0.45711446 -1.64596662 -0.37750626\n",
      " -0.421019   -0.47693938 -1.82899351 -1.74235051]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.10962502  0.02191545 -0.12986396 -0.0298843   0.15100076  0.64549059\n",
      "  0.15465532 -0.15129149  0.34380138  0.59736235]\n",
      "\n",
      "# 7 Gradient out:  [2.87119823 2.50404789 1.98845691 1.00831356 3.00635085 0.90746604\n",
      " 0.96254572 1.03374962 3.24178332 3.13067387]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [-0.20018378 -0.24285798 -0.34029601 -0.12130719 -0.17819256  0.56998934\n",
      "  0.07045152 -0.24667937 -0.02199733  0.24889225]\n",
      "\n",
      "# 8 Gradient out:  [-0.24917535 -0.21753059 -0.17917647 -0.09536347 -0.26280787 -0.08397885\n",
      " -0.09022521 -0.09817363 -0.28898374 -0.27646907]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.37405586  0.2579516   0.05739537  0.08035552  0.42307761  0.75148255\n",
      "  0.26296067 -0.03992945  0.62635934  0.87502702]\n",
      "\n",
      "# 9 Gradient out:  [-0.37757641 -0.3283492  -0.26862256 -0.13827747 -0.39874626 -0.12066307\n",
      " -0.13032131 -0.1426323  -0.4392508  -0.41991801]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.32422079  0.21444548  0.02156008  0.06128283  0.37051603  0.73468678\n",
      "  0.24491563 -0.05956417  0.56856259  0.81973321]\n",
      "\n",
      "# 10 Gradient out:  [-0.68499999 -0.59208102 -0.47924526 -0.23333676 -0.72487368 -0.20034799\n",
      " -0.21841693 -0.24151391 -0.80074257 -0.76463134]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.24870551  0.14877564 -0.03216443  0.03362733  0.29076678  0.71055417\n",
      "  0.21885136 -0.08809063  0.48071243  0.73574961]\n",
      "\n",
      "# 11 Gradient out:  [-1.57528261 -1.34567888 -1.06894815 -0.46221651 -1.67422218 -0.38085832\n",
      " -0.42533395 -0.48246938 -1.86125857 -1.77268351]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.11170551  0.03035944 -0.12801348 -0.01304002  0.14579205  0.67048457\n",
      "  0.17516798 -0.13639342  0.32056391  0.58282334]\n",
      "\n",
      "# 12 Gradient out:  [2.94309078 2.56464069 2.03669483 1.0266806  3.08358167 0.92101305\n",
      " 0.97875835 1.05327905 3.33003152 3.21354187]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [-0.20335101 -0.23877634 -0.34180311 -0.10548332 -0.18905239  0.59431291\n",
      "  0.09010119 -0.23288729 -0.0516878   0.22828664]\n",
      "\n",
      "# 13 Gradient out:  [-0.23522436 -0.20503961 -0.16843714 -0.08849565 -0.24821947 -0.07765436\n",
      " -0.08360169 -0.09117277 -0.27314739 -0.26123419]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.38526715  0.2741518   0.06553585  0.0998528   0.42766394  0.77851552\n",
      "  0.28585286 -0.02223148  0.6143185   0.87099501]\n",
      "\n",
      "# 14 Gradient out:  [-0.34929423 -0.30341399 -0.24772601 -0.12624654 -0.36901515 -0.10984833\n",
      " -0.11883893 -0.13030165 -0.40672462 -0.38873005]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.33822227  0.23314388  0.03184842  0.08215367  0.37802005  0.76298465\n",
      "  0.26913252 -0.04046603  0.55968902  0.81874817]\n",
      "\n",
      "# 15 Gradient out:  [-0.6118836  -0.52872684 -0.42771063 -0.20762717 -0.64755911 -0.17810785\n",
      " -0.19427754 -0.21494334 -0.71545082 -0.6831309 ]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.26836343  0.17246108 -0.01769678  0.05690436  0.30421702  0.74101498\n",
      "  0.24536473 -0.06652636  0.4783441   0.74100216]\n",
      "\n",
      "# 16 Gradient out:  [-1.38299392 -1.18388992 -0.94310329 -0.41673796 -1.46857968 -0.34632043\n",
      " -0.38483238 -0.43425194 -1.63050093 -1.55373121]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.14598671  0.06671571 -0.1032389   0.01537893  0.1747052   0.70539341\n",
      "  0.20650923 -0.10951503  0.33525394  0.60437598]\n",
      "\n",
      "# 17 Gradient out:  [1.68153421 1.46802531 1.13967221 0.56727808 1.75056182 0.52247926\n",
      " 0.54669243 0.57899653 1.85707013 1.80819739]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [-0.13061208 -0.17006227 -0.29185956 -0.06796866 -0.11901074  0.63612933\n",
      "  0.12954275 -0.19636542  0.00915375  0.29362974]\n",
      "\n",
      "# 18 Gradient out:  [-1.00639467 -0.86442731 -0.69211429 -0.31659478 -1.06727003 -0.26644446\n",
      " -0.29388873 -0.32905236 -1.18261365 -1.12784156]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.20569477  0.12354279 -0.06392512  0.04548695  0.23110163  0.74062518\n",
      "  0.23888124 -0.08056611  0.38056778  0.65526922]\n",
      "\n",
      "# 19 Gradient out:  [-1.44741368 -1.222402   -0.9737066  -0.3816126  -1.55168505 -0.29190569\n",
      " -0.3410567  -0.40374005 -1.75681401 -1.65904901]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.00441583 -0.04934267 -0.20234798 -0.017832    0.01764762  0.68733629\n",
      "  0.18010349 -0.14637658  0.14404505  0.4297009 ]\n",
      "\n",
      "# 20 Gradient out:  [2.81256514 2.46989077 2.01457576 1.09996146 2.94817421 0.98995667\n",
      " 1.05057921 1.12698486 3.2030765  3.07988763]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [-0.2850669  -0.29382307 -0.3970893  -0.09415452 -0.29268939  0.62895515\n",
      "  0.11189215 -0.2271246  -0.20731775  0.0978911 ]\n",
      "\n",
      "# 21 Gradient out:  [-0.5858727  -0.50388896 -0.40414932 -0.18721378 -0.62097263 -0.15826672\n",
      " -0.17411492 -0.19439753 -0.68756001 -0.65590304]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.27744612  0.20015508  0.00582586  0.12583777  0.29694545  0.82694648\n",
      "  0.32200799 -0.00172762  0.43329755  0.71386863]\n",
      "\n",
      "# 22 Gradient out:  [-1.31570807 -1.12444796 -0.89313542 -0.38746676 -1.39793156 -0.31974863\n",
      " -0.35679342 -0.4043     -1.55365114 -1.4797734 ]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.16027159  0.09937729 -0.07500401  0.08839501  0.17275093  0.79529314\n",
      "  0.28718501 -0.04060713  0.29578554  0.58268802]\n",
      "\n",
      "# 23 Gradient out:  [0.97176813 0.83881367 0.60886093 0.2511344  1.00586638 0.23701624\n",
      " 0.24421127 0.25547452 1.04181779 1.02764305]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [-0.10287003 -0.1255123  -0.25363109  0.01090166 -0.10683539  0.73134341\n",
      "  0.21582632 -0.12146713 -0.01494468  0.28673334]\n",
      "\n",
      "# 24 Gradient out:  [-1.77956652 -1.51601053 -1.20333162 -0.50721101 -1.89483576 -0.41122031\n",
      " -0.46375992 -0.53101901 -2.11527362 -2.01053168]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.0914836   0.04225043 -0.13185891  0.06112854  0.09433789  0.77874666\n",
      "  0.26466858 -0.07037222  0.19341887  0.49226195]\n",
      "\n",
      "# 25 Gradient out:  [2.88933    2.5334509  2.05993679 1.10991667 3.02998598 0.99580869\n",
      " 1.05870495 1.13793747 3.29443071 3.16656633]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [-0.2644297  -0.26095167 -0.37252523 -0.04031366 -0.28462926  0.6965026\n",
      "  0.17191659 -0.17657603 -0.22963585  0.09015561]\n",
      "\n",
      "# 26 Gradient out:  [-0.45931958 -0.39435129 -0.31521393 -0.14330584 -0.48709691 -0.12043077\n",
      " -0.13295258 -0.14898535 -0.53972299 -0.51471428]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [0.3134363  0.24573851 0.03946213 0.18166967 0.32136793 0.89566434\n",
      " 0.38365758 0.05101147 0.42925029 0.72346888]\n",
      "\n",
      "# 27 Gradient out:  [-0.92767353 -0.79301854 -0.6293796  -0.27325238 -0.98531778 -0.22587477\n",
      " -0.25179355 -0.28503121 -1.09430278 -1.04259256]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.22157238  0.16686825 -0.02358066  0.15300851  0.22394855  0.87157818\n",
      "  0.35706707  0.0212144   0.32130569  0.62052602]\n",
      "\n",
      "# 28 Gradient out:  [-1.71401504 -1.46095493 -1.17546656 -0.50784661 -1.82981745 -0.40773281\n",
      " -0.46272757 -0.53241062 -2.05900032 -1.94904011]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.03603767  0.00826454 -0.14945658  0.09835803  0.026885    0.82640323\n",
      "  0.30670836 -0.03579184  0.10244514  0.41200751]\n",
      "\n",
      "# 29 Gradient out:  [2.53622506 2.23995273 1.85442786 1.0625827  2.6568865  0.96061159\n",
      " 1.01711873 1.08725732 2.89260018 2.77703048]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [-0.30676534 -0.28392645 -0.38454989 -0.00321129 -0.33907849  0.74485666\n",
      "  0.21416284 -0.14227397 -0.30935493  0.02219949]\n",
      "\n",
      "# 30 Gradient out:  [-1.03788626 -0.88425401 -0.69776665 -0.29154864 -1.10369301 -0.23750769\n",
      " -0.26706442 -0.30499158 -1.22800273 -1.16905902]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.20047968  0.1640641  -0.01366432  0.20930525  0.19229881  0.93697898\n",
      "  0.41758659  0.0751775   0.26916511  0.57760558]\n",
      "\n",
      "# 31 Gradient out:  [-1.26982678 -1.0906784  -0.91411436 -0.44238139 -1.36086588 -0.35702455\n",
      " -0.40429031 -0.46283366 -1.55509686 -1.4598882 ]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [-0.00709758 -0.0127867  -0.15321765  0.15099552 -0.0284398   0.88947744\n",
      "  0.36417371  0.01417918  0.02356456  0.34379378]\n",
      "\n",
      "# 32 Gradient out:  [2.78318245 2.43561998 1.9757908  1.0475103  2.92169443 0.93366547\n",
      " 0.99653464 1.07532659 3.18533881 3.05723694]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [-0.26106293 -0.23092238 -0.33604052  0.06251924 -0.30061297  0.81807253\n",
      "  0.28331564 -0.07838755 -0.28745481  0.05181614]\n",
      "\n",
      "# 33 Gradient out:  [-0.52450417 -0.4472846  -0.35302764 -0.1487909  -0.55741151 -0.12185798\n",
      " -0.13658597 -0.15549519 -0.61939018 -0.59001584]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [0.29557356 0.25620161 0.05911764 0.2720213  0.28372591 1.00480563\n",
      " 0.48262257 0.13667777 0.34961295 0.66326353]\n",
      "\n",
      "# 34 Gradient out:  [-1.12797218 -0.95928225 -0.75487212 -0.30890836 -1.20033193 -0.24945044\n",
      " -0.28196924 -0.3236984  -1.33708884 -1.27224551]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.19067272  0.16674469 -0.01148789  0.24226312  0.17224361  0.98043403\n",
      "  0.45530538  0.10557873  0.22573491  0.54526036]\n",
      "\n",
      "# 35 Gradient out:  [-0.67753973 -0.59502627 -0.55261507 -0.33680372 -0.73323605 -0.27561075\n",
      " -0.30995499 -0.35086383 -0.87099305 -0.80099443]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [-0.03492171 -0.02511176 -0.16246231  0.18048145 -0.06782277  0.93054394\n",
      "  0.39891153  0.04083905 -0.04168285  0.29081126]\n",
      "\n",
      "# 36 Gradient out:  [2.45969559 2.10997535 1.61771319 0.68515324 2.58759326 0.59147686\n",
      " 0.64246534 0.70898014 2.80647197 2.70409101]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [-0.17042966 -0.14411701 -0.27298533  0.1131207  -0.21446998  0.87542179\n",
      "  0.33692053 -0.02933372 -0.21588146  0.13061237]\n",
      "\n",
      "# 37 Gradient out:  [-0.49499824 -0.42267141 -0.33441635 -0.14310013 -0.5258396  -0.11782485\n",
      " -0.13164952 -0.14938822 -0.58400052 -0.55641917]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [0.32150946 0.27787806 0.05055731 0.25015135 0.30304867 0.99371716\n",
      " 0.4654136  0.11246231 0.34541293 0.67143057]\n",
      "\n",
      "# 38 Gradient out:  [-1.03776727 -0.883413   -0.69604581 -0.28793381 -1.10387584 -0.23366262\n",
      " -0.26334355 -0.30143598 -1.22871689 -1.16953018]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.22250981  0.19334378 -0.01632596  0.22153133  0.19788075  0.97015219\n",
      "  0.43908369  0.08258467  0.22861283  0.56014674]\n",
      "\n",
      "# 39 Gradient out:  [-1.26401236 -1.08702273 -0.91419216 -0.44804396 -1.35458463 -0.36254924\n",
      " -0.409933   -0.46848053 -1.54907047 -1.45351642]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.01495636  0.01666118 -0.15553512  0.16394456 -0.02289442  0.92341967\n",
      "  0.38641498  0.02229747 -0.01713055  0.3262407 ]\n",
      "\n",
      "# 40 Gradient out:  [2.75967127 2.41311235 1.95483079 1.02919035 2.89787991 0.91547071\n",
      " 0.97828051 1.05696447 3.16121828 3.03321345]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [-0.23784611 -0.20074337 -0.33837355  0.07433577 -0.29381134  0.85090982\n",
      "  0.30442838 -0.07139863 -0.32694464  0.03553742]\n",
      "\n",
      "# 41 Gradient out:  [-0.54180601 -0.46155673 -0.36358354 -0.15134725 -0.57599232 -0.12338957\n",
      " -0.13867583 -0.15830901 -0.64033116 -0.60984926]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [0.31408814 0.2818791  0.0525926  0.28017384 0.28576464 1.03400396\n",
      " 0.50008449 0.13999426 0.30529901 0.64218011]\n",
      "\n",
      "# 42 Gradient out:  [-1.1809076  -1.00356573 -0.78893681 -0.32012987 -1.25706426 -0.25750175\n",
      " -0.29175636 -0.33570547 -1.40110097 -1.3327951 ]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.20572694  0.18956776 -0.0201241   0.24990439  0.17056617  1.00932605\n",
      "  0.47234932  0.10833246  0.17723278  0.52021026]\n",
      "\n",
      "# 43 Gradient out:  [-0.2723546  -0.25436839 -0.29871663 -0.25383836 -0.30339589 -0.21061603\n",
      " -0.23526052 -0.26325697 -0.39937087 -0.34849541]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [-0.03045458 -0.01114539 -0.17791146  0.18587842 -0.08084668  0.9578257\n",
      "  0.41399805  0.04119136 -0.10298741  0.25365124]\n",
      "\n",
      "# 44 Gradient out:  [1.37785159 1.15912226 0.81518916 0.23147138 1.44474012 0.19461649\n",
      " 0.21392206 0.24185513 1.53355041 1.49602655]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [-0.0849255  -0.06201907 -0.23765479  0.13511075 -0.14152586  0.91570249\n",
      "  0.36694594 -0.01146003 -0.18286159  0.18395216]\n",
      "\n",
      "# 45 Gradient out:  [-1.48258008 -1.26150141 -0.99593729 -0.4115981  -1.57822166 -0.33242868\n",
      " -0.3757584  -0.43124984 -1.7601951  -1.67375015]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.19064482  0.16980538 -0.07461696  0.18140503  0.14742217  0.95462579\n",
      "  0.40973036  0.036911    0.1238485   0.48315746]\n",
      "\n",
      "# 46 Gradient out:  [2.11121495 1.80106846 1.3499667  0.52287941 2.21930392 0.44878868\n",
      " 0.48879092 0.54215521 2.39351812 2.31376092]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [-0.1058712  -0.0824949  -0.27380442  0.09908541 -0.16822216  0.88814005\n",
      "  0.33457868 -0.04933897 -0.22819052  0.14840744]\n",
      "\n",
      "# 47 Gradient out:  [-0.7124802  -0.60800515 -0.48074014 -0.20441761 -0.75709834 -0.16782189\n",
      " -0.18783852 -0.21352114 -0.84129816 -0.80136767]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.31637179  0.27771879 -0.00381108  0.20366129  0.27563862  0.97789779\n",
      "  0.43233686  0.05909207  0.2505131   0.61115962]\n",
      "\n",
      "# 48 Gradient out:  [-1.65675261 -1.40993622 -1.11589571 -0.46366806 -1.76437303 -0.37398591\n",
      " -0.42310015 -0.48588704 -1.97038742 -1.87235633]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [ 0.17387575  0.15611776 -0.0999591   0.16277776  0.12421895  0.94433341\n",
      "  0.39476916  0.01638784  0.08225347  0.45088609]\n",
      "\n",
      "# 49 Gradient out:  [2.78178383 2.4082358  1.8990851  0.90244516 2.92474141 0.79112361\n",
      " 0.85218061 0.93016609 3.18353595 3.06002352]\n",
      "\n",
      "     Weights  out:  [ 0.23877833  0.11428138 -0.01415766 -0.35657236  0.30553285 -0.43709186\n",
      " -0.39037543 -0.33947689  0.48961613  0.38823943] [-0.15747477 -0.12586948 -0.32313825  0.07004415 -0.22865565  0.86953623\n",
      "  0.31014913 -0.08078957 -0.31182402  0.07641482]\n",
      "\n",
      "Tanh error cuadrático medio (ECM): 1.1060970961533176\n",
      "\n",
      "# 0 Gradient out:  [-0.52782534  0.00836201 -0.82694011 -0.11755636 -0.22858396 -0.64154856\n",
      " -0.84080206 -0.7412073  -0.49865791 -0.28522234]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [ 0.47093287 -0.03555909  0.15278221 -0.07487426 -0.1468693  -0.31184884\n",
      "  0.13670077 -0.48578787  0.49777397  0.33010933]\n",
      "\n",
      "# 1 Gradient out:  [2.92537979 0.91570855 3.7743049  1.16566189 1.44460838 3.35334224\n",
      " 3.80104587 3.60275285 2.77825108 1.63684241]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [ 0.3653678  -0.03388669 -0.01260582 -0.09838554 -0.19258609 -0.44015855\n",
      " -0.03145964 -0.63402933  0.39804239  0.27306486]\n",
      "\n",
      "# 2 Gradient out:  [-14.55442581  -3.80497561 -19.46593214  -5.44928567  -7.12785073\n",
      " -16.83951058 -19.64401259 -18.34231044 -13.81942742  -8.18260748]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [0.95044376 0.14925502 0.74225516 0.13474684 0.09633558 0.2305099\n",
      " 0.72874953 0.08652124 0.9536926  0.60043335]\n",
      "\n",
      "# 3 Gradient out:  [73.90432135 19.98224704 98.18509558 27.93099316 36.17195727 85.37209812\n",
      " 99.04413014 92.74846221 70.16700568 41.4379937 ]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [-1.9604414  -0.6117401  -3.15093126 -0.95511029 -1.32923456 -3.13739222\n",
      " -3.20005299 -3.58194085 -1.81019288 -1.03608815]\n",
      "\n",
      "# 4 Gradient out:  [-373.77078777 -100.48305287 -497.19437947 -141.07745282 -183.02685292\n",
      " -431.8854381  -501.58351511 -469.43546202 -354.88100648 -209.74109595]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [12.82042287  3.38470931 16.48608785  4.63108834  5.90515689 13.93702741\n",
      " 16.60877304 14.96775159 12.22320825  7.25151059]\n",
      "\n",
      "# 5 Gradient out:  [1891.82357329  509.10193662 2515.92887119  714.17949666  926.24219388\n",
      " 2185.86653734 2538.1001004  2375.68775635 1796.19691164 1061.3803474 ]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [-61.93373469 -16.71190127 -82.95278804 -23.58440222 -30.70021369\n",
      " -72.44006021 -83.70792998 -78.91934081 -58.75299304 -34.6967086 ]\n",
      "\n",
      "# 6 Gradient out:  [ -9573.91016221  -2575.94232917 -12732.88213657  -3614.15888371\n",
      "  -4687.59511391 -11062.05671139 -12845.1274     -12022.91096837\n",
      "  -9089.99547488  -5371.55526838]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [316.43097997  85.10848605 420.2329862  119.25149711 154.54822509\n",
      " 364.73324725 423.9120901  396.21821046 300.48638929 177.57936088]\n",
      "\n",
      "# 7 Gradient out:  [48451.93398407 13036.82309846 64438.39629321 18290.67921515\n",
      " 23722.90828234 55983.11079196 65006.40702138 60845.60601073\n",
      " 46002.8995228  27184.24929467]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [-1598.35105247  -430.07997978 -2126.34344112  -603.58027963\n",
      "  -782.9707977  -1847.67809502 -2145.1133899  -2008.36398322\n",
      " -1517.51270569  -896.7316928 ]\n",
      "\n",
      "# 8 Gradient out:  [-245205.56528859  -65976.37693554 -326110.40402792  -92565.47255536\n",
      " -120057.14419526 -283319.42025244 -328985.03614628 -307927.75871243\n",
      " -232811.51780622 -137574.36186324]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [ 8092.03574434  2177.28463991 10761.33581752  3054.5555634\n",
      "  3961.61085877  9348.94406337 10856.16801437 10160.75721893\n",
      "  7683.06719887  4540.11816614]\n",
      "\n",
      "# 9 Gradient out:  [1240937.85372569  333894.01453332 1650381.03318388  468455.89934316\n",
      "  607585.68164358 1433824.62207565 1664928.94636221 1558362.43734707\n",
      " 1178213.95183627  696236.86698404]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [-40949.07731337 -11017.9907472  -54460.74498806 -15458.53894767\n",
      " -20049.81798028 -47314.93998712 -54940.83921488 -51424.79452356\n",
      " -38879.23636237 -22974.75420651]\n",
      "\n",
      "# 10 Gradient out:  [-6280144.59579092 -1689772.19271384 -8352257.24238483 -2370764.03695473\n",
      " -3074872.98398432 -7256306.99478625 -8425881.43806922 -7886568.81775495\n",
      " -5962711.18515503 -3523519.4100706 ]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [207238.49343177  55760.81215947 275615.46164872  78232.64092096\n",
      " 101467.31834843 239449.98442801 278044.95005756 260247.69294585\n",
      " 196763.55400488 116272.6191903 ]\n",
      "\n",
      "# 11 Gradient out:  [31782589.1077275   8551608.39768725 42269147.27344993 11997975.16614861\n",
      " 15561333.22777084 36722756.90072154 42641744.95124805 39912389.06778661\n",
      " 30176120.38604732 17831845.38742821]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [-1048790.42572642  -282193.6263833  -1394835.98682825  -395920.16646999\n",
      "  -513507.27844843 -1211811.41452924 -1407131.33755628 -1317066.07060514\n",
      "  -995778.68302612  -588431.26282382]\n",
      "\n",
      "# 12 Gradient out:  [-1.60845494e+08 -4.32780245e+07 -2.13915924e+08 -6.07194159e+07\n",
      " -7.87528774e+07 -1.85846721e+08 -2.15801568e+08 -2.01988829e+08\n",
      " -1.52715469e+08 -9.02434974e+07]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [5307727.39581908 1428128.05315415 7058993.46786174 2003674.86675973\n",
      " 2598759.36710574 6132739.96561507 7121217.65269333 6665411.74295219\n",
      " 5039445.39418334 2977937.81466182]\n",
      "\n",
      "# 13 Gradient out:  [8.14007725e+08 2.19021655e+08 1.08258683e+09 3.07289140e+08\n",
      " 3.98552977e+08 9.40534068e+08 1.09212971e+09 1.02222613e+09\n",
      " 7.72863250e+08 4.56704767e+08]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [-26861371.45420707  -7227476.8451609  -35724191.23664186\n",
      " -10140208.32204845 -13151816.11523625 -31036604.32937697\n",
      " -36039095.91809023 -33732354.04616927 -25503648.38993805\n",
      " -15070761.65617823]\n",
      "\n",
      "# 14 Gradient out:  [-4.11953459e+09 -1.10842594e+09 -5.47876115e+09 -1.55513050e+09\n",
      " -2.01699901e+09 -4.75985977e+09 -5.52705580e+09 -5.17328739e+09\n",
      " -3.91131041e+09 -2.31129389e+09]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [1.35940174e+08 3.65768541e+07 1.80793175e+08 5.13176197e+07\n",
      " 6.65587793e+07 1.57070209e+08 1.82386846e+08 1.70712872e+08\n",
      " 1.29069002e+08 7.62701917e+07]\n",
      "\n",
      "# 15 Gradient out:  [2.08481624e+10 5.60952786e+09 2.77269433e+10 7.87021264e+09\n",
      " 1.02076392e+10 2.40887234e+10 2.79713531e+10 2.61810001e+10\n",
      " 1.97943803e+10 1.16970083e+10]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [-6.87966744e+08 -1.85108335e+08 -9.14959055e+08 -2.59708480e+08\n",
      " -3.36841022e+08 -7.94901744e+08 -9.23024314e+08 -8.63944606e+08\n",
      " -6.53193080e+08 -3.85988587e+08]\n",
      "\n",
      "# 16 Gradient out:  [-1.05508490e+11 -2.83887282e+10 -1.40320661e+11 -3.98296136e+10\n",
      " -5.16588743e+10 -1.21908338e+11 -1.41557571e+11 -1.32496943e+11\n",
      " -1.00175504e+11 -5.91962813e+10]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [3.48166573e+09 9.36797238e+08 4.63042961e+09 1.31433405e+09\n",
      " 1.70468682e+09 4.02284294e+09 4.67124631e+09 4.37225541e+09\n",
      " 3.30568299e+09 1.95341308e+09]\n",
      "\n",
      "# 17 Gradient out:  [5.33957922e+11 1.43669825e+11 7.10135540e+11 2.01569918e+11\n",
      " 2.61435503e+11 6.16954361e+11 7.16395304e+11 6.70541229e+11\n",
      " 5.06968721e+11 2.99580852e+11]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [-1.76200323e+10 -4.74094840e+09 -2.34337026e+10 -6.65158867e+09\n",
      " -8.62708804e+09 -2.03588247e+10 -2.36402680e+10 -2.21271332e+10\n",
      " -1.67294179e+10 -9.88584319e+09]\n",
      "\n",
      "# 18 Gradient out:  [-2.70225707e+12 -7.27085009e+11 -3.59385769e+12 -1.02010611e+12\n",
      " -1.32307417e+12 -3.12228588e+12 -3.62553713e+12 -3.39347858e+12\n",
      " -2.56566997e+12 -1.51612036e+12]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [8.91715521e+10 2.39930166e+10 1.18593405e+11 3.36623950e+10\n",
      " 4.36600126e+10 1.03032048e+11 1.19638793e+11 1.11981112e+11\n",
      " 8.46643262e+10 5.00303273e+10]\n",
      "\n",
      "# 19 Gradient out:  [1.36755968e+13 3.67963565e+12 1.81878139e+13 5.16255836e+12\n",
      " 6.69582075e+12 1.58012809e+13 1.83481374e+13 1.71737343e+13\n",
      " 1.29843561e+13 7.67278990e+12]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [-4.51279861e+11 -1.21423985e+11 -6.00178132e+11 -1.70358826e+11\n",
      " -2.20954822e+11 -5.21425129e+11 -6.05468633e+11 -5.66714604e+11\n",
      " -4.28469668e+11 -2.53193744e+11]\n",
      "\n",
      "# 20 Gradient out:  [-6.92095324e+13 -1.86219195e+13 -9.20449845e+13 -2.61267025e+13\n",
      " -3.38862449e+13 -7.99672055e+13 -9.28563505e+13 -8.69129251e+13\n",
      " -6.57112979e+13 -3.88304955e+13]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [2.28383950e+12 6.14503144e+11 3.03738465e+12 8.62152845e+11\n",
      " 1.11820933e+12 2.63883104e+12 3.06415885e+12 2.86803226e+12\n",
      " 2.16840156e+12 1.28136423e+12]\n",
      "\n",
      "# 21 Gradient out:  [3.50255966e+14 9.42419082e+13 4.65821743e+14 1.32222154e+14\n",
      " 1.71491687e+14 4.04698455e+14 4.69927908e+14 4.39849389e+14\n",
      " 3.32552083e+14 1.96513577e+14]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [-1.15580670e+13 -3.10988075e+12 -1.53716123e+13 -4.36318766e+12\n",
      " -5.65903966e+12 -1.33546101e+13 -1.55071113e+13 -1.45145528e+13\n",
      " -1.09738580e+13 -6.48473487e+12]\n",
      "\n",
      "# 22 Gradient out:  [-1.77257724e+15 -4.76939946e+14 -2.35743313e+15 -6.69150574e+14\n",
      " -8.67886034e+14 -2.04810007e+15 -2.37821363e+15 -2.22599211e+15\n",
      " -1.68298133e+15 -9.94516944e+14]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [5.84931263e+13 1.57385009e+13 7.77927363e+13 2.20812431e+13\n",
      " 2.86392977e+13 6.75850809e+13 7.84784704e+13 7.34553251e+13\n",
      " 5.55365585e+13 3.28179804e+13]\n",
      "\n",
      "# 23 Gradient out:  [8.97066824e+15 2.41370019e+15 1.19305100e+16 3.38644075e+15\n",
      " 4.39220221e+15 1.03650357e+16 1.20356761e+16 1.12653126e+16\n",
      " 8.51724081e+15 5.03305659e+15]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [-2.96022322e+14 -7.96494883e+13 -3.93693890e+14 -1.11748872e+14\n",
      " -1.44937909e+14 -3.42034934e+14 -3.97164257e+14 -3.71743097e+14\n",
      " -2.81059708e+14 -1.66085408e+14]\n",
      "\n",
      "# 24 Gradient out:  [-4.53988051e+16 -1.22152667e+16 -6.03779880e+16 -1.71381172e+16\n",
      " -2.22280801e+16 -5.24554271e+16 -6.09102130e+16 -5.70115534e+16\n",
      " -4.31040972e+16 -2.54713193e+16]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [1.49811133e+15 4.03090550e+14 1.99240811e+15 5.65539278e+14\n",
      " 7.33502534e+14 1.73097220e+15 2.00997096e+15 1.88131942e+15\n",
      " 1.42238845e+15 8.40525910e+14]\n",
      "\n",
      "# 25 Gradient out:  [2.29754512e+17 6.18190859e+16 3.05561240e+17 8.67326738e+16\n",
      " 1.12491985e+17 2.65466702e+17 3.08254727e+17 2.88524370e+17\n",
      " 2.18141442e+17 1.28905387e+17]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [-7.58164970e+15 -2.03996278e+15 -1.00831895e+16 -2.86208416e+15\n",
      " -3.71211349e+15 -8.76011321e+15 -1.01720716e+16 -9.52099125e+15\n",
      " -7.19843098e+15 -4.25373796e+15]\n",
      "\n",
      "# 26 Gradient out:  [-1.16274285e+18 -3.12854356e+17 -1.54638593e+18 -4.38937173e+17\n",
      " -5.69300031e+17 -1.34347528e+18 -1.56001715e+18 -1.46016565e+18\n",
      " -1.10397136e+18 -6.52365063e+17]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [3.83692528e+16 1.03238544e+16 5.10290585e+16 1.44844506e+16\n",
      " 1.87862835e+16 4.43332271e+16 5.14788738e+16 4.81838827e+16\n",
      " 3.64298574e+16 2.15273395e+16]\n",
      "\n",
      "# 27 Gradient out:  [5.88441513e+18 1.58329497e+18 7.82595808e+18 2.22137556e+18\n",
      " 2.88111660e+18 6.79906680e+18 7.89494301e+18 7.38961403e+18\n",
      " 5.58698408e+18 3.30149255e+18]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [-1.94179317e+17 -5.22470167e+16 -2.58248128e+17 -7.33029840e+16\n",
      " -9.50737226e+16 -2.24361830e+17 -2.60524556e+17 -2.43849248e+17\n",
      " -1.84364415e+17 -1.08945673e+17]\n",
      "\n",
      "# 28 Gradient out:  [-2.97798791e+19 -8.01274754e+18 -3.96056499e+19 -1.12419491e+19\n",
      " -1.45807701e+19 -3.44087531e+19 -3.99547692e+19 -3.73973976e+19\n",
      " -2.82746385e+19 -1.67082109e+19]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [9.82703709e+17 2.64411978e+17 1.30694349e+18 3.70972128e+17\n",
      " 4.81149597e+17 1.13545153e+18 1.31846405e+18 1.23407356e+18\n",
      " 9.33032401e+17 5.51352837e+17]\n",
      "\n",
      "# 29 Gradient out:  [1.50710169e+20 4.05509550e+19 2.00436482e+20 5.68933154e+19\n",
      " 7.37904380e+19 1.74135999e+20 2.02203306e+20 1.89260947e+20\n",
      " 1.43092439e+20 8.45570017e+19]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [-4.97327211e+18 -1.33813753e+18 -6.61418650e+18 -1.87741770e+18\n",
      " -2.43500441e+18 -5.74629909e+18 -6.67248979e+18 -6.24540597e+18\n",
      " -4.72189529e+18 -2.79028934e+18]\n",
      "\n",
      "# 30 Gradient out:  [-7.62714818e+20 -2.05220487e+20 -1.01437000e+21 -2.87925991e+20\n",
      " -3.73439037e+20 -8.81268381e+20 -1.02331156e+21 -9.57812798e+20\n",
      " -7.24162972e+20 -4.27926520e+20]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [2.51687617e+19 6.77205347e+18 3.34731099e+19 9.50124539e+18\n",
      " 1.23230832e+19 2.90809007e+19 3.37681715e+19 3.16067834e+19\n",
      " 2.38965926e+19 1.41211110e+19]\n",
      "\n",
      "# 31 Gradient out:  [3.85995117e+21 1.03858092e+21 5.13352906e+21 1.45713737e+21\n",
      " 1.88990225e+21 4.45992767e+21 5.17878053e+21 4.84730406e+21\n",
      " 3.66484778e+21 2.16565279e+21]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [-1.27374202e+20 -3.42720439e+19 -1.69400891e+20 -4.80839527e+19\n",
      " -6.23647243e+19 -1.47172776e+20 -1.70894140e+20 -1.59955776e+20\n",
      " -1.20936002e+20 -7.14641930e+19]\n",
      "\n",
      "# 32 Gradient out:  [-1.95344612e+22 -5.25605580e+21 -2.59797909e+22 -7.37428849e+21\n",
      " -9.56442726e+21 -2.25708255e+22 -2.62087998e+22 -2.45312619e+22\n",
      " -1.85470810e+22 -1.09599470e+22]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [6.44616032e+20 1.73444140e+20 8.57304922e+20 2.43343522e+20\n",
      " 3.15615725e+20 7.44812758e+20 8.64861966e+20 8.09505035e+20\n",
      " 6.12033555e+20 3.61666365e+20]\n",
      "\n",
      "# 33 Gradient out:  [9.88601044e+22 2.65998749e+22 1.31478663e+23 3.73198381e+22\n",
      " 4.84037039e+22 1.14226552e+23 1.32637632e+23 1.24147940e+23\n",
      " 9.38631652e+22 5.54661578e+22]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [-3.26227621e+21 -8.77767019e+20 -4.33865327e+21 -1.23151418e+21\n",
      " -1.59726973e+21 -3.76935233e+21 -4.37689800e+21 -4.09674735e+21\n",
      " -3.09738264e+21 -1.83032304e+21]\n",
      "\n",
      "# 34 Gradient out:  [-5.00311737e+23 -1.34616787e+23 -6.65387910e+23 -1.88868433e+23\n",
      " -2.44961720e+23 -5.78078339e+23 -6.71253228e+23 -6.28288547e+23\n",
      " -4.75023201e+23 -2.80703424e+23]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [1.65097447e+22 4.44220796e+21 2.19570793e+22 6.23245344e+21\n",
      " 8.08347105e+21 1.90759582e+22 2.21506285e+22 2.07328406e+22\n",
      " 1.56752504e+22 9.26290851e+21]\n",
      "\n",
      "# 35 Gradient out:  [2.53198028e+24 6.81269346e+23 3.36739864e+24 9.55826362e+23\n",
      " 1.23970356e+24 2.92554190e+24 3.39708188e+24 3.17964599e+24\n",
      " 2.40399992e+24 1.42058537e+24]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [-8.35526028e+22 -2.24811495e+22 -1.11120503e+23 -3.15412332e+22\n",
      " -4.09088729e+22 -9.65397096e+22 -1.12100017e+23 -1.04924869e+23\n",
      " -7.93293898e+22 -4.68777762e+22]\n",
      "\n",
      "# 36 Gradient out:  [-1.28138591e+25 -3.44777149e+24 -1.70417488e+25 -4.83725109e+24\n",
      " -6.27389833e+24 -1.48055979e+25 -1.71919699e+25 -1.60915692e+25\n",
      " -1.21661755e+25 -7.18930591e+24]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [4.22843453e+23 1.13772720e+23 5.62359226e+23 1.59624039e+23\n",
      " 2.07031840e+23 4.88568671e+23 5.67316358e+23 5.31004330e+23\n",
      " 4.01470594e+23 2.37239297e+23]\n",
      "\n",
      "# 37 Gradient out:  [6.48484459e+25 1.74485002e+25 8.62449722e+25 2.44803858e+25\n",
      " 3.17509777e+25 7.49282478e+25 8.70052117e+25 8.14362982e+25\n",
      " 6.15706449e+25 3.63836772e+25]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [-2.13992837e+24 -5.75781579e+23 -2.84599054e+24 -8.07826179e+23\n",
      " -1.04774783e+24 -2.47255091e+24 -2.87107762e+24 -2.68730951e+24\n",
      " -2.03176450e+24 -1.20062188e+24]\n",
      "\n",
      "# 38 Gradient out:  [-3.28185357e+26 -8.83034616e+25 -4.36469010e+26 -1.23890466e+26\n",
      " -1.60685515e+26 -3.79197272e+26 -4.40316434e+26 -4.12133247e+26\n",
      " -3.11597044e+26 -1.84130706e+26]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [1.08297608e+25 2.91391845e+24 1.44030039e+25 4.08825098e+24\n",
      " 5.30244772e+24 1.25130987e+25 1.45299647e+25 1.35999501e+25\n",
      " 1.02823645e+25 6.07611356e+24]\n",
      "\n",
      "# 39 Gradient out:  [1.66088218e+27 4.46886624e+26 2.20888467e+27 6.26985521e+26\n",
      " 8.13198103e+26 1.91904355e+27 2.22835573e+27 2.08572611e+27\n",
      " 1.57693197e+27 9.31849645e+26]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [-5.48073105e+25 -1.47467739e+25 -7.28907981e+25 -2.06898421e+25\n",
      " -2.68346554e+25 -6.33263557e+25 -7.35333221e+25 -6.88266993e+25\n",
      " -5.20370444e+25 -3.07500275e+25]\n",
      "\n",
      "# 40 Gradient out:  [-8.40540130e+27 -2.26160618e+27 -1.11787352e+28 -3.17305163e+27\n",
      " -4.11543725e+27 -9.71190572e+27 -1.12772744e+28 -1.05554537e+28\n",
      " -7.98054560e+27 -4.71590960e+27]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [2.77369126e+26 7.46305509e+25 3.68886135e+26 1.04707262e+26\n",
      " 1.35804965e+26 3.20482354e+26 3.72137824e+26 3.48318523e+26\n",
      " 2.63349349e+26 1.55619902e+26]\n",
      "\n",
      "# 41 Gradient out:  [4.25380992e+28 1.14455485e+28 5.65734018e+28 1.60581964e+28\n",
      " 2.08274265e+28 4.91500636e+28 5.70720899e+28 5.34190957e+28\n",
      " 4.03879872e+28 2.38663001e+28]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [-1.40371113e+27 -3.77690685e+26 -1.86686090e+27 -5.29903064e+26\n",
      " -6.87282484e+26 -1.62189879e+27 -1.88331706e+27 -1.76277222e+27\n",
      " -1.33275977e+27 -7.87562018e+26]\n",
      "\n",
      "# 42 Gradient out:  [-2.15277037e+29 -5.79236921e+28 -2.86306970e+29 -8.12674051e+28\n",
      " -1.05403550e+29 -2.48738901e+29 -2.88830733e+29 -2.70343641e+29\n",
      " -2.04395739e+29 -1.20782698e+29]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [7.10390871e+27 1.91141901e+27 9.44781947e+27 2.68173622e+27\n",
      " 3.47820282e+27 8.20811394e+27 9.53110091e+27 8.92104692e+27\n",
      " 6.74483768e+27 3.98569801e+27]\n",
      "\n",
      "# 43 Gradient out:  [1.08947516e+30 2.93140526e+29 1.44894382e+30 4.11278512e+29\n",
      " 5.33426841e+29 1.25881914e+30 1.46171610e+30 1.36815652e+30\n",
      " 1.03440703e+30 6.11257713e+29]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [-3.59514986e+28 -9.67331940e+27 -4.78135746e+28 -1.35717448e+28\n",
      " -1.76025072e+28 -4.15396663e+28 -4.82350457e+28 -4.51476813e+28\n",
      " -3.41343101e+28 -2.01708415e+28]\n",
      "\n",
      "# 44 Gradient out:  [-5.51362165e+30 -1.48352712e+30 -7.33282254e+30 -2.08140046e+30\n",
      " -2.69956937e+30 -6.37063855e+30 -7.39746053e+30 -6.92397374e+30\n",
      " -5.23493256e+30 -3.09345625e+30]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [1.81943534e+29 4.89547858e+28 2.41975190e+29 6.86839576e+28\n",
      " 8.90828610e+28 2.10224162e+29 2.44108174e+29 2.28483623e+29\n",
      " 1.72747096e+29 1.02080701e+29]\n",
      "\n",
      "# 45 Gradient out:  [2.79033655e+31 7.50784187e+30 3.71099870e+31 1.05335624e+31\n",
      " 1.36619949e+31 3.22405612e+31 3.74371072e+31 3.50408828e+31\n",
      " 2.64929743e+31 1.56553797e+31]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [-9.20780795e+29 -2.47750638e+29 -1.22458932e+30 -3.47596135e+29\n",
      " -4.50831013e+29 -1.06390355e+30 -1.23538393e+30 -1.15631113e+30\n",
      " -8.74239416e+29 -5.16610550e+29]\n",
      "\n",
      "# 46 Gradient out:  [-1.41213499e+32 -3.79957257e+31 -1.87806418e+32 -5.33083083e+31\n",
      " -6.91406957e+31 -1.63163202e+32 -1.89461910e+32 -1.77335084e+32\n",
      " -1.34075784e+32 -7.92288282e+31]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [4.65989230e+30 1.25381774e+30 6.19740807e+30 1.75911635e+30\n",
      " 2.28156796e+30 5.38420868e+30 6.25203752e+30 5.85186544e+30\n",
      " 4.42435544e+30 2.61446539e+30]\n",
      "\n",
      "# 47 Gradient out:  [7.14654021e+32 1.92288969e+32 9.50451708e+32 2.69782967e+32\n",
      " 3.49907597e+32 8.25737192e+32 9.58829831e+32 8.97458330e+32\n",
      " 6.78531434e+32 4.00961671e+32]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [-2.35828075e+31 -6.34532741e+30 -3.13638755e+31 -8.90254530e+30\n",
      " -1.15465712e+31 -2.72484317e+31 -3.16403444e+31 -2.96151515e+31\n",
      " -2.23908013e+31 -1.32313002e+31]\n",
      "\n",
      "# 48 Gradient out:  [-3.61672483e+33 -9.73137027e+32 -4.81005102e+33 -1.36531906e+33\n",
      " -1.77081421e+33 -4.17889513e+33 -4.85245106e+33 -4.54186185e+33\n",
      " -3.43391546e+33 -2.02918894e+33]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [1.19347997e+32 3.21124664e+31 1.58726466e+32 4.50540482e+31\n",
      " 5.84349483e+31 1.37899007e+32 1.60125622e+32 1.49876515e+32\n",
      " 1.13315485e+32 6.69610340e+31]\n",
      "\n",
      "# 49 Gradient out:  [1.83035401e+34 4.92485700e+33 2.43427315e+34 6.90961391e+33\n",
      " 8.96174591e+33 2.11485745e+34 2.45573099e+34 2.29854784e+34\n",
      " 1.73783775e+34 1.02693301e+34]\n",
      "\n",
      "     Weights  out:  [ 0.10662582 -0.4910687   0.41769912 -0.32108801 -0.21193698  0.2177655\n",
      "  0.43785041  0.31558412  0.0755818  -0.15777318] [-6.03996970e+32 -1.62514939e+32 -8.03283737e+32 -2.28009765e+32\n",
      " -2.95727894e+32 -6.97880020e+32 -8.10364591e+32 -7.58495855e+32\n",
      " -5.73467606e+32 -3.38876754e+32]\n",
      "\n",
      "Lineal error cuadrático medio (ECM): 2.879198076332471e+68\n",
      "\n",
      "# 0 Gradient out:  [-1.49960187 -1.59456349 -1.59711129 -1.03762764 -1.45970981 -0.28786519\n",
      " -0.62512107 -1.68517165 -1.24909846 -1.73380717]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.4083481   0.1848175  -0.36093654 -0.40174218 -0.38420029 -0.00709531\n",
      "  0.346839    0.29371282  0.35160146  0.32680422]\n",
      "\n",
      "# 1 Gradient out:  [1.79666376 1.8683151  1.87021535 1.39671891 1.76578652 0.76388255\n",
      " 1.02304432 1.93605899 1.5910981  1.97341766]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.10842772 -0.1340952  -0.6803588  -0.60926771 -0.67614225 -0.06466835\n",
      "  0.22181479 -0.04332151  0.10178177 -0.01995722]\n",
      "\n",
      "# 2 Gradient out:  [-1.69316203 -1.78665954 -1.78915013 -1.21285011 -1.65341263 -0.44263318\n",
      " -0.77640819 -1.87490127 -1.43785699 -1.92221935]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.46776047  0.23956782 -0.30631573 -0.32992393 -0.32298495  0.08810816\n",
      "  0.42642365  0.34389029  0.42000139  0.37472632]\n",
      "\n",
      "# 3 Gradient out:  [2.14198324 2.22833639 2.23062102 1.65525824 2.1046553  0.88703369\n",
      " 1.19950455 2.30959508 1.89248569 2.35423816]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 1.29128067e-01 -1.17764087e-01 -6.64145754e-01 -5.72493948e-01\n",
      " -6.53667476e-01 -4.18478515e-04  2.71142013e-01 -3.10899671e-02\n",
      "  1.32429991e-01 -9.71755488e-03]\n",
      "\n",
      "# 4 Gradient out:  [-0.92759957 -0.97442694 -0.97567408 -0.68449299 -0.90766393 -0.29525754\n",
      " -0.46272563 -1.01866923 -0.79897222 -1.04250276]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.55752472  0.32790319 -0.21802155 -0.2414423  -0.23273642  0.17698826\n",
      "  0.51104292  0.43082905  0.51092713  0.46113008]\n",
      "\n",
      "# 5 Gradient out:  [-0.89071113 -0.95732679 -0.9591611  -0.61804458 -0.86381717 -0.15478984\n",
      " -0.38882174 -1.02386223 -0.73320553 -1.06048942]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.3720048   0.1330178  -0.41315636 -0.3783409  -0.4142692   0.11793675\n",
      "  0.4184978   0.2270952   0.35113269  0.25262953]\n",
      "\n",
      "# 6 Gradient out:  [2.95740316 3.08057919 3.083796   2.2264869  2.90327275 1.08751516\n",
      " 1.53432436 3.19356515 2.58795035 3.25437757]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.19386258 -0.05844756 -0.60498858 -0.50194982 -0.58703263  0.08697878\n",
      "  0.34073345  0.02232276  0.20449158  0.04053164]\n",
      "\n",
      "# 7 Gradient out:  [-0.0890136  -0.09264546 -0.09274277 -0.07049247 -0.08747808 -0.04066104\n",
      " -0.05365601 -0.09612215 -0.07917518 -0.09802139]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.78534321  0.55766828  0.01177061 -0.05665244 -0.00637808  0.30448182\n",
      "  0.64759832  0.66103579  0.72208165  0.69140716]\n",
      "\n",
      "# 8 Gradient out:  [-0.10831353 -0.1128205  -0.1129412  -0.08529106 -0.1064069  -0.04822892\n",
      " -0.06435499 -0.11713042 -0.09608914 -0.11948241]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.76754049  0.53913919 -0.00677794 -0.07075093 -0.0238737   0.29634961\n",
      "  0.63686712  0.64181136  0.70624661  0.67180288]\n",
      "\n",
      "# 9 Gradient out:  [-0.13745752 -0.14331185 -0.14346853 -0.10749103 -0.1349791  -0.05928121\n",
      " -0.08022801 -0.14890302 -0.12155414 -0.15195032]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.74587778  0.51657509 -0.02936618 -0.08780914 -0.04515508  0.28670382\n",
      "  0.62399612  0.61838527  0.68702879  0.6479064 ]\n",
      "\n",
      "# 10 Gradient out:  [-0.18573829 -0.1938782  -0.19409588 -0.14396365 -0.18228904 -0.07681212\n",
      " -0.10593633 -0.20163932 -0.16358252 -0.20586226]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.71838628  0.48791272 -0.05805988 -0.10930735 -0.0721509   0.27484758\n",
      "  0.60795052  0.58860467  0.66271796  0.61751633]\n",
      "\n",
      "# 11 Gradient out:  [-0.27778294 -0.29041533 -0.2907528  -0.21272565 -0.27242322 -0.10826374\n",
      " -0.15346039 -0.30243232 -0.24330803 -0.30895577]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.68123862  0.44913708 -0.09687906 -0.13810008 -0.10860871  0.25948516\n",
      "  0.58676325  0.5482768   0.63000145  0.57634388]\n",
      "\n",
      "# 12 Gradient out:  [-0.49835034 -0.52222529 -0.52286208 -0.37479728 -0.48820191 -0.17672353\n",
      " -0.26213532 -0.54485895 -0.43294953 -0.55710123]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.62568203  0.39105402 -0.15502962 -0.18064521 -0.16309335  0.23783241\n",
      "  0.55607118  0.48779034  0.58133985  0.51455273]\n",
      "\n",
      "# 13 Gradient out:  [-1.24093068 -1.30577786 -1.30750416 -0.90451639 -1.21331619 -0.36596844\n",
      " -0.59778925 -1.36696899 -1.06282405 -1.39986684]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.52601197  0.28660896 -0.25960204 -0.25560466 -0.26073374  0.2024877\n",
      "  0.50364411  0.37881855  0.49474994  0.40313248]\n",
      "\n",
      "# 14 Gradient out:  [2.39025    2.48445006 2.48682441 1.74509817 2.34693789 0.77018635\n",
      " 1.11558629 2.56522412 2.07669129 2.6066579 ]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.27782583  0.02545339 -0.52110287 -0.43650794 -0.50339697  0.12929401\n",
      "  0.38408626  0.10542475  0.28218513  0.12315912]\n",
      "\n",
      "# 15 Gradient out:  [-0.13245814 -0.13805903 -0.13820897 -0.10380965 -0.1300876  -0.05770996\n",
      " -0.07774994 -0.14341051 -0.11725144 -0.1463284 ]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.75587583  0.5223434  -0.02373799 -0.08748831 -0.0340094   0.28333128\n",
      "  0.60720352  0.61846958  0.69752339  0.6444907 ]\n",
      "\n",
      "# 16 Gradient out:  [-0.17702612 -0.18472381 -0.18492972 -0.13755287 -0.17376519 -0.07408494\n",
      " -0.10162687 -0.19206691 -0.15608668 -0.19606433]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.7293842   0.49473159 -0.05137978 -0.10825024 -0.06002692  0.27178929\n",
      "  0.59165353  0.58978747  0.6740731   0.61522502]\n",
      "\n",
      "# 17 Gradient out:  [-0.25990894 -0.27162363 -0.27193667 -0.19963421 -0.25494024 -0.10282336\n",
      " -0.14473676 -0.28277424 -0.22796102 -0.28883095]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.69397898  0.45778683 -0.08836572 -0.13576081 -0.09477996  0.2569723\n",
      "  0.57132816  0.55137409  0.64285577  0.57601215]\n",
      "\n",
      "# 18 Gradient out:  [-0.45046033 -0.47180136 -0.47237077 -0.34013979 -0.44139273 -0.16321701\n",
      " -0.23956553 -0.49204851 -0.39204964 -0.50300884]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.64199719  0.40346211 -0.14275306 -0.17568765 -0.145768    0.23640763\n",
      "  0.54238081  0.49481925  0.59726356  0.51824596]\n",
      "\n",
      "# 19 Gradient out:  [-1.06303177 -1.11760267 -1.11905563 -0.77968283 -1.03979384 -0.32609822\n",
      " -0.52123119 -1.16912409 -0.91309347 -1.1968513 ]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.55190513  0.30910183 -0.23722721 -0.24371561 -0.23404655  0.20376423\n",
      "  0.4944677   0.39640954  0.51885363  0.41764419]\n",
      "\n",
      "# 20 Gradient out:  [0.55101415 0.55385666 0.5538215  0.4091535  0.54717545 0.22952439\n",
      " 0.24647948 0.54970503 0.49850538 0.54564885]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.33929877  0.0855813  -0.46103834 -0.39965218 -0.44200532  0.13854459\n",
      "  0.39022146  0.16258472  0.33623494  0.17827393]\n",
      "\n",
      "# 21 Gradient out:  [-1.78246772 -1.88460078 -1.88733237 -1.27038181 -1.73930677 -0.4444777\n",
      " -0.80841517 -1.98167192 -1.50800396 -2.03391282]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.4495016   0.19635263 -0.35027404 -0.31782148 -0.33257023  0.18444947\n",
      "  0.43951736  0.27252573  0.43593601  0.2874037 ]\n",
      "\n",
      "# 22 Gradient out:  [1.51385801 1.57181619 1.57336758 1.20147543 1.48916958 0.70241494\n",
      " 0.91184883 1.62764607 1.35179867 1.65893183]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.09300806 -0.18056753 -0.72774051 -0.57189784 -0.68043158  0.09555393\n",
      "  0.27783433 -0.12380865  0.13433522 -0.11937886]\n",
      "\n",
      "# 23 Gradient out:  [-1.2294149  -1.30985395 -1.31205184 -0.87726834 -1.19650345 -0.28925347\n",
      " -0.57332295 -1.3892403  -1.03136801 -1.43284809]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.39577966  0.13379571 -0.413067   -0.33160275 -0.38259767  0.23603691\n",
      "  0.46020409  0.20172056  0.40469496  0.2124075 ]\n",
      "\n",
      "# 24 Gradient out:  [2.30477445 2.39746392 2.39992213 1.78662277 2.26482367 0.96689746\n",
      " 1.30225664 2.4851231  2.03862329 2.53350758]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.14989668 -0.12817508 -0.67547736 -0.50705642 -0.62189836  0.17818622\n",
      "  0.3455395  -0.0761275   0.19842135 -0.07416211]\n",
      "\n",
      "# 25 Gradient out:  [-0.6124059  -0.64301131 -0.64382666 -0.45344754 -0.59937882 -0.19891124\n",
      " -0.30839546 -0.67195272 -0.52833391 -0.68756651]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.61085157  0.35131771 -0.19549294 -0.14973186 -0.16893362  0.37156571\n",
      "  0.60599083  0.42089712  0.60614601  0.4325394 ]\n",
      "\n",
      "# 26 Gradient out:  [-1.63965282 -1.72916849 -1.7315555  -1.18078284 -1.60163688 -0.44428429\n",
      " -0.76393836 -1.81386206 -1.39567315 -1.85942248]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.48837039  0.22271545 -0.32425827 -0.24042137 -0.28880938  0.33178346\n",
      "  0.54431174  0.28650658  0.50047923  0.2950261 ]\n",
      "\n",
      "# 27 Gradient out:  [2.47528582 2.57579329 2.57845525 1.91023266 2.43188908 1.01758626\n",
      " 1.38133455 2.6705988  2.18550708 2.72282479]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.16043983 -0.12311825 -0.67056937 -0.47657794 -0.60913676  0.24292661\n",
      "  0.39152407 -0.07626584  0.2213446  -0.0768584 ]\n",
      "\n",
      "# 28 Gradient out:  [-0.37418519 -0.39245823 -0.39294538 -0.27942817 -0.36641316 -0.12760179\n",
      " -0.19297931 -0.40976574 -0.3240571  -0.41912091]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.65549699  0.39204041 -0.15487832 -0.09453141 -0.12275894  0.44644386\n",
      "  0.66779098  0.45785393  0.65844602  0.46770656]\n",
      "\n",
      "# 29 Gradient out:  [-0.80445826 -0.84581464 -0.84691565 -0.58934898 -0.78684235 -0.24510292\n",
      " -0.39302438 -0.88486109 -0.69070966 -0.90588765]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.58065996  0.31354876 -0.2334674  -0.15041704 -0.19604157  0.4209235\n",
      "  0.62919511  0.37590078  0.5936346   0.38388238]\n",
      "\n",
      "# 30 Gradient out:  [-1.66335464 -1.76155013 -1.76420458 -1.19892872 -1.62248275 -0.43844241\n",
      " -0.7871943  -1.8567453  -1.40954163 -1.90867674]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.4197683   0.14438583 -0.40285053 -0.26828684 -0.35341004  0.37190292\n",
      "  0.55059024  0.19892856  0.45549267  0.20270485]\n",
      "\n",
      "# 31 Gradient out:  [1.55406385 1.61219996 1.61376598 1.24821597 1.52949653 0.75622192\n",
      " 0.96618548 1.66891959 1.39436521 1.70105107]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.08709738 -0.20792419 -0.75569144 -0.50807258 -0.67790659  0.28421443\n",
      "  0.39315138 -0.1724205   0.17358434 -0.1790305 ]\n",
      "\n",
      "# 32 Gradient out:  [-1.38415525 -1.46959298 -1.47193406 -1.01209531 -1.34930066 -0.38908094\n",
      " -0.69111924 -1.55448045 -1.1748192  -1.6015069 ]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.39791015  0.1145158  -0.43293825 -0.25842939 -0.37200729  0.43545882\n",
      "  0.58638848  0.16136342  0.45245738  0.16117971]\n",
      "\n",
      "# 33 Gradient out:  [2.00026187 2.07805493 2.08013993 1.5826221  1.96717412 0.91456873\n",
      " 1.19569691 2.15319838 1.78340397 2.19542241]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.1210791  -0.1794028  -0.72732506 -0.46084845 -0.64186742  0.35764263\n",
      "  0.44816463 -0.14953267  0.21749354 -0.15912166]\n",
      "\n",
      "# 34 Gradient out:  [-1.29509703 -1.364885   -1.3667436  -0.93403382 -1.26539711 -0.35567498\n",
      " -0.60510852 -1.43078657 -1.1037531  -1.4662333 ]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.52113147  0.23620819 -0.31129707 -0.14432403 -0.24843259  0.54055638\n",
      "  0.68730401  0.281107    0.57417434  0.27996282]\n",
      "\n",
      "# 35 Gradient out:  [2.48946466 2.59644677 2.59916585 1.78402497 2.44082303 0.71049438\n",
      " 1.10121381 2.68953675 2.14285366 2.7376306 ]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.26211206 -0.03676881 -0.58464579 -0.33113079 -0.50151202  0.46942138\n",
      "  0.56628231 -0.00505031  0.35342372 -0.01328384]\n",
      "\n",
      "# 36 Gradient out:  [-0.11834684 -0.12386292 -0.12401021 -0.08988452 -0.11600513 -0.04420596\n",
      " -0.06394351 -0.12910607 -0.10327272 -0.13195068]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.760005    0.48252054 -0.06481262  0.0256742  -0.01334741  0.61152026\n",
      "  0.78652507  0.53285704  0.78199445  0.53424228]\n",
      "\n",
      "# 37 Gradient out:  [-0.15461586 -0.16195225 -0.16214804 -0.11668633 -0.1514992  -0.05585124\n",
      " -0.08210207 -0.16891696 -0.13453752 -0.17269091]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.73633563  0.45774796 -0.08961467  0.0076973  -0.03654844  0.60267906\n",
      "  0.77373637  0.50703583  0.7613399   0.50785214]\n",
      "\n",
      "# 38 Gradient out:  [-0.21876105 -0.22937221 -0.22965519 -0.16376599 -0.21424918 -0.07562742\n",
      " -0.11359535 -0.23942967 -0.1896662  -0.2448707 ]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.70541246  0.42535751 -0.12204428 -0.01563997 -0.06684828  0.59150881\n",
      "  0.75731595  0.47325244  0.7344324   0.47331396]\n",
      "\n",
      "# 39 Gradient out:  [-0.35461279 -0.37231574 -0.37278737 -0.26258444 -0.34707684 -0.11523857\n",
      " -0.17857839 -0.38905918 -0.30595932 -0.39809717]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.66166025  0.37948307 -0.16797531 -0.04839317 -0.10969811  0.57638333\n",
      "  0.73459688  0.4253665   0.69649916  0.42433982]\n",
      "\n",
      "# 40 Gradient out:  [-0.74295831 -0.78162001 -0.78264889 -0.54155536 -0.72648219 -0.21938088\n",
      " -0.35767208 -0.81809493 -0.63650323 -0.83772467]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.59073769  0.30501992 -0.24253279 -0.10091006 -0.17911348  0.55333562\n",
      "  0.6988812   0.34755467  0.63530729  0.34472039]\n",
      "\n",
      "# 41 Gradient out:  [-1.78906537 -1.89134131 -1.89409483 -1.29173535 -1.74622151 -0.48283588\n",
      " -0.84686288 -1.98982067 -1.51996125 -2.04340353]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.44214603  0.14869592 -0.39906256 -0.20922113 -0.32440992  0.50945944\n",
      "  0.62734679  0.18393568  0.50800665  0.17717545]\n",
      "\n",
      "# 42 Gradient out:  [1.53802441 1.59459114 1.59612193 1.24577833 1.51426075 0.77319912\n",
      " 0.97741391 1.65029206 1.38467574 1.68209094]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.08433295 -0.22957235 -0.77788153 -0.4675682  -0.67365422  0.41289226\n",
      "  0.45797421 -0.21402845  0.2040144  -0.23150525]\n",
      "\n",
      "# 43 Gradient out:  [-1.2219107  -1.29873927 -1.30087254 -0.91394515 -1.19117989 -0.38548396\n",
      " -0.65608614 -1.37696579 -1.04335131 -1.42102756]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.39193783  0.08934588 -0.45865714 -0.21841253 -0.37080207  0.56753209\n",
      "  0.65345699  0.11602996  0.48094955  0.10491293]\n",
      "\n",
      "# 44 Gradient out:  [2.28968785 2.38139579 2.38384772 1.79228449 2.25055673 0.99881456\n",
      " 1.33036117 2.46955626 2.03215253 2.51890967]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.14755569 -0.17040197 -0.71883165 -0.40120156 -0.60903805  0.49043529\n",
      "  0.52223976 -0.1593632   0.27227928 -0.17929258]\n",
      "\n",
      "# 45 Gradient out:  [-0.61748102 -0.64988147 -0.65074333 -0.44834129 -0.60366479 -0.17792295\n",
      " -0.29383102 -0.68042302 -0.52813565 -0.69684934]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.60549326  0.30587719 -0.24206211 -0.04274466 -0.1589267   0.69019821\n",
      "  0.788312    0.33454805  0.67870979  0.32448936]\n",
      "\n",
      "# 46 Gradient out:  [-1.66008427 -1.75235032 -1.75481708 -1.19289825 -1.62103639 -0.4406218\n",
      " -0.76991715 -1.84009064 -1.41072606 -1.88748775]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.48199706  0.17590089 -0.37221077 -0.13241292 -0.27965966  0.65461362\n",
      "  0.7295458   0.19846345  0.57308266  0.18511949]\n",
      "\n",
      "# 47 Gradient out:  [2.34272352 2.43758654 2.44012331 1.82845657 2.30225463 1.00794594\n",
      " 1.35090894 2.52881882 2.07643319 2.57991521]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.1499802  -0.17456917 -0.72317419 -0.37099257 -0.60386694  0.56648926\n",
      "  0.57556236 -0.16955468  0.29093745 -0.19237806]\n",
      "\n",
      "# 48 Gradient out:  [-0.51754577 -0.54476484 -0.54548869 -0.37526849 -0.50593484 -0.14787048\n",
      " -0.24525124 -0.5704103  -0.44242116 -0.58419926]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.61852491  0.31294814 -0.23514953 -0.00530126 -0.14341601  0.76807844\n",
      "  0.84574415  0.33620908  0.70622409  0.32360498]\n",
      "\n",
      "# 49 Gradient out:  [-1.34182726 -1.4154964  -1.41745953 -0.96204734 -1.31050307 -0.35320148\n",
      " -0.61643819 -1.48513619 -1.14031544 -1.52261684]\n",
      "\n",
      "     Weights  out:  [ 0.24431105  0.3023572   0.30403914  0.01906428  0.22203706 -0.38257428\n",
      " -0.17284649  0.36795917  0.11616814  0.40993548] [ 0.51501575  0.20399517 -0.34424727 -0.08035496 -0.24460298  0.73850435\n",
      "  0.79669391  0.22212702  0.61773986  0.20676513]\n",
      "\n",
      "Tanh error cuadrático medio (ECM): 0.7430927996162502\n",
      "\n",
      "# 0 Gradient out:  [1.1996729  0.81580809 1.36466601 1.21561844 1.23095262 1.38814072\n",
      " 1.39530367 1.07411036 1.00541471 0.52572526]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [-0.17928613 -0.38460908 -0.15828268  0.14325779  0.11018731 -0.44160193\n",
      "  0.01708465  0.36980252  0.41576076  0.32633523]\n",
      "\n",
      "# 1 Gradient out:  [-7.18872831 -5.05873002 -8.53962996 -7.29353382 -7.39742141 -8.82461715\n",
      " -8.91970788 -6.44060986 -6.06517508 -3.22963317]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [ 0.06064845 -0.22144747  0.11465052  0.38638148  0.35637784 -0.16397379\n",
      "  0.29614538  0.58462459  0.6168437   0.43148028]\n",
      "\n",
      "# 2 Gradient out:  [44.52401182 31.15055391 52.52141908 45.16388549 45.79524314 54.13853806\n",
      " 54.67396948 39.88402237 37.5204178  19.91048965]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [-1.37709721 -1.23319347 -1.59327547 -1.07232529 -1.12310645 -1.92889722\n",
      " -1.4877962  -0.70349738 -0.59619132 -0.21444635]\n",
      "\n",
      "# 3 Gradient out:  [-274.27429752 -192.07772956 -323.90434537 -278.22496181 -282.12598949\n",
      " -334.01283898 -337.36430289 -245.69961672 -231.17859975 -122.75363845]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [7.52770515 4.99691731 8.91100835 7.96045181 8.03594218 8.8988104\n",
      " 9.4469977  7.27330709 6.90789224 3.76765158]\n",
      "\n",
      "# 4 Gradient out:  [1691.05093984 1184.07304136 1996.68489901 1715.40022326 1739.44063945\n",
      " 2058.86282022 2079.47339376 1514.86233337 1425.29225936  756.73169484]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [-47.32715435 -33.4186286  -55.86986073 -47.68454055 -48.38925572\n",
      " -57.9037574  -58.02586288 -41.86661625 -39.32782771 -20.78307611]\n",
      "\n",
      "# 5 Gradient out:  [-10424.77043464  -7299.61502919 -12309.26263601 -10574.88422386\n",
      " -10723.09678321 -12692.71499831 -12819.82527165  -9338.63758545\n",
      "  -8786.5085739   -4665.12112302]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [290.88303362 203.39597967 343.46711907 295.3955041  299.49887217\n",
      " 353.86880664 357.86881587 261.10585042 245.73062416 130.56326286]\n",
      "\n",
      "# 6 Gradient out:  [64266.7483652  45000.55300576 75883.93081544 65192.16333624\n",
      " 66105.85474412 78247.69687445 79031.25502309 57570.93048382\n",
      " 54167.11732109 28759.46580901]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [-1794.07105331 -1256.52702617 -2118.38540813 -1819.58134067\n",
      " -1845.12048447 -2184.67419302 -2206.09623846 -1606.62166667\n",
      " -1511.57109062  -802.46096175]\n",
      "\n",
      "# 7 Gradient out:  [-396190.93033399 -277419.109349   -467808.76172302 -401895.92628678\n",
      " -407528.6517909  -482381.02546048 -487211.54860771 -354912.64188458\n",
      " -333928.89503813 -177296.16822291]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [11059.27861973  7743.58357498 13058.40075496 11218.85132658\n",
      " 11376.05046436 13464.86518187 13600.15476616  9907.56443009\n",
      "  9321.8523736   4949.43220005]\n",
      "\n",
      "# 8 Gradient out:  [2442434.89015852 1710231.04658641 2883943.60948562 2477604.99869551\n",
      " 2512329.57206471 2973778.44736191 3003557.56787005 2187962.78972239\n",
      " 2058602.30071608 1092993.95207381]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [-68178.90744707 -47740.23829482 -80503.35158964 -69160.33393078\n",
      " -70129.67989383 -83011.33991022 -83842.15495538 -61074.96394682\n",
      " -57463.92663403 -30509.80144453]\n",
      "\n",
      "# 9 Gradient out:  [-15057102.89968132 -10543218.7654655  -17778912.64057698\n",
      " -15273919.30872414 -15487989.08900816 -18332725.8686115\n",
      " -18516308.00281723 -13488335.36567736 -12690854.91071084\n",
      "  -6738080.44375158]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [420308.07058464 294305.97102247 496285.37030748 426360.66580832\n",
      " 432336.23451912 511744.34956216 516869.35861863 376517.59399765\n",
      " 354256.53350919 188088.98897024]\n",
      "\n",
      "# 10 Gradient out:  [9.28239079e+07 6.49967508e+07 1.09603299e+08 9.41605360e+07\n",
      " 9.54802316e+07 1.13017442e+08 1.14149187e+08 8.31527823e+07\n",
      " 7.82364811e+07 4.15388644e+07]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [-2591112.50935163 -1814337.78207063 -3059497.15780792 -2628423.19593651\n",
      " -2665261.58328251 -3154800.82416014 -3186392.24194482 -2321149.47913782\n",
      " -2183914.44863298 -1159527.09978008]\n",
      "\n",
      "# 11 Gradient out:  [-5.72240086e+08 -4.00691450e+08 -6.75681540e+08 -5.80480120e+08\n",
      " -5.88615769e+08 -6.96729023e+08 -7.03705999e+08 -5.12619608e+08\n",
      " -4.82311634e+08 -2.56078460e+08]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [15973669.07484092 11185012.37397576 18861162.55502574 16203684.00073506\n",
      " 16430784.74628277 19448687.53448347 19643445.24172314 14309406.98392591\n",
      " 13463381.77532613  7148245.79004225]\n",
      "\n",
      "# 12 Gradient out:  [3.52774111e+09 2.47017945e+09 4.16543616e+09 3.57853921e+09\n",
      " 3.62869379e+09 4.29518952e+09 4.33820112e+09 3.16019327e+09\n",
      " 2.97335091e+09 1.57867044e+09]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [-9.84743481e+07 -6.89532777e+07 -1.16275145e+08 -9.98923400e+07\n",
      " -1.01292369e+08 -1.19897117e+08 -1.21097755e+08 -8.82145147e+07\n",
      " -8.29989450e+07 -4.40674462e+07]\n",
      "\n",
      "# 13 Gradient out:  [-2.17477902e+10 -1.52281426e+10 -2.56790476e+10 -2.20609499e+10\n",
      " -2.23701425e+10 -2.64789500e+10 -2.67441077e+10 -1.94819342e+10\n",
      " -1.83300899e+10 -9.73217495e+09]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [6.07073874e+08 4.25082613e+08 7.16812087e+08 6.15815502e+08\n",
      " 6.24446390e+08 7.39140786e+08 7.46542470e+08 5.43824139e+08\n",
      " 5.11671237e+08 2.71666643e+08]\n",
      "\n",
      "# 14 Gradient out:  [1.34070604e+11 9.38783317e+10 1.58305987e+11 1.36001168e+11\n",
      " 1.37907276e+11 1.63237220e+11 1.64871861e+11 1.20102072e+11\n",
      " 1.13001192e+11 5.99968344e+10]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [-3.74248417e+09 -2.62054590e+09 -4.41899743e+09 -3.79637449e+09\n",
      " -3.84958212e+09 -4.55664922e+09 -4.60227906e+09 -3.35256270e+09\n",
      " -3.15434675e+09 -1.67476835e+09]\n",
      "\n",
      "# 15 Gradient out:  [-8.26517387e+11 -5.78740389e+11 -9.75923487e+11 -8.38418914e+11\n",
      " -8.50169674e+11 -1.00632351e+12 -1.01640073e+12 -7.40404297e+11\n",
      " -6.96628847e+11 -3.69868006e+11]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [2.30716365e+10 1.61551204e+10 2.72422001e+10 2.34038591e+10\n",
      " 2.37318731e+10 2.80907947e+10 2.83720932e+10 2.06678518e+10\n",
      " 1.94458917e+10 1.03245985e+10]\n",
      "\n",
      "# 16 Gradient out:  [5.09530778e+12 3.56781413e+12 6.01636532e+12 5.16867823e+12\n",
      " 5.24111922e+12 6.20377513e+12 6.26589913e+12 4.56443850e+12\n",
      " 4.29457195e+12 2.28015933e+12]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [-1.42231841e+11 -9.95929574e+10 -1.67942497e+11 -1.44279924e+11\n",
      " -1.46302062e+11 -1.73173907e+11 -1.74908054e+11 -1.27413008e+11\n",
      " -1.19879878e+11 -6.36490026e+10]\n",
      "\n",
      "# 17 Gradient out:  [-3.14115127e+13 -2.19948321e+13 -3.70896409e+13 -3.18638263e+13\n",
      " -3.23104099e+13 -3.82449834e+13 -3.86279649e+13 -2.81388140e+13\n",
      " -2.64751429e+13 -1.40567080e+13]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [8.76829716e+11 6.13969869e+11 1.03533057e+12 8.89455722e+11\n",
      " 9.01921782e+11 1.06758112e+12 1.07827177e+12 7.85474692e+11\n",
      " 7.39034512e+11 3.92382863e+11]\n",
      "\n",
      "# 18 Gradient out:  [1.93645443e+14 1.35593565e+14 2.28649922e+14 1.96433862e+14\n",
      " 1.99186957e+14 2.35772368e+14 2.38133370e+14 1.73469936e+14\n",
      " 1.63213749e+14 8.66566813e+13]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [-5.40547283e+12 -3.78499654e+12 -6.38259761e+12 -5.48330953e+12\n",
      " -5.56016020e+12 -6.58141556e+12 -6.64732121e+12 -4.84228811e+12\n",
      " -4.55599406e+12 -2.41895874e+12]\n",
      "\n",
      "# 19 Gradient out:  [-1.19378388e+15 -8.35906127e+14 -1.40957921e+15 -1.21097390e+15\n",
      " -1.22794616e+15 -1.45348761e+15 -1.46804269e+15 -1.06940608e+15\n",
      " -1.00617882e+15 -5.34220417e+14]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [3.33236157e+13 2.33337165e+13 3.93473868e+13 3.38034628e+13\n",
      " 3.42772312e+13 4.05730581e+13 4.09793527e+13 2.98516991e+13\n",
      " 2.80867558e+13 1.49123775e+13]\n",
      "\n",
      "# 20 Gradient out:  [7.35942933e+15 5.15318742e+15 8.68976268e+15 7.46540224e+15\n",
      " 7.57003269e+15 8.96044882e+15 9.05017788e+15 6.59266604e+15\n",
      " 6.20288314e+15 3.29335776e+15]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [-2.05433160e+14 -1.43847509e+14 -2.42568456e+14 -2.08391318e+14\n",
      " -2.11312001e+14 -2.50124464e+14 -2.52629186e+14 -1.84029516e+14\n",
      " -1.73149008e+14 -9.19317059e+13]\n",
      "\n",
      "# 21 Gradient out:  [-4.53693512e+16 -3.17683286e+16 -5.35705795e+16 -4.60226521e+16\n",
      " -4.66676771e+16 -5.52393033e+16 -5.57924643e+16 -4.06424149e+16\n",
      " -3.82394845e+16 -2.03028656e+16]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [1.26645271e+15 8.86789974e+14 1.49538408e+15 1.28468913e+15\n",
      " 1.30269454e+15 1.54196530e+15 1.55740639e+15 1.13450369e+15\n",
      " 1.06742762e+15 5.66739846e+14]\n",
      "\n",
      "# 22 Gradient out:  [2.79692614e+17 1.95845139e+17 3.30251481e+17 2.83720078e+17\n",
      " 2.87696523e+17 3.40538816e+17 3.43948939e+17 2.50552035e+17\n",
      " 2.35738469e+17 1.25162944e+17]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [-7.80741753e+15 -5.46687575e+15 -9.21873183e+15 -7.91984129e+15\n",
      " -8.03084088e+15 -9.50589537e+15 -9.60108648e+15 -6.99397929e+15\n",
      " -6.58046927e+15 -3.49383328e+15]\n",
      "\n",
      "# 23 Gradient out:  [-1.72424679e+18 -1.20734455e+18 -2.03593169e+18 -1.74907527e+18\n",
      " -1.77358923e+18 -2.09935097e+18 -2.12037367e+18 -1.54460118e+18\n",
      " -1.45327863e+18 -7.71603517e+17]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [4.81311052e+16 3.37021520e+16 5.68315644e+16 4.88241744e+16\n",
      " 4.95084637e+16 5.86018679e+16 5.91887012e+16 4.31164277e+16\n",
      " 4.05672244e+16 2.15387555e+16]\n",
      "\n",
      "# 24 Gradient out:  [1.06296229e+19 7.44302802e+18 1.25510954e+19 1.07826853e+19\n",
      " 1.09338087e+19 1.29420621e+19 1.30716627e+19 9.52214505e+18\n",
      " 8.95916048e+18 4.75677520e+18]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [-2.96718253e+17 -2.07766757e+17 -3.50354774e+17 -3.00990880e+17\n",
      " -3.05209382e+17 -3.61268327e+17 -3.64886033e+17 -2.65803809e+17\n",
      " -2.50088501e+17 -1.32781948e+17]\n",
      "\n",
      "# 25 Gradient out:  [-6.55294141e+19 -4.58847197e+19 -7.73748929e+19 -6.64730121e+19\n",
      " -6.74046566e+19 -7.97851212e+19 -8.05840816e+19 -5.87020437e+19\n",
      " -5.52313610e+19 -2.93245298e+19]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [1.82920632e+18 1.28083885e+18 2.15986431e+18 1.85554617e+18\n",
      " 1.88155236e+18 2.22714410e+18 2.24944650e+18 1.63862520e+18\n",
      " 1.54174360e+18 8.18573092e+17]\n",
      "\n",
      "# 26 Gradient out:  [4.03975209e+20 2.82869754e+20 4.77000122e+20 4.09792294e+20\n",
      " 4.15535689e+20 4.91858678e+20 4.96784103e+20 3.61885891e+20\n",
      " 3.40489853e+20 1.80779627e+20]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [-1.12766765e+19 -7.89610509e+18 -1.33151143e+19 -1.14390562e+19\n",
      " -1.15993790e+19 -1.37298801e+19 -1.38673698e+19 -1.01017835e+19\n",
      " -9.50452860e+18 -5.04633286e+18]\n",
      "\n",
      "# 27 Gradient out:  [-2.49042314e+21 -1.74383320e+21 -2.94060654e+21 -2.52628426e+21\n",
      " -2.56169109e+21 -3.03220645e+21 -3.06257067e+21 -2.23095125e+21\n",
      " -2.09904913e+21 -1.11446880e+21]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [6.95183652e+19 4.86778456e+19 8.20849102e+19 7.05194026e+19\n",
      " 7.15077588e+19 8.46418555e+19 8.54894508e+19 6.22753946e+19\n",
      " 5.85934420e+19 3.11095925e+19]\n",
      "\n",
      "# 28 Gradient out:  [1.53529407e+22 1.07503690e+22 1.81282277e+22 1.55740170e+22\n",
      " 1.57922928e+22 1.86929221e+22 1.88801112e+22 1.37533504e+22\n",
      " 1.29402013e+22 6.87046836e+21]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [-4.28566263e+20 -3.00088794e+20 -5.06036399e+20 -4.34737450e+20\n",
      " -4.40830460e+20 -5.21799435e+20 -5.27024683e+20 -3.83914855e+20\n",
      " -3.61216384e+20 -1.91784167e+20]\n",
      "\n",
      "# 29 Gradient out:  [-9.46476861e+22 -6.62737888e+22 -1.11756754e+23 -9.60105759e+22\n",
      " -9.73562006e+22 -1.15237977e+23 -1.16391959e+23 -8.47865449e+22\n",
      " -7.97736496e+22 -4.23550085e+22]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [2.64202187e+21 1.84998500e+21 3.11960915e+21 2.68006596e+21\n",
      " 2.71762810e+21 3.21678499e+21 3.24899756e+21 2.36675523e+21\n",
      " 2.22682388e+21 1.18230950e+21]\n",
      "\n",
      "# 30 Gradient out:  [5.83483300e+23 4.08564124e+23 6.88957142e+23 5.91885231e+23\n",
      " 6.00180728e+23 7.10418160e+23 7.17532218e+23 5.22691415e+23\n",
      " 4.91787958e+23 2.61109818e+23]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [-1.62875154e+22 -1.14047728e+22 -1.92317416e+22 -1.65220492e+22\n",
      " -1.67536120e+22 -1.98308104e+22 -2.00293942e+22 -1.45905538e+22\n",
      " -1.37279061e+22 -7.28869219e+21]\n",
      "\n",
      "# 31 Gradient out:  [-3.59705319e+24 -2.51871285e+24 -4.24727749e+24 -3.64884935e+24\n",
      " -3.69998936e+24 -4.37958020e+24 -4.42343689e+24 -3.22228386e+24\n",
      " -3.03177048e+24 -1.60968772e+24]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [1.00409145e+23 7.03080520e+22 1.18559687e+23 1.01854997e+23\n",
      " 1.03282534e+23 1.22252822e+23 1.23477049e+23 8.99477293e+22\n",
      " 8.46296856e+22 4.49332714e+22]\n",
      "\n",
      "# 32 Gradient out:  [2.21750848e+25 1.55273409e+25 2.61835823e+25 2.24943973e+25\n",
      " 2.28096648e+25 2.69992010e+25 2.72695684e+25 1.98647098e+25\n",
      " 1.86902344e+25 9.92339001e+24]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [-6.19001493e+23 -4.33434518e+23 -7.30895811e+23 -6.27914873e+23\n",
      " -6.36715338e+23 -7.53663219e+23 -7.61210328e+23 -5.54509043e+23\n",
      " -5.21724410e+23 -2.77004273e+23]\n",
      "\n",
      "# 33 Gradient out:  [-1.36704785e+26 -9.57228269e+25 -1.61416339e+26 -1.38673281e+26\n",
      " -1.40616840e+26 -1.66444459e+26 -1.68111218e+26 -1.22461804e+26\n",
      " -1.15221408e+26 -6.11756355e+25]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [3.81601546e+24 2.67203365e+24 4.50582066e+24 3.87096459e+24\n",
      " 3.92521763e+24 4.64617699e+24 4.69270335e+24 3.41843292e+24\n",
      " 3.21632248e+24 1.70767373e+24]\n",
      "\n",
      "# 34 Gradient out:  [8.42756569e+26 5.90111319e+26 9.95098160e+26 8.54891935e+26\n",
      " 8.66873570e+26 1.02609547e+27 1.03637069e+27 7.54951554e+26\n",
      " 7.10316016e+26 3.77135069e+26]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [-2.35249416e+25 -1.64725317e+25 -2.77774472e+25 -2.38636916e+25\n",
      " -2.41981503e+25 -2.86427148e+25 -2.89295402e+25 -2.10739280e+25\n",
      " -1.98279591e+25 -1.05274534e+25]\n",
      "\n",
      "# 35 Gradient out:  [-5.19541897e+27 -3.63791355e+27 -6.13457319e+27 -5.27023098e+27\n",
      " -5.34409526e+27 -6.32566517e+27 -6.38900976e+27 -4.65411931e+27\n",
      " -4.37895050e+27 -2.32495926e+27]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [1.45026372e+26 1.01549732e+26 1.71242185e+26 1.47114695e+26\n",
      " 1.49176564e+26 1.76576380e+26 1.78344598e+26 1.29916383e+26\n",
      " 1.22235244e+26 6.48995604e+25]\n",
      "\n",
      "# 36 Gradient out:  [3.20286774e+28 2.24269804e+28 3.78183678e+28 3.24898778e+28\n",
      " 3.29452358e+28 3.89964101e+28 3.93869164e+28 2.86916776e+28\n",
      " 2.69953191e+28 1.43328903e+28]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [-8.94057422e+26 -6.26032977e+26 -1.05567245e+27 -9.06931500e+26\n",
      " -9.19642489e+26 -1.08855665e+27 -1.09945735e+27 -8.00907480e+26\n",
      " -7.53554856e+26 -4.00092292e+26]\n",
      "\n",
      "# 37 Gradient out:  [-1.97450134e+29 -1.38257670e+29 -2.33142372e+29 -2.00293339e+29\n",
      " -2.03100527e+29 -2.40404758e+29 -2.42812148e+29 -1.76878225e+29\n",
      " -1.66420528e+29 -8.83592876e+28]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [5.51167805e+27 3.85936310e+27 6.50800111e+27 5.59104407e+27\n",
      " 5.66940467e+27 6.71072537e+27 6.77792592e+27 4.93742804e+27\n",
      " 4.64550896e+27 2.46648577e+27]\n",
      "\n",
      "# 38 Gradient out:  [1.21723901e+30 8.52329777e+29 1.43727423e+30 1.23476678e+30\n",
      " 1.25207250e+30 1.48204533e+30 1.49688639e+30 1.09041747e+30\n",
      " 1.02594794e+30 5.44716631e+29]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [-3.39783488e+28 -2.37921708e+28 -4.01204733e+28 -3.44676238e+28\n",
      " -3.49507006e+28 -4.13702262e+28 -4.17845036e+28 -3.04382169e+28\n",
      " -2.86385965e+28 -1.52053718e+28]\n",
      "\n",
      "# 39 Gradient out:  [-7.50402534e+30 -5.25443580e+30 -8.86049671e+30 -7.61208038e+30\n",
      " -7.71876658e+30 -9.13650122e+30 -9.22799325e+30 -6.72219690e+30\n",
      " -6.32475566e+30 -3.35806473e+30]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [2.09469454e+29 1.46673785e+29 2.47334373e+29 2.12485732e+29\n",
      " 2.15463800e+29 2.55038840e+29 2.57592774e+29 1.87645277e+29\n",
      " 1.76550991e+29 9.37379544e+28]\n",
      "\n",
      "# 40 Gradient out:  [4.62607555e+31 3.23925039e+31 5.46231193e+31 4.69268923e+31\n",
      " 4.75845906e+31 5.63246298e+31 5.68886591e+31 4.14409458e+31\n",
      " 3.89908032e+31 2.07017707e+31]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [-1.29133561e+30 -9.04213376e+29 -1.52476497e+30 -1.30993034e+30\n",
      " -1.32828952e+30 -1.57226140e+30 -1.58800588e+30 -1.15679410e+30\n",
      " -1.08840014e+30 -5.77874993e+29]\n",
      "\n",
      "# 41 Gradient out:  [-2.85187936e+32 -1.99693049e+32 -3.36740170e+32 -2.89294531e+32\n",
      " -2.93349104e+32 -3.47229628e+32 -3.50706751e+32 -2.55474811e+32\n",
      " -2.40370192e+32 -1.27622110e+32]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [7.96081549e+30 5.57428740e+30 9.39985890e+30 8.07544812e+30\n",
      " 8.18862860e+30 9.69266455e+30 9.78972594e+30 7.13139505e+30\n",
      " 6.70976050e+30 3.56247914e+30]\n",
      "\n",
      "# 42 Gradient out:  [1.75812431e+33 1.23106612e+33 2.07593311e+33 1.78344062e+33\n",
      " 1.80843621e+33 2.14059844e+33 2.16203418e+33 1.57494908e+33\n",
      " 1.48183224e+33 7.86763767e+32]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [-4.90767717e+31 -3.43643225e+31 -5.79481751e+31 -4.97834581e+31\n",
      " -5.04811922e+31 -5.97532610e+31 -6.03516243e+31 -4.39635672e+31\n",
      " -4.13642779e+31 -2.19619429e+31]\n",
      "\n",
      "# 43 Gradient out:  [-1.08384707e+34 -7.58926656e+33 -1.27976959e+34 -1.09945405e+34\n",
      " -1.11486331e+34 -1.31963441e+34 -1.33284910e+34 -9.70923350e+33\n",
      " -9.13518757e+33 -4.85023499e+33]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [3.02548091e+32 2.11848901e+32 3.57238447e+32 3.06904665e+32\n",
      " 3.11206050e+32 3.68366426e+32 3.72055212e+32 2.71026248e+32\n",
      " 2.55002170e+32 1.35390811e+32]\n",
      "\n",
      "# 44 Gradient out:  [6.68169177e+34 4.67862499e+34 7.88951332e+34 6.77790553e+34\n",
      " 6.87290045e+34 8.13527170e+34 8.21673752e+34 5.98554051e+34\n",
      " 5.63165314e+34 2.99006899e+34]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [-1.86514605e+33 -1.30600441e+33 -2.20230073e+33 -1.89200343e+33\n",
      " -1.91852057e+33 -2.27090240e+33 -2.29364300e+33 -1.67082045e+33\n",
      " -1.57203534e+33 -8.34656187e+32]\n",
      "\n",
      "# 45 Gradient out:  [-4.11912401e+35 -2.88427500e+35 -4.86372087e+35 -4.17843779e+35\n",
      " -4.23700018e+35 -5.01522580e+35 -5.06544778e+35 -3.68996123e+35\n",
      " -3.47179703e+35 -1.84331535e+35]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [1.14982375e+34 8.05124556e+33 1.35767259e+34 1.16638076e+34\n",
      " 1.18272803e+34 1.39996410e+34 1.41398320e+34 1.03002606e+34\n",
      " 9.69127093e+33 5.14548180e+33]\n",
      "\n",
      "# 46 Gradient out:  [2.53935428e+36 1.77809555e+36 2.99838276e+36 2.57591999e+36\n",
      " 2.61202249e+36 3.09178240e+36 3.12274320e+36 2.27478436e+36\n",
      " 2.14029066e+36 1.13636557e+36]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [-7.08842426e+34 -4.96342544e+34 -8.36976916e+34 -7.19049481e+34\n",
      " -7.29127232e+34 -8.63048750e+34 -8.71691236e+34 -6.34989641e+34\n",
      " -5.97446696e+34 -3.17208251e+34]\n",
      "\n",
      "# 47 Gradient out:  [-1.56545910e+37 -1.09615892e+37 -1.84844061e+37 -1.58800110e+37\n",
      " -1.61025754e+37 -1.90601954e+37 -1.92510624e+37 -1.40235724e+37\n",
      " -1.31944468e+37 -7.00545740e+36]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [4.36986613e+35 3.05984855e+35 5.15978861e+35 4.43279050e+35\n",
      " 4.49491774e+35 5.32051604e+35 5.37379517e+35 3.91457907e+35\n",
      " 3.68313462e+35 1.95552289e+35]\n",
      "\n",
      "# 48 Gradient out:  [9.65072974e+37 6.75759177e+37 1.13952519e+38 9.78969649e+37\n",
      " 9.92690280e+37 1.17502141e+38 1.18678796e+38 8.64524073e+37\n",
      " 8.13410200e+37 4.31871879e+37]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [-2.69393158e+36 -1.88633299e+36 -3.18090236e+36 -2.73272315e+36\n",
      " -2.77102330e+36 -3.27998748e+36 -3.31283296e+36 -2.41325658e+36\n",
      " -2.27057589e+36 -1.20553919e+36]\n",
      "\n",
      "# 49 Gradient out:  [-5.94947417e+38 -4.16591478e+38 -7.02493580e+38 -6.03514427e+38\n",
      " -6.11972911e+38 -7.24376258e+38 -7.31630091e+38 -5.32961110e+38\n",
      " -5.01450471e+38 -2.66240031e+38]\n",
      "\n",
      "     Weights  out:  [ 0.14390258 -0.04400456  0.30586633  0.15435411  0.16494745  0.35293562\n",
      "  0.3704597   0.0744142   0.04173074 -0.22278066] [1.66075279e+37 1.16288506e+37 1.96096015e+37 1.68466698e+37\n",
      " 1.70827823e+37 2.02204406e+37 2.04229262e+37 1.48772249e+37\n",
      " 1.39976281e+37 7.43189838e+36]\n",
      "\n",
      "Lineal error cuadrático medio (ECM): 4.038549045185269e+77\n",
      "\n",
      "# 0 Gradient out:  [-0.31369774 -0.42826315 -0.42309504 -0.45575751 -0.18553763 -0.49784001\n",
      " -0.39113567 -0.54696043 -0.22251323 -0.2672048 ]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-0.04705241  0.19933105 -0.0745167   0.0078121   0.07905066  0.36382412\n",
      " -0.33751737  0.1069178   0.22467252  0.0853141 ]\n",
      "\n",
      "# 1 Gradient out:  [0.78346151 1.00614203 0.99402257 1.07147611 0.65140476 1.16779682\n",
      " 0.9222683  1.26354441 0.68040057 0.72425141]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-0.10979196  0.11367842 -0.15913571 -0.0833394   0.04194314  0.26425612\n",
      " -0.4157445  -0.00247429  0.18016988  0.03187314]\n",
      "\n",
      "# 2 Gradient out:  [-0.90577476 -1.20281958 -1.18807749 -1.28180298 -0.64925406 -1.40031366\n",
      " -1.0989784  -1.52784962 -0.7173655  -0.80539505]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [ 0.04690034  0.31490683  0.03966881  0.13095582  0.17222409  0.49781548\n",
      " -0.23129084  0.2502346   0.31624999  0.17672343]\n",
      "\n",
      "# 3 Gradient out:  [1.20727723 1.56716531 1.54805167 1.6700413  0.96725217 1.82239672\n",
      " 1.43428343 1.97707968 1.02383896 1.10448778]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-0.13425461  0.07434291 -0.19794669 -0.12540477  0.04237328  0.21775275\n",
      " -0.45108652 -0.05533533  0.17277689  0.01564442]\n",
      "\n",
      "# 4 Gradient out:  [-0.73851048 -0.98713598 -0.97470396 -1.05377753 -0.52917095 -1.15362187\n",
      " -0.89969598 -1.26038279 -0.58419464 -0.65590553]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [ 0.10720083  0.38777597  0.11166364  0.20860349  0.23582371  0.5822321\n",
      " -0.16422984  0.34008061  0.37754469  0.23654197]\n",
      "\n",
      "# 5 Gradient out:  [-0.32098835 -0.42550213 -0.42087191 -0.45010032 -0.19907025 -0.48789836\n",
      " -0.39211001 -0.5326951  -0.23467241 -0.27727497]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-0.04050126  0.19034878 -0.08327715 -0.00215202  0.12998952  0.35150772\n",
      " -0.34416903  0.08800405  0.26070576  0.10536087]\n",
      "\n",
      "# 6 Gradient out:  [0.77463822 1.00579807 0.99322978 1.07354704 0.63702874 1.17344751\n",
      " 0.91880111 1.27284171 0.66729006 0.7130083 ]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-0.10469893  0.10524835 -0.16745153 -0.09217209  0.09017547  0.25392805\n",
      " -0.42259104 -0.01853497  0.21377128  0.04990587]\n",
      "\n",
      "# 7 Gradient out:  [-0.90692924 -1.20235066 -1.18770254 -1.28082566 -0.65099205 -1.39859458\n",
      " -1.09915293 -1.52543104 -0.71904139 -0.80688884]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [ 0.05022871  0.30640796  0.03119442  0.12253732  0.21758122  0.48861755\n",
      " -0.23883081  0.23603337  0.34722929  0.19250753]\n",
      "\n",
      "# 8 Gradient out:  [1.20537229 1.57174954 1.55229732 1.67644553 0.9607862  1.83150601\n",
      " 1.43650536 1.98897864 1.01846128 1.10065276]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-0.13115714  0.06593783 -0.20634609 -0.13362781  0.08738281  0.20889864\n",
      " -0.4586614  -0.06905284  0.20342101  0.03112976]\n",
      "\n",
      "# 9 Gradient out:  [-0.73685702 -0.98553707 -0.97310554 -1.05217477 -0.52728427 -1.15201845\n",
      " -0.89809608 -1.25880233 -0.58238979 -0.65418499]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [ 0.10991732  0.38028774  0.10411338  0.2016613   0.27954005  0.57519984\n",
      " -0.17136033  0.32874289  0.40711327  0.25126032]\n",
      "\n",
      "# 10 Gradient out:  [-0.33723086 -0.43740727 -0.43301581 -0.4607177  -0.21755017 -0.49662002\n",
      " -0.40566497 -0.5395492  -0.25273978 -0.29460638]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-0.03745408  0.18318032 -0.09050773 -0.00877366  0.1740832   0.34479615\n",
      " -0.35097954  0.07698242  0.29063531  0.12042332]\n",
      "\n",
      "# 11 Gradient out:  [0.79091988 1.03553994 1.02227336 1.10704131 0.64353503 1.21252446\n",
      " 0.94366597 1.3177035  0.67618305 0.72521456]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-0.10490025  0.09569887 -0.17711089 -0.1009172   0.13057316  0.24547215\n",
      " -0.43211254 -0.03092742  0.24008735  0.06150204]\n",
      "\n",
      "# 12 Gradient out:  [-0.90469295 -1.19855733 -1.18398663 -1.27661747 -0.65005821 -1.39376401\n",
      " -1.09590492 -1.51993154 -0.71777166 -0.80517218]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [ 0.05328372  0.30280686  0.02734378  0.12049107  0.25928017  0.48797704\n",
      " -0.24337934  0.23261328  0.37532396  0.20654496]\n",
      "\n",
      "# 13 Gradient out:  [1.15030158 1.50558937 1.48669252 1.60730784 0.9151032  1.75790929\n",
      " 1.37424966 1.91062119 0.97028977 1.04926668]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-0.12765487  0.06309539 -0.20945355 -0.13483243  0.12926853  0.20922423\n",
      " -0.46256033 -0.07137302  0.23176963  0.04551052]\n",
      "\n",
      "# 14 Gradient out:  [-0.76394761 -1.02105269 -1.00821154 -1.08988189 -0.546596   -1.19302727\n",
      " -0.93071456 -1.30342705 -0.60382166 -0.67829786]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [ 0.10240545  0.36421327  0.08788496  0.18662914  0.31228917  0.56080609\n",
      " -0.1877104   0.31075121  0.42582759  0.25536385]\n",
      "\n",
      "# 15 Gradient out:  [-0.16157294 -0.19931858 -0.19815205 -0.20530346 -0.08852069 -0.21541138\n",
      " -0.19011593 -0.23151756 -0.11208706 -0.13812577]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-0.05038407  0.16000273 -0.11375735 -0.03134724  0.20296997  0.32220064\n",
      " -0.37385331  0.0500658   0.30506325  0.11970428]\n",
      "\n",
      "# 16 Gradient out:  [0.34800831 0.46639668 0.45956166 0.50337672 0.30042919 0.55733058\n",
      " 0.41959139 0.60829284 0.30747132 0.32248213]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-0.08269866  0.12013901 -0.15338776 -0.07240793  0.18526583  0.27911836\n",
      " -0.41187649  0.00376229  0.28264584  0.09207913]\n",
      "\n",
      "# 17 Gradient out:  [-0.69718412 -0.90754157 -0.89745629 -0.96144267 -0.49502933 -1.04288326\n",
      " -0.83600865 -1.13314753 -0.55084956 -0.62070844]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-0.013097    0.21341835 -0.06147543  0.02826741  0.24535167  0.39058448\n",
      " -0.32795822  0.12542086  0.34414011  0.15657556]\n",
      "\n",
      "# 18 Gradient out:  [1.38337361 1.81120894 1.78863893 1.93263439 1.08961471 2.11268874\n",
      " 1.65409776 2.29655825 1.15993984 1.25891303]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-0.15253382  0.03191004 -0.24096669 -0.16402112  0.1463458   0.18200783\n",
      " -0.49515995 -0.10120865  0.2339702   0.03243387]\n",
      "\n",
      "# 19 Gradient out:  [-0.64407533 -0.86525412 -0.85418087 -0.92461702 -0.45866384 -1.01353493\n",
      " -0.78738964 -1.10851256 -0.50730639 -0.57080114]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [ 0.1241409   0.39415182  0.1167611   0.22250576  0.36426874  0.60454558\n",
      " -0.16434039  0.358103    0.46595816  0.28421647]\n",
      "\n",
      "# 20 Gradient out:  [-0.76762857 -0.99986303 -0.98863878 -1.05988636 -0.54957187 -1.15042781\n",
      " -0.92038191 -1.25009179 -0.60931528 -0.68455798]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-0.00467417  0.221101   -0.05407507  0.03758235  0.27253597  0.40183859\n",
      " -0.32181832  0.13640049  0.36449688  0.17005625]\n",
      "\n",
      "# 21 Gradient out:  [1.4362007  1.88151576 1.85806409 2.00767021 1.12815425 2.19479757\n",
      " 1.71821402 2.38617395 1.2021903  1.30604707]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-0.15819988  0.02112839 -0.25180283 -0.17439492  0.1626216   0.17175303\n",
      " -0.50589471 -0.11361787  0.24263383  0.03314465]\n",
      "\n",
      "# 22 Gradient out:  [-0.62022564 -0.83431152 -0.82358988 -0.89179075 -0.44097239 -0.97788172\n",
      " -0.75892425 -1.0698142  -0.48797494 -0.54935581]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [ 0.12904026  0.39743155  0.11980999  0.22713912  0.38825245  0.61071254\n",
      " -0.1622519   0.36361692  0.48307189  0.29435406]\n",
      "\n",
      "# 23 Gradient out:  [-0.82929344 -1.0820851  -1.06978247 -1.14790791 -0.59677877 -1.24705819\n",
      " -0.99508927 -1.35555622 -0.66002706 -0.74015133]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [ 0.00499513  0.23056924 -0.04490798  0.04878097  0.30005797  0.4151362\n",
      " -0.31403675  0.14965408  0.3854769   0.1844829 ]\n",
      "\n",
      "# 24 Gradient out:  [1.45767809 1.91082685 1.88698069 2.03909696 1.14319902 2.2293897\n",
      " 1.74475432 2.42413036 1.21890796 1.32496435]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-0.16086356  0.01415222 -0.25886448 -0.18080061  0.18070222  0.16572456\n",
      " -0.51305461 -0.12145716  0.25347149  0.03645264]\n",
      "\n",
      "# 25 Gradient out:  [-0.61125769 -0.82288068 -0.81228161 -0.87970313 -0.43411726 -0.96480918\n",
      " -0.74835624 -1.05568424 -0.48055956 -0.5412158 ]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [ 0.13067206  0.39631759  0.11853166  0.22701878  0.40934202  0.6116025\n",
      " -0.16410374  0.36336891  0.49725308  0.30144551]\n",
      "\n",
      "# 26 Gradient out:  [-0.84771105 -1.10580568 -1.09322464 -1.17312587 -0.61145703 -1.27449841\n",
      " -1.01687016 -1.38527504 -0.67561675 -0.75700323]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [ 0.00842052  0.23174146 -0.04392466  0.05107816  0.32251857  0.41864066\n",
      " -0.31377499  0.15223206  0.40114117  0.19320235]\n",
      "\n",
      "# 27 Gradient out:  [1.4544261  1.90807704 1.88420482 2.03648715 1.13959473 2.22698826\n",
      " 1.74182247 2.4219449  1.21538632 1.32156205]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-0.16112169  0.01058032 -0.26256959 -0.18354702  0.20022716  0.16374098\n",
      " -0.51714902 -0.12482295  0.26601782  0.0418017 ]\n",
      "\n",
      "# 28 Gradient out:  [-0.61243361 -0.82475108 -0.81411823 -0.88175422 -0.43465558 -0.96713253\n",
      " -0.74998775 -1.05830569 -0.48127091 -0.54214688]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [ 0.12976353  0.39219573  0.11427137  0.22375041  0.42814611  0.60913863\n",
      " -0.16878453  0.35956603  0.50909508  0.30611411]\n",
      "\n",
      "# 29 Gradient out:  [-0.8455595  -1.10096793 -1.08853173 -1.16750788 -0.6109264  -1.26772787\n",
      " -1.01303674 -1.37734908 -0.67473409 -0.75558001]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [ 0.00727681  0.22724551 -0.04855227  0.04739957  0.34121499  0.41571213\n",
      " -0.31878208  0.1479049   0.4128409   0.19768473]\n",
      "\n",
      "# 30 Gradient out:  [1.45127027 1.9053636  1.88146846 2.03389687 1.13612749 2.22458133\n",
      " 1.73894883 2.41972824 1.21199216 1.31827341]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-0.16183509  0.00705193 -0.26625862 -0.18610201  0.21902971  0.16216656\n",
      " -0.52138943 -0.12756492  0.27789408  0.04656873]\n",
      "\n",
      "# 31 Gradient out:  [-0.61364962 -0.82664479 -0.81597898 -0.88382424 -0.43524882 -0.96946818\n",
      " -0.75164836 -1.06093224 -0.48203325 -0.54312382]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [ 0.12841896  0.38812465  0.11003507  0.22067737  0.44625521  0.60708282\n",
      " -0.17359966  0.35638073  0.52029251  0.31022341]\n",
      "\n",
      "# 32 Gradient out:  [-0.84321915 -1.09598038 -1.08368671 -1.16175255 -0.61019653 -1.26083812\n",
      " -1.00903778 -1.36932073 -0.67365223 -0.75396068]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [ 0.00568904  0.22279569 -0.05316072  0.04391252  0.35920545  0.41318919\n",
      " -0.32392933  0.14419428  0.42388586  0.20159865]\n",
      "\n",
      "# 33 Gradient out:  [1.44797777 1.90239177 1.87847992 2.03101484 1.1326179  2.22183286\n",
      " 1.73586033 2.41711775 1.20853186 1.31488651]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-0.16295479  0.00359961 -0.26989806 -0.18843799  0.23716614  0.16102156\n",
      " -0.52573689 -0.12966987  0.28915541  0.05080651]\n",
      "\n",
      "# 34 Gradient out:  [-0.61498223 -0.82866439 -0.81796515 -0.88602267 -0.43595098 -0.97193602\n",
      " -0.75343157 -1.06369497 -0.48290655 -0.54421436]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [ 0.12664076  0.38407797  0.10579792  0.21776498  0.46368972  0.60538813\n",
      " -0.17856482  0.35375368  0.53086179  0.31378381]\n",
      "\n",
      "# 35 Gradient out:  [-0.84055206 -1.09064138 -1.07849133 -1.15564005 -0.60917145 -1.25358237\n",
      " -1.00469519 -1.36091582 -0.67226542 -0.75202538]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [ 0.00364432  0.21834509 -0.05779511  0.04056044  0.37649952  0.41100093\n",
      " -0.32925114  0.14101469  0.43428048  0.20494094]\n",
      "\n",
      "# 36 Gradient out:  [1.44459816 1.89922934 1.87530606 2.02791389 1.12910164 2.21882319\n",
      " 1.73261821 2.41420159 1.20504458 1.31144523]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-1.64466093e-01  2.16813271e-04 -2.73493374e-01 -1.90567570e-01\n",
      "  2.54665232e-01  1.60284455e-01 -5.30190174e-01 -1.31168472e-01\n",
      "  2.99827391e-01  5.45358657e-02]\n",
      "\n",
      "# 37 Gradient out:  [-0.61639882 -0.83076894 -0.82003622 -0.8883064  -0.43673681 -0.97448965\n",
      " -0.75529931 -1.06654389 -0.48386358 -0.54538871]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [ 0.12445354  0.38006268  0.10156784  0.21501521  0.48048556  0.60404909\n",
      " -0.18366653  0.35167185  0.54083631  0.31682491]\n",
      "\n",
      "# 38 Gradient out:  [-0.83762671 -1.08504224 -1.07303567 -1.14926816 -0.60790424 -1.24606802\n",
      " -1.00009186 -1.35225155 -0.67063039 -0.74983603]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [ 0.00117378  0.21390889 -0.06243941  0.03735393  0.3931382   0.40915116\n",
      " -0.33472639  0.13836307  0.44406359  0.20774717]\n",
      "\n",
      "# 39 Gradient out:  [1.44115214 1.89590688 1.87197692 2.02462734 1.12559233 2.21558975\n",
      " 1.72924945 2.41102144 1.20154567 1.30796729]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-0.16635157 -0.00309955 -0.27704654 -0.1924997   0.27155735  0.15993756\n",
      " -0.53474477 -0.13208724  0.30993751  0.05777996]\n",
      "\n",
      "# 40 Gradient out:  [-0.61788012 -0.83293503 -0.82216896 -0.89065092 -0.43759083 -0.97710291\n",
      " -0.75722961 -1.06945109 -0.48488783 -0.54662908]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [ 0.12187886  0.37608182  0.09734885  0.21242576  0.49667582  0.60305551\n",
      " -0.18889487  0.35011705  0.55024665  0.31937342]\n",
      "\n",
      "# 41 Gradient out:  [-0.83448568 -1.07923883 -1.06737492 -1.14269652 -0.6064283  -1.23836032\n",
      " -0.9952788  -1.34339888 -0.66878274 -0.74743134]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-0.00169716  0.20949481 -0.06708495  0.03429558  0.40915765  0.40763493\n",
      " -0.3403408   0.13622683  0.45326908  0.2100476 ]\n",
      "\n",
      "# 42 Gradient out:  [1.43766034 1.89245457 1.86852222 2.02118805 1.12210359 2.21216936\n",
      " 1.72578078 2.40761822 1.19805045 1.30447042]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-0.1685943  -0.00635295 -0.28055993 -0.19424372  0.28787199  0.15996287\n",
      " -0.53939656 -0.13245295  0.31951253  0.06056134]\n",
      "\n",
      "# 43 Gradient out:  [-0.61940867 -0.83514151 -0.82434241 -0.89303412 -0.43849896 -0.97975225\n",
      " -0.75920258 -1.07239143 -0.48596429 -0.54791927]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [ 0.11893777  0.37213796  0.09314451  0.20999389  0.51229271  0.60239674\n",
      " -0.1942404   0.3490707   0.55912262  0.32145542]\n",
      "\n",
      "# 44 Gradient out:  [-0.83116837 -1.07328334 -1.0615606  -1.13598095 -0.60477404 -1.23052042\n",
      " -0.9903035  -1.33442448 -0.66675506 -0.74484691]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-0.00494396  0.20510966 -0.07172397  0.03138706  0.42459292  0.40644629\n",
      " -0.34608091  0.13459241  0.46192977  0.21187156]\n",
      "\n",
      "# 45 Gradient out:  [1.43414198 1.88890058 1.86496964 2.01762665 1.11864799 2.20859633\n",
      " 1.72223715 2.40403009 1.19457317 1.3009711 ]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-0.17117764 -0.00954701 -0.28403609 -0.19580913  0.30363811  0.1603422\n",
      " -0.54414162 -0.13229249  0.32857875  0.06290218]\n",
      "\n",
      "# 46 Gradient out:  [-0.62096909 -0.83736993 -0.82653827 -0.89543675 -0.43944867 -0.98241723\n",
      " -0.76120084 -1.07534313 -0.48707967 -0.54924502]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [ 0.11565076  0.36823311  0.08895784  0.2077162   0.52736771  0.60206147\n",
      " -0.19969419  0.34851353  0.56749339  0.3230964 ]\n",
      "\n",
      "# 47 Gradient out:  [-0.82771046 -1.06722326 -1.05563956 -1.12917224 -0.60296881 -1.22260406\n",
      " -0.98520916 -1.32538914 -0.66457674 -0.74211494]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-0.00854306  0.20075912 -0.07634982  0.02862885  0.43947797  0.40557802\n",
      " -0.35193435  0.13344491  0.47007745  0.2132474 ]\n",
      "\n",
      "# 48 Gradient out:  [1.43061525 1.88527147 1.8613453  2.013972   1.11523734 2.20490297\n",
      " 1.71864208 2.40029295 1.19112722 1.2974849 ]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [-0.17408515 -0.01268553 -0.28747773 -0.19720559  0.31888421  0.16105721\n",
      " -0.54897619 -0.13163292  0.33716211  0.06482441]\n",
      "\n",
      "# 49 Gradient out:  [-0.62254781 -0.83960412 -0.8287405  -0.89784195 -0.44042879 -0.98507995\n",
      " -0.7632091  -1.07828721 -0.48822214 -0.55059367]\n",
      "\n",
      "     Weights  out:  [-0.14515989 -0.02075671 -0.02672604  0.01116051 -0.27204177  0.05933185\n",
      " -0.06305303  0.11262221 -0.23508727 -0.19129356] [ 0.1120379   0.36436876  0.08479133  0.20558881  0.54193168  0.60203781\n",
      " -0.20524777  0.34842567  0.57538755  0.32432139]\n",
      "\n",
      "Tanh error cuadrático medio (ECM): 0.5815687508969086\n",
      "Promedio MSE salida lineal: 9.915642643052184e+77 ± 2.842582876425456e+78\n",
      "Promedio MSE salida tanh: 0.7859124872246648 ± 0.20710862659294654\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "errors_linear = []\n",
    "errors_tanh = []\n",
    "\n",
    "for _ in range(10):\n",
    "    train(X, t)\n",
    "    _, mse_lin = recall(X, t)\n",
    "    errors_linear.append(mse_lin)\n",
    "\n",
    "    train_tanh(X, t)\n",
    "    _, mse_tanh = recall_tanh(X, t)\n",
    "    errors_tanh.append(mse_tanh)\n",
    "\n",
    "print(\"Promedio MSE salida lineal:\", np.mean(errors_linear), \"±\", np.std(errors_linear))\n",
    "print(\"Promedio MSE salida tanh:\", np.mean(errors_tanh), \"±\", np.std(errors_tanh))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el Error Cuadrático Medio (MSE) obtenido con activación lineal en la capa de salida es consistentemente más alto, con un promedio cercano a 1.422. En contraste, al emplear la función tangente hiperbólica (tanh) como activación de salida, el modelo logra un MSE promedio de aproximadamente 0.794.\n",
    "\n",
    "Este resultado sugiere que la red con activación tanh en la salida ofrece un mejor desempeño predictivo, al adaptarse más eficazmente a la distribución del conjunto de datos.\n",
    "La función tanh, al ser no lineal y acotada en [-1, 1], proporciona una salida más adecuada para problemas donde las variables objetivo también están dentro de ese rango, favoreciendo una mejor aproximación a la función real y facilitando la convergencia del modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución de problema C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Modifique la arquitectura de la red PMC usando ahora 4, 6, 8 y 12 neuronas en la capa oculta. Aplique las etapas de entrenamiento/validación de la red.\n",
    "2. Determine el mejor modelo, indicando específicamente con cuántas neuronas ocultas obtuvo la mejor respuesta de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de entrenamiento y validación:\n",
      "==================================================\n",
      "Neuronas: 4\n",
      "  MSE Final: 0.481860\n",
      "------------------------------\n",
      "Neuronas: 6\n",
      "  MSE Final: 0.426074\n",
      "------------------------------\n",
      "Neuronas: 8\n",
      "  MSE Final: 0.462260\n",
      "------------------------------\n",
      "Neuronas: 12\n",
      "  MSE Final: 0.375825\n",
      "------------------------------\n",
      "\n",
      "Mejor modelo:\n",
      "Neuronas ocultas: 12\n",
      "MSE: 0.375825\n",
      "\n",
      "Comparación de resultados:\n",
      "========================================\n",
      "Neuronas\tMSE Final\n",
      "-------------------------\n",
      "4\t\t0.481860\n",
      "6\t\t0.426074\n",
      "8\t\t0.462260\n",
      "12\t\t0.375825\n",
      "\n",
      "El mejor modelo tiene 12 neuronas ocultas con MSE de 0.375825\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Dataset = np.array([[0.00000, 0.00000], [1.00000, 0.84000], [2.00000, 0.91000], [3.00000, 0.14000],\n",
    "[4.00000, -0.77000], [5.00000, -0.96000],[6.00000, -0.28000], [7.00000, 0.66000], [8.00000, 0.99000]])\n",
    "\n",
    "X = Dataset[:,0]\n",
    "t = Dataset[:,1]\n",
    "\n",
    "def logistica(u):\n",
    "    return 1/(1 + np.exp(-u))\n",
    "\n",
    "def deriv_logistica(x):\n",
    "    return x * (1.0 - x)\n",
    "\n",
    "def train_modified(X, t, hidden_num, learning_rate=0.2, epochs=50):\n",
    "    input_num = 1\n",
    "    output_num = 1\n",
    "    intervalo = 0.5\n",
    "\n",
    "    w1 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
    "    w2 = np.random.uniform(-intervalo, intervalo, hidden_num)\n",
    "\n",
    "    mse_history = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        gradient_out = 0.0\n",
    "        gradient_hidden = np.zeros(hidden_num)\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            x = X[i]\n",
    "\n",
    "            u1 = x * w1\n",
    "            o = logistica(u1)\n",
    "            u2 = o.dot(w2)\n",
    "            y = u2\n",
    "\n",
    "            delta_hidden_s = []\n",
    "            gradient_hidden_s = []\n",
    "\n",
    "            delta_out_s = t[i] - y\n",
    "            gradient_out_s = delta_out_s * o\n",
    "\n",
    "            for j in range(hidden_num):\n",
    "                delta_hidden_s.append(deriv_logistica(o[j]) * w2[j] * delta_out_s)\n",
    "                gradient_hidden_s.append(delta_hidden_s[j] * x)\n",
    "\n",
    "            gradient_out = gradient_out + gradient_out_s\n",
    "            gradient_hidden = gradient_hidden + np.array(gradient_hidden_s)\n",
    "\n",
    "        w2 = w2 + learning_rate * gradient_out\n",
    "        for j in range(hidden_num):\n",
    "            w1[j] = w1[j] + learning_rate * gradient_hidden[j]\n",
    "        \n",
    "        mse = calculate_mse(X, t, w1, w2)\n",
    "        mse_history.append(mse)\n",
    "\n",
    "    return w1, w2, mse_history\n",
    "\n",
    "def calculate_mse(X, t, w1, w2):\n",
    "    total_error = 0.0\n",
    "    for i in range(X.shape[0]):\n",
    "        x = X[i]\n",
    "        u1 = x * w1\n",
    "        o = logistica(u1)\n",
    "        u2 = o.dot(w2)\n",
    "        y = u2\n",
    "        error = (t[i] - y)**2\n",
    "        total_error += error\n",
    "    return total_error / X.shape[0]\n",
    "\n",
    "def recall_network(X, w1, w2):\n",
    "    predictions = []\n",
    "    for i in range(X.shape[0]):\n",
    "        x = X[i]\n",
    "        u1 = x * w1\n",
    "        o = logistica(u1)\n",
    "        u2 = o.dot(w2)\n",
    "        y = u2\n",
    "        predictions.append(y)\n",
    "    return np.array(predictions)\n",
    "\n",
    "hidden_neurons = [4, 6, 8, 12]\n",
    "results = []\n",
    "\n",
    "print(\"Resultados de entrenamiento y validación:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for neurons in hidden_neurons:\n",
    "    w1, w2, mse_history = train_modified(X, t, neurons, learning_rate=0.2, epochs=50)\n",
    "    \n",
    "    final_mse = mse_history[-1]\n",
    "    predictions = recall_network(X, w1, w2)\n",
    "    \n",
    "    results.append({\n",
    "        'neuronas': neurons,\n",
    "        'mse_final': final_mse,\n",
    "        'mse_history': mse_history,\n",
    "        'predictions': predictions,\n",
    "        'w1': w1,\n",
    "        'w2': w2\n",
    "    })\n",
    "    \n",
    "    print(f\"Neuronas: {neurons}\")\n",
    "    print(f\"  MSE Final: {final_mse:.6f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "best_model = min(results, key=lambda x: x['mse_final'])\n",
    "print(f\"\\nMejor modelo:\")\n",
    "print(f\"Neuronas ocultas: {best_model['neuronas']}\")\n",
    "print(f\"MSE: {best_model['mse_final']:.6f}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nComparación de resultados:\")\n",
    "print(\"=\" * 40)\n",
    "print(\"Neuronas\\tMSE Final\")\n",
    "print(\"-\" * 25)\n",
    "for result in results:\n",
    "    print(f\"{result['neuronas']}\\t\\t{result['mse_final']:.6f}\")\n",
    "\n",
    "print(f\"\\nEl mejor modelo tiene {best_model['neuronas']} neuronas ocultas con MSE de {best_model['mse_final']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución de problema D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Modifique la arquitectura de la red PMC usando ahora **dos capas ocultas**, inicialmente con 10 neuronas en la primera capa oculta y 8 neuronas en la segunda capa oculta. Use diferentes números de neuronas en las capas ocultas. Aplique las etapas de entrenamiento/validación de la red para cada combinación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "Dataset = np.array([[0.00000, 0.00000], [1.00000, 0.84000], [2.00000, 0.91000], [3.00000, 0.14000],\n",
    "[4.00000, -0.77000], [5.00000, -0.96000],[6.00000, -0.28000], [7.00000, 0.66000], [8.00000, 0.99000]])\n",
    "\n",
    "X = Dataset[:, 0:1]\n",
    "t = Dataset[:,1]\n",
    "X, t\n",
    "\n",
    "def logistica(u):\n",
    "    return 1/(1 + np.exp(-u))\n",
    "\n",
    "def deriv_logistica(x):\n",
    "    return x * (1.0 - x)\n",
    "\n",
    "\n",
    "def train_with_two_layers(X, t, hidden_num1=10, hidden_num2=8, learning_rate=0.2, epochs=50):\n",
    "    input_num = X.shape[1]  \n",
    "    output_num = 1\n",
    "    intervalo = 0.5\n",
    "\n",
    "    # Inicializando pesos con shapes apropiadas\n",
    "    w1 = np.random.uniform(-intervalo, intervalo, (input_num, hidden_num1))   \n",
    "    w2 = np.random.uniform(-intervalo, intervalo, (hidden_num1, hidden_num2))\n",
    "    w3 = np.random.uniform(-intervalo, intervalo, (hidden_num2, output_num))  \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        error_total = 0\n",
    "        grad_w1 = np.zeros_like(w1)\n",
    "        grad_w2 = np.zeros_like(w2)\n",
    "        grad_w3 = np.zeros_like(w3)\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            x = X[i].reshape(1, -1)       \n",
    "            target = t[i]\n",
    "\n",
    "            # Forward pass\n",
    "            z1 = np.dot(x, w1)            \n",
    "            o1 = logistica(z1)             \n",
    "            z2 = np.dot(o1, w2)           \n",
    "            o2 = logistica(z2)            \n",
    "            z3 = np.dot(o2, w3)           \n",
    "            y = z3[0, 0]                  \n",
    "\n",
    "            # Error\n",
    "            error = target - y\n",
    "            error_total += error**2\n",
    "\n",
    "            # Backpropagation\n",
    "            delta3 = error\n",
    "            grad_w3 += (o2.T * delta3)                   \n",
    "            delta2 = deriv_logistica(o2) * (delta3 * w3.T) \n",
    "            grad_w2 += np.dot(o1.T, delta2)                \n",
    "            delta1 = deriv_logistica(o1) * np.dot(delta2, w2.T)  \n",
    "            grad_w1 += np.dot(x.T, delta1)                \n",
    "\n",
    "        # Actualizar pesos\n",
    "        w1 += learning_rate * grad_w1\n",
    "        w2 += learning_rate * grad_w2\n",
    "        w3 += learning_rate * grad_w3\n",
    "\n",
    "    mse_final = error_total / X.shape[0]\n",
    "    return w1, w2, w3, mse_final\n",
    "\n",
    "\n",
    "\n",
    "def predict_network(X_test, w1, w2, w3):\n",
    "    predictions = []\n",
    "    for x in X_test:\n",
    "        x = x.reshape(1, -1)\n",
    "        z1 = np.dot(x, w1)\n",
    "        o1 = logistica(z1)\n",
    "        z2 = np.dot(o1, w2)\n",
    "        o2 = logistica(z2)\n",
    "        z3 = np.dot(o2, w3)\n",
    "        y = z3[0, 0]\n",
    "        predictions.append(y)\n",
    "    return np.array(predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_configuration(hidden1, hidden2):\n",
    "\n",
    "    w1, w2, w3, mse_train = train_with_two_layers(X, t, hidden1, hidden2)\n",
    "    predictions = predict_network(X, w1, w2, w3)\n",
    "    mse = np.mean((t - predictions) ** 2)\n",
    "    \n",
    "    ss_res = np.sum((t - predictions) ** 2)\n",
    "    ss_tot = np.sum((t - np.mean(t)) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    \n",
    "    return mse, r2, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MSE: 0.506030\n",
      "   R²:  -0.058690\n"
     ]
    }
   ],
   "source": [
    "mse_inicial, r2_inicial, pred_inicial = evaluate_configuration(10, 8)\n",
    "print(f\"   MSE: {mse_inicial:.6f}\")\n",
    "print(f\"   R²:  {r2_inicial:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Determine con qué combinación de neuronas en las capas ocultas obtuvo el mejor modelo, el que produjo la mejor respuesta de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración (H1, H2) | MSE        | R²\n",
      "---------------------------------------------\n",
      "(10,  8)              | 0.478701 | -0.001512\n",
      "( 8,  6)              | 0.468643 | 0.019529\n",
      "(12, 10)              | 0.507578 | -0.061928\n",
      "(15,  5)              | 0.464937 | 0.027284\n",
      "( 5, 15)              | 0.545100 | -0.140429\n",
      "(20,  3)              | 0.474965 | 0.006304\n",
      "( 6, 12)              | 0.477735 | 0.000508\n",
      "( 8,  8)              | 0.526700 | -0.101935\n",
      "(14,  7)              | 0.467416 | 0.022097\n",
      "( 9,  9)              | 0.506920 | -0.060552\n",
      "(16,  4)              | 0.469940 | 0.016817\n",
      "( 7, 14)              | 0.506878 | -0.060462\n",
      "\n",
      "Best: {'config': (15, 5), 'mse': np.float64(0.46493669536636084), 'r2': np.float64(0.027283867614196988), 'predictions': array([0.34139717, 0.27120941, 0.21246285, 0.16877155, 0.1387579 ,\n",
      "       0.11909981, 0.10660484, 0.09887149, 0.09426355])}\n"
     ]
    }
   ],
   "source": [
    "configurations = [\n",
    "    (10, 8),   \n",
    "    (8, 6),    \n",
    "    (12, 10),  \n",
    "    (15, 5),   \n",
    "    (5, 15),   \n",
    "    (20, 3),   \n",
    "    (6, 12),   \n",
    "    (8, 8),    \n",
    "    (14, 7),  \n",
    "    (9, 9),    \n",
    "    (16, 4),   \n",
    "    (7, 14)    \n",
    "]\n",
    "\n",
    "print(\"Configuración (H1, H2) | MSE        | R²\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "results = []\n",
    "for hidden1, hidden2 in configurations:\n",
    "    mse_inicial, r2_inicial, pred_inicial = evaluate_configuration(hidden1, hidden2)\n",
    "    results.append({\n",
    "        'config': (hidden1, hidden2),\n",
    "        'mse': mse_inicial,\n",
    "        'r2': r2_inicial,\n",
    "        'predictions': pred_inicial,\n",
    "    })\n",
    "    print(f\"({hidden1:2d}, {hidden2:2d})              | {mse_inicial:.6f} | {r2_inicial:.6f}\")\n",
    "\n",
    "best_result = min(results, key=lambda x: x['mse'])\n",
    "print(f\"\\nBest: {best_result}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
